[
  {
    "page_content": "第 1 章 自然语言处理基础 自然语言处理（Natural Language Processing，NLP）是一个跨学科领域，它结合了计算科学、 语言学、认知科学和人工智能，主要研究能够让计算机实现与人类语言有关的各类任务的各种理论 和方法，特别是如何对计算机进行编程以处理和分析大量自然语言数据（非结构化的数据）。从科 学的角度来看，NLP 旨在对人类语言理解和产生的认知机制进行建模。从工程角度来看，NLP 关 注如何开发新颖的实际应用程序以促进计算机与人类语言之间的交互。在自然语言处理中，经常遇 到的挑战包括语音识别、口语理解、对话系统、词汇分析、句法解析、机器翻译、知识图谱、信息 检索、问题问答、情感分析、社交计算、自然语言生成和自然语言摘要等。当然，自然语言处理工 作也是计算机科学中极其困难的工作任务。语言本身存在着各种各样的问题，亦因语言而异。 幸运的是，最近几年深度学习领域获得快速发展，使得深度学习算法在诸如图像分类、语音识 别、文本生成、机器翻译等诸多带有很强挑战性的工作任务中表现优异，加速了深度学习与 NLP 各工作任务的深度融合，从而使得自然语言处理领域焕发出新的活力。而在深度学习被广泛应用的 过程中，出现了多种技术框架，其中 TensorFlow 是目前最直观、最有效的深度学习框架之一。本 书重点探讨如何利用 TensorFlow 深度学习框架去实现 NLP 的各种任务，例如句子分类、文档分类、 文本生成、图像字幕自动生成、机器翻译、智能问答等。 在本章中，我们将要对于自然语言处理基础有一个初步了解，并对 NLP 的主要工作任务做一 个划分；然后我们将对 NLP 领域的三个发展浪潮做详细解读，并对当前 NLP 领域中深度学习的局 限性进行剖析；最后，我们还会对于 NLP 的应用场景和应用前景做个简要阐述。 2 | TensorFlow 与自然语言处理应用 1.1 认识自然语言处理 根据《2017 微信数据报告》显示，每天会有 380 亿条信息从微信上发出，如果按照每条信息 都是文字“你吃饭了么”计算，通过微信发送的信息每天的数据量在 350GB 以上（一个汉字占 2 字节，1024 字节=1KB）。而实际的数据量会更多，因为这些信息会有不少语音、动画表情、图片、 小视频等。其实，在实际工作中，我们每天都在处理的电子邮件、各类报告文档等同样也在以惊人 的速度充斥着整个网络环境。2018 年 6 月，据科技公司 Domo 预测，到 2020 年，世界上每人每 天将产生超过 140GB 的数据，并且随着物联网的迅猛发展，这个数字将会继续扩大。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 0
    }
  },
  {
    "page_content": "的速度充斥着整个网络环境。2018 年 6 月，据科技公司 Domo 预测，到 2020 年，世界上每人每 天将产生超过 140GB 的数据，并且随着物联网的迅猛发展，这个数字将会继续扩大。 正是由于这些统计数据的存在，才使得我们为界定 NLP 提供了良好的基础。简而言之，NLP 的目标就是让机器拥有真正理解人类语言并以与人类相同的方式处理它的能力。如今，NLP 的应 用已经广泛存在，就像我们日常生活中常用到的虚拟助手（VA），常见的有百度语音助手、讯飞 语音助手、Google 智能助理、微软的个人智能助理小娜（Cortana）、苹果系统的 Siri 等，这些虚 拟助手主要是 NLP 系统在运行。比如，你告诉语音助手“请告诉我附近好吃的麻辣烫在哪儿？” 首先，VA 需要将你的声音转换为文本（语音到文本）。接下来，VA 必须理解你请求的语义（例 如，你正在寻找带有麻辣烫美食且好吃的餐厅）并制定结构化请求（例如，美食=麻辣烫，评级= 3-5， 距离<３公里）。然后，VA 必须按位置和菜肴两个条件搜索并筛选出餐厅，再按收到的评级对餐 厅进行排序。为了计算餐厅的整体评级，良好的 NLP 系统可以查看每个用户提供的评级和文本描 述。最后，用户到达餐厅，VA 还可以将各种菜品组合的受欢迎程度进行综合推荐，以此来帮助你 做出更好的选择。这个例子表明 NLP 已成为人类生活中不可或缺的一部分。 1.2 自然语言处理方面的任务 NLP 其实有许多实际的应用，而一个好的 NLP 系统会执行多个任务系统。比如，上面提到的 你要在当前位置选择麻辣烫小吃店的例子，其实就是在执行多个 NLP 任务系统。关于 NLP 的任务， 主要有以下几类： (cid:2) 标记化：标记化是将文本语料库分离为原子单元（例如，单词）的任务。虽然看似微不 足道，但是标记化却是一项非常重要的工作任务。例如，在日语中，单词不以空格或标 点符号分隔。 (cid:2) 词义消歧（Word-sense Disambiguation，WSD）：词义消歧是识别单词正确含义的任务。 例如，有两个句子，“你提供的图真好看”和“你图啥？”，其中“图”就有两种不同 的含义。词义消歧对于诸如问答之类的任务至关重要。 (cid:2) 命名实体识别（Named Entity Recognition，NER）：NER 尝试从给定的文本主体或文本 语料库中提取实体（例如，人、位置和组织）。例如，有一个句子，“林阿姨昨天在小 区 门 口 给 了 小 明 两 瓶 牛 奶 ” ， 将 被 转 换 为 林阿姨 位置 给 了 时间 在 小区门口 昨天 人 第 1 章 自然语言处理基础 | 3 小明 两瓶 人",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 1
    }
  },
  {
    "page_content": "时间 在 小区门口 昨天 人 第 1 章 自然语言处理基础 | 3 小明 两瓶 人 数量牛奶。NER 是信息检索和知识表示等领域的一个重要课题。 (cid:2) 词性（Part-of-Speech，PoS）标注：是词汇基本的语法属性，通常也称为词类，既可以 是名词、动词、形容词、副词、介词等基本标签，也可以是诸如专有名词、普通名词、 短语动词等。词性标注就是在给定句子中判定每个词的语法范畴，确定其词性并加以标 注的过程，是中文信息处理面临的重要基础性问题，主要可以分为基于规则和基于统计 的方法。 (cid:2) 句子/概要分类：句子或概要（例如，电影评论）分类有许多用例，例如垃圾邮件检测、 新闻文章分类（诸如政治、科技和体育等）和产品评论评级（正面或负面）。这是通过 训练带标签的数据（由人类注释的评论，带有积极或消极的标签）来训练分类模型实现 的。 (cid:2) 文本生成：在文本生成中，学习模型（例如，神经网络）使用文本语料库（大量文本文 档集合）进行训练，预测随后的新文本。例如，文本生成可以通过使用现有的小说故事 文本进行训练来输出一个全新的小说故事文本。当然，具体的实现过程会涉及具体模型 的实施，具有一定的复杂性。本书第 8 章将专门针对文本生成做详细解读。 (cid:2) 问答（QA）系统：QA 技术具有很高的商业价值，因为这些技术是聊天机器人和 VA（例 如谷歌 Assistant 和苹果 Siri）实现的基础所在。聊天机器人已经被许多公司用于客户支持 工作。聊天机器人可以用来回答和解决客户直接关心的问题，而不需要人工干预。QA 涉 及 NLP 的许多方面，比如信息检索和知识图谱中的知识表示。因此开发 QA 系统变得更 加具有挑战性。 (cid:2) 机器翻译：是将一个句子/短语从源语言（如汉语）转换为目标语言（如英语）的任务。 这是一个非常具有挑战性的任务，因为不同的语言具有高度不同的形态结构，这意味着 它不是一对一的转换。此外，语言之间的字对字关系可以是一对多、一对一、多对一或 多对多。这在 MT 文献中被称为单词对齐问题。 为了开发一个可以帮助人们完成日常任务的系统（例如，VA 或聊天机器人），这些任务中的 许多工作需要放在一起执行。正如我们在前面的例子中看到的那样，“请告诉我附近好吃的麻辣烫 在哪儿？”需要完成几个不同的 NLP 任务，例如语音到文本转换、语义和情感分析、问题回答和 机器翻译。在图 1.1 中，我们提供了不同 NLP 任务的层次分类。我们首先有两大类任务：分析（分 析现有文本）和生成（生成新文本）任务。然后将分析分为三类：句法（基于语言结构的任务）、 语义（基于意义的任务）和语用（难以解决的开放问题），如图 1-1 所示。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 2
    }
  },
  {
    "page_content": "在哪儿？”需要完成几个不同的 NLP 任务，例如语音到文本转换、语义和情感分析、问题回答和 机器翻译。在图 1.1 中，我们提供了不同 NLP 任务的层次分类。我们首先有两大类任务：分析（分 析现有文本）和生成（生成新文本）任务。然后将分析分为三类：句法（基于语言结构的任务）、 语义（基于意义的任务）和语用（难以解决的开放问题），如图 1-1 所示。 目前，我们对于自然语言处理及其各种任务分类有了一定的了解，下面我们将探讨一下 NLP 的起源、发展及现状。 4 | TensorFlow 与自然语言处理应用 图 1-1 广义范畴下的 NLP 主要任务分类 1.3 第一阶段：偏理论的理性主义 NLP 研究的第一次浪潮持续了很长一段时间，可以追溯到 20 世纪 50 年代。1950 年，阿兰·图 灵提出了图灵测试来评估计算机展示与人类无法区分的智能行为的能力（图灵，1950）（注意：本 书这种“人名，年份”的说明方式用于读者必要时查阅下载资源文件，以确认参考文献的出处）。 该测试基于人和计算机之间的自然语言对话，旨在产生类似人的响应。 1954 年，Georgetown-IBM 实验展示了第一个能够将 60 多个俄语句子翻译成英语的机器翻译系统。 这些方法基于这样一种信念，即人类大脑中的语言知识是通过一般遗传而提前固定下来的，这 在 20 世纪 60 年代到 20 世纪 80 年代后期的 NLP 研究中占主导地位。这些方法被称为理性主义方 法（Church，2007）。理性主义方法在 NLP 中占有主导地位，主要是由于诺姆·乔姆斯基关于先 天语言结构的论点得到广泛接受，以及他对 N-gram 的批评（Chomsky，1957）。假设语言的关键 部分在出生时就已经扎根于大脑，作为人类遗传的一部分，理性主义方法会努力设计人工制作的规 则，将相关知识和推理机制融入智能 NLP 系统。直到 20 世纪 80 年代，最著名的 NLP 系统是基于 复杂的手写规则集的，例如模拟罗格氏（Rogerian）心理治疗师的 ELIZA 和将现实世界的信息构 造成概念本体的 MARGIE，是基于复杂的手写规则集。 这一时期大致与人工智能的早期发展相吻合，人工智能以专家知识工程为特征，行业专家根据 他们所拥有的（非常狭窄的）应用领域的知识设计了计算机程序（Nilsson，1982；Winston，1993）。 专家们使用基于细致的表示和工程学知识的符号逻辑规则来设计这些程序。这些基于知识的人工智 能系统往往通过检查“大脑”或最重要的参数，并针对每个具体情况采取适当行动，从而有效地解 决特定领域的问题。这些“大脑”参数由人类专家提前确定，使“尾部”参数和案例保持不变。由",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 3
    }
  },
  {
    "page_content": "他们所拥有的（非常狭窄的）应用领域的知识设计了计算机程序（Nilsson，1982；Winston，1993）。 专家们使用基于细致的表示和工程学知识的符号逻辑规则来设计这些程序。这些基于知识的人工智 能系统往往通过检查“大脑”或最重要的参数，并针对每个具体情况采取适当行动，从而有效地解 决特定领域的问题。这些“大脑”参数由人类专家提前确定，使“尾部”参数和案例保持不变。由 第 1 章 自然语言处理基础 | 5 于缺乏学习能力，很难将其解决方案推广到新的场景和领域。在此期间的典型方法是专家系统，例 如模拟人类专家决策能力的计算机系统。这种系统旨在通过推理知识来解决复杂问题（Nilsson， 1982）。第一个专家系统创建于 20 世纪 70 年代，而后在 20 世纪 80 年代兴起。使用的主要“算法” 是“if-then-else”形式的推理规则（Jackson，1998）。这些第一代人工智能系统的主要优势在于其 执行逻辑推理（有限的）能力的透明性和可解释性。就像 ELIZA 和 MARGIE 这样的 NLP 系统一 样，早期的专家系统使用人工制作的专家知识库，这些知识在某些特定的问题中往往是有效的，尽 管推理机制不能处理实际应用中普遍存在的不确定性。 对于语音识别的研究和系统设计，NLP 和人工智能面临的一个长期挑战是在很大程度上需要 依赖于专家知识工程的范式，正如 Church 和 Mercer （Church 和 Mercer，1993）所分析的那样。 在 20 世纪 70 年代和 80 年代初期，语音识别的专家系统方法非常受欢迎（Reddy，1976；Zue，1985）。 然而，研究人员敏锐地认识到该阶段缺乏从数据中学习和处理推理中不确定性的能力，继而出现接 下来描述的第二阶段语音识别、NLP 和人工智能。 1.4 第二阶段：偏实践应用的经验主义 该阶段 NLP 的特点是通过数据语料库和（浅）机器学习、统计或其他方法来使用数据样本 （Manning 和 Schtze，1999）。由于自然语言的大部分结构和理论被数据驱动的方法所忽视或抛弃， 所以这期间发展起来的主要方法被称为经验的（或实用的）方法（Church and Mercer，1993；Church， 2014）。随着机器可读数据可用性的增加和计算能力的不断提高，从 1990 年开始，经验方法一直 主导着 NLP。其中一个主要的 NLP 会议甚至被命名为“自然语言处理中的经验方法（EMNLP）”， 以最直接地反映出 NLP 研究人员在该阶段对经验方法的强烈（积极）倾向性。 与理性主义方法相反，经验方法假设人类思维只从联想、模式识别和概括的一般操作着手。为",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 4
    }
  },
  {
    "page_content": "与理性主义方法相反，经验方法假设人类思维只从联想、模式识别和概括的一般操作着手。为 了使得大脑更好地学习自然语言的详细结构，需要存在丰富的感官输入才可以。自 1920 年以来， 经验主义在人口学中普遍存在，自 1990 年以来经验主义也一直在复苏。早期的 NLP 经验方法侧重 于开发生成模型，如隐马尔可夫模型（HMM）（Baum 和 Petrie，1966）、IBM 翻译模型（Brown 等，1993）和脑部驱动的解析模型（Collins，1997）从大型语料库中发现语言的规律性。自 20 世 纪 90 年代末以来，判别模型已成为各种 NLP 任务中实用的方法。NLP 中的代表性判别模型和方 法包括最大熵模型（Ratnaparkhi，1997）、支持向量机（Vapnik，1998）、条件随机场（Lafferty 等，2001）、最大互信息和最小分类误差（He 等，2008）和感知器（Collins，2002）。 同样，NLP 中的经验主义时代与人工智能以及语音识别和计算机视觉中的方法相对应。这是 因为有明确的证据表明，学习和感知能力对于复杂的人工智能系统至关重要，但在前一波流行的专 家系统中却缺失了。例如，当 DARPA 开启其首次自动驾驶大挑战时，大多数车辆依赖于基于知识 的人工智能范式。与语音识别和 NLP 非常相似，自动驾驶和计算机视觉研究人员立即意识到基于 知识范式的局限性，因为机器学习必须具有不确定性处理和泛化能力。 NLP 中的经验主义和第二阶段中的语音识别是基于数据密集型的机器学习，我们现在称之为 “浅层”机器学习，因为这里通常会缺少由多层或“深层”数据表示构成的抽象，第三阶段深度学 6 | TensorFlow 与自然语言处理应用 习方面将在后面继续开展。在机器学习中，研究人员无须关注构建第一阶段期间基于知识的 NLP 和语音系统所需的精确度和正确规则。他们关注统计模型（Bishop，2006；Murphy，2012）或简 单的神经网络（Bishop，1995）作为潜在引擎。然后，他们使用充足的训练数据自动学习或“调整” 引擎的参数，以使它们处理不确定性，并尝试从一个场景推广到另一个场景，从一个域到另一个域。 用于机器学习的关键算法和方法包括 EM、贝叶斯网络、支持向量机、决策树及用于神经网络的反 向传播算法。 现在回过头来看，基于机器学习的 NLP、语音识别和其他人工智能系统，比早期的基于知识 的对应部分表现更佳。诸如一些成功的例子，包括机器知觉中的几乎所有人工智能任务——语音识",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 5
    }
  },
  {
    "page_content": "用于机器学习的关键算法和方法包括 EM、贝叶斯网络、支持向量机、决策树及用于神经网络的反 向传播算法。 现在回过头来看，基于机器学习的 NLP、语音识别和其他人工智能系统，比早期的基于知识 的对应部分表现更佳。诸如一些成功的例子，包括机器知觉中的几乎所有人工智能任务——语音识 别（Jelinek，1998）、人脸识别（Viola 和 Jones，2004）、视觉对象识别（Fei-Fei 和 Perona，2005）、 手写识别（Plamondon 和 Srihari，2000）和机器翻译（Och，2003）。 具体来看，针对机器翻译应用方面，传统方法还是以统计方法主，我们也会在本书的第 11 章 对机器翻译部分做详细解读 双语训练数据中句子级对齐的可用性使得不通过规则而是直接从数据中获得表层翻译成为可 能，代价是丢弃或忽略自然语言中的结构化信息。当然，在本阶段的后续发展中，机器翻译的质量 也得到了显著提升（Och 和 Ney，2002；Och，2003；Chiang，2007；He 和 Deng，2012），但还 是没有达到现实世界中大规模部署的水平（后续深度学习阶段将会继续探讨）。 在 NLP 的对话和口语理解领域，这个经验主义时代也以数据驱动的机器学习方法为显著标志， 这些方法非常适合于定量评价和具体可交付成果的要求。他们关注的是文本和域的更广泛但肤浅的 表层覆盖，而不是对高度受限的文本和域的详细分析。我们训练数据的目的，不是从对话系统中设 计出有关语言理解和动作反映方面的规则，而是从数据样本中自动学习（浅层）统计或神经模型方 面的参数。这种学习有助于降低人工制作复杂对话管理器的设计成本，并有助于提高整体口语理解 和对话系统中语音识别错误的鲁棒性水平（He 和 Deng，2013）。具体来看，对话系统中对话策略 部分，在本阶段引入了基于马尔科夫决策过程的强化学习，有关评论，可以参阅 Young 等人的文 章（Young 等，2013）。在口语理解方面，主要方法从第一阶段基于规则或模板的方法转移到生成 模型，如隐马尔科夫模型（HMMs）（Wang 等，2011），再到判别模型，如条件随机场（Tur 和 Deng，2011）。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 6
    }
  },
  {
    "page_content": "同样，在语音识别领域，从 20 世纪 80 年代早期到 2010 年左右，该领域主要由机器学习（浅） 范式主导，使用基于与高斯混合模型集成的 HMM 的统计生成模型，以及不同版本的泛化方面 （Baker 等，2009；Deng 和 O’Shaughnessy，2003；Rabiner 和 Juang，1993）。广义 HMMs 的许多 版本是基于统计和神经网络的隐藏动态模型（Deng，1998；Bridle 等，1998；Deng 和 Yu，2007)。 前者采用 EM 和扩展卡尔曼滤波算法来学习模型参数（Ma 和 Deng，2004；Lee 等，2004）；后者 使用了反向传播（Picone 等，1999）。它们都广泛地利用了多个潜在的表示层来生成语音波形，遵 循人类语音感知中长期存在的通过合成进行分析的框架。更重要的是，将这种“深层”生成过程转 化为端到端判别过程的对应，引起了深度学习第一次在工业上的成功（Deng 等，2010，2013；Hinton 等，2012），形成了第三阶段的语音识别和 NLP 的驱动力，接下来我们将对此进行阐述。 第 1 章 自然语言处理基础 | 7 1.5 第三阶段：深度学习阶段 虽然在第二阶段开发的 NLP 系统，包括语音识别、语言理解和机器翻译，比第一阶段开发系 统的表现更好，具有更高的鲁棒性，但它们远未达到人类级别的水平，还有很多地方需要改进。除 了少数例外，NLP 的（浅）机器学习模型通常没有足够大的容量来吸收大量的训练数据。此外， 涉及的这些学习算法、方法和基础结构不够强大。所有这一切都在几年前发生了很大变化，由于深 层结构化机器学习或深层学习的新范式推动（Bengio，2009；Deng 和 Yu，2014；LeCun 等，2015； Goodfellow 等，2016），引发了 NLP 的第三波浪潮。 在传统的机器学习中，由于特征是由人设计的，需要大量的人类专业知识，显然特征工程也存 在一些瓶颈。同时，相关的浅层模型缺乏表示能力，因此缺乏形成可分解抽象级别的能力，这些抽 象级别在形成观察到的语言数据时将自动分离复杂的因素。深度学习的进步是当前 NLP 和人工智 能拐点背后的主要推动力，并且直接推动了神经网络的复兴，包括商业领域的广泛应用（Parloff， 2016）。 进一步讲，尽管在第二次浪潮期间开发的许多重要的 NLP 任务中，判别模型（浅层）取得了 成功，但它们仍然难以通过行业专家人工设计特征来涵盖语言中的所有规则。除了不完整性问题之 外，这种浅层模型还面临稀疏性问题，因为特征通常仅在训练数据中出现一次，特别是对于高度稀",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 7
    }
  },
  {
    "page_content": "进一步讲，尽管在第二次浪潮期间开发的许多重要的 NLP 任务中，判别模型（浅层）取得了 成功，但它们仍然难以通过行业专家人工设计特征来涵盖语言中的所有规则。除了不完整性问题之 外，这种浅层模型还面临稀疏性问题，因为特征通常仅在训练数据中出现一次，特别是对于高度稀 疏的高阶特征。因此，在深度学习出现之前，特征设计已经成为统计 NLP 的主要障碍之一。深度 学习为解决我们的特征工程问题带来了希望，其观点被称为“从头开始 NLP”（Collobert 等，2011）， 这在深度学习早期被认为是非同寻常的。这种深度学习方法利用了包含多个隐藏层的强大神经网络 来解决一般的机器学习任务，而无须特征工程。与浅层神经网络和相关的机器学习模型不同，深层 神经网络能够利用多层非线性处理单元的级联来从数据中学习表示以进行特征提取。由于较高级别 的特征源自于较低级别的特征，因此这些级别构成了概念上的层次结构。 深度学习起源于人工神经网络，可以将其视为受生物神经系统启发的细胞类型的级联模型。随 着反向传播算法的出现（Rumelhart 等，1986），从零开始训练深度神经网络在 20 世纪 90 年代受 到了广泛的关注。其实在早期，由于没有大量的训练数据，也没有适当的设计模式和学习方法，在 神经网络训练期间，学习信号在层与层之间传播时会随着层数呈指数级消失，难以调整深度神经网 络的连接权重值，尤其是循环模式。Hinton 等人最初克服了这个问题（Hinton 等，2006），使用 无监督的预训练，首先学习通常有用的特征检测器，然后通过监督学习进一步训练网络，进而对标 记数据进行分类。因此，可以使用低级表示来学习高级表示的分布。这项开创性的工作标志着神经 网络的复兴。此后各种网络架构被提出并开发出来，包括深度信念网络（deep belief networks） （Hinton 等，2006）、栈式自动编码器（stacked auto-encoders）（Vincent 等，2010）、深度玻尔 兹曼机（deep Boltzmann machines）（Hinton 和 Salakhutdinov，2012）、深度卷积神经网络（Krizhevsky 等，2012）、深度堆叠网络（deep stacking networks）（Deng 等，2012）以及深度 Q 网络（Mnih 等，2015）。2010 年以来，深度学习能够发现高维数据中复杂的结构，已成功应用于人工智能的 各种实际任务中，尤其是语音识别（Yu 等，2010；Hinton 等，2012）、图像分类（Krizhevsky 等， 8 | TensorFlow 与自然语言处理应用 2012；He 等，2016）和 NLP。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 8
    }
  },
  {
    "page_content": "8 | TensorFlow 与自然语言处理应用 2012；He 等，2016）和 NLP。 语音识别是 NLP 的核心任务之一，且它在工业 NLP 实际应用中受到深度学习很大的影响，所 以我们这里对此进行一些解读。深度学习在大规模语音识别中的工业应用在 2010 年左右开始起飞。 相关工作是由学术界和产业界合作发起的，最初的成果是在 2009 年 NIPS 语音识别和相关应用的 深度学习研讨会上发布的。这次研讨会的目的是语音深层生成模型的局限性，以及大计算、大数据 时代需要对深层神经网络进行认真研究的可能性。当时认为，使用基于对比散度学习算法 （Contrastive Divergence Learning Algorithm）的深度信念网络生成模型进行 DNNs 预处理，可以克 服 20 世纪 90 年代神经网络遇到的主要困难（Dahl 等，2011；Mohamed 等，2009）。然而，在微 软早期关于这项的研究中，人们发现，没有对比散度预训练，而是使用大量的训练数据，连同深层 神经网络，这些深层神经网络设计成具有相应的大型、上下文相关的输出层，并且经过精心的工程 设计，可以获得比当时最先进的（浅）机器学习系统显著更低的识别误差（Yu 等，2010，2011； Dahl 等，2012）。北美的其他几个主要语音识别研究小组（Hinton 等，2012 年；Deng 等，2013 年）以及随后一些海外研究小组很快就证实了这一发现。此外，还发现这两种类型系统产生的识别 错误的本质是不同的，这为如何将深度学习集成到现有的由主要参与者在语音识别中部署的高效运 行的语音解码系统提供了技术支持（Yu 和 Deng，2015；Abdel-Hamid 等，2014；Xiong 等，2016； Saon 等，2017）。如今，应用于各种形式的深层神经网络的反向传播算法被统一应用于所有当前 最先进的语音识别系统（Yu 和 Deng，2015；Amodei 等，2016；Saon 等，2017），以及所有主要 的商业语音识别系统——微软 Cortana、Xbox、Skype 翻译、亚马逊 Alexa、谷歌助理、苹果 Siri、 百度小度和 iFlyTek 语音搜索等——都基于深度学习方法。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 9
    }
  },
  {
    "page_content": "2010 年、2011 年语音识别的惊人成功预示着第三波 NLP 和人工智能的到来。随着深度学习在 语音识别领域的成功，计算机视觉（Krizhevsky 等，2012）和机器翻译（Bahdanau 等，2015）也 很快被类似的深度学习范式所取代。特别是，虽然早在 2001 年就开发了强大的词汇神经词嵌入技 术（Bengio 等，2001，Bengio 等人在 2001 年发表在 NIPS 上的文章《A Neural Probabilistic Language Model》，现在多数看到的是他们在 2003 年投到 JMLR 上的同名论文），但直到十多 年后，由于大数据的可用性和计算机更快的计算能力，它才被证明在实际大规模场景下具有真正的 价值（Mikolov 等，2013）。此外，还有大量的其他 NLP 应用，如图像字幕（Karpathy 和 Fei-Fei， 2015；Fang 等，2015；Gan 等人，2017）、视觉问答（Fei-Fei 和 Perona，2016）、语音理解（Mesnil 等，2013）、网络搜索（Huang 等，2013）和推荐系统；由于深度学习的广泛应用，也有许多非 NLP 任务，像药物发现和毒理学、客户关系管理、手势识别、医学信息学、广告、医学图像分析、 机器人、无人驾驶车辆和电子竞技游戏（例如，雅达利 Atari、Go、扑克和最新的 DOTA2）等。 在基于文本的 NLP 应用领域，机器翻译可能受到深度学习的影响最大。当前，在实际应用中 表现最佳的机器翻译系统是基于深度神经网络的模式，例如，谷歌于 2016 年 9 月宣布开发第一阶 段的神经网络机器翻译，而微软在 2 个月后发表了类似的声明。Facebook 已经致力于神经网络机 器翻译一年左右，到 2017 年 8 月，它正在全面部署。最近，谷歌发布了机器翻译领域最强的 BERT 的多语言模型。BERT 的全称是 Bidirectional Encoder Representations from Transformers，是一种预 训练语言表示的最新方法。 BERT 在机器阅读理解顶级水平测试 SQuAD1.1 中表现出惊人的成绩：两个衡量指标上全面超 第 1 章 自然语言处理基础 | 9 越人类，而且在 11 种不同 NLP 测试中同样给出了最好的成绩，其中包括将 GLUE 基准推至 80.4％ （绝对改进率 7.6％），MultiNLI 准确度达到 86.7%（绝对改进率 5.6％）等。对于机器翻译的解读， 本书也会在第 11 章进行深入探讨。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 10
    }
  },
  {
    "page_content": "第 1 章 自然语言处理基础 | 9 越人类，而且在 11 种不同 NLP 测试中同样给出了最好的成绩，其中包括将 GLUE 基准推至 80.4％ （绝对改进率 7.6％），MultiNLI 准确度达到 86.7%（绝对改进率 5.6％）等。对于机器翻译的解读， 本书也会在第 11 章进行深入探讨。 在将深度学习应用于 NLP 问题的过程中，近年来出现的两个重要技术突破是序列到序列学习 （Sutskevar 等，2014）和注意力建模（Bahdanau 等，2015）。序列到序列学习引入了一个强大的 思想，即利用循环网络以端到端的方式进行编码和解码。虽然注意力建模最初是为了解决对长序列 进行编码的困难，但随后的发展显然扩展了它的功能，能够对任意两个序列进行高度灵活的排列， 且可以与神经网络参数一起进行学习。与基于统计学习和单词\\短语的局部表示的最佳系统相比， 序列到序列学习和注意力机制的关键思想提高了基于分布式嵌入的神经网络机器翻译的性能。在这 一成功之后不久，这些概念也被成功地应用到其他一些与 NLP 相关的任务中，例如图像字幕生成 （Karpathy 和 Fei-Fei，2015；Devlin 等，2015）、语音识别（Chorowski 等，2015）、句法解析、 文本理解、问答系统等。 其实，基于神经网络的深度学习模型通常比早期开发的传统机器学习模型更易于设计。在许多 应用中，以端到端的方式同时对模型的所有部分执行深度学习，从特征提取一直到预测。促成神经 网络模型简化的另一个因素是相同模型构建的模块（例如不同类型的层）通常也可以适用于许多不 同的任务。另外，还开发了软件工具包，以便更快更有效地实现这些模型。基于这些原因，深度神 经网络现在是大型数据集（包括 NLP 任务）上的各种机器学习和人工智能任务的主要选择方法。 尽管深度学习已经被证明能够以革命性的方式对语音、图像和视频进行重塑处理，并且在许多 实际的 NLP 任务中取得了经验上的成功，在将深度学习与基于文本的 NLP 进行交叉时，但其效果 却不那么明显。在语音、图像和视频处理中，深度学习通过直接从原始感知数据中学习高级别概念， 有效地解决了语义鸿沟问题。然而，在 NLP 中，研究人员在形态学、句法和语义学上提出了更强 大的理论和结构化模型，提炼出了理解和生成自然语言的基本机制，但这些机制与神经网络并不容 易兼容。与语音、图像和视频信号相比，从文本数据中学习到的神经表征似乎不能同样直接洞察自 然语言。因此，将神经网络特别是具有复杂层次结构的神经网络应用于 NLP，近年来得到了越来 越多的关注，也已经成为 NLP 和深度学习社区中最活跃的领域，并取得了显著的进步（Deng，2016； Manning 和 Socher，2017）。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 11
    }
  },
  {
    "page_content": "易兼容。与语音、图像和视频信号相比，从文本数据中学习到的神经表征似乎不能同样直接洞察自 然语言。因此，将神经网络特别是具有复杂层次结构的神经网络应用于 NLP，近年来得到了越来 越多的关注，也已经成为 NLP 和深度学习社区中最活跃的领域，并取得了显著的进步（Deng，2016； Manning 和 Socher，2017）。 1.6 NLP 中深度学习的局限性 目前，尽管深度学习在 NLP 任务中取得了巨大的成功，尤其是在语音识别/理解、语言建模和 机器翻译方面，但目前仍然存在着一些巨大的挑战。目前基于神经网络作为黑盒的深度学习方法普遍 缺乏可解释性，甚至是远离可解释性，而在 NLP 的理论阶段建立的“理性主义”范式中，专家设计的 规则自然是可解释的。在现实工作任务中，其实是迫切需要从“黑盒”模型中得到关于预测的解释， 这不仅仅是为了改进模型，也是为了给系统使用者提供有针对性的合理建议（Koh 和 Liang，2017）。 在许多应用中，深度学习方法已经证明其识别准确率接近或超过人类，但与人类相比，它需要 更多的训练数据、功耗和计算资源。从整体统计的角度来看，其精确度的结果令人印象深刻，但从 10 | TensorFlow 与自然语言处理应用 个体角度来看往往不可靠。而且，当前大多数深度学习模型没有推理和解释能力，使得它们容易遭 受灾难性失败或攻击，而没有能力预见并因此防止这类失败或攻击。另外，目前的 NLP 模型没有 考虑到通过最终的 NLP 系统制定和执行决策目标及计划的必要性。当前 NLP 中基于深度学习方法 的一个局限性是理解和推理句子间关系的能力较差，尽管在句子中的词间和短语方面已经取得了巨 大进步。 目前，在 NLP 任务中使用深度学习时，虽然我们可以使用基于（双向）LSTM 的标准序列模 型，且遇到任务中涉及的信息来自于另外一个数据源时可以使用端到端的方式训练整个模型，但是 实际上人类对于自然语言的理解（以文本形式）需要比序列模型更复杂的结构。换句话说，当前 NLP 中基于序列的深度学习系统在利用模块化、结构化记忆和用于句子及更大文本进行递归、树 状表示方面还存在优化的空间（Manning，2016）。 为了克服上述挑战并实现 NLP 作为人工智能核心领域的更大突破，有关 NLP 和深度学习研究 人员需要在基础研究和应用研究方面做出一些里程碑式的工作。 1.7 NLP 的应用场景 目前，随着自然语言处理领域研究越来越深入，其应用的行业越来越广。比如在文本和语音方 面的应用。其中，我们可以看到 NLP 在文本方面的应用有基于自然语言理解的智能搜索引擎和智 能检索、智能机器翻译、自动摘要与文本综合、文本分类与文件整理、智能自动作文系统、智能判",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 12
    }
  },
  {
    "page_content": "人员需要在基础研究和应用研究方面做出一些里程碑式的工作。 1.7 NLP 的应用场景 目前，随着自然语言处理领域研究越来越深入，其应用的行业越来越广。比如在文本和语音方 面的应用。其中，我们可以看到 NLP 在文本方面的应用有基于自然语言理解的智能搜索引擎和智 能检索、智能机器翻译、自动摘要与文本综合、文本分类与文件整理、智能自动作文系统、智能判 卷系统、信息过滤与垃圾邮件处理、文学研究与古文研究、语法校对、文本数据挖掘与智能决策以 及基于自然语言的计算机程序设计等。在语音方面的应用有机器同声传译、智能远程教学与答疑、 语音控制、智能客户服务、机器聊天与智能参谋、智能交通信息服务（ATIS）、智能解说与体育 新闻实时解说、语音挖掘与多媒体挖掘、多媒体信息提取与文本转化以及对残疾人智能帮助系统等。 下面我们给出一些常见的应用场景。 1．搜索引擎 在搜索引擎中，我们常常使用词义消歧、指代消解、句法分析等自然语言处理技术，以便更好 地为用户提供更加优质的服务。因为我们的搜索引擎不仅仅是为用户提供所寻找的答案，还要做好 用户与实体世界连接的贴心服务。搜索引擎最基本的模式就是自动化地聚合足够多的信息，对之进 行解析、处理和组织，响应用户的搜索请求并找到对应结果再返回给用户。这里涉及的每一个环节， 都需要用到自然语言处理技术。例如，我们日常生活中使用百度搜索“天气”“XX 公交线路”“火 车票”等这样略显模糊的需求信息，一般情况下都会得到满意的搜索结果。自然语言处理技术在搜 索引擎领域中有了更多的应用，才使得搜索引擎能够快速精准地返回给用户所要的搜索结果。当然， 另一方面，正是谷歌和百度这样 IT 巨头商业上的成功，推进了自然语言处理技术的不断进步。 2．推荐系统 早在 1992 年 Goldberg 就首次给出了一个推荐系统：Tapestry。它其实只是一个个性化的邮件 推荐系统，首次提出了协同过滤的思想，利用用户的标注和行为信息对邮件进行重排序。推荐系统 第 1 章 自然语言处理基础 | 11 依赖的是数据、算法、人机交互等环节的相互配合，其中使用了数据挖掘、信息检索和计算统计学 等技术。我们使用推荐系统的目的是关联用户和一些信息，协助用户找到对其有价值的信息，且让 这些信息能够尽快呈现在对其感兴趣的用户面前，从而实现精准推荐。 推荐系统在音乐电影的推荐、电子商务产品推荐、个性化阅读、社交网络好友推荐等场景发挥 着重要的作用，美国 Netflix 中 2/3 的电影是因为被推荐而观看的，Google News 利用推荐系统提 升了 38%的点击率，Amazon 的销售中推荐占比高达 35%。 3．机器翻译",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 13
    }
  },
  {
    "page_content": "这些信息能够尽快呈现在对其感兴趣的用户面前，从而实现精准推荐。 推荐系统在音乐电影的推荐、电子商务产品推荐、个性化阅读、社交网络好友推荐等场景发挥 着重要的作用，美国 Netflix 中 2/3 的电影是因为被推荐而观看的，Google News 利用推荐系统提 升了 38%的点击率，Amazon 的销售中推荐占比高达 35%。 3．机器翻译 机器翻译是自然语言处理中最为人知的应用场景，一般是将机器翻译作为某个应用的组成部分， 例如跨语言的搜索引流等。目前以 IBM、谷歌、微软为代表的国外科研机构和企业均相继成立机 器翻译团队，专门从事智能翻译研究。例如，IBM 于 2009 年 9 月推出 ViaVoiceTranslator 机器 翻译软件，为自动化翻译奠定了基础；2011 年开始，伴随着语音识别、机器翻译技术、DNN（深 度神经网络）技术的快速发展和经济全球化的需求，口语自动翻译研究已成为当今信息处理领域新 的研究热点，Google 于 2011 年 1 月正式在其 Android 系统上推出了升级版的机器翻译服务； 微软的 Skype 于 2014 年 12 月宣布推出实时机器翻译的预览版、支持英语和西班牙语的实时翻 译，并宣布支持 40 多种语言的文本实时翻译功能。 尤其值得注意的是，在“一带一路”这一发展背景下，合作沟通会涉及 60 多个国家、53 种 语言，此时机器翻译的技术应用显得尤为重要，语言的畅通是“一带一路”倡议得以实施的重要基 础。机器翻译涉及语义分析、上下文环境等诸多挑战，其发展道路还有很长一段路要走。 4．聊天机器人 聊天机器人是指能通过聊天 App、聊天窗口或语音唤醒 App 进行交流的计算机程序，是被用 来解决客户问题的智能数字化助手，其特点是成本低、高效且持续工作。例如，Siri、小娜等对话 机器人就是一个应用场景。除此之外，聊天机器人在一些电商网站有着很实用的价值，可以充当客 服角色，例如京东客服 JIMI。有很多基本的问题，其实并不需要联系人工客服来解决。通过应用 智能问答系统，可以排除掉大量的用户问题，比如商品的质量投诉、商品的基本信息查询等程式化 问题，在这些特定的场景中，特别是会被问到高度可预测的问题中，利用聊天机器人可以节省大量 的人工成本。图 1-2 给出了一些聊天机器人产品。 5．知识图谱 知识图谱能够描述复杂的关联关系，它的应用极为广泛，最为人所知的就是被用在搜索引擎中 丰富搜索结果，并为搜索结果提供结构化结果来体现关联性，这也是谷歌提出知识图谱的初衷。同",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 14
    }
  },
  {
    "page_content": "问题，在这些特定的场景中，特别是会被问到高度可预测的问题中，利用聊天机器人可以节省大量 的人工成本。图 1-2 给出了一些聊天机器人产品。 5．知识图谱 知识图谱能够描述复杂的关联关系，它的应用极为广泛，最为人所知的就是被用在搜索引擎中 丰富搜索结果，并为搜索结果提供结构化结果来体现关联性，这也是谷歌提出知识图谱的初衷。同 时微软小冰、苹果 Siri 等聊天机器人中也加入了知识图谱的应用。IBM Watson 是问答系统中应用 知识图谱较为典型的例子。按照应用方式，可以将知识图谱的应用分为语义搜索、知识问答以及基 于知识的大数据分析和决策等。 12 | TensorFlow 与自然语言处理应用 图 1-2 部分聊天机器人示意图 语义搜索利用建立大规模知识库对搜索关键词和文档内容进行语义标注，改善搜索结果，如谷 歌、百度等在搜索结果中嵌入知识图谱。知识问答是基于知识库的问答，通过对提问句子的语义分 析，将其解析为结构化的询问，在已有的知识库中获取答案。在大数据的分析和决策方面，知识图 谱起到了辅助作用，典型应用是美国 Netflix 公司利用其订阅用户的注册信息以及观看行为构建的 知识图谱反映出英剧版《纸牌屋》很受欢迎，于是拍摄了美剧《纸牌屋》，大受追捧。知识图谱展 示如图 1-3 所示。 图 1-3 知识图谱展示图 第 1 章 自然语言处理基础 | 13 1.8 NLP 的发展前景 随着深度学习时代的来临，神经网络成为一种强大的机器学习工具，并使得自然语言处理取得 了许多突破性发展，如情感分析、智能问答、机器翻译等领域都在飞速发展。下面我们梳理一些自 然语言处理近期热点和全球热点的情况。 1．文本理解与推理：浅层分析向深度理解迈进 谷歌等公司已经推出了以阅读理解作为深入探索自然语言理解的平台。 文本理解和推理是自然语言处理的重要部分，现在的机器软件已经可以根据文本的上下文来分 辨代词等指示词，这是文本理解与推理从浅层分析向深度理解迈进的重要一步。 2．对话机器人：实用化、场景化 从最初 2012 年到 2014 年的语音助手，到 2014 年起逐渐出现的聊天机器人微软小冰、百度 小度，再到 2016 年哈尔滨工业大学 SCIR 的笨笨，对话机器人越来越智能。最初的语音助手可以 听得到但是听不懂，之后的对话机器人可以听得懂但是实用性却不强，现在对话机器人更多的是和 场景结合，即在特定场景做有用的人机对话。 3．NLP+行业：与专业领域深度结合 银行、电器、医药、司法、教育等领域对自然语言处理的需求都非常多。自然语言处理与各行",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 15
    }
  },
  {
    "page_content": "场景结合，即在特定场景做有用的人机对话。 3．NLP+行业：与专业领域深度结合 银行、电器、医药、司法、教育等领域对自然语言处理的需求都非常多。自然语言处理与各行 各业的结合越来越紧密，专业化的服务趋势逐渐增强。可以预测，自然语言处理首先会在信息准备 充分并且服务方式本身就是知识和信息的领域产生突破，例如医疗、金融、教育和司法领域。 4．学习模式：先验语言知识与深度学习结合 自然语言处理中学习模式有一个较为明显的变化。在浅层到深层的学习模式中，浅层学习是分 步骤的，深度学习的方法贯穿在浅层分析的每个步骤中，由各个步骤连接而成。而直接的深度学习 则是直接从端到端，人为贡献的知识在深度学习中所占的比重大幅度减小。但如何将深度学习应用 于自然语言处理需要进行更多的研究和探索，针对不同任务的不同字词表示，将先验知识和深度学 习相结合是未来的一个发展趋势。 5．文本情感分析：事实性文本到情感文本 之前的研究主要是新闻领域的事实性文本，现在情感文本分析更受重视，并且在商业和政府舆 情上可以得到很好的应用。例如，2017 年新浪微舆情和哈尔滨工业大学推出“情绪地图”，网民 可以登录新浪舆情官方网站查询任何关键词的“情绪地图”，这是语义情绪分析在舆情分析产业上 的首次正式应用。 14 | TensorFlow 与自然语言处理应用 1.9 总结 在本章中，为了建立本书的基本框架，我们首先解释了为什么我们需要 NLP，然后讨论了 NLP 的各类任务。对于 NLP 的来龙去脉，我们又从理性主义和经验主义到当前深层学习浪潮的三次自 然语言处理浪潮出发，回顾了自然语言处理领域几十年来的历史发展情况，以便从历史发展中提炼 出有助于指导未来方向的见解。接着，我们对于当前 NLP 中深度学习的局限性进行了解读。最后， 我们对于 NLP 中的应用场景和前景做了简述。 首先，我们通过一个日常生活中常见的寻找小吃店位置的例子开启了解读 NLP 的篇章，并对 NLP 主要的工作任务进行了初步划分，包括标记化、词义消歧、词性标注、实体命名识别、句子 或概要分类、文本生成、问答系统、机器翻译等。 其次，通过对于 NLP 发展的三个阶段的分析，我们知道当前的 NLP 深度学习技术是从前两波 发展起来的一种 NLP 技术概念和范式上的革新。这场革新的关键支撑包括通过嵌入对语言实体（子 单词、单词、短语、句子、段落、文档等）的分布式表示、嵌入引起的语义概括、语言的大跨度深 层序列建模、能够从低到高有效表达语言水平的层次网络以及端到端的深度学习方法，以共同解决",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 16
    }
  },
  {
    "page_content": "其次，通过对于 NLP 发展的三个阶段的分析，我们知道当前的 NLP 深度学习技术是从前两波 发展起来的一种 NLP 技术概念和范式上的革新。这场革新的关键支撑包括通过嵌入对语言实体（子 单词、单词、短语、句子、段落、文档等）的分布式表示、嵌入引起的语义概括、语言的大跨度深 层序列建模、能够从低到高有效表达语言水平的层次网络以及端到端的深度学习方法，以共同解决 许多 NLP 任务中的问题。在深度学习浪潮出现之前，这些都是不可能实现的，这不仅是因为之前 的两次发展浪潮缺乏大数据和强大的计算能力，更重要的是在于近年来深度学习范式出现了之前缺 少的正确框架。 接着，我们对于当前 NLP 领域深度学习方面的局限性进行了解读，并给出了局限性存在的成 因和简要的解决之道。 最后，我们对于 NLP 的常见应用领域进行了说明并给出了 NLP 的发展前景。 总之，深度学习开创了一个新的世界，使得 NLP 比过去任何时候都更具有活力。深度学习不 仅提供了一个强大的建模框架，用于表示计算机系统中人类自然语言的认知能力，更重要的是，它 已经在 NLP 的许多关键应用领域创造了卓越的实际效果。在本书的其余章节中，将提供使用深度 学习框架开发（具体利用 TensorFlow 工具）的 NLP 技术的详细描述，同时也希望本书能够对 NLP 领域的人员有一些帮助，以便使得 NLP 领域有更多突破性成果的出现。接下来的一章，我们将介 绍深度学习基础。 第 2 章 深度学习基础 2.1 深度学习介绍 具有机器学习基础的朋友可能都知道，机器学习实际上是一个寻找最优模型的过程。深度学习 是机器学习的一个扩展领域，其概念源自于科学家对人工网络长期研究的积累，深度学习的基本结 构其实也是深度神经网络。在深度学习下实现的算法集合与人类大脑中的刺激和神经元之间的关系 具有相似之处。深度学习在计算机视觉、语言翻译、语音识别、图像识别等方面具有广泛的应用。 这些算法集很简单，既可以在有监督的情况下学习，也可以在无监督的情况下学习。 大多数的深度学习算法都是基于人工神经网络的理念，数据丰富，计算资源充足，使得目前世 界上对这种算法的训练变得更加容易、深度学习模型的性能得到不断提升。对于这一点，我们可以 在图 2-1 中看到更好的表示。 图 2-1 基于神经网络的深度学习算法和传统学习算法效果图 这里深度学习中的“深度”是指人工神经网络结构的深度，而“学习”是指通过人工神经网络 16 | TensorFlow 与自然语言处理应用 本身进行学习。图 2-2 给出了深度和浅度网络之间差异的展示，以及为什么“深度学习”会受到大 家的热捧。 图 2-2 深度和浅度网络示意图",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 17
    }
  },
  {
    "page_content": "这里深度学习中的“深度”是指人工神经网络结构的深度，而“学习”是指通过人工神经网络 16 | TensorFlow 与自然语言处理应用 本身进行学习。图 2-2 给出了深度和浅度网络之间差异的展示，以及为什么“深度学习”会受到大 家的热捧。 图 2-2 深度和浅度网络示意图 通过利用深度神经网络，我们能够从未标记和非结构化数据（如图像（像素数据）、文档（文 本数据）或文件（音频、视频数据））中寻找出潜在的结构情况（或特征学习）。实际上，虽然深 度学习中的人工神经网络和模型在本质上具有相似的结构，但这并不意味着两个人工神经网络的组 合在利用数据进行训练时，我们获得的表现（或效果）与深度神经网络就相似。其中一个重要的原 因是，深度神经网络与普通人工神经网络之间所使用的反向传播方式不同。 接下来，我们先介绍一下深度学习的演变过程，然后从神经网络开始详细解读。 2.2 深度学习演变简述 2.2.1 深度学习早期 1943 年，心理学家麦卡洛克和数学逻辑学家皮兹发表了论文《神经活动中内在思想的逻辑演 算》，提出了 MP 模型。MP 模型是模仿神经元的结构和工作原理构建的一个基于神经网络的数学 模型，本质上是一种“模拟人类大脑”的神经元模型。MP 模型作为人工神经网络的起源，开创了 人工神经网络的新时代，也奠定了神经网络模型的基础。 1949 年，加拿大著名心理学家唐纳德·海布在《行为的组织》中提出了一种基于无监督学习 的规则——海布学习规则（Hebb Rule）。海布学习规则模仿人类认知世界的过程建立一种“网络 模型”，该网络模型针对训练数据集进行大量的训练并提取训练集的统计特征，然后按照样本的相 似程度进行分类，把相互之间联系密切的样本分为一类，这样就把样本分成了若干类。海布学习规 则与“条件反射”机理一致，为后面的神经网络学习算法奠定了基础，具有重大的历史意义。 20 世纪 50 年代末，在 MP 模型和海布学习规则的研究基础上，美国科学家罗森布拉特发现了 一种类似于人类学习过程的学习算法——感知机学习，并于 1958 年正式提出了由两层神经元组成 第 2 章 深度学习基础 | 17 的神经网络，称之为“感知器”。感知器本质上是一种线性模型，可以对输入的训练集数据进行二 分类，且能够在训练集中自动更新权重值。感知器的提出吸引了大量科学家对人工神经网络研究的 兴趣，对神经网络的发展具有里程碑式的意义。 随着研究的深入，在 1969 年，“AI 之父”马文·明斯基和 LOGO 语言的创始人西蒙·派珀 特共同编写了一本图书《感知器》，在书中他们证明了单层感知器无法解决线性不可分问题（例如",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 18
    }
  },
  {
    "page_content": "分类，且能够在训练集中自动更新权重值。感知器的提出吸引了大量科学家对人工神经网络研究的 兴趣，对神经网络的发展具有里程碑式的意义。 随着研究的深入，在 1969 年，“AI 之父”马文·明斯基和 LOGO 语言的创始人西蒙·派珀 特共同编写了一本图书《感知器》，在书中他们证明了单层感知器无法解决线性不可分问题（例如 异或问题）。由于这个致命的缺陷以及没有及时推广感知器到多层神经网络中，在 20 世纪 70 年代 人工神经网络进入了第一个寒冬期，人们对神经网络的研究也停滞了将近 20 年。 2.2.2 深度学习的发展 1982 年，著名物理学家约翰·霍普菲尔德发明了 Hopfield 神经网络。Hopfield 神经网络是一 种结合存储系统和二元系统的循环神经网络。Hopfield 网络也可以模拟人类的记忆，根据激活函数 的选取不同，有连续型和离散型两种类型，分别用于优化计算和联想记忆。由于容易陷入局部最小 值的缺陷，该算法并未在当时引起很大的轰动。 直到 1986 年，深度学习之父杰弗里·辛顿提出了一种适用于多层感知器的反向传播算法—— BP 算法。BP 算法在传统神经网络正向传播的基础上，增加了误差的反向传播过程。反向传播过程 不断地调整神经元之间的权重值和阈值，直到输出的误差减小到允许的范围之内，或达到预先设定 的训练次数为止。BP 算法完美地解决了非线性分类问题，让人工神经网络再次引起了人们广泛的 关注。 20 世纪 80 年代计算机的硬件水平有限，比如运算能力跟不上，导致当神经网络的规模增大时 使用 BP 算法出现“梯度消失”的问题。这使得 BP 算法的发展受到了很大的限制。再加上 20 世纪 90 年代中期，以 SVM 为代表的其他浅层机器学习算法的提出，及其在分类、回归问题上均取得了 很好的效果，其原理又明显不同于神经网络模型，所以人工神经网络的发展再次进入了瓶颈期。 2.2.3 深度学习的爆发 2006 年，杰弗里·辛顿以及他的学生鲁斯兰·萨拉赫丁诺夫正式提出了深度学习的概念。他 们在世界顶级学术期刊《科学》发表的一篇文章中详细地给出了“梯度消失”问题的解决方案—— 通过无监督的学习方法逐层训练算法，再使用有监督的反向传播算法进行调优。该深度学习方法的 提出，立即在学术圈引起了巨大的反响，以斯坦福大学、多伦多大学为代表的众多世界知名高校纷 纷投入巨大的人力、财力进行深度学习领域的相关研究，而后又迅速蔓延到工业界中。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 19
    }
  },
  {
    "page_content": "通过无监督的学习方法逐层训练算法，再使用有监督的反向传播算法进行调优。该深度学习方法的 提出，立即在学术圈引起了巨大的反响，以斯坦福大学、多伦多大学为代表的众多世界知名高校纷 纷投入巨大的人力、财力进行深度学习领域的相关研究，而后又迅速蔓延到工业界中。 2012 年，在著名的 ImageNet 图像识别大赛中，杰弗里·辛顿领导的小组采用深度学习模型 AlexNet 一举夺冠。AlexNet 采用 ReLU 激活函数，从根本上解决了梯度消失问题，并采用 GPU 极 大地提高了模型的运算速度。同年，由斯坦福大学的吴恩达教授和世界顶尖计算机专家 Jeff Dean 共同主导的深度神经网络——DNN 技术在图像识别领域取得了惊人的成绩，在 ImageNet 评测中成 功地把错误率从 26％降低到了 15％。深度学习算法在世界大赛中脱颖而出，再一次吸引了学术界 和工业界对深度学习领域的关注。 18 | TensorFlow 与自然语言处理应用 随着深度学习技术的不断进步以及数据处理能力的不断提升，2014 年，Facebook 基于深度学 习技术的 DeepFace 项目，在人脸识别方面的准确率已经能达到 97%以上，跟人类识别的准确率几 乎没有差别。这样的结果也再一次证明了深度学习算法在图像识别方面的一骑绝尘。 2016 年，随着谷歌公司基于深度学习开发的 AlphaGo 以 4:1 的比分战胜了国际顶尖围棋高手 李世石，深度学习的热度一时无两。后来，AlphaGo 又接连和众多世界级围棋高手过招，均取得了 完胜。这也证明了在围棋界，基于深度学习技术的机器人已经超越了人类。 2017 年，基于强化学习算法的 AlphaGo 升级版 AlphaGo Zero 横空出世。其采用“从零开始” “无师自通”的学习模式，以 100:0 的比分轻而易举打败了之前的 AlphaGo。除了围棋，它还精通 国际象棋等其他棋类游戏，可以说是真正的棋类“天才”。此外在这一年，深度学习的相关算法在 医疗、金融、艺术、无人驾驶等多个领域均取得了显著的成果。所以，也有专家把 2017 年看作是 深度学习甚至是人工智能发展最为突飞猛进的一年。 2.3 神经网络介绍 神经网络这个词，其实是一个非常泛的概念，有两个类别：生物神经网络和人工神经网络。生 物神经网络是研究生物学的，一般是指生物的大脑神经元、细胞、触点等组成的网络，用于产生生",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 20
    }
  },
  {
    "page_content": "医疗、金融、艺术、无人驾驶等多个领域均取得了显著的成果。所以，也有专家把 2017 年看作是 深度学习甚至是人工智能发展最为突飞猛进的一年。 2.3 神经网络介绍 神经网络这个词，其实是一个非常泛的概念，有两个类别：生物神经网络和人工神经网络。生 物神经网络是研究生物学的，一般是指生物的大脑神经元、细胞、触点等组成的网络，用于产生生 物的意识、帮助生物进行思考和行动。人工神经网络（Artificial Neural Networks，ANN）有时也称 为神经网络（NN）或连接模型（Connection Model），它是一种模仿动物神经网络的行为特征，进 行分布式并行信息处理的算法数学模型。这种网络依靠系统的复杂程度，通过调整内部大量节点之 间相互连接的关系，从而达到处理信息的目的。人工神经网络是一种应用类似于大脑神经突触联接 的结构进行信息处理的数学模型。在工程与学术界也常直接简称为“神经网络”或类神经网络。所 以，我们有必要先简要介绍一下生物神经网络中的神经元模型。 神经元 对于神经元的研究由来已久，1904 年生物学家就已经知晓了神经元的组成结构。一个神经元 通常具有多个树突，主要用来接受传入信息；而轴突只有一条，轴突尾端有许多轴突末梢可以给其 他多个神经元传递信息。轴突末梢跟其他神经元的树突产生连接，从而传递信号。这个连接的位置 在生物学上叫作“突触”。神经元的基本功能是通过接受、整合、传导和输出信息实现信息交换。 这样一来，神经元按照用途可以分为三种：输入神经、传出神经和连体神经。人脑中的神经元形状 如图 2-3 所示。 第 2 章 深度学习基础 | 19 图 2-3 人脑中的神经元形状图 2.4 神经网络的基本结构 神经网络背后的原理源自于一些基本元素组成的集合，如人工神经元或感知器（Perceptron）， 这些元素最早是由弗兰克·罗森布拉特（Frank Rosenblatt）在 20 世纪 50 年代开发的。它们有几个 二进制输入（0 或 1），x1,x2,…,xn，如果这些输入的总和大于激活电位（等同于偏差），则产生单 个二进制的输出。每当超过激活电位时，神经元被称为“激活”，并表现为一个阶跃函数（step function）。发射信号的神经元将信号传递给与其树突相连的其他神经元，如果超过激活电位，树 突就会激活信号，从而产生级联效应，如图 2-4 所示，其实这也是早期的单层神经网络（感知器）。 图 2-4 神经元样例示意图 由于并非所有输入都具有相同的重要性，因此每个输入 xi 都被分配了自己的权重值，允许模 型为某些输入指定更高的权重值。因此，若加权和大于激活电位或偏差，则输出为 1，即可以给出 输出的结果，具体如下：",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 21
    }
  },
  {
    "page_content": "图 2-4 神经元样例示意图 由于并非所有输入都具有相同的重要性，因此每个输入 xi 都被分配了自己的权重值，允许模 型为某些输入指定更高的权重值。因此，若加权和大于激活电位或偏差，则输出为 1，即可以给出 输出的结果，具体如下： (cid:2)(cid:3)(cid:4)(cid:5)(cid:3)(cid:4) (cid:6) ∑ (cid:8)(cid:2)(cid:9)(cid:2) (cid:2) (cid:10) (cid:11)(cid:12)(cid:13)(cid:14) （2.1） 实际上，阶跃函数的跳跃性质使得它具有不连续、不光滑、不可导等特点，如果利用这种简单 形式的函数，我们很难达到理想的效果，如图 2-5 所示。因此，在实际应用中，我们通常不会直接 采用阶跃函数来作为激活函数，我们需要对其进行两处修改，以使其表现得更可预测，即权重值和 偏差的微小变化仅导致输出的微小变化，这两处具体如下： 20 | TensorFlow 与自然语言处理应用 图 2-5 阶跃函数示意图 （1）输入可以取 0~1 之间的任何值，而不是二进制（0 或 1）； （2）为了使输出在给定的输入(cid:9)(cid:3), (cid:9)(cid:4), . . . , (cid:9)(cid:5)、权重值(cid:8)(cid:3), (cid:8)(cid:4), . . . , (cid:8)(cid:5)和偏差(cid:17)下更平稳地工作， 我们使用以下 Sigmoid 函数（见图 2-6）： (cid:18)(cid:19)(cid:9)(cid:6), (cid:8)(cid:6)(cid:20) (cid:6) (cid:3) (cid:3)(cid:7)(cid:8)(cid:9)(cid:10)(cid:11)(cid:12) ∑ (cid:14)(cid:2)(cid:15)(cid:2)(cid:12)(cid:16) (cid:2) (cid:17) （2.2） 图 2-6 Sigmoid 函数 指数函数（或σ）的平滑度意味着权重值和偏差的微小变化将引起神经元输出的微小变化（变 化可能是权重值和偏差变化的线性函数）。 除了通常的 Sigmoid 函数外，更常用的其他非线性函数还包括以下几个函数，它们中的每一个 都可能具有类似或不同的输出范围，因此可以相应地使用。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 22
    }
  },
  {
    "page_content": "图 2-6 Sigmoid 函数 指数函数（或σ）的平滑度意味着权重值和偏差的微小变化将引起神经元输出的微小变化（变 化可能是权重值和偏差变化的线性函数）。 除了通常的 Sigmoid 函数外，更常用的其他非线性函数还包括以下几个函数，它们中的每一个 都可能具有类似或不同的输出范围，因此可以相应地使用。 ReLU：线性整流函数（Rectified Linear Unit，ReLU），又称修正线性单元，是一种人工神经 网络中常用的激活函数（Activation Function），通常指代以斜坡函数及其变种为代表的非线性函 数。这将使激活保持在 0 位，使用以下函数计算： (cid:21)(cid:2) (cid:6) (cid:22)(cid:2)(cid:19)(cid:9)(cid:2)(cid:20) (cid:6) max(cid:19)0, (cid:9)(cid:2)(cid:20) （2.3） 其中，(cid:9)(cid:2)是第 j 个输入值，(cid:27)(cid:2)是经过 ReLU 函数 f 处理过的相应输出值。ReLU 函数的图形如图 2-7 所示，对于所有 x≤0，函数值为 0；对于所有 x> 0，函数线性斜率为 1。 第 2 章 深度学习基础 | 21 图 2-7 ReLU 函数 ReLU 经常面临着“死亡”的问题，特别是当学习率被设置为更高的数值时，因为这会触发不 允许激活特定神经元的权重值更新，从而使该神经元的梯度永远为零。 ReLU 提供的另一个风险 是激活函数的爆炸，因为输入值(cid:9)(cid:2)本身就是输出。ReLU 也存在不少优点，例如在(cid:9)(cid:2)低于 0 的情况 下引入稀疏性，引起稀疏表示，并且当 ReLU 不变时返回梯度，它会导致更快的学习，伴随着梯度 消失的可能性会降低。 下面给出其他几个常见的函数，这些函数能够使我们很容易对梯度下降进行训练，具体如下： (cid:2) LReLU（Leaky ReLU）：通过为 x 小于 0 的值引入略微减小的斜率（约 0.01）来减轻 ReLU 死亡的问题，LReLU 确实提供了很多成功的场景，尽管有时也会出错。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 23
    }
  },
  {
    "page_content": "下面给出其他几个常见的函数，这些函数能够使我们很容易对梯度下降进行训练，具体如下： (cid:2) LReLU（Leaky ReLU）：通过为 x 小于 0 的值引入略微减小的斜率（约 0.01）来减轻 ReLU 死亡的问题，LReLU 确实提供了很多成功的场景，尽管有时也会出错。 (cid:2) ELU（指数线性单位）：它们提供负值，通过将附近的梯度移动到单位自然梯度，将平 均 单 位 激 活 推 至 接 近 零 ， 从 而 加 快 学 习 过 程 。 有 关 ELU 更 详 细 的 解 释 ， 请 参 阅 Djork-ArnéClevert 的原始论文，网址为 https://arxiv.org/abs/1511.07289。 softmax：也被称为归一化指数函数，它转换（0,1）范围内的一组给定实值，使得组合和 为 1。softmax 函数表示如下： (cid:2) (cid:18)(cid:19)(cid:27)(cid:20)(cid:2) (cid:6) (cid:28) (cid:18)(cid:19) ∑ ⁄ (cid:19) (cid:19)(cid:20)(cid:3) (cid:28) (cid:18)(cid:19) （2.4） 这里，(cid:30) (cid:6) 1,2, . . . , !。 与哺乳动物大脑一样，单个神经元也是分层组织的，在一层内与下一层相连，形成一个 ANN 或者说人工神经网络或多层感知器（MLP）。这样，整个网络的复杂性就是基于这些元素和连接 相邻层的数量情况。 输入和输出之间的层称为隐藏层，层之间的连接密度和类型是结构（也叫配置）。例如，一个 完全连接的结构将 L 层的所有神经元连接到 L+1 层的所有神经元。若要具有更明显的结构，我们 只能将一个局部邻域连接到下一层。图 2-8 显示了两个具有密集连接的隐藏层。 22 2 | T Tens sorF Flow w 与 与自 然语 语言 言处理 理应 应用 图 2- 图 8 神 神经 经网络 络架构 构示 图 示例图 两层 两 层神 经 神经 2 .5 述 简述 简 络 网络 网 （多 多层 感 层感 感知 知器 器） 2. .5. 1 两层 两 用 。 大家 大 可 以解 解决 因 为没 没有 神经 经网 络是 是本 文的 的重 点， 因为 为正 是从 从两 两层结 结构 构为起 起点 神经 经网 络才 才开 开始了 了大",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 24
    }
  },
  {
    "page_content": "经 神经 2 .5 述 简述 简 络 网络 网 （多 多层 感 层感 感知 知器 器） 2. .5. 1 两层 两 用 。 大家 大 可 以解 解决 因 为没 没有 神经 经网 络是 是本 文的 的重 点， 因为 为正 是从 从两 两层结 结构 构为起 起点 神经 经网 络才 才开 开始了 了大 范围 围的 的推广 广与 与使 知道 道，单 单层 层神经 经网 网络无 无法 法解决 决异 异或 问题 题，但 但是 是当增 增加 加一个 个计 计算层 层以 以后， 两 层神 神经 经网络 络不 不仅 异或 或问 题， 而且 且具 有非 非常 好的 的非 线性 性分 分类效 效果 一个 个较 好的 的解 法。 。不 过， 两层 层神 神经网 网络 络的计 计算 则是 是一 一个问 问题 题， 1 986 年， ，Ru ume elhar r 和 Hin nton 等人 人提 提出了 了反 反向传 传播 的问 问题 ，从 从而带 带动 动了业 业界 播（B 界使用 Back 用两 kpro 两层神 pag 神经 atio 经网络 n，B 络研 BP） 研究 ）算 算法， 解 解决了 了两 两层 的热 热潮。 。目 目前， ，大 大量 本都 都是 以介 介绍 两层 层（ 带一 一个 隐藏 藏层 ）神 神经 经网络 络为 重点 点。 的 H Hint ton 还 还很 很年轻 轻， 30 年以 以后 ，正 正是 是他重 重新 新定义 义了 神经 经网 络， 带来了 带 了神 经网 网络 络复苏 苏的 的又 所需 需要 的复 复杂 网络 络的 教材 材之 计算 算量 内容 容基 神 经网 网络 讲 解神 神经 当时 当 一 波发 发展 浪潮 潮。 2. .5.2 2 两层 两 层神 神经 经网 络 构 结构 两层 两 输 出层 层都 现在 现 例如 例 ，我 的权 我们 (cid:3)代 代表第 (cid:2)(cid:2) ，(cid:2) 神经 经网 络除 除了 包含 含一 个输 输入 层和 和一 个输 输出 层以 以外 ，还 还增加 加了 了一个 个中 中间层 层。 此时 时， 中间 间层 层和 是计 计算 层。 我 我们扩 扩展",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 25
    }
  },
  {
    "page_content": "出层 层都 现在 现 例如 例 ，我 的权 我们 (cid:3)代 代表第 (cid:2)(cid:2) ，(cid:2) 神经 经网 络除 除了 包含 含一 个输 输入 层和 和一 个输 输出 层以 以外 ，还 还增加 加了 了一个 个中 中间层 层。 此时 时， 中间 间层 层和 是计 计算 层。 我 我们扩 扩展 上节 节的 单层 层神 经网 网络 络，在 在右 边新 新加 一个 个层 权重 值矩 矩阵 增加 加到 了两 两个 ，我 我们 用上 上标 来区 区分 不同 同层 次。 次之 之间 的变 变量 。 第(cid:2)层 层中 中的第 第(cid:2)个 个节 节点。 。(cid:2)(cid:2) (cid:2), (cid:3)(cid:3)变 变成 成了 (cid:2)。 (cid:3), (cid:2) (cid:2)(cid:2) (cid:2)(cid:2) 图 2-9 9 给 出了 (cid:3), , (cid:3)(cid:2) 了(cid:2)(cid:2) (cid:2)的 的计 计算公 公式 式。 第 2 第 章 深 深度学 学习 基础 础 | 2 23 图 图 2-9 9 两 两层神 神经 经网络 络（中 中间 间层计 ） 计算） 计算 计 最终 终输 出 z z 的方 方式 式是利 利用 用了中 中间 间层的 (cid:2)和第 (cid:3) (cid:3), (cid:3)(cid:3) 的(cid:2)(cid:2) (cid:2) (cid:2) 第二 二个权 权值 值矩阵 阵计 计算得 得到 到的， ，如图 图 2 2-10 图 2-10 0 两 两层 层神经 经网络 络（ 输出 出层计 计算 算） 假设 假 我们 们的 预测 测目 标是 是一 个向 向量 ，那 那么 与前 前面 面类似 似， 只需 需要 在“ “输 输出层 层” 再增 增加 节点 点即 所示 示。 可。 2.6 2 6 述 简述 简 2. .6. 1 多 多 层神 层 神经 经网 络 网络 （深 （ 深度 度学 习 学习 ） 人工 人 神经 经网 络在 在被 人摒 摒弃 的 1 10 年 年中 ，有 有几 几个学 学者 者仍然 然在 坚持 持研 研究，",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 26
    }
  },
  {
    "page_content": "再增 增加 节点 点即 所示 示。 可。 2.6 2 6 述 简述 简 2. .6. 1 多 多 层神 层 神经 经网 络 网络 （深 （ 深度 度学 习 学习 ） 人工 人 神经 经网 络在 在被 人摒 摒弃 的 1 10 年 年中 ，有 有几 几个学 学者 者仍然 然在 坚持 持研 研究， 其中的 其 的典 型代 代表 表就是 是加 加拿 大 多伦 伦多 大学 学的 Geo offe ery H Hinto on 教 教授 授。 2 006 年 ，H Hinto on 在 在《 Scie ence e》和 和相 关期 期刊 上发 发表 表了论 论文 ，首 首次 次提出 出了 “深 深度 信念 念网 络” ”的 的概 24 4 | T Tens sorF Flow w 与 与自 然语 语言 言处理 理应 应用 念 。与 与传 传统的 的训 练方 方式 式不同 同， “深 深度 度信念 念网 网络” ”有 有一个 个“ “预训 训练 练” 权重 重值 值找到 到一 个接 接近 最优 优解 解的值 值，之 之后 后再使 使用 训练 练。这 这两 两个技 技术 术的运 运用 用大幅 幅度 度减少 少了 了训练 练多 多层神 神经 经网络 （Pr 用“微 re-T 微调 Train 调” ning （Fin 络的 ）的 的过 程， 可以 可 ne-T 的时间 Tuni 间。 ing） 他给 ）技 技术 给多 层 神经 经网 络中 中的 网络 络进 行优 优化 方 便地 地让 来 对整 整个 神 经网 网络 相关 关的 学习 习方 法赋 赋予 了一 一个 新名 名词 —— —“ “深度 度学 学习” ”。 很快 很 ，深 深度 学习 习在 语音 音识 识别领 领域 崭露 露头 角。 接着， 接 与他 他的学 学生 。H 图片 Hinto 片进 on 与 行了 了训 练， 生在 I 得了 取 Imag 了分 geN 类错 Net 竞 错误 竞赛 赛中用 用多 率 1 优越 15% 越性 %的好 性。 分证 证明 了多 多层 之后 后， 关于 于深 神经 经网 度神 神经 络识 识别 效果 果的 网络 络的 研究 究与 应用",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 27
    }
  },
  {
    "page_content": "学生 。H 图片 Hinto 片进 on 与 行了 了训 练， 生在 I 得了 取 Imag 了分 geN 类错 Net 竞 错误 竞赛 赛中用 用多 率 1 优越 15% 越性 %的好 性。 分证 证明 了多 多层 之后 后， 关于 于深 神经 经网 度神 神经 络识 识别 效果 果的 网络 络的 研究 究与 应用 用不 断涌 涌现 。 20 012 层的 的卷 年， 深度学 深 学习 技术 术又 又在图 图像 像识别 别领 领域 积神 神经 经网络 络成 成功地 地对 对包含 含一 一千类 类别 别的 好成 成绩， 这个成 这 成绩 绩比第 第二 名高 高了 近 1 11 个 个百 百分 CN 网络 NN（ 络） Con 及其 nven 其变 ntion 体 L nal N Neur LST TM ral N 的架 Netw 架构 work ，我 k，卷 我们 卷积 神经 经网 络） 与 会在 在后 面的 的章 节中 RNN 中进 N（R 进行单 Recu 单独 urre 独解读 ent N 读， Neur 这里 ral N 里不 Netw 不做过 work 过多 k， 阐 大 展拳 拳脚 一 百万 万张 点 ，这 这充 在这 在 关于 关 循 环神 神经 释 。 2. .6.2 2 多 多层 层神 神经 经网 络 结构 构 我们 我 在两 在 的 输出 出层 依照 依 经 网络 络类 延续 续两 层神 神经 层神 神经 网络 络的 网络 络的 输出 出层 方式 式来 设计 计一 个多 多层 神经 经网 络。 后面 面，继 继续 续添加 加层 层次 。原 原来的 的输 输出层 层变 变成中 中间 间层， 新 加的 的层 层次成 成为 新 ，可 可以 得到 到图 2-1 1。 图 2-1 图 1 多层 层神经 络 经网络 这样 样的 方式 式不 似， 使 用矩 矩阵 断添 添加 运算 算的 ，我 我们可 可以 以得到 到更 更多层 层的 的多层 层神 神经网 网络 络。公 公式 式推导 导的 话其 其实 实跟两 两层 层神 话就 就仅 仅是 是加 一个 个公 式而 而已 。 2. 7 编码 编 编 器- 码器 解码 解 码器 器网 网络 络 编码 编",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 28
    }
  },
  {
    "page_content": "用矩 矩阵 断添 添加 运算 算的 ，我 我们可 可以 以得到 到更 更多层 层的 的多层 层神 神经网 网络 络。公 公式 式推导 导的 话其 其实 实跟两 两层 层神 话就 就仅 仅是 是加 一个 个公 式而 而已 。 2. 7 编码 编 编 器- 码器 解码 解 码器 器网 网络 络 编码 编 解码 码器 器-解 ，并 （E 表示用 ncod 用作 der- 作另一 -Dec 一个 code 个网络 er） 络的 “ 编码 码” 并且该 该表 网络 络使 用一 一个 网络 络来 创建 建输 入的 的内 部表 表示 ，或 或者 者对其 其进 进行 的输入 入以 以产生 生输 输出。 。这 这有助 助于 于超越 越输 输入的 的分 分类。 。最 最终输 输出 以 是相 相同 的模 模态 ，即 即语言 言翻 翻译 ，或 或基于 于概 概念的 的不 不同模 模态 态，例 例如 如图像 像的 的文本 本标 标记。 。作 作为参 参考 考，可 可以 可 阅 第 2 章 深度学习基础 | 25 读谷歌团队发表的论文“使用神经网络进行序列学习”（https://papers.nips.cc/paper/5346-sequence -to-sequence-learning-with-neural-networks.pdf）。 编码器-解码器网络其实可以看作一个解决问题的框架，主要解决 seq2seq 类问题，Sequence （序列）在这里可以理解为一个字符串序列，当我们在给定一个字符串序列后，希望得到与之对应 的另一个字符串序列，比如问答系统、翻译系统。 编码器-解码器网络的流程可以理解为“编码—存储—解码”这一流程，可以用人脑流程来类 比。我们先看到源 Sequence，将其读一遍，然后在我们大脑当中就记住了这个源 Sequence，并且 存在大脑的某一个位置上，形成我们自己的记忆（对应后面的 Context），然后我们再经过思考， 将这个大脑里的东西转变成输出，写下来。我们大脑读入的过程叫作编码器（Encoder），即将输 入的东西变成我们自己的记忆，放在大脑当中，而这个记忆可以叫作 Context，然后我们再根据这 个 Context 转化成答案写下来，这个写的过程叫作解码器（Decoder）。 整个模型可以用图 2-12 表示。 图 2-12 编码器-解码器（Encoder-Decoder）网络架构 2.8 随机梯度下降",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 29
    }
  },
  {
    "page_content": "整个模型可以用图 2-12 表示。 图 2-12 编码器-解码器（Encoder-Decoder）网络架构 2.8 随机梯度下降 几乎所有优化问题的解决方案都是梯度下降算法。它是一种迭代算法，通过随后更新函数的参 数来最小化损失函数。 从图 2-13 中可以看到，我们首先把函数想象成一种山谷，想象一个球滚下山谷斜坡的情形。 日常生活经验告诉我们，球最终会滚到谷底。也许我们可以用这个方法求出损失函数的最小值。 我们这里使用的函数依赖于两个变量：v1 和 v2。这可能是显而易见的，因为我们的损失函数 看起来像前面的那个。为了达到这样一个平滑的损失函数，我们取二次损失： (cid:2)(cid:3) (cid:4) (cid:3)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:4)(cid:5)(cid:5)(cid:9) 26 | TensorFlow 与自然语言处理应用 图 2-13 球滚下斜坡示意图 同样，我们应该注意到二次损失函数只是一种方法，其实还有许多其他方法来定义损失。但不 管选择哪种方法，最终，我们选择不同损失函数的目的是为了得到： （1）对权重值的平滑偏导数。 （2）一个良好的凸曲线，可以达到全局最小值。然而，在寻找全局最小值时，还有许多其他 因素也在发挥作用。 我们随机选择一个（假想的）球的起点，然后模拟球在向下滚动到山谷底部时的运动。与之类 比的情景中，假设我们初始化网络的权重值，或者一般来说，在曲线上的某个任意点上初始化函数 的参数（就像在斜坡的任何一点上放一个球），然后检查附近的斜率（导数）。 我们知道，由于重力的作用，球会朝着最大坡度的方向下落。同样，在该点沿导数方向移动权 重值，并根据以下规则更新权重值： 设 J(w) = 成本作为权重值的函数，w =网络参数（v1 和 v2），(cid:6)(cid:10)=初始权重值集（随机初始化）。 (cid:6)(cid:11)(cid:12)(cid:13)(cid:14)(cid:15)(cid:16) (cid:7) (cid:6)(cid:10) (cid:4) (cid:8)(cid:9)(cid:10) (cid:2)(cid:6)(cid:5) (cid:9)(cid:6)⁄ 这里，dJ(w)/dw 为权重值 w 对 J(w)的偏导数，η 是学习率（Learning Rate）。 学习率更多的是一个超参数，这里虽然没有固定的方法来找到最合适的学习率，但是我们总是 可以通过批量损失来找到它。 一种方法是看到损失并分析损失的模式。一般来说，较差的学习率会导致小批量的不稳定损失。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 30
    }
  },
  {
    "page_content": "这里，dJ(w)/dw 为权重值 w 对 J(w)的偏导数，η 是学习率（Learning Rate）。 学习率更多的是一个超参数，这里虽然没有固定的方法来找到最合适的学习率，但是我们总是 可以通过批量损失来找到它。 一种方法是看到损失并分析损失的模式。一般来说，较差的学习率会导致小批量的不稳定损失。 它（损失）可以递归地上升和下降，而不需要稳定。 图 2-14 给出了一个更直观的解释。 第 2 章 深度学习基础 | 27 图 2-14 小型和大型学习率影响的示意图 在图 2-14 中，有两种情况：情景 1，小的学习速率；情景 2，大的学习速率。我们的目标是为 了达到图 2-14 中的最小值，所以必须达到谷底（就像图 2-13 中球的情况那样）。学习率则与球滚 下山时的跳跃幅度有关。 首先考虑情景 1（图 2-14 中的左侧部分），我们在其中进行小的跳跃，逐渐继续向下滚动， 慢慢地，最终达到最小值，而球有可能卡在路上的一些小缝隙中，并且由于无法进行大跳跃而无法 逃脱它。 在情景 2（图的右侧部分）中，与曲线的斜率相比，学习速率更大。这是一个次优的策略，实 际上可能将我们从山谷中驱逐出去，在某些情况下，这可能是一个良好的开端，可以摆脱局部极小 的范围，但如果我们跳过全局最小值，就会让人对其感到失望。 在图 2-14 中，我们实现了局部最小值，但这只是一个例子。这意味着权重值会停留在局部最 小值上而错过全局最小值。梯度下降或随机梯度下降不保证能够收敛到神经网络的全局最小值（假 设隐藏单元不是线性的），因为损失函数是非凸性的。理想情况是阶跃（步长）继续变化并且拥有 更具适应性的特点，在起初时可以略高，然后在一段时间内逐渐减小，直到收敛为止。 2.9 反向传播 理解反向传播（Backpropagation）算法可能需要一些时间，读者也可以跳过本节内容，因为很 多软件库都具有自动区分和执行整个训练过程的能力。但是，理解这个算法肯定会让你深入了解与 深度学习相关的问题（学习问题、缓慢学习、梯度爆炸、梯度下降）。 让我们首先看一张典型的神经网络结构图，如图 2-15 所示。 28 8 | T Tens sorF Flow w 与 与自 然语 语言 言处理 理应 应用 图 2- 图 -15 是 是一 一个包 包含 含了输 输入 入层 L1、 、隐 藏层 层 L2 2 和 和输出 出层 层 L3 的简 简单 单神经 经网 网络， ，它 的处 处理 理流程 程为 根 图 2 2-15 5 神 神经网 网络 络结构 构图 据 输入 入层 结",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 31
    }
  },
  {
    "page_content": "然语 语言 言处理 理应 应用 图 2- 图 -15 是 是一 一个包 包含 含了输 输入 入层 L1、 、隐 藏层 层 L2 2 和 和输出 出层 层 L3 的简 简单 单神经 经网 网络， ，它 的处 处理 理流程 程为 根 图 2 2-15 5 神 神经网 网络 络结构 构图 据 输入 入层 结 果映 映射 根据 根 也 是神 神经 首 先初 初始 的 i inpu ut 以 及相 相应 应的权 权重 重值和 和配 配置 （图 中黑 黑色 色带箭 箭头 头的边 边） ，通 通过 过隐藏 藏层 的加 加工 工，最 最终 终将 到输 输出 层得 得到 结果 果的 输出 出。模 模型 型可以 以抽 抽象表 表示 示为(cid:17) (cid:18) (cid:13) (cid:19) (cid:19)(cid:2)(cid:6) (cid:12)，(cid:6) (cid:20), (cid:17)分 分别 别表示 示输 输入和 和输 输出向 向量 量。 神经 经网 络的 的处 理流 流程 程，我 我们如 如果 果要得 得到 到输 出(cid:17) ，就 就必须 须知 知道图 图 2 2-15 中每 每条 条边的 的参 参数值 值， 这 网络 络中 最重 重要 的部 部分 。在 神经 经网 络中 中是 是通过 过迭 迭代的 的方 法来 来计 计算这 这些 些参数 数的 ，具 体来 来讲 讲就是 是， 化这 这些 参数 数， 通过 过神 经网 网络 的前 前向 传导 导过 程来 来计 算得 得到 输出 出(cid:17)， 但这些 但 些值 值与真 真实 实值存 存在 在着 误 差， 我 们假 假设 累计 计误 差函 函数 为(cid:7)(cid:8) (cid:5)(cid:5)(cid:2)(cid:6) (cid:6)(cid:12)， 然后 后利 利用梯 梯度 度方法 法极 极小化 化(cid:4)(cid:5) (cid:8)(cid:8)(cid:12)(cid:20) (cid:20)(cid:6)来 来更新 新参 参数， 直 直至误 误差 差值 达 到符 符合 为了 为 失 一般 般性 要求 求而 停止 止计 更好 好地 去说 说明 算。 在 神经 经网 更新 新参 数这",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 32
    }
  },
  {
    "page_content": "度方法 法极 极小化 化(cid:4)(cid:5) (cid:8)(cid:8)(cid:12)(cid:20) (cid:20)(cid:6)来 来更新 新参 参数， 直 直至误 误差 差值 达 到符 符合 为了 为 失 一般 般性 要求 求而 停止 止计 更好 好地 去说 说明 算。 在 神经 经网 更新 新参 数这 这一 过程 程中 络的 的传 播算 算法 法，我 我们 ，假 假设 路径 径如 图 2 2-16 6 所示 示。 ，我 我们 就用 用到 了著 著名 的反 反向 传播 播算 法。 这里 里取 图 2 2-15 5 中 的一 一条 条路径 径来 来做说 说明 ，但 但这 这不 图 图 2- 图 -16 中 中的 的边表 表示 示偏导 导数 数，如 如(cid:7) 2-16 6 神 神经 网络 络传播 播路径 径示 示例 (cid:13) (cid:2) (cid:2)(cid:3) (cid:16) (cid:13) (cid:3)⁄ (cid:5) (cid:5)(cid:6)。 想要 想 我们 我 知道 道输 输入 X X 对 对输出 出 Z Z 的 影响 响，我 我们 们可 以用 用偏 导数 数(cid:2)(cid:3) (cid:10) (cid:3)⁄ (cid:3) (cid:15)(cid:12) (cid:6) (cid:9) (cid:12)(cid:3) (cid:2) (cid:2) (cid:3)⁄ (cid:16)(cid:12) (cid:22) (cid:22) (cid:2)(cid:3) (cid:16) (cid:3)⁄ (cid:3) (cid:5)(cid:6) ，即 即： (cid:2)(cid:3) (cid:2) (cid:3)⁄ (cid:3) (cid:5)(cid:6) (cid:9) (cid:10) (cid:7)(cid:8) (cid:9) (cid:9) (cid:7)(cid:14) (cid:14) (cid:9) (cid:10)(cid:14) (cid:15) (cid:15) (cid:16)(cid:11) (cid:11) (cid:15) (cid:16)(cid:18) (cid:9) (cid:20) (cid:17) (cid:9) (cid:21)(cid:8) (cid:15) (cid:19) (cid:19)(cid:18) (cid:15)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 33
    }
  },
  {
    "page_content": "(cid:10)(cid:14) (cid:15) (cid:15) (cid:16)(cid:11) (cid:11) (cid:15) (cid:16)(cid:18) (cid:9) (cid:20) (cid:17) (cid:9) (cid:21)(cid:8) (cid:15) (cid:19) (cid:19)(cid:18) (cid:15) (cid:19)(cid:14) （ （2.5 5） 如果 果直 直接使 使用 链式 式法 法则进 进行 行求导 导就 就会遇 遇到 到一个 个问 问题， 当路径 当 径数 数量增 增加 加时， ，式 式（2 2.5） ）中 的 子 项目 目数 次 乘法 法就 会呈 呈指 数增 增长 ，所 所以这 这时 时我们 们需 需要把 把上 上式右 右侧 侧部分 分进 进行合 合并 并，合 合并 并后， 我们只 我 只需 需要进 进行 行一 可以 以获 得所 所需 要的 的结 果， 这 样大 大幅 度提 提升 了模 模型 的运 运算 效率 率， 合并 并后 的式 式子 如下 下： (cid:3) (cid:10)⁄ (cid:12)(cid:3) (cid:3)⁄ (cid:15) (cid:15)(cid:12) (cid:13) (cid:9) (cid:12)(cid:10) (cid:15) (cid:16) (cid:16) (cid:15) (cid:19)(cid:6)(cid:12)(cid:11) (cid:8) (cid:9) (cid:14) (cid:9) (cid:9) (cid:17)(cid:12) （ （2.6 6） 接下 接 来， 我们解 我 解决 决式 （2.6 6）的 的实 实现 问题 题。根 根据 据计算 算方 方向 的不 不同 ，可 可以 分为 为正 向微 微分 分与反 反向 微 先看 看针 对图 图 2- -16 的 的正 正向微 微分 分算法 法， 第 2 第 章 深 深度学 学习 基础 础 | 2 29 如 图 2 2-17 所示 示。 图 2-1 图 7 正 正向 向微分 分算法 法 看到 到，正 正向 向微分 分算 算法根 根据 据路径 径的 的传播",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 34
    }
  },
  {
    "page_content": "看针 对图 图 2- -16 的 的正 正向微 微分 分算法 法， 第 2 第 章 深 深度学 学习 基础 础 | 2 29 如 图 2 2-17 所示 示。 图 2-1 图 7 正 正向 向微分 分算法 法 看到 到，正 正向 向微分 分算 算法根 根据 据路径 径的 的传播 播方 方向， 依次 次计 计算路 路径 径中的 的各 各结点 点对 对输入 入 X X 的 的偏导 导数 数， 留了 了输 入对 对各 ，我 我们 看一 一下 结点 点的 影响 响。 反向 向微 分算 算法 （见 见图 2-1 18） 。 图 2-1 图 8 反向 向微分 法 分算法 看到 到， 该算 算法 法从后 后向 前进 进行 计算 算， 结果 果中 保留 留了 路径 径中 各结 结点 对输 输出 的影 影响 。 分 。我 我们 可以 可 结 果中 中保 下面 下 可以 可 这里 这 就有 有一 个问 问题 题了， 既然正 既 正向 反向 向都 都可以 以实 实现式 式（ （2.6 ）的 的计算 算， 那 么我 我们 应该 该选 选择哪 哪个 个算 法 来实 实现 首先 首 其中 其 呢？ 答 案是 是反 向微 微分 算法 法， 理由 由如 下： 我们 们看 一个 个计 算式 式子 (cid:7) (cid:9) (cid:3)(cid:4) (cid:5) (cid:6) (cid:6)(cid:7) (cid:8) (cid:12)(cid:22) (cid:15) (cid:15) 1(cid:6) (cid:6)的图 图模 模型 （见 见图 2 2-19 。 9）。 图 2 2-19 9 图 图模型 型计 计算示 示例 ，c ,d 表 表示 中间 间结 果， 边 的方 方向 表示 示一 个结 结点 是另 另一 个结 结点 的输 输入 。 假设 假 输入 入变 量 a a=2、 、b= =1， 图 2-19 9 中 中各结 结点 点的偏 偏导 导计算 算结 结果如 如图 图 2-2 20 所 所示 。 30 | TensorFlow 与自然语言处理应用 图 2-20 利用正向微分算法得到各结点的偏导计算结果",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 35
    }
  },
  {
    "page_content": "的输 输入 。 假设 假 输入 入变 量 a a=2、 、b= =1， 图 2-19 9 中 中各结 结点 点的偏 偏导 导计算 算结 结果如 如图 图 2-2 20 所 所示 。 30 | TensorFlow 与自然语言处理应用 图 2-20 利用正向微分算法得到各结点的偏导计算结果 利用正向微分算法，我们得到关于变量 b 的偏导计算结果如图 2-21 所示。 图 2-21 利用正向微分算法得到变量 b 的偏导计算结果 利用反向微分算法，我们得到的偏导计算结果如图 2-22 所示。 图 2-22 利用反向微分算法得到的偏导计算结果 由此可见，反向微分算法保留了所有变量（包括中间变量）对结果 e 的影响。若 e 为误差函数， 则对图进行一次计算，可以得出所有结点对 e 的影响，也就是梯度值，下一步就可以利用这些梯度 值来更新边的权重值了；而正向微分算法得到的结果是只保留了一个输入变量对误差 e 的影响，显 然，想要获得多个变量对 e 的影响，我们就需要进行多次计算。所以正向微分算法在效率上明显不 如反向微分，这也是我们选择反向微分算法的原因。 第 2 章 深度学习基础 | 31 2.10 总结 在本章，我们首先对深度学习的理念和产生的历史背景做了说明，认识到深度学习在人工智能 当中起到非常重要的作用。 其次，我们为了对深度学习的内部原理进行解读，介绍了其中的关键部分——神经元模型。通 过神经元模型的解读，我们对深度学习的基本结构有了认知。 接着，我们从单层神经网络、多层神经网络和 Encoder-Decoder 网络等方面对于深度学习的内 部网络结构进行了更深层次的解析，对其内部逻辑和机制运行情况有了大致清晰的认知。因为现实 中的问题一般都非常复杂，怎样选择一个高效的优化算法便成为我们着重关注的方法，所以我们就 介绍了随机梯度下降算法。 最后，我们介绍了著名的反向传播算法（BP），从数学的角度做简要解读，使我们认识到反 向传播算法的魅力所在，为我们进一步学习深度学习或者说神经网络模型奠定了良好的基础。 下一章，我们将介绍本书所使用的技术框架：TensorFlow。 第 3 章 TensorFlow",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 36
    }
  },
  {
    "page_content": "介绍了随机梯度下降算法。 最后，我们介绍了著名的反向传播算法（BP），从数学的角度做简要解读，使我们认识到反 向传播算法的魅力所在，为我们进一步学习深度学习或者说神经网络模型奠定了良好的基础。 下一章，我们将介绍本书所使用的技术框架：TensorFlow。 第 3 章 TensorFlow 在本章中，首先我们会对 TensorFlow 的概念、主要特征、安装及其三个组成部分进行详细解 读，梳理出这些核心概念之间的关系。其次，在了解了一些核心概念之后，我们会对 TensorFlow 的工作原理进行深度解析，将 TensorFlow 平台的“client—master—worker”架构底层中涉及到的 内在逻辑和技术路径进行详细解读，以便我们对 TensorFlow 框架的运行机制有更多的认知。接着， 我们会利用示例对 TensorFlow 客户端进行专门解读，读者会在示例中感受 TensorFlow 客户端内在 的运行情况。然后，我们会对 TensorFlow 中的常见元素逐一详解，并做一些对比分析。最后，我 们对 TensorFlow 的变量作用域机制做一些介绍，并实现一个三层神经网络对 MNIST 数字数据集进 行分类的例子。 本章中涉及的完整代码，请查看文件夹 ch3 下的代码文件：3_tensorflow_introduction.ipynb。 3.1 TensorFlow 概念解读 由于深度学习研究的最终目的是为了解决我们现实世界中遇到的困难，因此在学术界不断探索 新理念、新模型的同时，业界优秀的从业人员也在加速发布各类可实现的技术框架，这样深度学习 框架就在学术界和工业界的相互推动下得以迅速发展起来。这里给出谷歌公司经过长期的研究和尝 试，在实践的基础上推出的目前最优秀的深度学习框架之一——TensorFlow。TensorFlow 最初是 由谷歌公司的大脑小组（隶属于谷歌机器智能研究机构）的研究员和工程师们开发出来的，是一个采",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 37
    }
  },
  {
    "page_content": "新理念、新模型的同时，业界优秀的从业人员也在加速发布各类可实现的技术框架，这样深度学习 框架就在学术界和工业界的相互推动下得以迅速发展起来。这里给出谷歌公司经过长期的研究和尝 试，在实践的基础上推出的目前最优秀的深度学习框架之一——TensorFlow。TensorFlow 最初是 由谷歌公司的大脑小组（隶属于谷歌机器智能研究机构）的研究员和工程师们开发出来的，是一个采 用数据流图（Data Flow Graph）的开源分布式数值计算框架，主要用于减轻实现神经网络细节层面的 工作量（例如，计算神经网络权重值的导数）。TensorFlow 通过使用统一计算设备架构（Compute Unified Device Architecture，CUDA）对数值进行有效计算，该架构是由 NVIDIA 公司引入的并行计算平台。 TensorFlow 主要是由计算图、张量以及模型会话三个部分组成的。TensorFlow 中的计算可以 表示为一个计算图（Computation Graph），或者称作有向图（Directed Graph），图中的每一个数 学运算或操作（Operation）都将被视为一个节点（Node），而节点与节点之间的连接被称为边（Edge）， 第 3 章 TensorFlow | 33 图中的这些边（Edge）则表示在节点间相互关联的流动（Flow）的多维数据数组，即张量（Tensor）。 这个计算图表述了数据的计算流程，它负责维护和更新状态，我们可以对计算图中的分支进行条件 控制或循环操作。简单说，我们可以用张量表示数据，用计算图搭建神经网络，用会话执行计算图， 在优化线上的权重值（参数）后得到我们的模型。 这里，我们还可以使用多种语言对计算图进行设计。TensorFlow 这样灵活的架构让我们可以 在多种平台上展开计算，例如台式计算机中的一个或多个 CPU（或 GPU）、服务器、移动设备等。 作为优秀的技术架构，TensorFlow 在机器学习方面解决了以下几个核心问题： （1）使用 TensorFlow 工具可以利用很简洁的语言来实现各类复杂算法模型，这样一来，我们 就可以从日常中极为消耗精力的编码、调试工作中解放出来。 （2）由于 TensorFlow 内核执行系统使用的是 C++，因此在执行效率方面非常高效。 （3）TensorFlow 极佳的分层架构使得模型能够很方便地运行在异构设备之上。 （4）TensorFlow 包含了 TensorBoard 等极好的配套工具，且第三方社区也在不断贡献很多实 用的辅助工具，例如 TFLearn 等，这些工具使得代码变得更加简洁、数据处理工作更便捷。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 38
    }
  },
  {
    "page_content": "（2）由于 TensorFlow 内核执行系统使用的是 C++，因此在执行效率方面非常高效。 （3）TensorFlow 极佳的分层架构使得模型能够很方便地运行在异构设备之上。 （4）TensorFlow 包含了 TensorBoard 等极好的配套工具，且第三方社区也在不断贡献很多实 用的辅助工具，例如 TFLearn 等，这些工具使得代码变得更加简洁、数据处理工作更便捷。 如果读者感兴趣，可以参考下面的网址以查阅关于 TensorFlow 方面的内容。 (cid:2) TensorFlow 官网： tensorflow.google.cn。 (cid:2) TensorFlow 的应用程序编程接口（API）：tensorflow.google.cn/api_docs/python。 (cid:2) GitHub 网址：github.com/tensorflow。 (cid:2) 模型仓库：github.com/tensorflow/models。 3.2 TensorFlow 主要特征 3.2.1 自动求微分 基于梯度的机器学习算法会受益于 TensorFlow 自动求微分的能力。在使用 TensorFlow 时，我 们只需要定义预测模型的结构，将这个结构和目标函数（Objective Function）结合在一起，并添加 数据，TensorFlow 将自动为我们计算相关的微分导数。计算某个变量相对于其他变量的导数仅仅 是通过扩展你的计算图来完成的，所以我们可以一直很清晰地看到系统中究竟在发生什么。 3.2.2 多语言支持 TensorFlow 有一个合理的 C++使用界面，也有一个易用的 Python 使用界面来构建和执行我们 的计算图（Computation Graph）。我们可以直接编写 Python/C++程序，也可以用交互式的 iPython 界面来调用 TensorFlow 以尝试一些想法，它可以帮我们将笔记、代码、可视化等有条理地归置好。 当然这仅仅是一个起点，它同时也在促使我们创造自己最喜欢的语言界面，比如 Go、Java、Lua、 JavaScript、R 等。 34 | TensorFlow 与自然语言处理应用 3.2.3 高度的灵活性",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 39
    }
  },
  {
    "page_content": "34 | TensorFlow 与自然语言处理应用 3.2.3 高度的灵活性 TensorFlow 不是一个严格意义上的“神经网络”库。如果我们能够将计算表示为一个数据流 图，那么就可以使用 TensorFlow 来构建图和描写驱动计算的内部循环。TensorFlow 提供了有用的 工具来帮助你组装“子图”（常用于神经网络），当然用户也可以自己在 TensorFlow 基础上编写 自己的“上层库”。定义顺手好用的新复合操作和编写一个 Python 函数一样容易，而且也不用担 心性能损耗。当然万一我们发现找不到想要的底层数据操作，我们也可以自己编写一点 C++代码 来丰富底层的操作。 3.2.4 真正的可移植性 TensorFlow 在 CPU 和 GPU 上运行，比如说可以运行在台式机、服务器、移动设备等上面。 在没有特殊硬件的前提下，TensorFlow 能够帮我们在自己的笔记本上运行一下机器学习、深度学 习模型。TensorFlow 也可以帮助我们将自己的训练模型在多个 CPU 上进行规模化的运算，同时不 必修改代码。TensorFlow 还可以帮助我们将自己训练好的模型作为产品的一部分部署到手机 App 里。TensorFlow 更可以帮助我们将自己的模型作为云端服务运行在自己的服务器上，或者运行在 Docker 容器里。 3.2.5 将科研和产品联系在一起 过去，要将科研中的机器学习想法用到产品中，需要大量的代码重写工作。现在，谷歌公司的 科学家用 TensorFlow 尝试新的算法，产品团队则用 TensorFlow 来训练和使用计算模型，并直接提 供给在线用户。使用 TensorFlow 可以让应用型研究者将想法迅速地运用到产品中，也可以让学术 性研究者更直接地彼此分享代码，从而提高科研产出率。 3.2.6 性能最优化 例如，现在你有一个带有 32 个 CPU 内核、4 个 GPU 显卡的工作站，就可以利用 TensorFlow 将工作站的计算潜能全部发挥出来。TensorFlow 给予了线程、队列、异步操作等最佳的支持，能 够让我们将自己手边硬件的计算潜能全部发挥出来。我们可以自由地将 TensorFlow 图中的计算元 素分配到不同设备上，让 TensorFlow 帮我们管理好这些不同的副本。 3.3 TensorFlow 安装 我们可以在多个平台上安装和使用 TensorFlow，例如 Linux、Mac OS 和 Windows。当然，我 们也可以使用 TensorFlow 最新的 GitHub 源来构建和安装 TensorFlow。此外，如果我们的电脑运行 第 3 章 TensorFlow | 35",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 40
    }
  },
  {
    "page_content": "3.3 TensorFlow 安装 我们可以在多个平台上安装和使用 TensorFlow，例如 Linux、Mac OS 和 Windows。当然，我 们也可以使用 TensorFlow 最新的 GitHub 源来构建和安装 TensorFlow。此外，如果我们的电脑运行 第 3 章 TensorFlow | 35 的是 Windows 系统，那么比较常用的是通过 Anaconda 来安装 TensorFlow。 由于 Python 3 附带了 pip3 包管理器，它是用于安装 TensorFlow 的程序，因此如果我们使用的 是 Python 的这个版本，就无须安装 pip。为简单起见，在本节中将展示如何使用本机 pip 安装 TensorFlow。下面给出在 Windows 系统下安装 TensorFlow 的两个命令。启动一个“终端”程序， 然后在该“终端”中执行相应的 pip3 install 命令。 （1）要安装 TensorFlow 的 CPU 版本，输入以下命令： C:\\> pip3 install --upgrade tensorflow （2）要安装 TensorFlow 的 GPU 版本，输入以下命令： C:\\> pip3 install --upgrade tensorflow-gpu 在 Linux 方面，TensorFlow Python API 支持 Python 2.7 和 Python 3.3+，因此我们需要安装 Python 才能启动 TensorFlow 安装。我们必须安装 Cuda Toolkit 7.5 和 cuDNN v5.1 +才能获得 GPU 支持。 笔者使用的是 Ubuntu 系统，是采用 pip3 的命令来安装 TensorFlow 的，更多信息也可以参考 https://tensorflow.google.cn/install/source 上的说明。 在 Linux 上安装 TensorFlow 这里将给出如何在 Ubuntu 14.04 或更高版本上安装 TensorFlow。此处提供的说明可能也适用 于 Linux 其他版本，只需进行少量的调整即可。 但是，在继续执行正式步骤之前，我们需要确定在平台上安装哪个 TensorFlow，我们可以在 GPU 和 CPU 上运行数据密集型张量应用程序。因此，应该选择以下 TensorFlow 两种版本中的一 个，在我们的平台上进行安装： (cid:2) 仅支持 CPU 的 TensorFlow：如果计算机上没有安装 NVIDIA 等 GPU，就必须使用此版本 安装并开始计算。这个很简单，可以在 5 到 10 分钟内完成。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 41
    }
  },
  {
    "page_content": "(cid:2) 仅支持 CPU 的 TensorFlow：如果计算机上没有安装 NVIDIA 等 GPU，就必须使用此版本 安装并开始计算。这个很简单，可以在 5 到 10 分钟内完成。 (cid:2) 支持 GPU 的 TensorFlow：深度学习应用程序通常需要非常高的计算资源，TensorFlow 也 不例外，我们通常可以在 GPU 上而不是在 CPU 上加快数据计算和分析速度。如果你的 计算机上有 NVIDIAGPU 硬件，你应该安装并使用此版本。 根据我们的经验，即使计算机上集成了 NVIDIA GPU 硬件，也有必要安装并首先尝试仅使用 CPU 的版本，如果你没有体验到良好的性能，那么再切换到 GPU 来进行支持。 支持 GPU 的 TensorFlow 版本有几个要求，例如 64 位 Linux、Python 2.7（或 Python 3 的 3.3+）， NVIDIACUDA7.5 或更高版本（Pascal GPU 需要 CUDA 8.0）和 NVIDIA cuDNN v4.0（最小）或 v5.1 （推荐）。更具体地说，TensorFlow 的当前开发仅支持使用 NVIDIA 工具包和软件的 GPU 计算。 因此，必须在 Linux 计算机上安装以下软件才能使得预测分析应用程序获得 GPU 的支持： (cid:2) Python (cid:2) NVIDIA Driver 36 | TensorFlow 与自然语言处理应用 (cid:2) CUDA with compute capability >= 3.0 (cid:2) CuDNN (cid:2) TensorFlow 1. 安装 Python 和 NVIDIA 驱动程序 在不同的平台上安装 Python 的操作相对比较简单，这里不再赘述。另外，假设你的计算机中 已经安装了 NVIDIA GPU。 要检查一下你的计算机中的 GPU 是否已正确安装和正常工作，请在终端上执行以下命令： $ lspci -nnk | grep -i nvidia 由于预测分析很大程度上依赖于机器学习和深度学习算法，因此请确保你的计算机上安装了一 些基本软件包，例如 GCC 和一些用于科学计算的 Python 软件包。 只需在终端上执行如下命令： $ sudo apt-get update $ sudo apt-get install libglu1-mesa libxi-dev libxmu-dev -y $ sudo apt-get — yes install build-essential $ sudo apt-get install python-pip python-dev -y",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 42
    }
  },
  {
    "page_content": "只需在终端上执行如下命令： $ sudo apt-get update $ sudo apt-get install libglu1-mesa libxi-dev libxmu-dev -y $ sudo apt-get — yes install build-essential $ sudo apt-get install python-pip python-dev -y $ sudo apt-get install python-numpy python-scipy –y 现在通过 wget 下载 NVIDIA 驱动程序（不要忘记为你的计算机选择正确的版本），并以 silent 模式运行脚本： $ wget http://us.download.nvidia.com/XFree86/Linux-x86_64/367.44/NVIDIA-Linux-x86_64- 367.44.run $ sudo chmod +x NVIDIA-Linux-x86_64-367.35.run $ ./NVIDIA-Linux-x86_64-367.35.run --silent 一些 GPU 显卡，如 NVidia GTX 1080，附带内置驱动程序。因此，如果你的计算机具有不同 于 GTX 1080 的 GPU，就必须下载该 GPU 的驱动程序。 要确保驱动程序是否已正确安装，请在终端上执行以下命令： $ nvidia-smi 命令的结果应如图 3-1 所示。 第 3 章 TensorFlow | 37 2. 安装 NVIDIA CUDA 图 3-1 nvidia-smi 命令的输出结果 为了将 TensorFlow 与 NVIDIA GPU 配合使用，需要安装 CUDA Toolkit 8.0 及其相关的 NVIDIA 驱动程序。CUDA 工具包包括： (cid:2) GPU 加速库，如用于快速傅里叶变换的 cuFFT（FFT）。 (cid:2) 基本线性代数子程序（BLAS）的 cuBLAS。 (cid:2) 稀疏矩阵例程的 cuSPARSE。 (cid:2) 用于密集和稀疏的直接求解器的 cuSOLVER。 (cid:2) 用于随机数生成的 cuRAND，用于图像的 NPP 和视频处理原语。 (cid:2) NVIDIA 图形分析库的 nvGRICH。 (cid:2) 推力模板并行算法和数据结构专用的 CUDA 数学库。 对于 Linux，下载和安装所需的包： https://developer.nvidia.com/cuda-downloads 使用的 wget 命令如下：",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 43
    }
  },
  {
    "page_content": "对于 Linux，下载和安装所需的包： https://developer.nvidia.com/cuda-downloads 使用的 wget 命令如下： $ wget https://developer.nvidia.com/compute/cuda/8.0/Prod2/local_ installers/cuda_8.0.61_375.26_linux-run $ sudo chmod +x cuda_8.0.61_375.26_linux.run $ ./ cuda_8.0.61_375.26_linux.run --driver --silent $ ./ cuda_8.0.61_375.26_linux.run --toolkit --silent $ ./ cuda_8.0.61_375.26_linux.run --samples –silent 另外，确保你已经将 CUDA 安装路径添加到 LD_LIBRARY_PATH 环境变量中： $ echo 'export LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH:/usr/local/cuda/lib64:/ usr/local/cuda/extras/CUPTI/lib64\"' >> ~/.bashrc $ echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc $ source ~/.bashrc 38 | TensorFlow 与自然语言处理应用 3. 安装 NVIDIA cuDNN v5.1+ 安装 CUDA Toolkit 后，从 Linux 上下载 cuDNN v5.1 库，解压缩文件并将其复制到 CUDA Toolkit 目录（假设在/ usr / local / cuda /中）： $ cd /usr/local $sudo mkdir cuda $ cd ~/Downloads/ $ wget http://developer2.download.nvidia.com/compute/machine-learning/ cudnn/secure/v6/prod/8.0_20170427/cudnn-8.0-linux-x64-v6.0.tgz $ sudo tar –xvzf cudnn-8.0-linux-x64-v6.0.tgz $ cp cuda/lib64/* /usr/local/cuda/lib64/ $ cp cuda/include/cudnn.h /usr/local/cuda/include/",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 44
    }
  },
  {
    "page_content": "$ sudo tar –xvzf cudnn-8.0-linux-x64-v6.0.tgz $ cp cuda/lib64/* /usr/local/cuda/lib64/ $ cp cuda/include/cudnn.h /usr/local/cuda/include/ 注意，要安装 cuDNN v5.1 库，我们必须在 https://developer.nvidia.com/accelerated-computing- developer 上注册加速计算开发程序。现在，当安装了 cuDNN v5.1 库之后，请确保创建了 CUDA_HOME 环境变量。 4. 安装 libcupti-dev 库 最后，需要在你的计算机上安装 libcupti-dev 库，这是提供高级分析支持的 NVIDIA CUDA。 要安装此库，请执行以下命令： $ sudo apt-get install libcupti-dev 5. 安装 TensorFlow 有关如何为 CPU 安装最新版本的 TensorFlow，以及如何为具有 NVIDIA 、cuDNN 和 CUDA 计算能力的 GPU 提供支持，请参阅下面的部分。可以在计算机上以多种方式安装 TensorFlow，比 如使用 virtualenv、pip、Docker 和 Anaconda。这里使用 pip 和 virtualenv 方式。（有兴趣的读者可 以尝试使用 Docker 和 Anaconda 安装，详见 https://tensorflow.google.cn/install/。） （1）使用本地 pip 安装 TensorFlow 对于 Python 2.7，仅支持 CPU 版本的，具体如下： $ pip install tensorflow # For Python 3.x and of course with only CPU support: $ pip3 install tensorflow # For Python 2.7 and of course with GPU support: $ pip install tensorflow-gpu # For Python 3.x and of course with GPU support: $ pip3 install tensorflow-gpu （2）使用 virtualenv 安装 TensorFlow 如果你已经在系统上安装了 Python 2+（或 3+）和 pip（或 pip3)，请按照以下步骤安装 TensorFlow。 ①创建 virtualenv 环境： 第 3 章 TensorFlow | 39",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 45
    }
  },
  {
    "page_content": "$ pip3 install tensorflow-gpu （2）使用 virtualenv 安装 TensorFlow 如果你已经在系统上安装了 Python 2+（或 3+）和 pip（或 pip3)，请按照以下步骤安装 TensorFlow。 ①创建 virtualenv 环境： 第 3 章 TensorFlow | 39 $ virtualenv --system-site-packages targetDirectory targetDirectory 表示 virtualenv 树的根目录。默认情况下，它是〜/ tensorflow（也可以选择任何 其他目录）。 ②按如下方式激活 virtualenv 环境： $ source ~/tensorflow/bin/activate # bash, sh, ksh, or zsh $ source ~/tensorflow/bin/activate.csh # csh or tcsh 如果命令在步骤 2 中执行成功，那么在“终端”程序中上应该可以看到以下内容： (tensorflow)$ ③安装 TensorFlow。 按照以下命令之一在激活的 virtualenv 环境中安装 TensorFlow。 对于仅支持 CPU 的 Python 2.7，请使用以下命令： (tensorflow)$ pip install --upgrade tensorflow 对于仅支持 CPU 的 Python 3.x，请使用以下命令： (tensorflow)$ pip3 install --upgrade tensorflow 对于支持 GPU 的 Python 2.7，请使用以下命令： (tensorflow)$ pip install --upgrade tensorflow-gpu 对于仅支持 GPU 的 Python 3.x，请使用以下命令： (tensorflow)$ pip3 install --upgrade tensorflow-gpu 如果上述命令成功，就跳过步骤 5；如果上述命令失败，请执行步骤 5。此外，如果步骤 3 以 某种方式失败，请尝试通过执行以下命令以在激活的 virtualenv 环境中安装 TensorFlow：",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 46
    }
  },
  {
    "page_content": "对于仅支持 GPU 的 Python 3.x，请使用以下命令： (tensorflow)$ pip3 install --upgrade tensorflow-gpu 如果上述命令成功，就跳过步骤 5；如果上述命令失败，请执行步骤 5。此外，如果步骤 3 以 某种方式失败，请尝试通过执行以下命令以在激活的 virtualenv 环境中安装 TensorFlow： #对于 python 2.7（选择具有 CPU 或 GPU 支持的适当 URL）： (tensorflow)$ pip install --upgrade TF_PYTHON_URL #对于 python ３.x（选择具有 CPU 或 GPU 支持的适当 URL）： (tensorflow)$ pip3 install --upgrade TF_PYTHON_URL ④验证安装。 要在步骤 3 中验证安装，必须激活虚拟环境。如果 virtualenv 环境当前未处于激活状态，请执 行以下命令之一： $ source ~/tensorflow/bin/activate # bash, sh, ksh, or zsh $ source ~/tensorflow/bin/activate.csh # csh or tcsh ⑤卸载 TensorFlow。 要卸载 TensorFlow，只需删除创建的目录树即可。例如： 40 | TensorFlow 与自然语言处理应用 $ rm -r targetDirectory 6. 测试安装的 TensorFlow 启动一个 Python 终端（只需在终端上输入 python 或 python3），执行一段常见的“Hello, TensorFlow!”程序，代码行如下： >>> import tensorflow as tf >>> hello = tf.constant(\"Hello, TensorFlow!\") >>> sess=tf.Session() >>> print sess.run(hello) 如果 TensorFlow 安装成功，我们将看到输出结果为“Hello, TensorFlow!”。 3.4 TensorFlow 计算图 在执行 TensorFlow 程序时，我们需要构建一个计算图，然后按照计算图启动一个会话，在会 话中完成变量赋值、计算等操作并得到最终结果。换句话说，TensorFlow 的计算图可以划分为两 部分： (cid:2) 构造部分，包含计算流图，用于构建模型。 (cid:2) 执行部分，通过会话（Session）执行图中的计算，用于提供数据并获得结果。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 47
    }
  },
  {
    "page_content": "在执行 TensorFlow 程序时，我们需要构建一个计算图，然后按照计算图启动一个会话，在会 话中完成变量赋值、计算等操作并得到最终结果。换句话说，TensorFlow 的计算图可以划分为两 部分： (cid:2) 构造部分，包含计算流图，用于构建模型。 (cid:2) 执行部分，通过会话（Session）执行图中的计算，用于提供数据并获得结果。 对于计算图的构造部分而言，我们又可以分为两部分： (cid:2) 创建源节点。 (cid:2) 源节点的输出传递给其他节点做运算操作。 这里，更吸引我们的是，TensorFlow 会在 C ++引擎上执行每一项运算操作，这意味着在 Python 中也不会执行任何乘法或加法，Python 只是一个包装器。从根本上讲，TensorFlow C ++引擎包含 以下两方面： (cid:2) 卷积、最大池化、Sigmoid 等操作的高效实现。 (cid:2) 转发模式操作的导数。 计算图基本上类似于数据流图。图 3-2 显示了一个简单计算的计算图，用于计算简单的等式， 如 z = d×c =（a + b）×c。 第 3 3 章 章 T Tens sorF Flow w | 4 41 图 3 3-2 一个 个简 单的 的执行 行图 表示 示节 节点处 处的 操作 作， 矩形 形表 表示整 整个 数据 据计 算图 图。 在 T Ten sorF Flow w 的 的实施 施中 ， 在图 在 3-2 2 中 ，圆 圆圈 Te ensor rFlo ow 计 计算 算图包 包含 含以下 下内 容： (cid:2) (cid:2) (cid:2) (cid:2) 使用 使 一组 组 tf f.Ope erati ion 对象 象： 用于 于表 示要 要执 行的 的计 算单 单元 。 tf.T Tenso or 对 对象 象：用 用于 表示 示控 制操 操作 之间 间数 数据流 流的 数据 据单 元。 Ten nsor rFlow w 还 还可 可以执 执行 行延迟 迟操 作。 一旦在 一 在计 计算图 图的 构建 建阶 阶段编 编写 写了高 高度 组合 合的 的表达 达式 式， 我 们仍 仍然 可以 以在 会话 话的 的运行 行阶 阶段去 去对 对它们 们求 求值。 从技术 从 术上 上讲， Te enso orFlo ow 方 式按 按时 执行 行。 例如",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 48
    }
  },
  {
    "page_content": "行延迟 迟操 作。 一旦在 一 在计 计算图 图的 构建 建阶 阶段编 编写 写了高 高度 组合 合的 的表达 达式 式， 我 们仍 仍然 可以 以在 会话 话的 的运行 行阶 阶段去 去对 对它们 们求 求值。 从技术 从 术上 上讲， Te enso orFlo ow 方 式按 按时 执行 行。 例如 如， 使用 用 G PU 并行 行执 行代 代码 的独 独立 立部分 分， 如图 图 3- -3 所 所示 措施 施并 并以有 有效 效的 会给 给出 。 图 3-3 Te enso orFlo ow 图 图中的 的边 边和节 节点将 将在 在 CPU U 或 或 GP PU 等 等设备 备上 上的会 会话下 下执 行 42 | TensorFlow 与自然语言处理应用 3.5 TensorFlow 张量和模型会话 3.5.1 张量 在 TensorFlow 中，张量（Tensor）是对运算结果的引用，运算结果多数情况下是以数组的形 式存储的，与 numpy 中的数组不同的是，张量还具有三个重要属性：名字、维度、类型。张量的 名字是张量的唯一标识符，我们通过名字可以发现张量是如何被计算出来的。例如“multiply:0” 代表的是计算节点“multiply”的第 1 个输出结果，“add:2”代表的是计算节点“add”的第 3 个 输出结果。 TensorFlow 有两种类型的边，或者说张量（Tensor）的类型有两种： (cid:2) 正常：它们承载节点之间的数据结构。来自一个节点的一个运算或操作的输出变为另一 个运算或操作的输入。连接两个节点的线携带这些数值。 (cid:2) 特殊：此边不携带数值，但是只表示两个节点（比如 X 和 Y）之间的控制依赖关系。这 意味着节点 Y 只有在 X 中的运算或操作已经执行时才会被执行。 我们也可以这样理解，TensorFlow 计算图中的每个节点的输入输出都是张量（Tensor），而 连接节点的边（有向线段）就是 Flow，表示从一个张量（Tensor）状态到另一个张量（Tensor） 状态。我们在编写程序时，都是逐步计算的，每计算完一步便能够获得一个执行结果。对于 Tensor 数据类型而言，虽然我们可以事先定义或者根据计算图的结构推断得到，但是有一类特殊的边中并",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 49
    }
  },
  {
    "page_content": "我们也可以这样理解，TensorFlow 计算图中的每个节点的输入输出都是张量（Tensor），而 连接节点的边（有向线段）就是 Flow，表示从一个张量（Tensor）状态到另一个张量（Tensor） 状态。我们在编写程序时，都是逐步计算的，每计算完一步便能够获得一个执行结果。对于 Tensor 数据类型而言，虽然我们可以事先定义或者根据计算图的结构推断得到，但是有一类特殊的边中并 没有数据流动，这种边便是依赖控制（Control Dependencies），其作用便是让它的起始节点执行完 之后再去执行目标节点，这样一来我们就可以使用边进行灵活的条件控制了。比如，我们在 TensorFlow 实施中定义了依赖控制关系，便可以在其他独立的操作之间强制执行排序，以作为限 制使用内存最高峰值的一种方式。 在 TensorFlow 中，一个张量基本上是一个 n 维数组，下面让我们通过表 3-1 中的内容来解读 一下张量和维数的关系。 表 3-1 张量和维数的关系 维数 0-D 1-D 2-D 3-D ... n-D 阶 0 1 2 3 ... n 名称 标量(Scalar) 向量(Vector) 矩阵 张量 ... 张量 示例 s=1 2 3 v=[1,2,3] m=[[1,2,3],[4,5,6]] t=[[... ... T=[[... 张量可以表示 0 阶到 n 阶的数组（列表）。这里，阶是张量的维数。第 0 阶张量是一个数，也 就是标量；第 1 阶张量是一个一维数组，也就是向量；第 2 阶张量是一个二维数组，也就是矩阵； 第 n 阶张量是一个 n 维数组。 第 3 章 TensorFlow | 43 3.5.2 会话 如前所述，TensorFlow 中的会话（Session）用来执行事先定义好的运算，负责完成多个计算 设备或集群分布式节点的布置和数据传输节点的添加，并且还负责将子图分配给相应的执行器单元 进行运行。会话拥有并管理 TensorFlow 程序运行时的所有资源。当计算完成之后需要关闭会话来 帮助系统回收资源，否则就可能出现计算资源被占用的问题。 3.6 TensorFlow 工作原理",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 50
    }
  },
  {
    "page_content": "进行运行。会话拥有并管理 TensorFlow 程序运行时的所有资源。当计算完成之后需要关闭会话来 帮助系统回收资源，否则就可能出现计算资源被占用的问题。 3.6 TensorFlow 工作原理 TensorFlow 是一个具有“client—master—worker”架构的分布式系统。在 TensorFlow 中，参 与分布式系统的所有节点或者设备被统称为一个 cluster（集群），一个 cluster 中包含多个 server （服务器），每个 server 去执行一项 task（任务），而 server 和 task 又是一一对应的。这样看来， 我们可以把 cluster 看成是 server 的集合，也可以看成是 task 的集合。TensorFlow 为每个 task 又增 加了一个抽象层，将一系列相似的 task 集合称为一个 job（工作）。例如，我们在 PS 架构中，习 惯称 parameter server（参数服务器）的 task 集合为 ps，而把执行梯度计算的 task 集合称为 worker。 因此，cluster 又可以被看成是 job 的集合，实际上这只是逻辑上的意义，我们还需要具体看一下这 个 server 真正做的是什么。在 TensorFlow 中，job 用 name（字符串）标识，task 用 index（整数索 引或整数下标）标识，cluster 中的每个 task 都可以用 job 的 name 加上 task 的 index 来作唯一标识。 在分布式系统中，一般情况下各个 task 在不同的节点或者设备上执行。 通常情况下，客户端（client）通过会话 tf.Session 接口和 master 展开通信，且将触发执行的请 求提交给 master，而 master 会把所要执行的任务分派给单个或多个 worker 进程，相关结果通过 master 返回给客户端。这里，worker 负责计算的执行，任何一个 worker 进程都会管理和使用计算 机上的计算硬件设备资源，比如一块或者多块 CPU 和 GPU，进而处理计算子图（Subgraph）的运 算或操作过程。 其实，TensorFlow 的架构横向扩展是很灵活的。在单机模式的多数情况下，client、master 和 worker 均在同一个进程中启动，而 worker 进程会管理本机上所有的计算设备资源。在分布式的架 构中，我们可以通过远程调用的方式将 client、master 和 worker 连接在一起，且任何一个 worker 进程各自监控关联执行机上的计算设备。关于 TensorFlow 的单机和分布式架构如图 3-4 所示。 44 4 | T Tens sorF Flow w 与",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 51
    }
  },
  {
    "page_content": "44 4 | T Tens sorF Flow w 与 与自 然语 语言 言处理 理应 应用 图 3-4 Te ensor rFlow w 的 的单机 机和分 分布 布式架 架构示 示意 意图 在创 在 激 活的 的会 使 用其 其中 建计 计算 图之 之后 ，T Tens orFl low 需要 要以 以分布 布式 式方式 式由 多个 个 C PU （以 以及 GPU U， 如果 果可 可用） ）执 执行 话。 通 常， 实 际上 上不 需要 要明 确指 指定 是使 使用 CP PU 还 还是 是 GP PU， 因 为 T Tens sorF Flow w 可 可以选 选择 择并 一个 个。 默认 认情 况下 下， 将选 选择 GP U 进 进行 尽可 可能 多的 的运 算； 否 则， 将使 使用 用 CP PU。 因此， 因 从广 从 义 上看 看， 以下 下是 Ten nsor rFlow w 的 的主要 要组 ： 组件： (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) 变量 量（ Var riabl le） ：用 用于 包含 含 Te enso orFlo ow 会 会话 话之 间权 权重值 值和 和偏差 差的 的值 。 张量 量（ Ten nsor ）： 在节 节点 点之 间传 传递的 的一 一组值 值。 占位 位符 符（P Place ehol lder ）： 用于 于在 在程序 序和 和 Te enso orFlo ow 图 图之 之间发 发送 送数据 据。 会话 话（ Ses sion n）： 启动会 启 会话 话时， Te enso orFlo ow 会自 自动 计算 算图 中所 所有 计算 算的 梯度 度， 并在 在链 链式 规则 则中 使用 用它 们。 实际上 实 上， 在执 执行 行图形 形时 时会调 调用 会话 话。 从技 从 技术上 上说 说，我 我们 们要编 编写 写的程 程序 序可以 以被 被视为 为客 客户 端， 而 客户 户端 端用于 于以 以符号 号方 方式在 在 C C/C ++ +或 Py ython n 中",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 52
    }
  },
  {
    "page_content": "则中 使用 用它 们。 实际上 实 上， 在执 执行 行图形 形时 时会调 调用 会话 话。 从技 从 技术上 上说 说，我 我们 们要编 编写 写的程 程序 序可以 以被 被视为 为客 客户 端， 而 客户 户端 端用于 于以 以符号 号方 方式在 在 C C/C ++ +或 Py ython n 中 中创建 建计 计算图 图， 接着 着， 我们 们的 的代码 码可 可以要 要求 求 Te ensor rFlo ow 执 执行 行此该 该图 图，请 请参 参见图 图 3- -5 中 中的 的详 细 信息 息。 计算 计 图有 有助 于在 在具 图 3-5 图 5 在 在 Te enso rFlo ow 分 分布式 式架 构下 下执行 行代 码示 图 示意图 有 C CPU U 或 GPU U 的 的多 个计 计算 节点 点上 分配 配工 作负 负载 。这 这样， ，神 经网 网络 络等同 同于 于复 第 3 章 TensorFlow | 45 合函数，其中每个层（输入层、隐藏层或输出层）可以表示为函数。现在想要了解在张量上执行的 运算或操作，有必要探讨 TensorFlow 编程模块方面的解决方案。 3.7 通过一个示例来认识 TensorFlow 现在让我们结合示例对 TensorFlow 框架中的一些基本组件进行更多的解读。我们编写一个示 例来执行以下计算，这在神经网络中非常常见： 这里 W 和 x 是矩阵，b 是向量，*表示点积。 sigmoid 是一个非线性变换，由下式给出： h = sigmoid(W * x + b) sigmoid(cid:8)(cid:9)(cid:10)＝ １ １ (cid:11) e－(cid:2) 我们将逐步讨论如何通过 TensorFlow 进行上述计算。 首先，我们需要导入 TensorFlow 和 NumPy。在 Python 中运行任何类型的 TensorFlow 或 NumPy 相关操作之前，均必须导入它们： import tensorflow as tf import numpy as np 接下来，我们定义一个图对象，稍后将使用运算或操作和变量填充它们： graph = tf.Graph() # 创建一个图（graph）对象 session = tf.InteractiveSession(graph=graph) # 创建一个会话（session）对象",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 53
    }
  },
  {
    "page_content": "import tensorflow as tf import numpy as np 接下来，我们定义一个图对象，稍后将使用运算或操作和变量填充它们： graph = tf.Graph() # 创建一个图（graph）对象 session = tf.InteractiveSession(graph=graph) # 创建一个会话（session）对象 graph 对象包含一个计算图，该计算图连接我们在程序中定义的各种输入和输出，以获得最终 所需的输出（即它定义 W、x 和 b 如何被连接以便我们根据图生成 h）。此外，我们将定义一个会 话对象，该对象以定义的图作为输入，执行该图。我们后面会详细讨论这些元素。 要创建新的图对象，可以使用以下操作： graph = tf.Graph() 也可以使用以下操作来获取 TensorFlow 默认计算图： graph = tf.get_default_graph() 现在我们将定义一些张量，即 x、W、b 和 h。在 TensorFlow 中，定义张量有几种不同的方法， 在这里列出三种： （1）首先，x 是一个占位符。顾名思义，占位符没有被初始化。相反，我们将在图执行时提 供一些数值。 （2）其次，这里有变量 W 和 b。由于变量是可变的，这意味着它们的值可以随时间而变化。 （3）最后，我们有 h，这是一个通过对 x、W 和 b 执行一些操作而产生的不可变的张量： 46 | TensorFlow 与自然语言处理应用 x = tf.placeholder(shape=[1,10],dtype=tf.float32,name='x') W = tf.Variable(tf.random_uniform(shape=[10,5], minval=-0.1,maxval=0.1, dtype=tf.float32),name='W') b = tf.Variable(tf.zeros(shape=[5],dtype=tf.float32),name='b') h = tf.nn.sigmoid(tf.matmul(x,W) + b) 注意，对于 W 和 b，我们提供了一些重要的参数： tf.random_uniform(shape=[10,5], minval=-0.1, maxval=0.1,dtype=tf.float32) tf.zeros(shape=[5],dtype=tf.float32)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 54
    }
  },
  {
    "page_content": "h = tf.nn.sigmoid(tf.matmul(x,W) + b) 注意，对于 W 和 b，我们提供了一些重要的参数： tf.random_uniform(shape=[10,5], minval=-0.1, maxval=0.1,dtype=tf.float32) tf.zeros(shape=[5],dtype=tf.float32) 这些被称为变量初始化器，是最初分配给 W 和 b 变量的张量。变量不能在没有初始值的情况 下作为占位符流动，并且需要始终为它们分配一些数值。这里，tf.random_uniform 意味着我们在 minval(-0.1)和 maxval(0.1)之间均匀地采样以将值赋给张量，并且 tf.zeros 用零初始化张量。在定义 张量时，定义张量的 shape 也非常重要。 shape 属性定义张量每个维度的大小。例如，如果形状（shape） 是[10,5]，这意味着它将是一个二维结构，在 0 轴上有 10 个元素，在 1 轴上有 5 个元素。 接下来，我们将进行初始化操作，初始化图中的变量 W 和 b： tf.global_variables_initializer().run() 现在，将执行计算图以获得我们需要的最终输出 h。这是通过运行 session.run(...)来完成的，我 们将以占位符的值作为 session.run()命令的参数： h_eval = session.run(h,feed_dict={x: np.random.rand(1,10)}) 最后，关闭会话，释放 session 对象持有的所有资源。 session.close() 以下是此 TensorFlow 示例的完整代码。本章中的所有代码示例都将在 ch3 文件夹中的 3_tensorflow_introduction.ipynb 文件中提供： import tensorflow as tf import numpy as np # 定义 graph 和 session graph = tf.Graph() # Creates a graph session = tf.InteractiveSession(graph=graph) # Creates a session # 构建 graph # 占位符是一种符号输入 x = tf.placeholder(shape=[1,10],dtype=tf.float32,name='x') W = tf.Variable(tf.random_uniform(shape=[10,5], minval=-0.1,maxval=0.1, dtype=tf.float32),name='W') # 相关变量",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 55
    }
  },
  {
    "page_content": "# 构建 graph # 占位符是一种符号输入 x = tf.placeholder(shape=[1,10],dtype=tf.float32,name='x') W = tf.Variable(tf.random_uniform(shape=[10,5], minval=-0.1,maxval=0.1, dtype=tf.float32),name='W') # 相关变量 # 相关变量 b = tf.Variable(tf.zeros(shape=[5],dtype=tf.float32),name='b') 第 3 章 TensorFlow | 47 h = tf.nn.sigmoid(tf.matmul(x,W) + b) # Operation to be performed # 在图中执行操作和评估节点 tf.global_variables_initializer().run() # 初始化变量 #通过为输入 x 提供数值来运行该操作 h_eval = session.run(h,feed_dict={x: np.random.rand(1,10)}) # 关闭会话以释放会话中的所有已保存资源 session.close() 3.8 TensorFlow 客户端 前面的示例程序可以称为 TensorFlow 客户端，本节结合示例和上面的内容，对 TensorFlow 客 户端做详细的解读。在使用 TensorFlow 编写的任何客户端程序中，主要将有两种主要类型的对象： 运算（Operation）和张量（Tensor）。在前面的例子中，tf.nn.sigmoid 是一个运算，h 是张量。 然后，这里还有一个 graph 对象，它是存储程序数据流的计算图。当我们在代码中添加定义的 x、W、b 和 h 的后续代码行时，TensorFlow 会自动将这些张量（Tensor）和每个运算（Operation） （例如，tf.matmul()）作为节点添加到图中。该图将存储重要信息，例如张量的依赖性以及要执行 的运算。在我们的示例中，如果要计算 h，那么张量 x、W 和 b 是必需的。因此，如果在运行时没 有正确初始化其中一个参数，TensorFlow 将在这里指出需要修正的具体的初始化错误。 接着，由前面内容，我们知道会话（Session）将扮演执行计算图的角色，方法是将图划分为 子图、更精细的图，然后将这些图分配给将执行指定任务的 worker，这是通过 session.run(...)函数 来完成的。下面，我们来看看 TensorFlow 架构中执行客户端时的情况。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 56
    }
  },
  {
    "page_content": "接着，由前面内容，我们知道会话（Session）将扮演执行计算图的角色，方法是将图划分为 子图、更精细的图，然后将这些图分配给将执行指定任务的 worker，这是通过 session.run(...)函数 来完成的。下面，我们来看看 TensorFlow 架构中执行客户端时的情况。 大家知道，TensorFlow 擅长创建一个包含所有依赖关系和运算的精确计算图，且它能够准确 地知道数据流以何种方式、何时、在哪里流动。当然，还有一个元素使得 TensorFlow 变得更优秀， 那就是能够有效执行计算图的会话（Session），这也是会话进入 TensorFlow 架构的入口之处。现 在让我们来看看会话的内部情况，以了解图形是如何被执行的。 首先，由前面的介绍，我们知道 TensorFlow 客户端中的相关元素有计算图、张量和会话。创 建会话时，它会将计算图作为 tf.GraphDef 协议缓冲区发送到分布式架构的主机。 tf.GraphDef 是图 的标准化表示。分布式主服务器查看图中的所有计算，并将计算划分到不同的设备（例如，不同的 GPU 和 CPU）。我们的 sigmoid 示例中的计算图如图 3-6 所示。 接下来，计算图将被分解为子图，并进一步细分为更细的部分，这在具有许多隐藏层的现实世 界解决方案中意义更大。此外，为了并行地执行任务（例如，多个设备），将计算图分解为多个部 分就变得很重要。执行此图（若该图被划分为子图，则执行子图）称为单个任务，其中任务被分配 给单个 TensorFlow 服务器。 48 8 | T Tens sorF Flow w 与 与自 然语 语言 言处理 理应 应用 图 3-6 客 客户端 端的计 计算 算图 然而 然 执 行的 的： (cid:2) (cid:2) (cid:2) (cid:2) ，在 现实 实中 ，每 个任 任务 都是 是通 过将 将其 分解 解为 两个 个部 分来 来执 行的 的，每 每个 个部分 分都 是由 由单 单个 w work ker 一个 个 w worke er 使 使用 参数 数的 当前 前值 （运 运算执 执行 行器 ）执 执行 Ten nsor rFlow w 操 。 操作。 一个 个 w worke er 存 存储 参数 数， 并使 使用执 执行 行运 算器 器后 获得 得新值 值来 来更新 新它 它们 （参 参数服 服务 务器 ）。 Tens T orFl low 客户 户端 端的通 通用 用工作 作流 流程如",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 57
    }
  },
  {
    "page_content": "行器 ）执 执行 Ten nsor rFlow w 操 。 操作。 一个 个 w worke er 存 存储 参数 数， 并使 使用执 执行 行运 算器 器后 获得 得新值 值来 来更新 新它 它们 （参 参数服 服务 务器 ）。 Tens T orFl low 客户 户端 端的通 通用 用工作 作流 流程如 如图 图 3-7 7 所 示。 图 3-7 图 7 T Tenso orFlo ow 客 客户 端的 的通用 用执 行路 路线图 图 图 3- 图 -8 说 说明了 了计 计算图 图的 的分解 解情 情况。 。除 除了分 分解 解计算 算图 图之外 外，T Ten nsorF Flow w 还 还插入 入发 发送节 节点 和接 接收 收节 点 ，以 以利于 于参 参数服 服务 务器和 和运 运算执 执行 行器之 之间 间的通 通信 信。我 我们 们可以 以理 理解为 为每 每当数 数据 据可用 用时 时，发 发送 送节点 点就 就发 送 数据 据， 其中 中接 收节 节点 在对 对应 的发 发送 节点 点发 送数 数据 时继 继续 侦听 听和 捕获 获数 数据。 第 3 章 TensorFlow | 49 图 3-8 计算图的分解情况 最后，一旦计算完成，会话就将更新的数据从参数服务器端带回到客户端。从现在技术角度来 看，我们也可以给出 TensorFlow 的技术架构，如图 3-9 所示。此解释基于 https://tensorflow.google.cn/ extend/architecture 上的官方 TensorFlow 文档。 图 3-9 TensorFlow 技术架构 3.9 TensorFlow 中常见元素解读 在了解底层架构的同时，我们下面将介绍构成 TensorFlow 客户端中最常见的元素。 (cid:2) 输入（Input）：用于训练和测试算法的数据。 50 | TensorFlow 与自然语言处理应用 (cid:2) 变量（Variable）：可变张量，主要定义算法的参数。 (cid:2) 输出（Output）：存储终端和中间输出的不可变张量。 (cid:2) 运算或操作（Operation）：输入的各种变换以产生期望的输出。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 58
    }
  },
  {
    "page_content": "(cid:2) 输入（Input）：用于训练和测试算法的数据。 50 | TensorFlow 与自然语言处理应用 (cid:2) 变量（Variable）：可变张量，主要定义算法的参数。 (cid:2) 输出（Output）：存储终端和中间输出的不可变张量。 (cid:2) 运算或操作（Operation）：输入的各种变换以产生期望的输出。 在之前的 sigmoid 示例中，我们可以找到相关类别的实例，如表 3-2 中所示。 表 3-2 sigmoid 例子中相关类别的实例 TensorFlow 元素 示例客户端的值 Input—输入 Variable—变量 Output—输出 x W 和 b h Operation—运算操作 tf.matmul(...), tf.nn.sigmoid(...) 接下来，我们将详细解读 TensorFlow 中的这些元素。 3.9.1 在 TensorFlow 中定义输入 客户端主要以下面三种不同的方式接收数据： (cid:2) 使用 Python 代码在算法的每个步骤中提供数据。 (cid:2) 将数据预加载并存储为 TensorFlow 张量。 (cid:2) 构建输入管道。 接下来，具体看看这三种不同的方式。 1. 使用 Python 代码提供数据 在第一种方法中，可以使用传统的 Python 代码方法将数据提供给 TensorFlow 客户端。在我们 之前的示例中，x 是此方法的示例。为了从外部数据结构（例如，numpy.ndarray）向客户端提供数 据 ， TensorFlow 库 提 供 了 一 种 极 佳 的 数 据 结 构 符 号 ， 称 为 占 位 符 （ Placeholder ） ， 定 义 为 tf.placeholder(...)。前面我们说过，占位符在计算图构建阶段不需要实际数据，相反，我们仅通过执 行 session.run(...，feed_dict = {placeholder：value})调用的图时提供数据，方法是将外部数据以 Python 字典的形式传递给 feed_dict 参数。占位符的定义如下： tf.placeholder(dtype, shape=None, name=None) 参数如下： (cid:2) dtype：这是提供占位符的数据的类型。 (cid:2) shape：这是占位符的 shape，以一维向量给出。 (cid:2) name：这是占位符的名称，对于调试很重要。 第 3 章 TensorFlow | 51 2. 将数据预加载并存储为张量",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 59
    }
  },
  {
    "page_content": "参数如下： (cid:2) dtype：这是提供占位符的数据的类型。 (cid:2) shape：这是占位符的 shape，以一维向量给出。 (cid:2) name：这是占位符的名称，对于调试很重要。 第 3 章 TensorFlow | 51 2. 将数据预加载并存储为张量 第二种方法与第一种方法类似，但有一点需要注意。我们不必在计算图执行期间提供数据，因 为数据是预先加载的。为了了解这一点，让我们修改一下 sigmoid 示例，将 x 定义为占位符： x = tf.placeholder(shape=[1,10],dtype=tf.float32,name='x') 另外，也将 x 定义为包含具体数值的张量： x = tf.constant(value=[[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]], dtype=tf.float32,name='x') 其完整代码将变为如下： import tensorflow as tf # 定义 graph 和 session graph = tf.Graph() session = tf.InteractiveSession(graph=graph) # 创建计算图 graph #x - 预加载的输入 x = tf.constant(value=[[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]], dtype=tf.float32,name='x') W = tf.Variable(tf.random_uniform(shape=[10,5], minval=-0.1, maxval=0.1, dtype=tf.float32),name='W') # 变量 # 相关变量 b = tf.Variable(tf.zeros(shape=[5],dtype=tf.float32),name='b') h = tf.nn.sigmoid(tf.matmul(x,W) + b) # 将要执行的运算 # 在图中执行运算和评估节点 tf.global_variables_initializer().run() # 初始化变量 #执行不带有 feed_dict 的运算 h_eval = session.run(h) print(h_eval) #关闭会话，释放资源 session.close()",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 60
    }
  },
  {
    "page_content": "print(h_eval) #关闭会话，释放资源 session.close() 其实，可以发现这里与原来 sigmoid 示例存在两个主要区别。我们以不同的方式定义了 x。现 在直接指定一个具体值并将 x 定义为张量，而不是使用占位符对象并在计算图执行时输入实际值。 另外，正如你看到的，我们在 session.run(...)中不会提供任何额外的参数。但是，在缺点方面，现 在我们无法在 session.run(..)处向 x 提供不同的值并查看输出是如何变化的。 3. 构建数据输入管道 输入管道是专门为需要快速处理大量数据的“重量级”客户端而设计的。这实际上创建了一个 保存数据的队列，直到等到需要它的时候为止。TensorFlow 还提供了各种预处理步骤（例如，用 于调整图像对比度/亮度或者标准化），在将数据提供给算法之前执行。为了提高效率，可以让多 52 2 | T Tens sorF Flow w 与 与自 然语 语言 言处理 理应 应用 个 线程 程并 行读 读取 和处 处理 理数据 据。 （1） 数 据输 输入 管道 道的 构 结构 道也可 Tens T orFl low 数据 据输 输入管 管道 可以 以被抽 抽象 象为一 一个 个 ET TL 过程 程（E Extr ract、 、Tr rans sform m、 Loa ad） 。 (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) Ext tract t：从 orm： 剪、翻 Tra 机裁 ansfo 裁剪 从硬盘 盘上 上读取 取数 数据， 可以 以是 是本地 ：使 使用 去解 解析、 、预 预处理 PU 去 CP 色变换 颜色 翻转 转、颜 换） 、打 打乱 地（H 理数 HDD 数据 D 或 ，比 或 SS 比如 D）， 图像 ，也可 可以 以是 网盘 像解码 码、 数 据增 、变 变换 GCS 盘（G 增强 或 H HDF 换（比 ）。 FS） 如随 比如 Loa ad： 将 Tra ansfo orm 后 的数 数据加 加载 备， 例如 如 G GPU TPU U 等 设备 备。 乱（s 载到计 shuff 计算 fle） 算设备 、分 分批 批量 （ba hing ）。 atch U、T 这种 这 模式 式有 效地 地利 用了 了 C CPU",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 61
    }
  },
  {
    "page_content": "Loa ad： 将 Tra ansfo orm 后 的数 数据加 加载 备， 例如 如 G GPU TPU U 等 设备 备。 乱（s 载到计 shuff 计算 fle） 算设备 、分 分批 批量 （ba hing ）。 atch U、T 这种 这 模式 式有 效地 地利 用了 了 C CPU U，从 从而 让 GPU U、 TPU U 等 等设 备专 专注 于进 进行 模型 型的 训练 练过 过程 （提 提高 了 设备 备的 具体 具 (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) (cid:2) 利用 用率 ）。 来看 看， 典型 型的 管道 道将 包含 含以 下组 组件 ： 文件 件名 列表 表。 文件 件名 队列 列， 为输 输入 入（记 记录 录）阅 阅读 读器生 生成 成文件 件名 。 用于 于读 读取输 输入 入的记 记录 录阅读 读器 器（记 记录 录）。 解码 码读 读取记 记录 录的解 解码 码器 （例 如， PEG JP 图像 像解 解码） ）。 预处 处理 理步骤 骤（ 可选 选） 一个 个示 示例 （解 解码输 输入 。 入）队 队列 。 ）的 的应用 用， 使得 得以 越来 来越 越快的 的速 速度训 训练 神经 经网 络成 成为 可 的瓶 瓶颈。 。tf.d data API 提供数 I 提 数据 据输入 入管 道所 所需 的各 各种 种部件 件， ract Extr 据时， 数据 、T rans 计算设 计 sform 设备 m 训 处于 训练 练数据 据， 然后 后将 其提 提供 供给计 计算 算设 于闲 置状 状态 态；当 当计 计算设 设备 备执行 行训 练 （2） 随着 随 数 据输 输入 管道 道（ 新的 的计 算设 设备 （例 能 可 ，CP 以对 PU 处 对数 处理 理方式 式很 很容易 易遇 遇到海 据输 输入 管道 道进 行优 优化 在执 在 备 上运 运行 行一 一个 训练 的模 模型 。在 练 st 在以 tep 前， Pipe 例如 的优 优化 eline",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 62
    }
  },
  {
    "page_content": "数 据输 输入 管道 道（ 新的 的计 算设 设备 （例 能 可 ，CP 以对 PU 处 对数 处理 理方式 式很 很容易 易遇 遇到海 据输 输入 管道 道进 行优 优化 在执 在 备 上运 运行 行一 一个 训练 的模 模型 。在 练 st 在以 tep 前， Pipe 例如 的优 优化 eline e）的 U 和 量数据 GP 海量 和 TP 据计 PU） 计算的 。 前， 之前 必须 须先 先做 在准 准备数 当 CP 态。因 U 在 因此 型时 时，C 行训 CPU 练 执行 p 时 操作 step ng 操 ep 时 的时间 linin 练 ste p 的 我们 们没 时， CP 将取 间将 有进 进行 P Pipel 训练 个训 练 step 如果 如 时间的 的总 。 总和。 ep 中 练 ste 将为 PU 将 模 备 N 训 如 U 又 又处于 于闲 闲置状 状态 此，单 单个 训练 练 st tep 的时 时间 等于 于 C CPU U 准 准备数 数据 的时 时间 和计 计算 算设 作将训 训练 中的 的数据 据准 准备和 和模 模型执 执行 行实现 现了 了并行 行操 操作 。当 当计 算设 设备 备在执 执行 个训 练 为第 准备 N+ 备数据 +1 个 据的 时间 间和 step 和计算 p 准 算设 CPU 管道 U 准 道化 （P Pipel linin ng） 操作 作， CPU U 和 和 GP PU/T TPU 设备执 执行 行训练 练 st tep U 中 的时 时间 间中的 的较 较大值 值。 大部 部分 时间 间处 于空 空闲 状态 态， 准备数 数据 据。这 这样 样，通 通过 过两个 个过 过程的 的重 重叠， 行第 单个 单 图 3 3-10 0 所示 示。 图 3-1 图 10 没有 有使用 用 Pi ipeli ining g 操作 作的 的 CPU U 和 和 GP PU / T TPU U 处于 于空 空闲状 状态的 的时 间示 图 示意图 用 P Pipe elinin ng 操 操作 作，C CPU U 和 第 3 3 章 章 T Tens sorF Flow",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 63
    }
  },
  {
    "page_content": "用 Pi ipeli ining g 操作 作的 的 CPU U 和 和 GP PU / T TPU U 处于 于空 空闲状 状态的 的时 间示 图 示意图 用 P Pipe elinin ng 操 操作 作，C CPU U 和 第 3 3 章 章 T Tens sorF Flow w | 5 53 GPU U/TP PU 中处 处于 空闲 闲状 态的 的时 间显 显著 减少 少， 如图 图 3- -11 3-1 1 使 使用 Pip elini ing 操 操作 的 C CPU 和 G GPU U/TPU U 处 处于空 空闲状 状态 态的时 时间示 示意 意图 示 提示 提 我们 我 如果 果使 所 示。 图 有 关 有 关 更 更 多 pipel p line_ _stru uctu 上有 有关数 数据 信 息 息 ， ure 上 请 参 请 阅 http 据输入 ps:// 入管 /tens 管道的 sorf 的官 flow 官方说 w.goo 说明 ogle. 。 .cn/g guid de/pe erfo rma ance/ /data aset s#in _ nput_ （3） 让我 让 编 写输 输入 管道 道示 们使 使用 Ten nsor 例 w 编 rFlow t 和 5、0 text 0.6、 文 件（ xt1.tx （tex 0.2、 xt，t 3、0 text2 0.4、 0.3 2.txt 0.5 0.1 1、0 t3.tx xt）， 7、0 0.7 0.8、 0.9 9、1 有 1 我们 0 个 们具 接着 着， 体来 来看 看一下 下。 ，每 个文 文件 ，每 每行有 个用逗 逗号 号分隔 示例 例行 行： 编写一 一个 个输入 入管 管道示 示例 例。在 在这 这个例 例子 子中， ，我 我们有 有三 格式的 的文 文本 三个 C 隔的 CSV 的数字 V 格 字（ 有 5 1.0） 5 行 。 示 提示 提 更多 更 相关 关信 请 参阅 信息， 的 Ten 阅 ht w 官 ttps:/ 官方说 //ten 说明 nsor 明。 导入 导 入数据 据的 nsor rFlow flow w.go ogle e.cn/ /pro gram",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 64
    }
  },
  {
    "page_content": "的文 文本 三个 C 隔的 CSV 的数字 V 格 字（ 有 5 1.0） 5 行 。 示 提示 提 更多 更 相关 关信 请 参阅 信息， 的 Ten 阅 ht w 官 ttps:/ 官方说 //ten 说明 nsor 明。 导入 导 入数据 据的 nsor rFlow flow w.go ogle e.cn/ /pro gram mme ers_ _guid de/re eadi ng_ _data a 上有 关 有关 首先 首 ，和 和以 前一 一样 导入 入一 些重 重要 的库 库： im mpo im mpo rt ten nsor rflo ow as tf rt num mpy as np p 接下 接 来， 我 们将 将定 义计 计算 图 g grap ph 和 和会话 话 se essi on 对 对象 象： gr rap se ess h = = tf f.Gr raph h() ion n = tf .Int ter ract tive eSes ssi on( gra aph= =gr aph ) 然后 然 ，我 我们 将定 定义 义一个 个文 文件名 名队 队列， 一 一个包 包含 含文件 件名 名的队 队列 列数据 据结 结构 。这 这将 作为 为参 数传 传递 递给 后面 将被 被定 义） 。 队列 列将 根据 据 re eader r 的 请求 求生 生成文 文件 件名， 以 便读 读者 者可以 以使 使用这 这些 些文件 件名 获 rea 取 ader 文件 r（后 件进 而读 读取 数据 据： fi ile fi ile nam mes = ['te est %d. txt t'%i i f or i i in r ran ge( 1,4 4)] nam me_q queu ue = = t f.t trai in.s str ing g_in nput t_p rod duce er(f file ena mes s, c capa acit ty= =3, sh huff fle= =Tru ue, nam me=' 'str rin g_i inpu ut_p prod duc cer' ) 这里 这 数 据进 进行 ，ca 重新",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 65
    }
  },
  {
    "page_content": "str ing g_in nput t_p rod duce er(f file ena mes s, c capa acit ty= =3, sh huff fle= =Tru ue, nam me=' 'str rin g_i inpu ut_p prod duc cer' ) 这里 这 数 据进 进行 ，ca 重新 apac 新打 city 乱 （shu uffle 。 e）。 是在 在给 给定时 时间 时队 队列 中保 保存 存的数 数据 据量， shu uffle e 告 告诉队 队列 列是否 否在 发出 出数 数据之 之前 前对 54 | TensorFlow 与自然语言处理应用 TensorFlow 有几种不同类型的 reader（https://tensorflow.google.cn/api_guides/python/io_ops#Readers 上提供了可用 reader 列表）。由于我们有一些单独的文本文件，其中一行代表一个数据点，因此， 这里 TextLineReader 是最适合的： reader = tf.TextLineReader() 在定义 reader 之后，我们可以使用 read()函数从文件中读取数据。它输出的是“键-值”对。该 键识别出文件和该文件中正在读取的记录（文本行），我们可以省略这个。该值返回 reader 所读取 行的实际值： key, value = reader.read(filename_queue, name='text_read_op') 下面我们将定义 record_defaults，如果发现存在任何错误记录提示，将给出如下输出： record_defaults = [[-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0],[-1.0], [-1.0], [-1.0], [-1.0]] 现在，我们将读取的文本行解码为数字列（就像我们的 CSV 文件一样）。为此，我们使用 decode_csv()方法。打开文件（例如，test1.txt），将看到在一行中有 10 列： col1, col2, col3, col4, col5, col6, col7, col8, col9, col10 =tf.decode_csv(value, record_defaults=record_defaults)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 66
    }
  },
  {
    "page_content": "decode_csv()方法。打开文件（例如，test1.txt），将看到在一行中有 10 列： col1, col2, col3, col4, col5, col6, col7, col8, col9, col10 =tf.decode_csv(value, record_defaults=record_defaults) 然后，我们将连接这些列来组成单个张量（称之为特征），这些张量将被传递给另一个方法 tf.train.shuffle_batch()。 tf.train.shuffle_batch()方法采用先前定义的张量，随机填充张量并输出一批 给定的批量大小： features = tf.stack([col1, col2, col3, col4, col5, col6, col7, col8,col9, col10]) x = tf.train.shuffle_batch([features], batch_size=3, capacity=5, name='data_batch', min_after_dequeue=1, num_threads=1) batch_size 参数是我们在给定 step 中采样的数据批量大小，capacity 是数据队列的容量（大型 队列需要更多内存），min_after_dequeue 表示部分元素出队后还留在队列中的最小元素数量。最后， num_threads 定义了用于生成一批数据的线程数。如果管道中进行了大量预处理，可以增加这个线 程数量。此外，如果我们需要在不进行 shuffle 的情况下读取数据（与 tf.train.shuffle_batch 一样）， 就可以调用 tf.train.batch 方法。接着，我们将通过以下命令来启动此管道： coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(coord=coord, sess=session) 可以将 tf.train.Coordinator()类看成为线程管理器。它控制着各种管理线程的机制。我们需要 f.train.Coordinator()类，因为输入管道产生许多线程来填充入队队列、出列队列以及许多其他任务。 接下来，我们将使用之前创建的线程管理器去执行 tf.train.start_queue_runners(...)。QueueRunner() 保存队列的入队操作，这些操作是在定义输入管道时自动创建的。因此，要填充已定义的队列，我 第 3 章 TensorFlow | 55",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 67
    }
  },
  {
    "page_content": "第 3 章 TensorFlow | 55 们需要调用 tf.train.start_queue_runners 函数来启动这些队列运行的程序。 接下来，在指定任务完成之后，我们需要停止相关线程并将它们连接到主线程，否则眼前的程 序将无限期挂起。这是通过调用 coord.request_stop()和 coord.join(threads)来实现的。这个数据输入 管道与我们的 sigmoid 示例相结合，便能够直接从文件中读取数据，如下所示： import tensorflow as tf import numpy as np import os # 定义 graph 和 session graph = tf.Graph() session = tf.InteractiveSession(graph=graph) ### 创建数据输入管道 ### # 文件名队列 filenames = ['test%d.txt'%i for i in range(1,4)] filename_queue = tf.train.string_input_producer(filenames, capacity=3, shuffle=True,name='string_input_producer') # 检查所有文件是否存在 for f in filenames: if not tf.gfile.Exists(f): raise ValueError('Failed to find file: ' + f) else: print('File %s found.'%f) #reader 接受一个文件名队列和 read()函数，read()函数依次输出数据 reader = tf.TextLineReader() # 输出“键-值”对 key, value = reader.read(filename_queue, name='text_read_op') # 如果在读取文件时遇到任何问题，这是返回的值 record_defaults = [[-1.0], [-1.0], [-1.0], [-1.0], [-1.0], [-1.0],[-1.0], [-1.0], [-1.0], [-1.0]] # 将读取到的数值解码为列 col1, col2, col3, col4, col5, col6, col7, col8, col9, col10 = tf.decode_csv(value, record_defaults=record_defaults)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 68
    }
  },
  {
    "page_content": "[-1.0], [-1.0]] # 将读取到的数值解码为列 col1, col2, col3, col4, col5, col6, col7, col8, col9, col10 = tf.decode_csv(value, record_defaults=record_defaults) # 现在我们将这些列叠加在一起，形成一个包含所有列的单个张量 features = tf.stack([col1, col2, col3, col4, col5, col6, col7, col8,col9, col10]) # 输出 x 被随机分配一批 batch_size 数据，其中从.txt 文件中读取数据 x = tf.train.shuffle_batch([features], batch_size=3, capacity=5, name='data_batch',min_after_dequeue=1,num_threads=1) #QueueRunner 从队列中检索数据，我们需要显式地启动它们 # Coordinator 协调多个 QueueRunners coord = tf.train.Coordinator() threads = tf.train.start_queue_runners(coord=coord, sess=session) 56 | TensorFlow 与自然语言处理应用 # 通过定义变量和计算来构建计算图 W = tf.Variable(tf.random_uniform(shape=[10,5], minval=-0.1,maxval=0.1, dtype=tf.float32),name='W') # 变量 # 相关变量 b = tf.Variable(tf.zeros(shape=[5],dtype=tf.float32),name='b') h = tf.nn.sigmoid(tf.matmul(x,W) + b) # 要执行的运算 #在图中执行运算和评估各节点 tf.global_variables_initializer().run() # 初始化变量 # 用 x 计算 h 并打印 5 个步的结果 for step in range(5): x_eval, h_eval = session.run([x,h]) print('========== Step %d =========='%step) print('Evaluated data (x)') print(x_eval) print('Evaluated data (h)') print(h_eval)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 69
    }
  },
  {
    "page_content": "x_eval, h_eval = session.run([x,h]) print('========== Step %d =========='%step) print('Evaluated data (x)') print(x_eval) print('Evaluated data (h)') print(h_eval) print('') # 关闭 coordinator，否则程序将无限期挂起 coord.request_stop() coord.join(threads) session.close() 3.9.2 在 TensorFlow 中定义变量 变量在 TensorFlow 中扮演着重要角色。变量本质上是一个张量，具有特定的形状（shape）， 该形状（shape）用于定义变量将具有多少个维度以及每个维度的大小。然而，与常规张量不同， 变量是可变的，也就意味着变量的值在定义后是可以改变的。这是实现学习模型参数（例如，神经 网络权重值）的理想属性，其中权重值在每个学习步骤之后会稍有变化。例如，如果使用 x = tf.Variable(0,dtype=tf.int32)定义变量，则可以使用诸如 tf.assign(x,x+1)之类的 TensorFlow 运算来更 改该变量的值。但是，如果这样定义张量，例如 x = tf.constant(0，dtype = tf.int32)，就无法更改该 张量的值，它应该保持 0 的状态直到程序执行结束。 变量的创建很简单。在我们 sigmoid 的示例中，已经创建了两个变量 W 和 b。在创建变量时， 有一些事情非常重要，在这里列出它们并在后续中详细讨论： (cid:2) Variable shape：变量形状。 (cid:2) Data type：数据类型。 Initial value：初始值。 (cid:2) (cid:2) Name (optional)：名称（可选）。 变量形状是[x，y，z，...]格式的一维向量。列表中的每个值表示相应维度或轴的大小。例如， 如果需要具有 50 行和 10 列的二维张量作为变量，那其形状将是 [50,10]。 第 3 章 TensorFlow | 57 变量的维数（形状向量的长度）在 TensorFlow 中被识别为张量的秩。不要把它与矩阵的秩混 淆起来。 提示 TensorFlow 中张量的秩表示张量的维数；但对于二维矩阵来说，其秩等于 2。 其实，数据类型在确定变量大小方面起着重要作用。有许多不同的数据类型，包括常用的 tf.bool、",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 70
    }
  },
  {
    "page_content": "第 3 章 TensorFlow | 57 变量的维数（形状向量的长度）在 TensorFlow 中被识别为张量的秩。不要把它与矩阵的秩混 淆起来。 提示 TensorFlow 中张量的秩表示张量的维数；但对于二维矩阵来说，其秩等于 2。 其实，数据类型在确定变量大小方面起着重要作用。有许多不同的数据类型，包括常用的 tf.bool、 tf.uint8、tf.float32 和 tf.int32（代码中的字段类型，其意义基本上都是通用的，这和我们平时编写 Java 或.net 程序时用到的布尔类型、浮点类型、整数类型类似，而 unit8 是 8 位无符号整型）。每 种数据类型都具有属于该类型的单个值所需的位数（bit）。例如，tf.uint8 类型需要有 8 位，而 tf.float32 需要 32 位。通常的做法是使用相同的数据类型进行计算，否则会导致数据类型的不匹配。因此， 如果需要对两个具有不同数据类型的张量进行转换，需要使用 tf.cast(...)操作将一个张量显式地转 换为另一个张量的类型。例如，对于具有 tf.int32 数据类型的 x 变量，需要将其转换为 tf.float32 的 类型，tf.cast(x，dtype=tf.float32)的调用就是将 x 变量转换为 tf.float32 类型。 接下来，我们需要对变量进行初始化，TensorFlow 也提供了几种不同的初始化器，包括常数 初始化器和正态分布初始化器。 TensorFlow 一些主要的初始化器如下所示： (cid:2) (cid:2) (cid:2) (cid:2) tf.zeros tf.constant_initializer tf.random_uniform tf.truncated_normal 最后，变量的名称（name）将作为一个标识符（ID），使我们能够在图（Graph）中对该变量 进行识别。因此，如果我们对计算图进行可视化操作，那变量将通过传递 name 关键字参数的形式 进行显示。如果未指定名称，TensorFlow 将使用默认命名方案。 注意 Python 变量 tf.variable 是赋给计算图的，它不是 TensorFlow 变量命名的一部分。考虑下 面的示例，可以在其中指定 TensorFlow 变量： a = tf.Variable（tf.zeros（[5]），name ='b'） 这里，TensorFlow 的图将通过名称 b 而不是 a 来识别该变量。 3.9.3 定义 TensorFlow 输出",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 71
    }
  },
  {
    "page_content": "Python 变量 tf.variable 是赋给计算图的，它不是 TensorFlow 变量命名的一部分。考虑下 面的示例，可以在其中指定 TensorFlow 变量： a = tf.Variable（tf.zeros（[5]），name ='b'） 这里，TensorFlow 的图将通过名称 b 而不是 a 来识别该变量。 3.9.3 定义 TensorFlow 输出 TensorFlow 的输出通常是张量，可以是输入或变量或两者转换后的结果。在我们的例子中，h 是一个输出，其中 h = tf.nn.sigmoid（tf.matmul（x，W）+ b）。当然，有时候 TensorFlow 的一个 输出也可能变成下一个输入的内容，依次输出下去可以形成一组链式运算或操作，而这里的运算或 操作也不一定必须是 TensorFlow 运算或操作，还可以使用标准 Python 算法，例如： 58 | TensorFlow 与自然语言处理应用 x = tf.matmul(w,A) y = x + B z = tf.add(y,C) 3.9.4 定义 TensorFlow 运算或操作 在 https://tensorflow.google.cn/api_docs/python/上查看 TensorFlow API，你会发现 TensorFlow 有 大量可用的运算或操作。下面，我们将对 TensorFlow 中几个常见的运算或操作进行解读。 1．比较运算 比较运算对于比较两个张量非常有用。对于比较运算部分的详细资料，读者可以查阅 https://github.com/tensorflow/docs/tree/master/site/en/api_guides/python 中比较运算符的详细内容。当 然，对于比较运算工作原理的理解，通过代码层面可能会更直观些。这里，我们给出示例张量 x 和 y： #假设 x 和 y 的取值如下 #x (2-D tensor) => [[1,2],[3,4]] #y (2-D tensor) => [[4,3],[3,2]] x= tf.constant([[1,2],[3,4]], dtype=tf.int32) y= tf.constant([[4,3],[3,2]], dtype=tf.int32) # 检查两个张量在元素方面是否相等，并返回布尔类型的张量 # x_equal_y => [[False,False],[True,False]]",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 72
    }
  },
  {
    "page_content": "x= tf.constant([[1,2],[3,4]], dtype=tf.int32) y= tf.constant([[4,3],[3,2]], dtype=tf.int32) # 检查两个张量在元素方面是否相等，并返回布尔类型的张量 # x_equal_y => [[False,False],[True,False]] x_equal_y = tf.equal(x, y, name=None) #检查 x 在对应元素方面是否小于 y 并返回布尔类型的张量 # x_less_y => [[True,True],[False,False]] x_less_y = tf.less(x, y, name=None) # 检查 x 在对应元素方面是否大于或等于 y 并返回布尔类型的张量 # x_great_equal_y => [[False,False],[True,True]] x_great_equal_y = tf.greater_equal(x, y, name=None) # 从 x 和 y 中选择元素，具体取决于条件是否满足（从 x 中选择元素）或 # 条件失败（从 y 中选择元素） condition = tf.constant([[True,False],[True,False]],dtype=tf.bool) # x_cond_y => [[1,3],[3,2]] x_cond_y = tf.where(condition, x, y, name=None) 2. 比较数学运算 TensorFlow 允许我们对从简单到复杂的张量执行数学运算。这里我们将讨论 TensorFlow 中提 供 的 一 些 数 学 运 算 。 完 整 的 运 算 集 可 在 https://github.com/tensorflow/docs/tree/master/site/en/ api_guides/python 上找到。 第 3 章 TensorFlow | 59 #假设 x 和 y 的取值如下 #x (2-D tensor) => [[1,2],[3,4]] #y (2-D tensor) => [[4,3],[3,2]] x= tf.constant([[1,2],[3,4]], dtype=tf.float32) y = tf.constant([[4,3],[3,2]], dtype=tf.float32) # 以元素方式增加两个张量 x 和 y # x_add_y => [[5,5],[6,6]]",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 73
    }
  },
  {
    "page_content": "#y (2-D tensor) => [[4,3],[3,2]] x= tf.constant([[1,2],[3,4]], dtype=tf.float32) y = tf.constant([[4,3],[3,2]], dtype=tf.float32) # 以元素方式增加两个张量 x 和 y # x_add_y => [[5,5],[6,6]] x_add_y = tf.add(x, y) # 执行矩阵乘法（不是元素方面） # x_mul_y => [[10,7],[24,17]] x_mul_y = tf.matmul(x, y) # 计算 x 元素的自然对数，相当于计算 ln（x） # log_x => [[0,0.6931],[1.0986,1.3863]] log_x = tf.log(x) # 在指定轴上执行归约（reduction） # x_sum_1 => [3,7] x_sum_1 = tf.reduce_sum(x, axis=[1], keepdims=False) # x_sum_2 => [[4],[6]] x_sum_2 = tf.reduce_sum(x, axis=[0], keepdims=True) # 根据 segment_ids（同一段中具有相同 id 的项）对张量进行分段，并计算数据的分段总和 data = tf.constant([1,2,3,4,5,6,7,8,9,10], dtype=tf.float32) segment_ids = tf.constant([0,0,0,1,1,2,2,2,2,2 ], dtype=tf.int32) # x_seg_sum => [6,9,40] x_seg_sum = tf.segment_sum(data, segment_ids) 3. 比较分散（Scatter）和聚合（Gather）操作 随着人工智能的迅猛发展，尤其是 GPU 可编程性能的增强以及 GPGPU（General Purpose Computing on GPU，在图形处理器上进行通用计算）技术的不断发展，相关研究/技术人员也迫切 希望基于流处理器模型的 GPU 也可以和 CPU 一样，在支持流程分支的同时，也能够实现对存储器 进行灵活的读写操作。其实，Ian Buck 在进行早期的 GPU 通用可编程技术研究时，就发现 GPU 完 成复杂计算任务时存在一个关键性的缺陷，那就是缺乏灵活的存储器操作。所以，他在后来的研究 中就增加了对分散和聚合操作的支持，但是结果还是以牺牲一些性能为代价的情况下完成了整个过 程。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 74
    }
  },
  {
    "page_content": "中就增加了对分散和聚合操作的支持，但是结果还是以牺牲一些性能为代价的情况下完成了整个过 程。 在 GPU 中，CUDA 中分散和聚合操作实现的结构示意图与第一向量机中的很相似，分散允许 将数据输出到非连续的存储器地址内，而聚合则允许从非连续的存储器地址内读取数据。因此，如 果认为存储器（如 DRAM）是一个二维数组，分散则可以看作利用数组下标或索引将数据写入数 组中的任意位置，即 a[i] = x，而聚合则可以看作是利用数组下标或索引从数组中的任意位置读出 数据，即 x = a[i]。 下面，我们给出 CUDA 中分散（Scatter）和聚合（Gather）操作的结构示意图，如图 3-12 所 示。其中，每个 ALU 可以看作是一个处理核心，通过分散/聚合操作，多个 ALU 之间可以共享存 60 | TensorFlow 与自然语言处理应用 储器，实现对任意地址数据的读写操作。 图 3-12 CUDA 中分散（Scatter）和聚合（Gather）操作的结构示意图 分散和聚合操作在矩阵运算任务中起着至关重要的作用，因为目前来看这两种变体在 TensorFlow 中是把张量编入索引的唯一方法。换句话说，不能像在 NumPy 中那样访问 TensorFlow 中的张量元素。分散操作允许我们将值分配给指定张量的特定索引，而聚合操作允许我们提取指定 张量的切片（或单个元素）。以下代码显示了分散和聚合操作的一些变体： # 1-D scatter 操作 ref = tf.Variable(tf.constant([1,9,3,10,5],dtype=tf.float32), name='scatter_update') indices = [1,3] updates = tf.constant([2,4],dtype=tf.float32) tf_scatter_update = tf.scatter_update(ref, indices, updates, use_locking=None, name=None) # n-D scatter 操作 indices = [[1],[3]] updates = tf.constant([[1,1,1],[2,2,2]]) shape = [4,3] tf_scatter_nd_1 = tf.scatter_nd(indices, updates, shape, name=None) # n-D scatter 操作 indices = [[1,0],[3,1]] # 2 x 2",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 75
    }
  },
  {
    "page_content": "shape = [4,3] tf_scatter_nd_1 = tf.scatter_nd(indices, updates, shape, name=None) # n-D scatter 操作 indices = [[1,0],[3,1]] # 2 x 2 updates = tf.constant([1,2]) # 2 x 1 shape = [4,3] # 2 tf_scatter_nd_2 = tf.scatter_nd(indices, updates, shape, name=None) # 1-D gather 操作 params = tf.constant([1,2,3,4,5],dtype=tf.float32) indices = [1,4] 第 3 章 TensorFlow | 61 tf_gather = tf.gather(params, indices, validate_indices=True,name=None) #=> [2,5] # n-D gather 操作 params = tf.constant([[0,0,0],[1,1,1],[2,2,2],[3,3,3]],dtype=tf.float32) indices = [[0],[2]] tf_gather_nd = tf.gather_nd(params, indices, name=None) #=>[[0,0,0],[2,2,2]] params = tf.constant([[0,0,0],[1,1,1],[2,2,2],[3,3,3]],dtype=tf.float32) indices = [[0,1],[2,2]] tf_gather_nd_2 = tf.gather_nd(params, indices, name=None) #=>[[0,0,0],[2,2,2]] 4. 比较与神经网络相关的运算或操作 下面让我们看看几个很有用的神经网络运算或操作，这些将在后面的章节中使用到。这里，我 们会对简单元素的转换进行讨论，也会对一组参数对于另一个值的偏导数的运算进行讨论，并给出 一个简单的神经网络实现例子。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 76
    }
  },
  {
    "page_content": "#=>[[0,0,0],[2,2,2]] 4. 比较与神经网络相关的运算或操作 下面让我们看看几个很有用的神经网络运算或操作，这些将在后面的章节中使用到。这里，我 们会对简单元素的转换进行讨论，也会对一组参数对于另一个值的偏导数的运算进行讨论，并给出 一个简单的神经网络实现例子。 （1）神经网络的非线性激活 非线性激活能够使神经网络很好地执行许多任务。通常，在神经网络的每一层输出后（最后一 层除外）都会有一个非线性的激活转换（激活层）。非线性变换有助于神经网络学习数据中出现的 各种非线性模式。这对于解决现实世界中复杂的问题非常有用，因为与线性模式相比，数据通常具 有更复杂的非线性模式。 提示 让我们通过一个例子来观察一下非线性激活的重要性。首先，回想一下我们在 sigmoid 示例中看到的神经网络的计算。如果我们忽视 b，那将是这样的： h = sigmoid(W*x) 假设有一个三层神经网络（W1、W2 和 W3 是层的权重值），其中每层都执行前面的计算； 我们可以给出完整计算： h = sigmoid(W3*sigmoid(W2*sigmoid(W1*x))) 但是，如果我们删除非线性激活（sigmoid），我们就可以得到： h = (W3 * (W2 * (W1 *x))) = (W3*W2*W1)*x 因此，在没有非线性激活的情况下，可以将三个层降为单个线性层。 如果没有各层之间的非线性激活，深度神经网络就将是一堆相互叠加的线性层而已，而且一组 线性层基本上可以压缩成一个更大的线性层。综上所述，如果没有非线性激活，我们就无法创建具 62 | TensorFlow 与自然语言处理应用 有多个层的神经网络。 现在，我们将列出神经网络中两种常用的非线性激活函数以及它们是如何在 TensorFlow 中实 现的： #x 的 Sigmoid 激活由 1 /（1 + exp（-x））给出 tf.nn.sigmoid(x,name=None) #x 的 ReLU 激活由 max(0,x)给出 tf.nn.relu(x, name=None) ①卷积运算 卷积运算是一种广泛使用的信号处理技术。对于图像，卷积运算可以给出不同的图像效果。这 里，图 3-13 给出了使用卷积进行边缘检测（包括横向边缘检测和纵向边缘检测）的示例。我们可 以通过在图像顶部移动卷积过滤器以便在每个位置产生不同的输出来实现边缘检测，如图 3-14 所 示（在本书第 5 章介绍卷积神经网络时会详细解读卷积运算的工作原理）。具体来说，在每个位置， 我们使用与卷积过滤器重叠的图像块（与卷积过滤器相同的大小）对卷积过滤器中的元素进行逐元 素乘法，并获取乘法的总和。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 77
    }
  },
  {
    "page_content": "素乘法，并获取乘法的总和。 图 3-13 利用卷积运算在图像中进行边缘检测示意图 提示 源自 https://en.wikipedia.org/wiki/Kernel_(image_processing)。 以下是卷积运算的实现： x = tf.constant( [[ [[1],[2],[3],[4]], [[4],[3],[2],[1]], [[5],[6],[7],[8]], [[8],[7],[6],[5]] ]], dtype=tf.float32) x_filter = tf.constant( [ [ [[0.5]],[[1]] ], [ 第 3 章 TensorFlow | 63 [[0.5]],[[1]] ] ], dtype=tf.float32) x_stride = [1,1,1,1] x_padding = 'VALID' x_conv = tf.nn.conv2d( input=x, filter=x_filter, strides=x_stride, padding=x_padding ) 这里，对于 tf.conv2d(...)方法中涉及的 input 、filter 和 stride 等参数格式而言，TensorFlow 对 它们的要求是很精确的，下面我们将对这些参数（input、filter、strides、padding）做进一步的解释。 (cid:2) 输入（input）：通常是四维张量，其尺寸应按[batch_size，height，width，channels]排序。 ★ batch_size：这是一批数据中的数据量（例如，输入的图像和单词等）。我们通常按 批量处理数据，因为模型可以使用大型数据集进行深入学习。在给定的训练步骤（step） 中，我们随机抽样一小部分可以大致代表完整的数据集的数据，然后重复足够多次该",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 78
    }
  },
  {
    "page_content": "(cid:2) 输入（input）：通常是四维张量，其尺寸应按[batch_size，height，width，channels]排序。 ★ batch_size：这是一批数据中的数据量（例如，输入的图像和单词等）。我们通常按 批量处理数据，因为模型可以使用大型数据集进行深入学习。在给定的训练步骤（step） 中，我们随机抽样一小部分可以大致代表完整的数据集的数据，然后重复足够多次该 操作，我们便可以很好地逼近这个完整的数据集。此 batch_size 参数与我们在 TensorFlow 输入管道示例中讨论的参数相同。 ★ height and width：这是输入的高度和宽度。 ★ channels：这是输入的深度（例如，对于 RGB 图像，将为 3 通道）。 (cid:2) 过滤器（filter）：这是一个四维张量，表示卷积运算的卷积窗口。过滤器尺寸应为[height， width，in_channels，out_channels]。 ★ height and width：这是滤镜的高度和宽度（通常小于输入的高度和宽度）。 ★ in_channels：这是图层输入的通道数。 ★ out_channels：这是在图层输出中生成的通道数。 (cid:2) 步幅（strides）：这是一个包含四个元素的列表，具体为 [batch_stride，height_stride， width_stride，channels_stride]。 (cid:2) 填充（padding）：这里可以选择['SAME'，'VALID']中的任何一个选项。它能够决定如何 处理输入边界附近的卷积运算。VALID 操作是在没有填充的情况下执行卷积。如果我们 用大小为 h 的卷积窗口、卷积长度为 n 的输入，这将给出输出的尺寸（或大小）。输出 尺寸的减小会严重限制神经网络的深度。SAME 将零填充到边界，使输出具有与输入相 同的高度和宽度。 为了更好地了解过滤器大小、步幅和填充是什么，请参见图 3-14（我们在本书第 5 章介绍卷 积神经网络时做详细解读）。 644 | TTenssorFFloww 与与自然语语言言处理 理应 应用 图 3-1 图 14 卷积积网络络运运算示示意图图 第 3 章 TensorFlow | 65 ②池化操作 池化运算与卷积运算的行为类似，但最终输出是不同的。我们这里选取的是该位置中图像 patch 的最大元素，而不是输出过滤器和图像 patch 中按元素相乘得到的总和（我们在在本书第 5 章介绍 卷积神经网络中会做详细解读），如图 3-15 所示。 x = tf.constant(",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 79
    }
  },
  {
    "page_content": "第 3 章 TensorFlow | 65 ②池化操作 池化运算与卷积运算的行为类似，但最终输出是不同的。我们这里选取的是该位置中图像 patch 的最大元素，而不是输出过滤器和图像 patch 中按元素相乘得到的总和（我们在在本书第 5 章介绍 卷积神经网络中会做详细解读），如图 3-15 所示。 x = tf.constant( [[ [[1],[2],[3],[4]], [[4],[3],[2],[1]], [[5],[6],[7],[8]], [[8],[7],[6],[5]] ]], dtype=tf.float32) x_ksize = [1,2,2,1] x_stride = [1,2,2,1] x_padding = 'VALID' x_pool = tf.nn.max_pool( value=x, ksize=x_ksize, strides=x_stride, padding=x_padding ) 代码运行后返回的结果如下（完整代码和结果，读者可以查看代码文件中的“二维操作（2D 图 3-15 最大池化运算示意图 66 | TensorFlow 与自然语言处理应用 卷积和 2D 最大池化）”部分）： [[[[ 4.] [ 4.]], [[ 8.] [ 8.]]]] ③定义损失 为了让神经网络模型能够学习到有用的东西，我们需要定义一个损失函数。这里有几种可以自 动 计 算 TensorFlow 中 损 失 的 函 数 。 其 中 ， tf.nn.l2_loss 是 均 方 误 差 损 失 函 数 ， tf.nn.softmax_cross_entropy_with_logits_v2 是交叉熵损失函数。交叉熵损失函数在分类任务中能够 使模型表现更佳。这里涉及均方误差损失函数和交叉熵损失函数的代码如下： x = tf.constant([[2,4],[6,8]],dtype=tf.float32) x_hat = tf.constant([[1,2],[3,4]],dtype=tf.float32)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 80
    }
  },
  {
    "page_content": "x = tf.constant([[2,4],[6,8]],dtype=tf.float32) x_hat = tf.constant([[1,2],[3,4]],dtype=tf.float32) # MSE = (1**2 + 2**2 + 3**2 + 4**2)/2 = 15 MSE = tf.nn.l2_loss(x-x_hat) # 神经网络中用于优化网络的常见损失函数 # 使用 logits（最后一层的归一输出）代替输出来计算交叉熵,会使数值获得的更加稳定 y = tf.constant([[1,0],[0,1]],dtype=tf.float32) y_hat = tf.constant([[3,1],[2,5]],dtype=tf.float32) # 此函数并不能平均所有数据点的交叉熵损失，我们需要使用 reduce_mean 函数手动实现这一点 CE = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=y_hat, labels=y)) ④神经网络的优化 在定义了神经网络的损失函数之后，我们的目标是随着时间的推移尽量减少这种损失，这个过 程就是常说的模型优化工作。换言之，优化器的目标是找到为所有输入提供最小损失的神经网络参 数（权重值和偏差）。TensorFlow 为我们提供了几种不同的优化器，因此我们不需要从头开始实 现相关模型。 图 3-16 说明了一个简单的优化问题，并显示了优化是如何随时间变化的。该曲线可以想象为 损失曲线（对于高维空间的情况，我们称之为损失面），其中 x 可以被认为是神经网络的参数（在 这种情况下，是一个单一权重值的神经网络），y 可以被认为是损失。我们初步估计起始点是 x=2 位置。从这一点开始，我们使用优化器来实现在 x=0 处得到最小的 y（损失）。然而，在实际问题 中，损失表面不会像图 3-16 中所示的这么简单，它会更加复杂。 第 3 3 章 章 T Tens sorF Flow w | 6 67 图 3 3-16 6 优 优化过 过程 程示意 意图 在此 在 此示例 例中 ，我 我们 们使用 用的 的是常 常见 见的梯 梯度 度下 降优 优化法 法： entO Opti mize er。 lear rnin ng_ra ate 参 数表 表示 在最 最小 化方 方向 上的 的步 长 （图 3-1 6 中 中两个 个圆 圆点之 之间 Gr 间的距 radie 距离 Desc entD 离）： ： #优 tf 优化",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 81
    }
  },
  {
    "page_content": "的是常 常见 见的梯 梯度 度下 降优 优化法 法： entO Opti mize er。 lear rnin ng_ra ate 参 数表 表示 在最 最小 化方 方向 上的 的步 长 （图 3-1 6 中 中两个 个圆 圆点之 之间 Gr 间的距 radie 距离 Desc entD 离）： ： #优 tf 优化 化器起 起到调 调整 整神经 经网络 络参 参数的 的作用 用， 以便 便最小 小化 化工作 作任务 务中 中的错 错误 f_x = tf. .Var riab ble (tf f.co onst tan t(2 2.0, ,dty ype= =tf .fl loat t32) ),n ame e='x x') tf f_y = tf_ _x** *2 mi inim miz e_o op = = t f.t mi inim mize e(t f_y y) rai in.G Grad die ntD Desc cent tOp tim mize er(l lear rni ng_ _rat te=0 0.1 ). 完整 完 部 分。 执 代码 码详 见代 代码 行该 该部 分代 代码 文件 件 3_ 除 _ten 了会 sorf 会得 flow 到图 w_int 图 3- ucti trodu 之外 -16 之 on.ip 外，还 pynb 还会 b 中 会得到 后， （St 果： 到如 如下结 结果 中随机 机优 优化 toch astic c Op ptim miza ation n） 第 第 1 第 2 第 第 第 3 第 4 第 1 个 2 个 3 个 4 个 步长 步长 , x , x , x 长上, 长上, 长上, 长上, , x 步长 步长 : 1 1.2 8 , y: 2 .56 6000 002 : 1 1.02 239 999 9 , y: 1. .63 : 0 0.8 191 999 9 , y: 1. .04 : 0 0.65 553 599 9 , y: 0. .67 84 857 59 108 85 从上 从 运 算时 时， ⑤控 ⑤ 顾名 顾 面的 的代 码运 运行 结果 果来 看， 显然 然， 当我 我们 们每次 次调 调用",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 82
    }
  },
  {
    "page_content": ".63 : 0 0.8 191 999 9 , y: 1. .04 : 0 0.65 553 599 9 , y: 0. .67 84 857 59 108 85 从上 从 运 算时 时， ⑤控 ⑤ 顾名 顾 面的 的代 码运 运行 结果 果来 看， 显然 然， 当我 我们 们每次 次调 调用 sess sion n.run n(mi inim mize_ _op) )执行 行损 失最 最小 小化 将会 会接 近 t tf_x 值， 进而可 进 可以 以得到 到最 最小的 的 tf f_y 值 值。 制流 流操 作 控制 思义 义， 制流 操作 作控 制图 图中 的执 执行 顺序 序。 例如 如， 假设 设我 们需 需要 要按以 以下 顺序 序执 行计 计算 算： x = x+5 5 z = x*2 实际 实 上， 如 果 x x = 2， 我们 们应 应该得 得到 z = = 14 4。下 下面 面，让 让我 我们尝 尝试 试以一 一种 种简单 单的 方法 法来 来实现 现这 这一 点 ： se ess x = x_ _as ion n = tf .Int ter ract tive eSes ssi on( tf. Var riab ble sig gn_o op = = t (tf f.co onst tant t(2 .0) f.a assi ign (x, x+ 5) z = x*2 tf f.g pr rin pr rin lob bal_ _var riab ble s_i init tial liz er( t(' z=' ',se ess t(' x=' ',se ess ion n.ru un(z z)) ion n.ru un(x x)) ) , n name e='x x') ).r run () 68 | TensorFlow 与自然语言处理应用 session.close()",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 83
    }
  },
  {
    "page_content": "liz er( t(' z=' ',se ess t(' x=' ',se ess ion n.ru un(z z)) ion n.ru un(x x)) ) , n name e='x x') ).r run () 68 | TensorFlow 与自然语言处理应用 session.close() 我们期望的输出结果是 x = 7 和 z = 14，而在 TensorFlow 中，上面的代码运行结果却是 x = 2 和 z = 14。引起这种错误的原因是，TensorFlow 不关心对象的执行顺序，除非我们在程序中给出明 确的执行顺序。我们本部分讨论的控制流操作，就可以实现执行指定顺序的操作。为了得到期望的 运行结果（x = 7 和 z = 14），我们需要对上述代码进行调整，具体如下： session = tf.InteractiveSession() x = tf.Variable(tf.constant(2.0), name='x') with tf.control_dependencies([tf.assign(x, x+5)]): z = x*2 tf.global_variables_initializer().run() print('z=',session.run(z)) print('x=',session.run(x)) session.close() 这样一来，我们就可以得到想要的结果（x = 7 和 z = 14）了。这里，tf.control_dependencies（...） 方法是确保在执行嵌套操作之前将会优先执行参数传递给它的运算操作。读者也可以在代码文件 “调用 tf.control_dependencies(...)方法”部分执行这些代码并查看运行结果。 3.10 变量作用域机制 3.10.1 基本原理 目前为止，我们已经对 TensorFlow 架构和 TensorFlow 客户端的实现有了基本的认识。但是， 在深度学习过程中，一方面，我们需要减少训练参数的个数（比如 CNN 和 LSTM 模型）或是面对 多机多卡并行化训练大数据大模型（比如数据并行化）等情况；另一方面，当我们的深度学习模型 变得异常复杂的时候，往往存在大量的变量和调用方法，如何有效地维护这些变量名称和方法名称",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 84
    }
  },
  {
    "page_content": "目前为止，我们已经对 TensorFlow 架构和 TensorFlow 客户端的实现有了基本的认识。但是， 在深度学习过程中，一方面，我们需要减少训练参数的个数（比如 CNN 和 LSTM 模型）或是面对 多机多卡并行化训练大数据大模型（比如数据并行化）等情况；另一方面，当我们的深度学习模型 变得异常复杂的时候，往往存在大量的变量和调用方法，如何有效地维护这些变量名称和方法名称 的唯一性（即不重复），同时又能维护好一个条理清晰的图（Graph）就变得非常重要了。这时， 变量共享机制就变得非常重要。比如，我们构建 CNN、LSTM 等模型时，需要使用很多变量集去 验证权重值（Weight）和偏差（Bias）等训练参数，非常希望在输入不同的数据时这些参数是可以 共享的（本书 5.3.4 小节“参数共享机制”部分会进行详细解读）。过去，我们创建一个全局变量 就可以使用了，但在深度学习中则不可以，不方便管理而且使代码的封装性受到极大影响。所以， TensorFlow 提供了一种变量管理方法：变量作用域机制，以此解决上面出现的问题。 关于变量作用域机制，有的文档也叫共享变量机制，根据笔者查阅的文献资料，大部分文章的 参考资料来自于 TensorFlow 官方说明（详见 https://tensorflow.google.cn/guide/variables）。TensorFlow 中是通过调用四个函数来进行变量作用域共享的，这四个函数是 tf.Variable(<variable_name>)、 tf.get_variable(<variable_name>)、tf.name_scope(<scope_name>)和 tf.variable_scope(<scope_name>)。 下面，我们具体来看一下这几个函数。 第 3 章 TensorFlow | 69 如果使用 Variable，那么每次都会新建变量，但是大多数时候我们是希望一些变量可以重用的， 所以就用到了 get_variable()。get_variable()会去搜索变量名称，搜索结果如果没有就新建变量，如 果有就直接使用该变量。既然用到变量名称，这就会涉及名称域的概念。通过不同的域来对变量名 称加以区分，因为如果让我们给所有变量都直接取不同名字其实是非常辛苦的且没必要，这就是为 什么会用到作用域（Scope）的概念了。name_scope 主要用于图（Graph）中的各种运算，variable_scope 可以通过设置 reuse 标志以及初始化方式来影响作用域中的变量。当然对我们而言，还有一个更直 观的感受就是：在使用 tensorboard 可视化的时候用名字作用域进行封装后会更清晰。 3.10.2 通过示例解读",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 85
    }
  },
  {
    "page_content": "什么会用到作用域（Scope）的概念了。name_scope 主要用于图（Graph）中的各种运算，variable_scope 可以通过设置 reuse 标志以及初始化方式来影响作用域中的变量。当然对我们而言，还有一个更直 观的感受就是：在使用 tensorboard 可视化的时候用名字作用域进行封装后会更清晰。 3.10.2 通过示例解读 假设我们需要一个执行某种计算的函数，给定 w，需要计算 x * w + y ** 2。让我们编写一个 TensorFlow 客户端： import tensorflow as tf session = tf.InteractiveSession() def very_simple_computation(w): x = tf.Variable(tf.constant(5.0, shape=None, dtype=tf.float32),name='x') y = tf.Variable(tf.constant(2.0, shape=None, dtype=tf.float32),name='y') z = x*w + y**2 return z 这里，为了得到想要的结果，我们可以调用 session.run（very_simple_computation（2））函数 （当然是在调用 tf.global_variables_initializer().run()函数之后）。实际上，每次调用这个函数时都会 创建两个 TensorFlow 变量。在多次调用该方法（在面向对象程序设计中把封装的函数也称为方法） 时，图（Graph）中 x 和 y 变量不会被替换，相反，将会保留这些旧变量，并在图（Graph）中创建 新的变量，直到内存不足为止。不管如何，最终的结果是正确的。为了更好地验证这个情况，我们 在 for 循环中运行 session.run(very_simple_computation(2))方法，并将变量名称也打印出来，循环 10 次的输出结果如下（完整的代码请在 ch3 文件夹中的 3_tensorflow_introduction.ipynb 文件“变量作 用域机制（Variable Scoping）”部分查看）： 14.0 ['x:0', 'y:0', 'x_1:0', 'y_1:0', 'x_2:0', 'y_2:0', 'x_3:0', 'y_3:0', 'x_4:0', 'y_4:0', 'x_5:0', 'y_5:0', 'x_6:0', 'y_6:0', 'x_7:0', 'y_7:0', 'x_8:0', 'y_8:0',",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 86
    }
  },
  {
    "page_content": "14.0 ['x:0', 'y:0', 'x_1:0', 'y_1:0', 'x_2:0', 'y_2:0', 'x_3:0', 'y_3:0', 'x_4:0', 'y_4:0', 'x_5:0', 'y_5:0', 'x_6:0', 'y_6:0', 'x_7:0', 'y_7:0', 'x_8:0', 'y_8:0', 'x_9:0', 'y_9:0', 'x_10:0', 'y_10:0'] 每次运行该函数时都会创建一对变量。如果运行这个函数 100 次，那么计算图中将有 198 个过 时变量（99x 变量和 99y 变量）。 作用域允许我们重复使用变量，而不是每次调用函数时都创建一个新的变量。我们现在为上面 的例子添加变量可复用性的操作，将代码更改为以下内容： def not_so_simple_computation(w): 70 | TensorFlow 与自然语言处理应用 x = tf.get_variable('x', initializer=tf.constant (5.0, shape=None,dtype=tf.float32)) y = tf.get_variable('y', initializer=tf.constant(2.0, shape=None,dtype=tf.float32)) z = x*w + y**2 return z def another_not_so_simple_computation(w): x = tf.get_variable('x', initializer=tf.constant(5.0, shape=None,dtype=tf.float32)) y = tf.get_variable('y', initializer=tf.constant(2.0, shape=None,dtype=tf.float32)) z = w*x*y return z # 这是第一次调用，因此将使用以下名称创建变量 # x => scopeA/x, y => scopeA/y with tf.variable_scope('scopeA'): z1 = not_so_simple_computation(tf.constant(1.0, dtype=tf.float32)) #我们重复使用已创建的 scopeA/x 和 scopeA/y with tf.variable_scope('scopeA',reuse=True):",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 87
    }
  },
  {
    "page_content": "with tf.variable_scope('scopeA'): z1 = not_so_simple_computation(tf.constant(1.0, dtype=tf.float32)) #我们重复使用已创建的 scopeA/x 和 scopeA/y with tf.variable_scope('scopeA',reuse=True): z2 = another_not_so_simple_computation(z1) # 由于这是第一次调用，因此将使用以下名称创建变量：x => scopeB/x，y => scopeB/y with tf.variable_scope('scopeB'): a1 = not_so_simple_computation(tf.constant(1.0, dtype=tf.float32)) #我们重复使用已创建的 scopeB/x 和 scopeB/y with tf.variable_scope('scopeB',reuse=True): a2 = another_not_so_simple_computation(a1) # 假设我们想再次重复使用“scopeA”，因为已经创建了变量， #所以我们应该在调用时将“reuse”参数设置为 True with tf.variable_scope('scopeA',reuse=True): zz1 = not_so_simple_computation(tf.constant(1.0, dtype=tf.float32)) zz2 = another_not_so_simple_computation(z1) 在这个例子中，如果执行 session.run（[z1，z2，a1，a2，zz1，zz2]）操作，就应该会看到 z1,z2,a1,a2,zz1,zz2 的值按顺序为 9.0,90.0,9.0, 90.0,9.0,90.0 值。现在，如果打印变量，应该只看到 四个不同的变量：scopeA / x、scopeA / y、scopeB / x 和 scopeB / y。我们现在可以在循环中多次运 行它，而不必担心创建冗余变量和内存不足。 现在你可能想知道，为什么我们不能在代码的开头创建这四个变量并在后面的方法中使用它们。 如果这样做，就会破坏代码的封装性，因为这样是在明显地依赖于代码之外的内容。 最后，作用域支持了可复用性，同时也保留了代码的封装性。此外，作用域使代码流更直观， 减少了错误的可能性，因为我们通过作用域和名称显式地获取变量，而不是使用 TensorFlow 变量 分配的 Python 变量。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 88
    }
  },
  {
    "page_content": "现在你可能想知道，为什么我们不能在代码的开头创建这四个变量并在后面的方法中使用它们。 如果这样做，就会破坏代码的封装性，因为这样是在明显地依赖于代码之外的内容。 最后，作用域支持了可复用性，同时也保留了代码的封装性。此外，作用域使代码流更直观， 减少了错误的可能性，因为我们通过作用域和名称显式地获取变量，而不是使用 TensorFlow 变量 分配的 Python 变量。 第 3 章 TensorFlow | 71 3.11 实现一个神经网络 目前，我们已经对 TensorFlow 的架构体系和作用域机制有了大体的认知，接下来，我们将实 现一个稍微复杂的模型，那就是完全连接的神经网络模型。这里使用的数据集是在深度学习过程中 都经常使用的 MNIST 数据集（详见 http://yann.lecun.com/exdb/mnist/），利用神经网络模型能够实 现对数字进行分类。 由于这是我们的第一个神经网络示例，因此，我们将逐步介绍其中的关键部分。如果要了解程 序从头到尾的运行情况，读者可以在 ch3 文件夹中的 3_tensorflow_introduction.ipynb 文件“MNIST 数字识别分类”部分自行查验。 3.11.1 数据准备 首先，我们需要调用 maybe_download(...)函数来下载数据集，并调用 read_mnist(...)函数对其进 行预处理。这里，read_mnist(...)函数执行以下两个主要步骤： (cid:2) 读取数据集的字节流并将其形成适当的 NUPYP.NDARRY 对象。将图像标准化为零均值 和单位方差。 def read_mnist(fname_img, fname_lbl): print('\\nReading files %s and %s'%(fname_img, fname_lbl)) with gzip.open(fname_img) as fimg: magic, num, rows, cols = struct.unpack(\">IIII\", fimg.read(16)) print(num,rows,cols) img = (np.frombuffer(fimg.read(num*rows*cols), dtype=np.uint8). reshape(num, rows * cols)).astype(np.float32)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 89
    }
  },
  {
    "page_content": "print(num,rows,cols) img = (np.frombuffer(fimg.read(num*rows*cols), dtype=np.uint8). reshape(num, rows * cols)).astype(np.float32) print('(Images) Returned a tensor of shape ',img.shape) # 对图像进行标准化处理 img = (img - np.mean(img))/np.std(img) with gzip.open(fname_lbl) as flbl: #flbl.read（8）读取最多 8 个字节 magic, num = struct.unpack(\">II\", flbl.read(8)) lbl = np.frombuffer(flbl.read(num), dtype=np.int8) print('(Labels) Returned a tensor of shape: %s'%lbl.shape) print('Sample labels: ',lbl[:10]) return img, lbl 3.11.2 定义 TensorFlow 计算图 为了定义 TensorFlow 计算图，我们首先为输入图像（tf_input）和其对应标签（tf_lab）定义占 位符： 72 | TensorFlow 与自然语言处理应用 # 定义输入和输出 tf_inputs = tf.placeholder(shape=[batch_size, input_size], dtype=tf.float32, name = 'inputs') tf_labels = tf.placeholder(shape=[batch_size, num_labels], dtype=tf.float32, name = 'labels') 接下来，编写一个 Python 函数，它将首次创建变量。需要说明的是，我们使用作用域来确保 变量的可重用性，并确保变量被正确命名： # 定义 TensorFlow 相关变量 def define_net_parameters(): with tf.variable_scope('layer1'):",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 90
    }
  },
  {
    "page_content": "name = 'labels') 接下来，编写一个 Python 函数，它将首次创建变量。需要说明的是，我们使用作用域来确保 变量的可重用性，并确保变量被正确命名： # 定义 TensorFlow 相关变量 def define_net_parameters(): with tf.variable_scope('layer1'): tf.get_variable(WEIGHTS_STRING,shape=[input_size,500], initializer=tf.random_normal_initializer(0,0.02)) tf.get_variable(BIAS_STRING, shape=[500], initializer=tf.random_uniform_initializer(0,0.01)) with tf.variable_scope('layer2'): tf.get_variable(WEIGHTS_STRING,shape=[500,250], initializer=tf.random_normal_initializer(0,0.02)) tf.get_variable(BIAS_STRING, shape=[250], initializer=tf.random_uniform_initializer(0,0.01)) with tf.variable_scope('output'): tf.get_variable(WEIGHTS_STRING,shape=[250,10], initializer=tf.random_normal_initializer(0,0.02)) tf.get_variable(BIAS_STRING, shape=[10], initializer=tf.random_uniform_initializer(0,0.01)) 下面，我们将定义神经网络的推理过程。这里需要说明一点，就是与没有使用作用域的变量相 比，作用域为函数中的代码提供了非常直观的流程。这里的神经网络有三层，具体如下：",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 91
    }
  },
  {
    "page_content": "initializer=tf.random_uniform_initializer(0,0.01)) 下面，我们将定义神经网络的推理过程。这里需要说明一点，就是与没有使用作用域的变量相 比，作用域为函数中的代码提供了非常直观的流程。这里的神经网络有三层，具体如下： (cid:2) 具有 ReLU 激活的完全连接层（第 1 层）。 (cid:2) 具有 ReLU 激活的完全连接层（第 2 层）。 (cid:2) 完全连接的 softmax 层（输出）。 通过作用域，我们将每个层的变量（权重值和偏差）命名为 layer1 / weight、layer1 / bias、layer2 / weight、layer2 / bias、output / weights 和 output / bias。在下面的代码中，它们都具有相同的名称， 但作用域是不同的： #在神经网络中定义根据输入进行逻辑推理的计算过程 #logit 是将 softmax 应用到最终输出之前的评估模型 def inference(x): 第 3 章 TensorFlow | 73 # calculations for layer 1 with tf.variable_scope('layer1',reuse=True): w,b = tf.get_variable(WEIGHTS_STRING), tf.get_variable(BIAS_STRING) tf_h1 = tf.nn.relu(tf.matmul(x,w) + b, name = 'hidden1') # calculations for layer 2 with tf.variable_scope('layer2',reuse=True): w,b = tf.get_variable(WEIGHTS_STRING), tf.get_variable(BIAS_STRING) tf_h2 = tf.nn.relu(tf.matmul(tf_h1,w) + b, name = 'hidden1') # calculations for output layer with tf.variable_scope('output',reuse=True): w,b = tf.get_variable(WEIGHTS_STRING), tf.get_variable(BIAS_STRING)",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 92
    }
  },
  {
    "page_content": "# calculations for output layer with tf.variable_scope('output',reuse=True): w,b = tf.get_variable(WEIGHTS_STRING), tf.get_variable(BIAS_STRING) tf_logits = tf.nn.bias_add(tf.matmul(tf_h2,w), b, name = 'logits') return tf_logits 现在，我们将定义一个损失函数并将损失进行最小化操作。损失最小化操作是通过在最小化损 失方向上对神经网络参数进行微移来开展的。TensorFlow 中提供了多种优化器，我们在这里将使 用 MomentumOptimizer，它提供了比 GradientDescentOptimizer 更好的最终精度和收敛性： # 定义损失函数 tf_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=inference(tf_ inputs), labels=tf_labels)) # 定义损失优化函数 tf_loss_minimize = tf.train.MomentumOptimizer(momentum=0.9, learning_rate=0.01).minimize(tf_loss) 最后，我们将定义一个操作来检索给定批量输入所预测的 softmax 概率。这个预测值将反过来用于计算 神经网络的准确性： # 定义预测 tf_predictions = tf.nn.softmax(inference(tf_inputs)) 3.11.3 运行神经网络 现在，我们实现了运行神经网络所需要的所有基本操作，可以对它进行检查，看它是否有能力 学习对图像中的数字进行正确分类： for epoch in range(NUM_EPOCHS): train_loss = [] 74 | TensorFlow 与自然语言处理应用 # 训练阶段 for step in range(train_inputs.shape[0]//batch_size): # Creating one-hot encoded labels with labels",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 93
    }
  },
  {
    "page_content": "train_loss = [] 74 | TensorFlow 与自然语言处理应用 # 训练阶段 for step in range(train_inputs.shape[0]//batch_size): # Creating one-hot encoded labels with labels # One-hot encoding dight 3 for 10-class MNIST data set will result in # [0,0,0,1,0,0,0,0,0,0] labels_one_hot = np.zeros((batch_size, num_labels),dtype=np.float32) labels_one_hot[np.arange(batch_size),train_labels[step*batch_size: (step+1)*batch_size]] = 1.0 # 运行优化程序 loss, _ = session.run([tf_loss,tf_loss_minimize],feed_dict={ tf_inputs: train_inputs[step*batch_size: (step+1)*batch_size,:], tf_labels: labels_one_hot} ) train_loss.append(loss) test_accuracy = [] # 测试阶段 for step in range(test_inputs.shape[0]//batch_size): test_predictions = session.run(tf_predictions,feed_dict={tf_inputs: test_inputs[step*batch_size: (step+1)*batch_size,:]}) batch_test_accuracy = accuracy(test_predictions, test_labels[step*batch_size:(step+1)*batch_size]) test_accuracy.append(batch_test_accuracy) print('Average train loss for the %d epoch: %.3f\\n'%(epoch+1,np.mean(train_loss)))",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 94
    }
  },
  {
    "page_content": "test_labels[step*batch_size:(step+1)*batch_size]) test_accuracy.append(batch_test_accuracy) print('Average train loss for the %d epoch: %.3f\\n'%(epoch+1,np.mean(train_loss))) train_loss_over_time.append(np.mean(train_loss)) print('\\tAverage test accuracy for the %d epoch: %.2f\\n'%(epoch+1,np.mean(test_accuracy)*100.0)) test_accuracy_over_time.append(np.mean(test_accuracy)*100) 在这段代码中，accuracy(test_prediction, test_tags)是一个函数，它接受一些预测和标签作为输 入，并提供准确性（有多少预测与实际标签匹配）。最终，我们会得到类似于图 3-17 所示的示意 图，从运行的结果来看，该模型表现良好，读者也可以自行运行代码进行查验。 第 3 3 章 章 T Tens sorF Flow w | 7 75 训练 练损失 失和测 测试 试准确 确性 示意 意图 图 3-17 7 M MNIS ST 数 数字分 分类 类任务 务的 3.1 3 12 总结 总 结 章中 中，我 我们 们通过 过一 一些 示例 例对算 算法 法的主 主要 要底 层平 平台 （T enso orFl ow） ）有 有了大 大体 体上的 的认 认知， 从而 从 NLP P 任务 务的 的第一 一步 步。 Ten 数值 nsorF 值计算 Flow 算的 我们讨 讨论 论了 w 的 的概念 念、 主要 要特 特征及 及其 其安装 装情 情况。 谷 歌推 推出 的 T Tens sorF 据流 流图 、用 用于数 的开源 源软 软件库 库。它 它有 有一些 些主 主要特 特征 征，例 例如 自动 动求微 微分 分、多 多语 是一 Flow 语言支 w 是 支持 持、 活性 性、 可移 移植 性、 性 能最 最优 化等 等。 对于 于 T enso orFl ow 的安 安装 ，我 我们 重点 点介 绍了",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 95
    }
  },
  {
    "page_content": "、用 用于数 的开源 源软 软件库 库。它 它有 有一些 些主 主要特 特征 征，例 例如 自动 动求微 微分 分、多 多语 是一 Flow 语言支 w 是 支持 持、 活性 性、 可移 移植 性、 性 能最 最优 化等 等。 对于 于 T enso orFl ow 的安 安装 ，我 我们 重点 点介 绍了 了 Li inux x 下 下的 我们 对于 于 T 的三 三个 个主要 要组 组成部 部分 分（计 计算 图、 张 张量和 和会 会话） 进行了 进 了详 详细解 解读 读。 讲， 我们 们可 可以用 示数据 据， 用计 计算 算图搭 搭建 建神经 经网 网络， ，用 用会话 话执 执行计 计算 算图， 再 再优化 化计 计算 的权 权重 值 （参 数） 后 得到 到模 型。 ster— —w work 式的架 架构 构系统 统。 enso 用张 ow orFl 表示 张量表 nsor 分布 rFlow 布式 Ten er” 界面 执行 行计 算的 的 w 工作 作方 式来 来计 我们 们通 过一 一个 worke 算子 er， 子图 。 id 示 专门的 sig 端做了 gmoi 了专 w 的 的客户 户端 的深 深度解 解读 sorF 读。 端借 借助 于会 会话 面可 以和 和 ma aster r 进行 行交 交互 ，把 将要 要触 发执 执行 的请 请求 发送 送给 mas ster， 部要 要执 行的 的任 务分 分配 给单 单个 或多 多个 对应 应的结 结果 果通过 再返 返回给 给客 任何 何一 一个 w work rker 都在管 管理 理并使 使用 算硬 硬件资 资源 源，进 进而 而采 wo orker 进程 r，对 程都 过 m 着整 maste 整个 er 再 个计算 ，而 m 客户端 mas 端。 ster 作 示例 对 T Tens Flow w 进 进行更 更深 一层 层的 解读 读， 并且 且在 后面 面结 结合该 该示 示例 然 后 然 后 ， 我 我 们 们 对 对 于 w 的 的 工 工 作 原 理 理 进 进 行 了 深 深 度 度 解 读 读 ， 了 解 到 到 T Tens sorF Flow w 是 是 一 个 决 N ，我",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 96
    }
  },
  {
    "page_content": "Flow w 进 进行更 更深 一层 层的 解读 读， 并且 且在 后面 面结 结合该 该示 示例 然 后 然 后 ， 我 我 们 们 对 对 于 w 的 的 工 工 作 原 理 理 进 进 行 了 深 深 度 度 解 读 读 ， 了 解 到 到 T Tens sorF Flow w 是 是 一 个 决 N ，我 。 ，我 在本 在 迈 出了 了解 首先 首 个 采用 用数 高 度的 的灵 安 装情 情况 其次 其 概 括起 起来 图 中线 线上 “ —ma nt— clien 客户 客 则 会把 把全 为 专注 注于 取 最优 优的 下面 下 nsor Ten 接下 接 rFlow 来， 对 运 Ten nsor 据，目 数据 rFlo 目的 w 客 的是用 我 们详 详细 讨论 论了 构成 成一 个典 典型 客户 端的 的常 常见元 元素 素：输 输入 入、变 变量 量、输 输出 和 算 （或操 操作 作）。 。输 输入是 是我 我们提 提供 供给算 算法 法的数 用于 于模型 型的 的训练 练和 和测试 试。 我们 们讨 讨论了 了三 三种 不 同的 的输 入方 方式 ：使 使用 占位 位符 、预 预加 载数 数据 并将 将数 数据存 存储 为 T Tens sorF 张量以 以及 然 后我 我们 讨论 论了 Ten nsor 变量 量，它 它们 与其 其他 他张量 量的 区别 别， 以及 及如 建和初 初始 Flow 何创 w 张 创建 使用 用输 输入管 管道 道。 化变 变量 量。之 之后 后， 我 们讨 讨论 算 或操 操作 了如 如何 使用 用变 建中 中间 和最 最终 的输 输出 。最 最后 ，我 我们 讨论 论了 几个 个可 用的 的 T enso ，例 例如数 数学 学运算 算、 矩阵 阵运 运算、 、神 神经网 网络 络相关 关的 的运算 算和 和控制 制流 流的操 操作 作，这 这些 运算 算和 运 orFl 操作 low 作将 将在 rFlo 量来 w 变 来创 76 | TensorFlow 与自然语言处理应用 本书后面使用。在对这些常见元素解读的过程中，我们逐步分析并结合代码加以实现，力求让每一",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 97
    }
  },
  {
    "page_content": "运算、 、神 神经网 网络 络相关 关的 的运算 算和 和控制 制流 流的操 操作 作，这 这些 运算 算和 运 orFl 操作 low 作将 将在 rFlo 量来 w 变 来创 76 | TensorFlow 与自然语言处理应用 本书后面使用。在对这些常见元素解读的过程中，我们逐步分析并结合代码加以实现，力求让每一 位读者都能够更直观地理解其内在逻辑和实现机制。 我们还讨论了在实现 TensorFlow 客户端时如何使用变量作用域来避免某些缺陷。作用域允许 我们轻松使用变量，同时也能保持代码的封装性。 最后，我们使用之前学习的所有概念实现了一个神经网络，我们使用三层神经网络对 MNIST 数字数据集进行分类。 下一章，我们将正式开始讲解 NLP 领域的重要模型：词嵌入（Word Embedding）。",
    "metadata": {
      "source": "input/082163-01.pdf",
      "type": "pdf",
      "chunk_index": 98
    }
  },
  {
    "page_content": "4 2 0 2 t c O 2 ] G L . s c [ 2 v 6 5 2 9 1 . 9 0 4 2 : v i X r a HybridFlow: A Flexible and Efficient RLHF Framework Guangming Sheng The University of Hong Kong gmsheng@connect.hku.hk Chi Zhang ByteDance zhangchi.usc1992@bytedance.com Zilingfeng Ye ByteDance yezilingfeng@bytedance.com Xibin Wu ByteDance wuxibin@bytedance.com Wang Zhang ByteDance zhangwang.nozomi@bytedance.com Ru Zhang ByteDance zhangru.1994@bytedance.com Yanghua Peng ByteDance pengyanghua.yanghua@bytedance.com Haibin Lin ByteDance haibin.lin@bytedance.com Chuan Wu The University of Hong Kong cwu@cs.hku.hk",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 99
    }
  },
  {
    "page_content": "Abstract Reinforcement Learning from Human Feedback (RLHF) is widely used in Large Language Model (LLM) alignment. Tra- ditional RL can be modeled as a dataflow, where each node represents computation of a neural network (NN) and each edge denotes data dependencies between the NNs. RLHF complicates the dataflow by expanding each node into a dis- tributed LLM training or generation program, and each edge into a many-to-many multicast. Traditional RL frameworks execute the dataflow using a single controller to instruct both intra-node computation and inter-node communication, which can be inefficient in RLHF due to large control dispatch overhead for distributed intra-node computation. Existing RLHF systems adopt a multi-controller paradigm, which can be inflexible due to nesting distributed computation and data communication. We propose HybridFlow, which combines single-controller and multi-controller paradigms in a hybrid manner to enable flexible representation and efficient execu- tion of the RLHF dataflow. We carefully design a set of hierar- chical APIs that decouple and encapsulate computation and data dependencies in the complex RLHF dataflow, allowing",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 100
    }
  },
  {
    "page_content": "tion of the RLHF dataflow. We carefully design a set of hierar- chical APIs that decouple and encapsulate computation and data dependencies in the complex RLHF dataflow, allowing efficient operation orchestration to implement RLHF algo- rithms and flexible mapping of the computation onto various devices. We further design a 3D-HybridEngine for efficient actor model resharding between training and generation phases, with zero memory redundancy and significantly re- duced communication overhead. Our experimental results demonstrate 1.53×∼20.57× throughput improvement when",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 101
    }
  },
  {
    "page_content": "Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands © 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-1196-1/25/03 https://doi.org/10.1145/3689031.3696075 running various RLHF algorithms using HybridFlow, as com- pared with state-of-the-art baselines. HybridFlow source code will be available at https://github.com/volcengine/verl CCS Concepts: • Computing methodologies → Distributed computing methodologies; Machine learning. Keywords: Distributed systems, Reinforcement Learning from Human Feedback",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 102
    }
  },
  {
    "page_content": "CCS Concepts: • Computing methodologies → Distributed computing methodologies; Machine learning. Keywords: Distributed systems, Reinforcement Learning from Human Feedback ACM Reference Format: Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. 2025. HybridFlow: A Flexible and Efficient RLHF Framework. In Twentieth European Conference on Computer Systems (EuroSys ’25), March 30- April 3, 2025, Rotterdam, Netherlands. ACM, New York, NY, USA, 19 pages. https://doi.org/10.1145/3689031.3696075",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 103
    }
  },
  {
    "page_content": "1 Introduction Large language models (LLMs) such as GPT [11], Llama [73] and Claude [7] have revolutionized various artificial intel- ligence (AI) applications, ranging from writing [2], search- ing [52] to coding [63]. LLMs are first pre-trained on trillions of tokens from books, websites, etc,. via next-word prediction to accumulate broad knowledge [11]. Next, LLMs are trained on domain-specific datasets via supervised fine-tuning (SFT), to be able to follow human instructions [11]. Despite the out- standing capabilities of LLMs on natural language tasks after pre-training and SFT, the detrimental and biased contents in the training datasets may still mislead an LLM to generate toxic and undesirable content. Reinforcement Learning from Human Feedback (RLHF) is introduced to further align an LLM to human values, for building helpful and harmless AI applications [7, 55].",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 104
    }
  },
  {
    "page_content": "RLHF is built upon traditional RL algorithms [4, 68, 78], e.g., Proximal Policy Optimization (PPO) [68] and REIN- FORCE [78]. The widely adopted PPO-based RLHF system typically consists of four LLMs [7, 55]: an actor, a critic, a ref- erence policy network and a reward model. PPO-based RLHF proceeds in iterations, each with three stages: (1) response generation using the actor model with a batch of prompts; EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu (2) preparation of training data by scoring the generated re- sponses through a single forward pass of the critic, reference policy, and reward models; (3) learning from human pref- erence by updating actor and critic through forward and backward computation. Other RLHF variants [19, 43] follow similar stages but involves different numbers of models and data dependencies among the models.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 105
    }
  },
  {
    "page_content": "Traditional RL can be modeled as a dataflow [46], which is a directed acyclic graph (DAG): each node in the RL dataflow represents computation of a neural network (e.g., actor or critic network which can be CNN or MLP); each edge de- notes data dependency between NN computations (e.g., out- put of the critic is used as input to actor training [68].) RLHF dataflow is more complex, with more complicated models involved (e.g., LLMs for the actor/critic/reference/reward models), each running distinct computation, and more di- verse data dependencies among them (i.e., multicast between distributed model partitions). Training and generation of an LLM in the RLHF dataflow requires distributed computation (e.g., using tensor/pipeline/data parallelism) [40, 71]. There- fore, each node in the RLHF dataflow is a complex distributed program, corresponding to distributed computation of the respective LLM. Models in different nodes typically use dif- ferent parallelism strategies as their workloads vary. The edge represents data resharding, which is often a many-to- many multicast. Consequently, Flexible representation and efficient execution of the complex and resource intensive",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 106
    }
  },
  {
    "page_content": "Traditional RL frameworks such as RLLib [45] and RLLib Flow [46] utilize a hierarchical single-controller paradigm to run RL dataflows. A centralized controller assigns nodes in the dataflow to different processes and coordinates their execution order. Each node process can further spawn more workers to perform computation, again following the single- controller paradigm. However, they only provide primitives for data-parallel training and are constrained to neural net- works that are at most hundreds of MB in size [45, 46]. In the RLHF dataflow, each node corresponds to an LLM with up to billions of operators, computed using some complex paral- lelism. A single-controller paradigm is inefficient due to the substantial overhead of dispatching operators to distributed accelerators [1, 9].",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 107
    }
  },
  {
    "page_content": "Existing RLHF systems adopt a multi-controller paradigm to manage intra-node computation and inter-node data re- sharding [17, 30, 80]. Each controller independently manages the computation of one device and uses multiple point-to- point operations to coordinate data dependencies between different nodes. This multi-controller paradigm introduces negligible dispatch overhead when performing LLM compu- tation (detailed in §2.2). However, without central control, it is inflexible to imple- ment various RLHF dataflow, as modifying a single node to adapt to different data dependencies requires changing all dependent nodes’ implementation, hindering code reuse.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 108
    }
  },
  {
    "page_content": "To address these limitations, we propose HybridFlow, a flexible and efficient RLHF framework to easily represent and execute diverse RLHF dataflows, attaining high throughput. Our key observation is that utilizing the single-controller paradigm on the inter-node level enables flexible expres- sion of various data dependencies and easy coordination of inter-node data resharding with minimal overhead, while integrating the multi-controller paradigm within intra-node computation enhances computation efficiency substantially. We advocate a hierarchical hybrid programming model to generate RLHF dataflows. At the node level, multiple model classes are provided that encapsulate distributed computa- tion (training, inference and generation) of different LLMs in the dataflow into primitive APIs. These APIs can seamlessly support various parallelism strategies from the existing LLM frameworks, including 3D parallelism [71], ZeRO [59], and PyTorch FSDP [57]), and perform distributed computation under the multi-controller paradigm. Among the nodes, a set of transfer protocols are designed to hide the complexity of data resharding from users, as coordinated by a single",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 109
    }
  },
  {
    "page_content": "under the multi-controller paradigm. Among the nodes, a set of transfer protocols are designed to hide the complexity of data resharding from users, as coordinated by a single controller. This programming model abstracts away the com- plexity of distributed computing, allowing users to imple- ment an RLHF dataflow in a few lines of code and run RLHF through a single process of the single controller. It also effec- tively decouples intra-node computation and inter-node data transfer, allowing independent optimization of each model without changing the code of other models in the dataflow. Training and generation of the actor model represent ma- jor computation in the RLHF dataflow. We further design a 3D-HybridEngine to enable efficient execution of training and generation of the actor model, introducing zero mem- ory redundancy and significantly reduced communication overhead during model parameter resharding between the training and generation stages. Our hybrid programming model also facilitates flexible placement of models onto the same or different sets of GPU devices. This allows us to pro- vide an effective algorithm to optimize GPU allocation and",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 110
    }
  },
  {
    "page_content": "model also facilitates flexible placement of models onto the same or different sets of GPU devices. This allows us to pro- vide an effective algorithm to optimize GPU allocation and placement of the models, with various model sizes and dis- tinct workloads, for any RLHF dataflow. Our contributions in designing HybridFlow are summarized as follows: • We propose a hierarchical hybrid programming model for conveniently building the RLHF dataflow. This programming model enables efficient distributed execution of intra-node computation and flexible inter-node data resharding and transfer, for various RLHF algorithms (§4). • We design a 3D-HybridEngine that executes training and generation of the actor model with high computation effi- ciency and zero-redundancy transition between the training stage and the generation stage (§5). • We devise an effective mapping algorithm to automatically identify optimized GPU allocation and placement of each node (model) in the RLHF dataflow (§6). • We conduct extensive experiments comparing HybridFlow with state-of-the-art RLHF systems [17, 30, 82] under various",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 111
    }
  },
  {
    "page_content": "HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands Figure 1. Dataflow graph of 3 RLHF algorithms [19, 43, 55]. Stage 1○, 2○, 3○ represent Generation, Preparation, and Training, respectively. RLHF algorithms, model sizes and cluster scales. Our evalua- tion demonstrates 1.53×∼20.57× throughput improvements. We have open-sourced HybridFlow and believe that Hy- bridFlow can boost future RLHF research and development.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 112
    }
  },
  {
    "page_content": "2 Background and Motivation 2.1 Reinforcement Learning from Human Feedback RLHF Workflow. RLHF aligns the linguistic space of LLMs with human values, using a set of human-ranked candidates of given prompts [7, 19, 41, 43, 55, 70, 91]. An RLHF sys- tem typically consists of multiple models, e.g., an actor, a critic, a reference policy, and one or multiple reward models. The actor and the reference are each pre-trained/fined-tuned LLM (i.e., the LLM that is undergoing RLHF). The critic and reward models can be different LLMs fine-tuned on the hu- man preference dataset, with the language modeling head replaced by a scalar output head [7, 55]. The RLHF workflow can be decomposed into 3 stages (Figure 1) and we take PPO as an example: •Stage 1 (Generation): The actor produces responses from a batch of prompts using auto-regressive generation. •Stage 2 (Preparation): Using prompts and generated responses, the critic computes their values [66, 68], the reference policy computes their reference log probabilities, and the reward model computes their rewards [7, 55], all via a single pass of forward computation of the respective model.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 113
    }
  },
  {
    "page_content": "computes their reference log probabilities, and the reward model computes their rewards [7, 55], all via a single pass of forward computation of the respective model. •Stage 3 (Learning/Training): The actor and the critic are updated via Adam [38], using the batch of data produced by previous stages and the loss function [55].",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 114
    }
  },
  {
    "page_content": "Other RLHF algorithms largely follow the 3-stage work- flow as well (Figure 1(b)(c)). Safe-RLHF [19] introduces an auxiliary pretrain loss following PPO-ptx [55] and includes an additional cost model to fit human preferences and safety labels simultaneously. ReMax [43] requires an additional gen- eration pass for variance reduction and eliminates the critic model in the dataflow. Researchers are actively exploring novel RLHF algorithms [41, 70, 91] and integrating tradi- tional RL methods into RLHF domains [37]. These variances necessitate a flexible representation of the RLHF dataflow graph to accommodate diverse algorithmic requirements. Figure 2. Programming model used in RLHF systems. (a) Existing RLHF systems adopt the multi-controller paradigm. (b) HybridFlow utilizes a hybrid programming model: the single-controller coordinates models; each model uses multi- controller paradigm in distributed computation. Inactive node in grey represents operation not executed at this time.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 115
    }
  },
  {
    "page_content": "Parallelism Strategies. LLMs are trained and served with data, pipeline, and tensor parallelism [36, 40, 54]. With data parallelism (DP), the input data is split into multiple sub- sets; each subset is processed by a separate device (e.g., a GPU) [69]. ZeRO [59] is a memory-optimized solution for DP training, progressively sharding optimizer states, gra- dients, and model parameters across GPUs. Pipeline paral- lelism (PP) [32, 53] and tensor parallelism (TP) [71] distrib- ute model parameters, gradients and optimizer states across multiple GPUs. Modern distributed training frameworks like Megatron-LM [71] and MegaScale [36] utilize 3D parallelism or PTD parallelism [54], where P, T, D stand for PP, TP, DP, respectively. In 3D parallelism, PP size represents the num- ber of pipeline stages in model training, TP size refers to the number of shards that a tensor is partitioned into, and DP size is the number of model replicas. LLM serving systems employ 3D parallelism similar to training while only model parameters and KVCache are sharded [16, 29, 40].",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 116
    }
  },
  {
    "page_content": "LLM models in the RLHF dataflow may perform distinct computations, including training (one forward pass, one backward pass and model update), inference (one forward pass) and generation (auto-regressive generation with multi- ple forward passes). In particular, training and generation are performed on the actor model, training and inference on the critic, and inference on reference policy and reward models. Distinct parallel strategies can be applied to different models for varied computations to achieve optimal throughput.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 117
    }
  },
  {
    "page_content": "ActorGenRefFwdCriticFwdRMFwdActorTrainingCriticTraining(a) PPOActorGenRefFwdCriticFwdRMFwdActorTrainingCriticTraining(b) Safe-RLHFCostFwdActorFwdactorcriticreference policyreward modelcost modelActorGenRefFwdRMFwdActorTrainingActorGen(c) ReMax123RMFwd(b) HybridFlow(a) Existing RLHF frameworksSingle ControllerworkerworkerworkerworkerActorCriticworkerworkerRewardInﬂexible: - Computation and data dependenciesare nested- Coupled with some LLM systems.for prompts in datasets: for _ in range(len): all_gather_weights() logit = model(prompts) ... all_gather_to_rank0(res) send_critic(res) send_rm(res)while True: res = recv_actor() broadcast(res) all_gather_weights() values = model(res)Multi-Controller implementation Actor ModelCritic Modelwhile True: res = recv_actor() broadcast(res) all_gather_weights() reward = model(res)Reward Modelresponses = actor.gen(prompts)value = critic.comp_value(responses)reward = rm.comp_reward(responses)Inter-Node: Single-Controller implementation def gen(prompts): for _ in range(len): all_gather_weights() logit = model(prompts) ... return responsesdef comp_values(res): all_gather_weights() values = model(res) return",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 118
    }
  },
  {
    "page_content": "def gen(prompts): for _ in range(len): all_gather_weights() logit = model(prompts) ... return responsesdef comp_values(res): all_gather_weights() values = model(res) return valuesIntra-Node: Multi-Controller implementation def comp_reward(res): all_gather_weights() reward = model(res) return rewardIneﬃcient: - Large transition cost between train & gen- Rigid support for model placement workerActorworkerCriticworkerworkerRewardData TransferRemote CallInactive NodeNode in RLHF dataﬂowA GPU workerwith a controllerworkerInactiveTransferEﬃcient: - Zero redundancy during transition- Support diﬀerent model placement strategiesFlexible: - Decouple the data and computationdependencies- Seamless integrate any LLM systems.workerworker EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 119
    }
  },
  {
    "page_content": "2.2 Programming Model for Distributed ML Single-Controller. It employs a centralized controller to manage the overall execution flow of the distributed program. With centralized control logic, users can build core function- alities of the dataflow as a single process (Figure 2(b)), while the controller automatically generates distributed workers to carry out the computation. With a global view of the hardware and dataflow graph, the single-controller para- digm allows flexible and optimized resource mapping and execution order coordination among dataflow tasks. How- ever, coordination messages are passed from the controller to all workers, incurring significant dispatch overhead when executing expansive dataflow graphs on large clusters [1, 9]. Multi-Controller. Each device (aka worker) has its own con- troller. State-of-the-art distributed LLM training and serving systems adopt the multi-controller paradigm, due to its scal- ability and low dispatch overhead (control messaging largely passed from CPU to GPU over fast PCIe links) [36, 40, 60, 71]. As shown in the example that employs multi-controller RLHF implementation in Figure 2(a), a separate program is run",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 120
    }
  },
  {
    "page_content": "passed from CPU to GPU over fast PCIe links) [36, 40, 60, 71]. As shown in the example that employs multi-controller RLHF implementation in Figure 2(a), a separate program is run for each model, and all workers of one model execute the same program. Each worker only possesses a local view of the system state and requires point-to-point communication between two models (blue code and arrows) to coordinate model execution order. To implement an RLHF workflow in the multi-controller architecture, a user must intricately in- tegrate the code for collective communication, computation, and point-to-point data transfer in the program run at each device. This leads to deeply nested code of computation and data transfer, challenging to develop, maintain, and optimize. In Figure 2(a), each model performs local computation and all_gather operations (black code), while the actor model must explicitly manage send operations to the critic and re- ward models, and the latter must correspondingly implement receive operations at precise points in their program.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 121
    }
  },
  {
    "page_content": "2.3 RLHF Characteristics Heterogeneous model workloads. The actor, critic, ref- erence and reward models in RLHF may execute training, inference or generation at different stages, with different memory footprint and computation demand. For reference policy and reward models, only their model parameters need to be stored in GPU memory, as they perform only the for- ward pass computation. For the actor and the critic, their model parameters, gradients, and optimizer states must be stored as they undergo model training. Moreover, a small actor model (e.g., a 7B pre-trained/fine-tuned LLM) can be paired with larger critic and reward models (e.g., 70B LLMs) in RLHF for better alignment [7]. Given such heterogeneity, different parallelism strategies and tailored optimizations are needed for running each model during RLHF. Unbalanced computation between actor training and generation. In the RLHF dataflow, training and generation of the actor model are represented by two nodes (Figure 1),",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 122
    }
  },
  {
    "page_content": "Figure 3. Dataflow execution given a model placement plan. Blocks with numbers represent GPUs. In dashed boxes, the models are placed on different sets of devices and can be concurrently computed. Reference model (blue) and reward model (green) are colocated on the same set of GPUs and executed sequentially.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 123
    }
  },
  {
    "page_content": "which often render majority of the workload in each RLHF iteration (e.g., 58.9% of total RLHF time with HybridFlow). Actor training is computation bound [24], often requiring a larger model-parallel (MP) size (i.e., the number of partitions the model is partitioned into) and distributing the workload to more GPUs, e.g., 8 partitions of a 7B model on 8 GPUs. Us- ing the same parallelism strategy (e.g., the same MP size) for generation can lead to underutilization of GPU computation resources due to its memory-bound nature [40]. Previous studies show that combining a larger DP size with a smaller MP size (hybrid data and model parallelism), e.g., partition a 7B model into two and replicate it four times on 8 GPUs, can improve the generation throughput [44, 92]. Although using different parallelism strategies for actor training and genera- tion may optimize throughput in both stages, resharding the actor model weights at runtime between the two stages can incur significant communication and memory overhead. For example, aligning a 70B actor model requires transferring 140GB of model weights from training to generation per RLHF iteration, taking up to 36.4% of an iteration time when",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 124
    }
  },
  {
    "page_content": "example, aligning a 70B actor model requires transferring 140GB of model weights from training to generation per RLHF iteration, taking up to 36.4% of an iteration time when the two stages are on different devices [30]. Diverse model placement requirements. Strategic device placement of models in the RLHF dataflow is necessary, ac- cording to computation workloads and data dependencies of the models. Figure 3 gives an example model placement plan and the corresponding RLHF execution flow. Models placed on different sets of devices can be executed in parallel if no data dependencies exist. Models placed on the same set of GPUs, referred to as colocated models, share the GPU memory and are executed sequentially in a time-sharing manner, as out-of-memory (OOM) error may easily happen if colocated LLMs execute concurrently.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 125
    }
  },
  {
    "page_content": "We observe a compromise: placing models on different de- vices permits parallel processing but may inevitably lead to some GPU idle time, given staged model execution in RLHF. In Figure 3, actor and critic are placed separately, perform- ing training in parallel, but incurring 1/3 of their GPU time being idle, during other RLHF stages. Supporting various GenGenValueValueActor TrainingActor TrainingCritic TrainingCritic Training012345Machine AMachine BMachine CActor -> A:0-1Critic -> B:2-3Ref -> C:4-5RM -> C:4-5GenActorTrainingCriticTrainingDataflow Graph RefRMPlacementExecution PatternValueRefRMPlacing modelson different machines HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands Table 1. Comparison of RLHF frameworks. Figures illustrate execution of one PPO iteration. Numbers 1-6 represent response generation, reward model inference, reference model inference, critic inference, actor training, and critic training, respectively. RLHF system DeepSpeed-Chat OpenRLHF NeMo-Aligner HybridFlow Parallelism Training: ZeRO Generation:TP Training: ZeRO Generation:TP 3D Parallelism for both training and generation",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 126
    }
  },
  {
    "page_content": "RLHF system DeepSpeed-Chat OpenRLHF NeMo-Aligner HybridFlow Parallelism Training: ZeRO Generation:TP Training: ZeRO Generation:TP 3D Parallelism for both training and generation Training: 3D, ZeRO, FSDP Generation: 3D Parallelism Actor weights in training & generation Model resharding from ZeRO to TP Using two copies of actor weights for the two stages Using identical model partition in two stages (shared weights) Colocate all models on the same set of devices Each model placed on separate devices Actor/Ref colocated on some GPUs Critic/RM colocated on other GPUs Model Placement Execution Pattern Zero-redundancy model resharding Support various model placement Support various execution patterns placement strategies and maximizing device utilization are crucial for optimizing RLHF performance at any model size and cluster scale.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 127
    }
  },
  {
    "page_content": "2.4 Limitations of existing RLHF systems Inflexible support for various RLHF dataflow graphs. Existing RLHF systems adopt the multi-controller paradigm for dataflow implementation [17, 30, 80, 82]. To implement various RLHF algorithms, a user must navigate and manage code that mixes collective communication, model computa- tion (potentially using various distributed training/serving frameworks), and point-to-point data transfer. This code structure lacks modularity/function encapsulation, making the RLHF systems tightly coupled with specific LLM train- ing and serving frameworks. Consequently, a user needs to implement and optimize different RLHF dataflows case-by- case [46], hindering code reuse and increasing the risk of making mistakes. Existing RLHF frameworks only support the PPO algorithm. In addition, limited parallel strategies are supported due to implementation complexity. For example, to incorporate 3D parallelism for LLM training and genera- tion in DeepSpeed-Chat [82], one may have to re-implement the whole system due to the mixed code structure. Inefficient RLHF execution. Table 1 summarizes paral- lelism strategies, model placement, and execution patterns",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 128
    }
  },
  {
    "page_content": "the whole system due to the mixed code structure. Inefficient RLHF execution. Table 1 summarizes paral- lelism strategies, model placement, and execution patterns adopted by the existing RLHF systems. DeepSpeed-Chat [82] and OpenRLHF [30] adopt ZeRO-3 for actor training and TP for actor generation. OpenRLHF uses different copies of the actor model on different devices for training and generation, incurring redundant memory usage and frequent weight syn- chronization among devices. DeepSpeed-Chat maintains the same copy of actor model on the same set of devices for train- ing and generation, and reshards model weights between training and generation (due to different parallelisms used in the two stages), which may still incur substantial memory and communication overhead for large models (detailed in §5.4). NeMo-Aligner [17] uses the same 3D parallelism con- figurations in actor training and generation, experiencing low generation throughput (§8.4).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 129
    }
  },
  {
    "page_content": "Existing RLHF frameworks are limited to one model place- ment plan and hence one RLHF execution pattern, as shown in Table 1. Implementing a different placement is difficult, requiring changing the inner logic of model initialization and inter-node data transfer as highlighted in blue in Fig- ure 2. OpenRLHF and NeMo-Aligner allow concurrent model computation in the preparation and learning stages; in the generation stage, models except the actor are idle, wasting the GPUs they occupy. DeepSpeed-Chat colocates all models on the same set of devices, and each device runs each model sequentially according to the RLHF dataflow. With unbal- anced workloads among the models, such a placement can be inefficient in resource utilization (evaluated in §8.3). 2.5 Design Considerations",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 130
    }
  },
  {
    "page_content": "To tackle limitations of existing systems, the key question is - How to design a flexible and efficient programming model to implement RLHF dataflow? A single-controller design is particularly advantageous at the inter-node level due to its flexibility in coordinating data transfer, execution order, and resource virtualization among distributed compu- tation of different models [9, 50]. The RLHF dataflow graph typically consists of only a few nodes. Dispatching control messages to different nodes from the single-controller in- curs negligible overhead as compared to distributed com- putation required for nodes (models) in the dataflow. The multi-controller paradigm, known for its low latency in dis- patching operators to accelerators [20], can be leveraged in distributed computation of each model. With these insights, we propose a hierarchical hybrid programming model for RLHF dataflow implementation. Our key design principle is to combine single-controller and multi-controller paradigms in a hybrid manner. This design ensures flexible expression and efficient execution of RLHF dataflow, maintaining low control overhead at both inter-node and intra-node levels.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 131
    }
  },
  {
    "page_content": "in a hybrid manner. This design ensures flexible expression and efficient execution of RLHF dataflow, maintaining low control overhead at both inter-node and intra-node levels. As shown in Figure 2(b), this paradigm decouples intra-node distributed computation and inter-node data transfer, allow- ing each model to focus solely on local computation without managing inter-node communication.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 132
    }
  },
  {
    "page_content": "3 HybridFlow Overview Figure 4 depicts the architecture of HybridFlow, which con- sists of three major components: Hybrid Programming Model, GPU ProcessActorCriticReference PolicyReward model123456123456123456 EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu Figure 4. Architecture of HybridFlow. 3D-HybridEngine and Auto-Mapping algorithm. The hybrid programming model includes a set of hierarchical APIs to enable flexible expression of the RLHF dataflow and effi- cient computation of models in the dataflow (§4). The 3D- HybridEngine is particularly designed for efficient training and generation of the actor model, allowing different 3D parallel configurations in the two stages and enabling zero memory redundancy and minimized communication over- head during the transition between two stages (§5). The auto- mapping algorithm determines optimized device placement of each model to maximize the throughput of RLHF (§6).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 133
    }
  },
  {
    "page_content": "The workflow of our RLHF system goes as follows. A user provides the following inputs to start the RLHF system: (i) model specifications, including the architecture and size of the actor/critic/reference policy/reward models in the RLHF dataflow; (ii) device placement of the models in the dataflow, as obtained by running the auto-mapping algorithm under given GPU cluster configurations; (iii) parallelism strategy for running each model in each stage, e.g., a tuple of (p, t, d) for 3D parallelism, where p, t, d represent PP size, TP size and DP size, respectively. The single controller program takes these inputs to initialize models in the RLHF dataflow and virtualized resource pool, dispatches operations/models to devices according to the placement plan, and invokes functions run by the multiple controllers on devices to carry out distributed computation of each model.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 134
    }
  },
  {
    "page_content": "The multi-controller program implements the Parallel- Worker class: it constructs parallel groups of each model among allocated devices according to its parallelism strate- gies, invokes the 3D-HybridEngine for actor training and generation, and can be integrated seamlessly with existing LLM engines [40, 57, 60, 71] for training, inference and gener- ation of other models. The transfer protocols are coordinated by the single controller program to support resharding of data (including prompts, responses, and other model outputs in RLHF) between models with distinct parallelism strate- gies. The data resharding of the actor between training and generation is handled by 3D-HybridEngine. 4 Hybrid Programming Model 4.1 Hierarchical APIs Intra-node: encapsulating distributed program. For dis- tributed computation of each model in different RLHF stages, we provide a base class, 3DParallelWorker. Given allocated Figure 5. An illustration of hierarchical APIs. (a) Model with 3D parallel configuration, resource allocation, and 3DParallelWorker initialization. (b) Asynchronous data re- sharding between two models with collect and distribute functions in 3D_PROTO.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 135
    }
  },
  {
    "page_content": "devices, it facilitates distributed model weight initialization and establishes 3D parallel groups for each model. A parallel group includes a set of GPUs to host a specific parallel di- mension of the model, e.g., different tensor shards in TP and different model replicas in DP. Figure 5(a) illustrates initial- ization of the actor model with our APIs, while initialization of other models is similar.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 136
    }
  },
  {
    "page_content": "Inheriting from the 3DParallelWorker class, several model classes, for actor, critic, reference, and reward model, respec- tively, are provided. Each of these model classes encapsu- lates APIs to implement the model’s distributed forward and backward computation, auto-regressive generation, and opti- mizer updates, decoupling the distributed computation code with data dependencies with other models. These APIs can be easily implemented by reusing the computation scripts from existing LLM systems. For example, the computation in- volved in update_actor function of ActorWorker (the class for the actor model) is similar to the pre-training scripts in Megatron-LM [71]. A model class encapsulates fundamental operations for implementing various RLHF algorithms, e.g., generate_sequences in the actor model class for generat- ing responses based on the prompts and compute_reward in the reward model class for evaluating responses through a forward pass. (More APIs are detailed in Appendix A).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 137
    }
  },
  {
    "page_content": "Besides base class 3DParallelWorker that implements 3D parallelism, we further provide base classes for PyTorch FSDP (FSDPWorker) and ZeRO (ZeROWorker), and the corre- sponding model classes inheriting each base class, to support different parallelism strategies in model computation. Paral- lelWorker in Figure 4 denotes one of these base classes.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 138
    }
  },
  {
    "page_content": "User InputAuto Mapping (§6)Model PlacementResource Pool (§4)Physical DevicesDevice Allocation ParallelWorker (§4)Transfer Protocol (§4)LLM Training EngineLLM Generation Engine3D-HybridEngine (§5)RLHF dataﬂow graphModel ConﬁgDevice ConﬁgModel+(a) Actor model initialization(b) Data resharding and asynchronous execution CriticTP0,PP0TP1,PP0DP0TP0,PP0TP1,PP0DP1TP0,PP0TP1,PP0DP2TP0,PP0TP0,PP1DP0TP0,PP0TP0,PP1DP1<latexit sha1_base64=\"5fUtIMUC6GDaKxFcmKHJtdHWN7Q=\">AAAB+HicbVBNS8NAEN34WetHox69BIvgQUoipXosePFYwX5AG8pmM22XbjZhdyLW0F/ixYMiXv0p3vw3btsctPXBwOO9md2ZFySCa3Tdb2ttfWNza7uwU9zd2z8o2YdHLR2nikGTxSJWnYBqEFxCEzkK6CQKaBQIaAfjm5nffgCleSzvcZKAH9Gh5APOKBqpb5d6CI/IuGICwqw67dtlt+LO4awSLydlkqPRt796YczSCCQyQbXuem6CfkYVcvPktNhLNSSUjekQuoZKGoH2s/niU+fMKKEziJUpic5c/T2R0UjrSRSYzojiSC97M/E/r5vi4NrPuExSBMkWHw1S4WDszFJwQq6AoZgYQpniZleHjaiiDE1WRROCt3zyKmldVrxapXZXLdcv8jgK5IScknPikStSJ7ekQZqEkZQ8k1fyZj1ZL9a79bFoXbPymWPyB9bnDyOBk1k=</latexit>4○<latexit",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 139
    }
  },
  {
    "page_content": "sha1_base64=\"aoixu1HEd7eIUDMbNIfV3GrETjg=\">AAAB+HicbVDLSgNBEOz1GeMjqx69DAbBg4Rd0egx4MVjBPOAZAmzs5NkyOyDmV4xLvkSLx4U8eqnePNvnCR70MSChqKqe6a7/EQKjY7zba2srq1vbBa2its7u3sle/+gqeNUMd5gsYxV26eaSxHxBgqUvJ0oTkNf8pY/upn6rQeutIijexwn3AvpIBJ9wSgaqWeXusgfkQnFJA+yy0nPLjsVZwayTNyclCFHvWd/dYOYpSGPkEmqdcd1EvQyqlCYJyfFbqp5QtmIDnjH0IiGXHvZbPEJOTFKQPqxMhUhmam/JzIaaj0OfdMZUhzqRW8q/ud1Uuxfe5mIkhR5xOYf9VNJMCbTFEggFGcox4ZQpoTZlbAhVZShyapoQnAXT14mzfOKW61U7y7KtbM8jgIcwTGcggtXUINbqEMDGKTwDK/wZj1ZL9a79TFvXbHymUP4A+vzByUGk1o=</latexit>5○<latexit sha1_base64=\"HUb68ji/9AxT6w+cvZjgfcF6EzY=\">AAAB+HicbVBNS8NAEN34WetHox69BIvgQUpSpHosePFYwX5AG8pmM22XbjZhdyLW0F/ixYMiXv0p3vw3btsctPXBwOO9md2ZFySCa3Tdb2ttfWNza7uwU9zd2z8o2YdHLR2nikGTxSJWnYBqEFxCEzkK6CQKaBQIaAfjm5nffgCleSzvcZKAH9Gh5APOKBqpb5d6CI/IuGICwqw67dtlt+LO4awSLydlkqPRt796YczSCCQyQbXuem6CfkYVcvPktNhLNSSUjekQuoZKGoH2s/niU+fMKKEziJUpic5c/T2R0UjrSRSYzojiSC97M/E/r5vi4NrPuExSBMkWHw1S4WDszFJwQq6AoZgYQpniZleHjaiiDE1WRROCt3zyKmlVK16tUru7LNcv8jgK5IScknPikStSJ7ekQZqEkZQ8k1fyZj1ZL9a79bFoXbPymWPyB9bnDyB3k1c=</latexit>2○<latexit",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 140
    }
  },
  {
    "page_content": "sha1_base64=\"Na/pcQ2WIU22F5P4eh8iYMa1qtA=\">AAAB+HicbVDLSgNBEOz1GeMjqx69DAbBg4Rdlegx4MVjBPOAZAmzs5NkyOyDmV4xLvkSLx4U8eqnePNvnCR70MSChqKqe6a7/EQKjY7zba2srq1vbBa2its7u3sle/+gqeNUMd5gsYxV26eaSxHxBgqUvJ0oTkNf8pY/upn6rQeutIijexwn3AvpIBJ9wSgaqWeXusgfkQnFJA+yi0nPLjsVZwayTNyclCFHvWd/dYOYpSGPkEmqdcd1EvQyqlCYJyfFbqp5QtmIDnjH0IiGXHvZbPEJOTFKQPqxMhUhmam/JzIaaj0OfdMZUhzqRW8q/ud1Uuxfe5mIkhR5xOYf9VNJMCbTFEggFGcox4ZQpoTZlbAhVZShyapoQnAXT14mzfOKW61U7y7LtbM8jgIcwTGcggtXUINbqEMDGKTwDK/wZj1ZL9a79TFvXbHymUP4A+vzByH8k1g=</latexit>3○<latexit sha1_base64=\"bDj2xs9J0e+TmZzdVf7qIUesb/s=\">AAAB+HicbVBNS8NAEN3Ur1o/GvXoJVgED1ISkeqx4MVjBfsBbSibzbRdutmE3YlYQ3+JFw+KePWnePPfuG1z0NYHA4/3ZnZnXpAIrtF1v63C2vrG5lZxu7Szu7dftg8OWzpOFYMmi0WsOgHVILiEJnIU0EkU0CgQ0A7GNzO//QBK81je4yQBP6JDyQecUTRS3y73EB6RccUEhJk37dsVt+rO4awSLycVkqPRt796YczSCCQyQbXuem6CfkYVcvPktNRLNSSUjekQuoZKGoH2s/niU+fUKKEziJUpic5c/T2R0UjrSRSYzojiSC97M/E/r5vi4NrPuExSBMkWHw1S4WDszFJwQq6AoZgYQpniZleHjaiiDE1WJROCt3zyKmldVL1atXZ3Wamf53EUyTE5IWfEI1ekTm5JgzQJIyl5Jq/kzXqyXqx362PRWrDymSPyB9bnDx7yk1Y=</latexit>1○ActorSingle Controller<latexit",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 141
    }
  },
  {
    "page_content": "Controller<latexit sha1_base64=\"YNK+hbfUXnQFsSt15AKxRPj6Mws=\">AAAB+HicbVBNS8NAEJ3Ur1o/GvXoJVgETyURqR6LXjxWsB/QhrLZbNulm03YnYg19Jd48aCIV3+KN/+N2zYHbX0w8HhvZnfmBYngGl332yqsrW9sbhW3Szu7e/tl++CwpeNUUdaksYhVJyCaCS5ZEzkK1kkUI1EgWDsY38z89gNTmsfyHicJ8yMylHzAKUEj9e1yD9kjUq6oYGFWm/btilt153BWiZeTCuRo9O2vXhjTNGISqSBadz03QT8jCrl5clrqpZolhI7JkHUNlSRi2s/mi0+dU6OEziBWpiQ6c/X3REYirSdRYDojgiO97M3E/7xuioMrP+MySZFJuvhokAoHY2eWghNyxSiKiSGEKm52deiIKELRZFUyIXjLJ6+S1nnVq1VrdxeV+nUeRxGO4QTOwINLqMMtNKAJFFJ4hld4s56sF+vd+li0Fqx85gj+wPr8AS0pk3E=</latexit>6○Machine 1ResourcePool()ParallelWoker()DP1TP1,PP0TP0,PP0DP0TP1,PP0TP0,PP0…Model (P, T, D)class ActorWorker(3DParallelWorker): # An example of distributed computation function @register(transfer_mode=3D_PROTO) def update_actor(self, prompts: DataProto): ...# Allocate devices for a ResourcePoolresource_pool = ResourcePool([n_gpus_per_machine] * n_machines)# Map the model to allocated devices and init modelactor_model = ActorWorker(actor_config, resource_pool)ConfigActor (p, t, d) = (1, 2, 3)Critic (p, t, d) = (2, 1, 2)Call from controllerTransfer dataReturn data futuresCollect data futuresDistribute data futuresTP,PPTP, PP rank on a GPU in a",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 142
    }
  },
  {
    "page_content": "(p, t, d) = (1, 2, 3)Critic (p, t, d) = (2, 1, 2)Call from controllerTransfer dataReturn data futuresCollect data futuresDistribute data futuresTP,PPTP, PP rank on a GPU in a DP group HybridFlow: A Flexible and Efficient RLHF Framework",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 143
    }
  },
  {
    "page_content": "Inter-node: unifying data resharding implementation between models. Many-to-many multicast is involved for data transfer between models employing different paral- lelism strategies on different devices. We unify this data transfer implementation by associating each operation in each model class with a transfer protocol, using @register. Each transfer protocol consists of a collect function and a dis- tribute function, to aggregate output data and distribute in- put data according to the parallelism strategy of each model. In the example in Figure 5(a), update_actor operation is registered to transfer protocol 3D_PROTO, as 3D parallelism is used for actor training. In 3D_PROTO, the collect function gathers all the output data of corresponding model function (e.g., the loss scalar return from the update_actor) in each DP group to the single controller, and the distribute func- tion distributes the input data to the registered function (e.g., advantages for the update_actor) to each DP group. Data resharding is enabled using the source model’s output collect function and the destination model’s input distribute func- tion. Figure 5(b) illustrates data resharding between the actor",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 144
    }
  },
  {
    "page_content": "resharding is enabled using the source model’s output collect function and the destination model’s input distribute func- tion. Figure 5(b) illustrates data resharding between the actor (generation) and the critic (inference), where computation of the models adopts different 3D parallelism strategies. The single controller gathers data futures using the collect func- tion in 3D_PROTO of actor (steps 1○- 3○) and sends it to critic (step 4○); critic distributes the received data futures to each DP group using the distribute function in its 3D_PROTO (step 5○). Then remote data is retrieved from actor to critic, with each of critic’s GPUs only fetching the required local batch of the actor’s output data according to its DP rank (step 6○). The actual data transfer only occurs between GPUs, avoiding any central bottleneck.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 145
    }
  },
  {
    "page_content": "We provide 8 transfer protocols, including 3D_PROTO, DP _PROTO, ONE_TO_ALL, etc., that cover most data resharding scenarios (detailed in Appendix B). A user can further extend the transfer protocols through implementing customized collect and distribute functions. Facilitating flexible model placement. We provide a ResourcePool class that virtualizes a set of GPU devices. When applying a ResourcePool instance to a model class (Figure 5(a)), distributed computation of the model will be mapped to the devices. Models utilizing the same ResourcePool instance are colocated on the same set of GPUs; models are placed on different sets of GPUs when different Resource Pool instances are applied in their model classes. We assume no overlap between different ResourcePool instances. Asynchronous dataflow execution. When models are placed on separate sets of devices, their execution is triggered automatically as soon as their inputs become available [50]. In Figure 5(b), the data future from actor is immediately returned after the controller’s call (steps 1○- 3○); the con- troller then initiates a new call to critic and distributes the",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 146
    }
  },
  {
    "page_content": "In Figure 5(b), the data future from actor is immediately returned after the controller’s call (steps 1○- 3○); the con- troller then initiates a new call to critic and distributes the futures following the transfer protocol (steps 4○- 5○). When some models are placed on the same set of devices, they are executed sequentially based on the calling order. With",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 147
    }
  },
  {
    "page_content": "Figure 6. Implementation of PPO [55], ReMax [43], and Safe- RLHF [19]. Users can adapt to different RLHF algorithms by simply adding or deleting a few lines of code. our programming model, HybridFlow is flexible in support- ing diverse distributed execution patterns without any code change of the RLHF algorithm (Figure 6). 4.2 Implementation of different RLHF algorithms",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 148
    }
  },
  {
    "page_content": "Our APIs enable streamlined development of various RLHF algorithms (dataflows). Users can implement an RLHF al- gorithm in a few lines of code as a single process program to run on the single controller, that involves a sequence of primitive API calls to invoke distributed computation of models. Examples of PPO, ReMax, and Safe-RLHF are given in Figure 6. PPO can be implemented in just 8 lines by in- voking model operations including compute_values and generate_sequences, which are executed under the multi- controller paradigm on multiple GPUs. To adapt to Safe- RLHF which integrates an additional cost model to evaluate safety preferences and the pre-taining loss for actor, only 5 more lines of code are added on top of PPO implementation. To adapt to ReMax, one additional call to actor generation is needed, and the critic-related code can be removed. Achieving flexible. This flexibility of extension is crucial for researchers to explore different RLHF algorithms: they can reuse distributed computation encapsulated in each model class and simply adjust the code for numerical computations according to specific algorithms, such as GAE [67] and KL di-",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 149
    }
  },
  {
    "page_content": "reuse distributed computation encapsulated in each model class and simply adjust the code for numerical computations according to specific algorithms, such as GAE [67] and KL di- vergence in compute_advantage and loss functions of actor and critic. The streamlined development can be attributed to the hybrid programming model. Our modular API design simplifies development, facilitates extensive code reuse, and enables directly incorporating the codebase of existing LLM training/serving frameworks. It also decouples model com- putation and data transfer among models. Any change in the distributed frameworks does not affect the code of the RLHF algorithm (Figure 6), enabling individualized optimization for each model’s execution (§5). Flexible placement of mod- els with diverse workloads is supported, enabling optimized mapping of RLHF dataflow onto various devices (§6).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 150
    }
  },
  {
    "page_content": "# Initialize cost model by reusing the RewardWorkercost = RewardWorker(cost_config, resource_pool)... # omit other models initializationalgo_type = “Safe-RLHF” # specify different RLHF numerical computation.# Examples of PPO and Safe-RLHFfor (prompts, pretrain_batch) in dataloader: # Stage 1: Generate responses batch = actor.generate_sequences(prompts) batch = actor.generate_sequences(prompts, do_sample=False) # Stage 2: Prepare experience batch = critic.compute_values(batch) batch = reference.compute_log_prob(batch) batch = reward.compute_reward(batch) batch = cost.compute_cost(batch) batch = compute_advantages(batch, algo_type) # Stage 3: Actor and critic training critic_metrics = critic.update_critic(batch, loss_func=algo_type) pretrain_loss = actor.compute_loss(pretrain_batch) batch[“pretrain_loss”] = pretrain_loss actor_metrics = actor.update_actor(batch, loss_func=algo_type)is added for Safe-RLHFis added for ReMaxNot necessary in ReMax EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 151
    }
  },
  {
    "page_content": "G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu Figure 7. 3D-HybridEngine workflow in one RLHF iteration. 4 GPUs are used for actor training and generation. 1-2-2 (𝑝-𝑡-𝑑) parallel groups are used in training and 1-1-2-2 (𝑝𝑔- 𝑡𝑔-𝑑𝑔-𝑑) parallel groups are used in generation. 5 3D-HybridEngine We design the 3D-HybridEngine to support efficient training and generation of the actor model, targeting significant RLHF throughput improvement. 5.1 Parallel Groups",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 152
    }
  },
  {
    "page_content": "To eliminate redundant actor model copies, we advocate deploying actor training and generation stages on the same set of devices, 𝑁𝑎 GPUs allocated to the actor, and execute them sequentially on the same copy of actor model weights. Nonetheless, actor training and generation may well adopt different 3D parallelism strategies, i.e., the generation stage typically requires smaller TP and PP sizes but a larger DP size, than the training stage (§2.3). 3D-HybridEngine enables efficient model parameter resharding between actor training and generation across the same set of devices in this context. Let 𝑝-𝑡-𝑑 denote 3D parallel groups constructed for ac- tor training, corresponding to the set of GPUs to host 𝑝 pipeline stages, 𝑡 tensor shards, and 𝑑 model replicas [54]. 3D-HybridEngine builds different parallel groups for actor training and generation, according to their different 3D paral- lelism strategies, respectively. We use 𝑝𝑔, 𝑡𝑔, and 𝑑𝑔 to denote the size of generation pipeline parallel group, generation tensor parallel group, and micro data parallel group, respec- tively, in the generation stage. 𝑑𝑔 indicates the ratio of model",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 153
    }
  },
  {
    "page_content": "the size of generation pipeline parallel group, generation tensor parallel group, and micro data parallel group, respec- tively, in the generation stage. 𝑑𝑔 indicates the ratio of model replica number in generation over that in training, i.e., each DP replica in training becomes 𝑑𝑔 micro DP replicas, to pro- cess 𝑑𝑔 microbatches of prompts and responses. We have 𝑝𝑡 𝑁𝑎=𝑝×𝑡×𝑑=𝑝𝑔×𝑡𝑔×𝑑𝑔×𝑑 such that 𝑑𝑔 = 𝑝𝑔𝑡𝑔 . The micro DP groups are employed exclusively in actor generation stage to render a larger DP size for full device utilization. The generation parallel groups are denoted by 𝑝𝑔-𝑡𝑔-𝑑𝑔-𝑑.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 154
    }
  },
  {
    "page_content": "5.2 3D-HybridEngine Workflow Between actor training in iteration 𝑖 of RLHF and actor gen- eration in iteration 𝑖 + 1, the actor model parameters need to be resharded and prompts data to be distributed, follow- ing the parallel group configurations in the two stages. In iteration 𝑖 + 1 of RLHF, 3D-HybridEngine gathers the actor Figure 8. Model weights resharding. 2 machines each with 4 GPUs are used for actor training and generation. model parameters updated in iteration 𝑖 (step 1○ in Figure 7), for generation within each micro DP group. Then, the batch of prompts are loaded to each model replica (step 2○), which generates responses (Generation stage of RLHF). Following this, 3D-HybridEngine performs an all-gather operation on the generation results within each micro DP group (step 3○), and re-partitions model parameters according to the 3D parallelism for actor training (step 4○). With model weights, prompts and responses correctly re-distributed, the loss of the actor model is computed and actor model weights are up- dated following the RLHF algorithm (step 5○) - actor training stage of iteration 𝑖 + 1. 5.3 Zero redundancy model resharding",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 155
    }
  },
  {
    "page_content": "Parallel grouping methods in 3D parallelism are typically as follows: PP and TP groups are formed by assigning consecu- tive ranks to pipeline stages and tensor shards, respectively; DP groups are constructed by selecting ranks at regular in- tervals, determined by the product of PP size and TP size. In Figure 8(a), actor training uses 3D parallel groups, 1-4-2: there is one PP group for all GPUs (for illustration clarify); the TP groups are [G1, G2, G3, G4], [G5, G6, G7, G8], and the DP groups are [G1, G5], [G2, G6], [G3, G7], [G4, G8]. Suppose the same parallel grouping methods are used but with different parallel sizes, e.g., 1-2-2-2 for generation in Figure 8(a). During the transition from training to genera- tion, 3D-HybridEngine applies all-gather operations among the model parallel groups to aggregate all parameters, and then retain only a subset of model weights on each device for its generation, according to the parallel groups the device belongs to. On some GPUs (e.g., G2, G3, G6, G7), there is no overlap between training and generation model weights, and separate memory is needed to maintain weights for sub- sequent training as well (grey boxes in Figure 8(a)).We call",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 156
    }
  },
  {
    "page_content": "GPU & rank1Model partitionPromptResponseMicro-DP groupTP groupPRAll Gather Model weights<latexit sha1_base64=\"bDj2xs9J0e+TmZzdVf7qIUesb/s=\">AAAB+HicbVBNS8NAEN3Ur1o/GvXoJVgED1ISkeqx4MVjBfsBbSibzbRdutmE3YlYQ3+JFw+KePWnePPfuG1z0NYHA4/3ZnZnXpAIrtF1v63C2vrG5lZxu7Szu7dftg8OWzpOFYMmi0WsOgHVILiEJnIU0EkU0CgQ0A7GNzO//QBK81je4yQBP6JDyQecUTRS3y73EB6RccUEhJk37dsVt+rO4awSLycVkqPRt796YczSCCQyQbXuem6CfkYVcvPktNRLNSSUjekQuoZKGoH2s/niU+fUKKEziJUpic5c/T2R0UjrSRSYzojiSC97M/E/r5vi4NrPuExSBMkWHw1S4WDszFJwQq6AoZgYQpniZleHjaiiDE1WJROCt3zyKmldVL1atXZ3Wamf53EUyTE5IWfEI1ekTm5JgzQJIyl5Jq/kzXqyXqx362PRWrDymSPyB9bnDx7yk1Y=</latexit>1○<latexit sha1_base64=\"HUb68ji/9AxT6w+cvZjgfcF6EzY=\">AAAB+HicbVBNS8NAEN34WetHox69BIvgQUpSpHosePFYwX5AG8pmM22XbjZhdyLW0F/ixYMiXv0p3vw3btsctPXBwOO9md2ZFySCa3Tdb2ttfWNza7uwU9zd2z8o2YdHLR2nikGTxSJWnYBqEFxCEzkK6CQKaBQIaAfjm5nffgCleSzvcZKAH9Gh5APOKBqpb5d6CI/IuGICwqw67dtlt+LO4awSLydlkqPRt796YczSCCQyQbXuem6CfkYVcvPktNhLNSSUjekQuoZKGoH2s/niU+fMKKEziJUpic5c/T2R0UjrSRSYzojiSC97M/E/r5vi4NrPuExSBMkWHw1S4WDszFJwQq6AoZgYQpniZleHjaiiDE1WRROCt3zyKmlVK16tUru7LNcv8jgK5IScknPikStSJ7ekQZqEkZQ8k1fyZj1ZL9a79bFoXbPymWPyB9bnDyB3k1c=</latexit>2○Load prompts<latexit",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 157
    }
  },
  {
    "page_content": "prompts<latexit sha1_base64=\"aoixu1HEd7eIUDMbNIfV3GrETjg=\">AAAB+HicbVDLSgNBEOz1GeMjqx69DAbBg4Rd0egx4MVjBPOAZAmzs5NkyOyDmV4xLvkSLx4U8eqnePNvnCR70MSChqKqe6a7/EQKjY7zba2srq1vbBa2its7u3sle/+gqeNUMd5gsYxV26eaSxHxBgqUvJ0oTkNf8pY/upn6rQeutIijexwn3AvpIBJ9wSgaqWeXusgfkQnFJA+yy0nPLjsVZwayTNyclCFHvWd/dYOYpSGPkEmqdcd1EvQyqlCYJyfFbqp5QtmIDnjH0IiGXHvZbPEJOTFKQPqxMhUhmam/JzIaaj0OfdMZUhzqRW8q/ud1Uuxfe5mIkhR5xOYf9VNJMCbTFEggFGcox4ZQpoTZlbAhVZShyapoQnAXT14mzfOKW61U7y7KtbM8jgIcwTGcggtXUINbqEMDGKTwDK/wZj1ZL9a79TFvXbHymUP4A+vzByUGk1o=</latexit>5○<latexit sha1_base64=\"Na/pcQ2WIU22F5P4eh8iYMa1qtA=\">AAAB+HicbVDLSgNBEOz1GeMjqx69DAbBg4Rdlegx4MVjBPOAZAmzs5NkyOyDmV4xLvkSLx4U8eqnePNvnCR70MSChqKqe6a7/EQKjY7zba2srq1vbBa2its7u3sle/+gqeNUMd5gsYxV26eaSxHxBgqUvJ0oTkNf8pY/upn6rQeutIijexwn3AvpIBJ9wSgaqWeXusgfkQnFJA+yi0nPLjsVZwayTNyclCFHvWd/dYOYpSGPkEmqdcd1EvQyqlCYJyfFbqp5QtmIDnjH0IiGXHvZbPEJOTFKQPqxMhUhmam/JzIaaj0OfdMZUhzqRW8q/ud1Uuxfe5mIkhR5xOYf9VNJMCbTFEggFGcox4ZQpoTZlbAhVZShyapoQnAXT14mzfOKW61U7y7LtbM8jgIcwTGcggtXUINbqEMDGKTwDK/wZj1ZL9a79TFvXbHymUP4A+vzByH8k1g=</latexit>3○Generate and AllGather responses<latexit",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 158
    }
  },
  {
    "page_content": "and AllGather responses<latexit sha1_base64=\"5fUtIMUC6GDaKxFcmKHJtdHWN7Q=\">AAAB+HicbVBNS8NAEN34WetHox69BIvgQUoipXosePFYwX5AG8pmM22XbjZhdyLW0F/ixYMiXv0p3vw3btsctPXBwOO9md2ZFySCa3Tdb2ttfWNza7uwU9zd2z8o2YdHLR2nikGTxSJWnYBqEFxCEzkK6CQKaBQIaAfjm5nffgCleSzvcZKAH9Gh5APOKBqpb5d6CI/IuGICwqw67dtlt+LO4awSLydlkqPRt796YczSCCQyQbXuem6CfkYVcvPktNhLNSSUjekQuoZKGoH2s/niU+fMKKEziJUpic5c/T2R0UjrSRSYzojiSC97M/E/r5vi4NrPuExSBMkWHw1S4WDszFJwQq6AoZgYQpniZleHjaiiDE1WRROCt3zyKmldVrxapXZXLdcv8jgK5IScknPikStSJ7ekQZqEkZQ8k1fyZj1ZL9a79bFoXbPymWPyB9bnDyOBk1k=</latexit>4○Partition weights to train mode2P1R1P2R2P1R1P2R2P3R3P4R4P3R3P4R412341234DataloaderP1P2P3P4Training12P1R1P2R234P3R3P4R4ModelUpdate1Train34GenTrainGenGen TP GroupAll GatherTrain DP GroupTrain TP GroupMicro DP GroupModel weight partitionRedundant training weight GPU & rankG1Discard unused weights from other ranks(a) Same grouping methods between training and generation (HybridFlow-V)(b) Optimized parallel grouping methods (HybridFlow)G1TrainGenTrainGenG1G2G3G4G5G6G7G8G2G3G4G5G6G7G8G1G2G3G4G5G6G7G8G1G2G4G3All-Gathercomplete weightsG5G6G7G8G1G3G2G4G5G7G6G8 All-Gather withinMicro-DP groups HybridFlow: A Flexible and Efficient RLHF Framework",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 159
    }
  },
  {
    "page_content": "EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands Table 2. Transition overhead between training & generation Comm. Vol Peak Mem. DS-Chat HybridFlow-V HybridFlow 𝑡𝑝 −𝑡𝑔𝑝𝑔 𝑡𝑝𝑑 −1 𝑡𝑝 −1 𝑡𝑔𝑝𝑔𝑡𝑝 𝑀 𝑡𝑝 𝑀 𝑡𝑝𝑑 𝑀 𝑀 𝑀 𝑀 1 𝑡𝑔𝑝𝑔 Redundancy 𝑡𝑝𝑑 𝑀 1 𝑡𝑝 𝑀 1 0 𝑑𝑔 −1 𝑡𝑝 𝑀 = each micro DP group. The communication overhead is re- 𝑡𝑝 −𝑡𝑔𝑝𝑔 𝑡𝑔𝑝𝑔𝑡𝑝 𝑀. Each GPU only needs to col- duced to lect remote parameters within its micro DP group and can reuse the training weights in generation. Therefore, the peak memory usage of model parameters in HybridFlow precisely matches the model partition size on each GPU in generation, eliminating any redundancy in GPU memory usage. 𝑡𝑔 and",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 160
    }
  },
  {
    "page_content": "the system HybridFlow-V, when 3D-HybridEngine uses the above vanilla parallel grouping methods in the two stages. We further design a new parallel grouping method for 3D- HybridEngine to use in the generation stage, that eliminates the redundancy in weights storage and leads to minimal memory footprint and communication due to actor model resharding between training and generation. Specifically, we form generation TP and PP groups by selecting ranks at 𝑝 regular intervals, determined by 𝑡 𝑝𝑔 , and construct micro DP groups by sequentially assigning ranks along the generation TP or PP dimensions. In Figure 8(b), 1-2-2-2 paral- lel groups are used in generation: the generation TP groups are [G1, G3], [G2, G4], [G5, G7], [G6, G8]; and the micro DP groups are [G1, G2], [G3, G4], [G5, G6], [G7, G8]. This strategic rearrangement of generation parallel groups leads to overlap between training and generation model weights on each device, enabling reuse of training weights during generation and zero redundancy in device memory usage due to model resharding. In addition, 3D-HybridEngine conducts several all-gather operations concurrently, one within each",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 161
    }
  },
  {
    "page_content": "generation and zero redundancy in device memory usage due to model resharding. In addition, 3D-HybridEngine conducts several all-gather operations concurrently, one within each micro DP group, leading to significantly reduced communi- cation overhead.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 162
    }
  },
  {
    "page_content": "5.4 Transition overhead In Table 2, we compare communication overhead and mem- ory footprint during the transition between training and generation stages, among different actor engine designs. We assume model size of the actor is 𝑀 and 𝑁𝑎 GPUs are used for its training and generation. The actor engine in DeepSpeed- Chat conducts an all-gather operation across all GPUs dur- ing transition; HybridFlow-V performs this all-gather within training TP and PP groups. The communication volumes 𝑡𝑝𝑑 −1 𝑡𝑝𝑑 𝑀 for DeepSpeed- for these operations are 𝑡𝑝 −1 𝑡𝑝 𝑀 for HybridFlow-V, calculated following [13]. Chat and Both engines aggregate all model parameters in each GPU’s memory before subsequently partitioning model states ac- cording to the generation parallel groups, resulting in a peak memory usage of model parameters 𝑀. As they cannot reuse training weights during generation on some GPUs, training weights need to be maintained on them, amounting to 1 𝑡𝑝𝑑 and 1 𝑡𝑝 redundant memory consumption, respectively. 𝑁𝑎 −1 𝑁𝑎 𝑀 = With our parallel grouping method for the generation stage, HybridFlow confines the all-gather operation within",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 163
    }
  },
  {
    "page_content": "6 Auto Device Mapping Our hybrid programming model requires users to input the following configurations, which are referred to as a mapping of the RLHF dataflow to the given devices: (a) device place- ment of the models in the dataflow; (b) the corresponding parallelism strategy for running each model in each stage. We provide an efficient algorithm (Algorithm 1) for users to identify the optimized mapping of executing the RLHF dataflow on a given cluster of devices, that minimizes the end-to-end latency of each RLHF iteration. Given a dataflow 𝐷, we first explore all possible placement plans P for the models in the given cluster (Line 3). For example, the PPO al- gorithm involves four models, resulting in 15 possible place- ments (from the Bell partition problem [10, 62]), ranging from a completely standalone placement where all models are placed on different devices (e.g., OpenRLHF’s placement) to colocating all models on the same set of devices (e.g., DeepSpeed-Chat’s placement). We refer to colocated models on the same set of GPUs as a colocated set. Models in a colo- cated set can employ different parallelism strategies across",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 164
    }
  },
  {
    "page_content": "DeepSpeed-Chat’s placement). We refer to colocated models on the same set of GPUs as a colocated set. Models in a colo- cated set can employ different parallelism strategies across the same set of GPUs. We identify the smallest number of GPUs to be allocated to each of the colocated model sets, 𝐴𝑚𝑖𝑛, based on memory consumption of colocated models, ensuring no out-of-memory errors (Line 9).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 165
    }
  },
  {
    "page_content": "Next, starting from the minimal GPU allocation in 𝐴𝑚𝑖𝑛, we enumerate all feasible device allocations to each colo- cated model set (Lines 10-12). Given device allocation 𝐴 to the colocated set and computation workload 𝑊 of models in the set, we explore optimized parallelism strategies for each model in the auto_parallel module, that minimizes model execution latency. The workload 𝑊 includes input and output shapes and computation (training, inference or generation) of each model. In auto_parallel, we utilize a simulator module simu to estimate the latency of different parallel strategies, following previous research [42, 84, 90, 92] (outline in Appendix. C).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 166
    }
  },
  {
    "page_content": "The d_cost module estimates the end-to-end latency of the RLHF dataflow under given model placement and par- allelism strategies, by iterating through all stages in the dataflow graph and summing up latencies of all stages (Lines 17, 25). For models in the same colocated set and involving com- putation in the same stage (such as actor and critic both performing model update in RLHF training stage), their exe- cution latencies are summed up (Line 32). For models in dif- ferent colocated sets, their execution within the same stage EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu Algorithm 1 Device Mapping for an RLHF Dataflow 1: Input: RLHF dataflow graph 𝐷, LLMs in RLHF dataflow 𝐿=[𝑙1, 𝑙2, . . . , 𝑙𝑘 ], workload 𝑊 of LLMs in RLHF dataflow, total # of GPUs 𝑁 , memory capacity per GPU 𝑄 2: Output: device mapping of models in RLHF dataflow 3: P ← get_placements(𝐷, 𝐿, 𝑁 ) 4: 𝐶∗ ← ∞ 5: 𝑏𝑒𝑠𝑡_𝑚𝑎𝑝𝑝𝑖𝑛𝑔 ← ∅ 6: for all 𝑝𝑙𝑚 ∈ P do 𝐶𝑝𝑙𝑚 ← ∞ 7: 𝑏𝑒𝑠𝑡_𝑝𝑙𝑚_𝑎𝑙𝑙𝑜𝑐 ← ∅ 8: 𝐴𝑚𝑖𝑛 ← get_min_alloc(𝑝𝑙𝑚, 𝑄, 𝑁 ) 9: for all 𝐴 ∈ enum_alloc(𝑁 , 𝐴𝑚𝑖𝑛) do 10: 11: 12: 13: 14:",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 167
    }
  },
  {
    "page_content": "(cid:98)𝐿 ← [] for all set ∈ 𝑝𝑙𝑚 do for all 𝑙 ∈ set do (cid:98)𝑙 ← auto_parallel(𝐴, 𝐴𝑚𝑖𝑛, 𝑙,𝑊 ) (cid:98)𝐿.append((cid:98)𝑙) if 𝐶𝑝𝑙𝑚 < 𝐶∗ then 𝐶∗ ← 𝐶𝑝𝑙𝑚 𝑏𝑒𝑠𝑡_𝑚𝑎𝑝𝑝𝑖𝑛𝑔 ← 𝑏𝑒𝑠𝑡_𝑝𝑙𝑚_𝑎𝑙𝑙𝑜𝑐 𝑝𝑙𝑚.update((cid:98)𝐿) 𝐶𝑎𝑙𝑙𝑜𝑐 ← d_cost(𝐷, 𝑝𝑙𝑚,𝑊 ) if 𝐶𝑎𝑙𝑙𝑜𝑐 < 𝐶𝑝𝑙𝑚 then 𝐶𝑝𝑙𝑚 ← 𝐶𝑎𝑙𝑙𝑜𝑐 𝑏𝑒𝑠𝑡_𝑝𝑙𝑚_𝑎𝑙𝑙𝑜𝑐 ← (𝑝𝑙𝑚, 𝐴) 15: 16: 17: 18: 19: 20: 21: 22: 23: 24: return 𝑏𝑒𝑠𝑡_𝑚𝑎𝑝𝑝𝑖𝑛𝑔 25: Procedure d_cost(𝐷, 𝑝𝑙𝑚, 𝑊 ): 26: 27: 28: 29: 30: 31: 32: 33: 34: 𝑐𝑔 ← [0] × 𝑠 for all 𝑖 ∈ {0, ..., 𝑠 − 1} do 𝑐 [𝑖] ← 𝑚𝑎𝑥 {𝑐 [𝑖], 𝑐𝑔 [𝑖]} 𝑐𝑔 [𝑖] ← 𝑐𝑔 [𝑖] + simu((cid:98)𝑙,𝑊 [𝑖]) for all (cid:98)𝑙 ∈ set do return sum(𝑐) 𝑠 ← number of stages in 𝐷 𝑐 ← [0] × 𝑠 // Initialize latency for each stage to 0 for all set ∈ 𝑝𝑙𝑚 do can be parallelized, and the latency of the stage is deter- mined by the maximum execution time among different sets (Line 33). We identify the best device placement of the mod- els with their corresponding parallelism strategies, achieving minimal execution time per RLHF iteration (Lines 18-23). (𝑁 −1)! The complexity of Algorithm 1 is 𝑂 (",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 168
    }
  },
  {
    "page_content": "(𝑁 −1)! The complexity of Algorithm 1 is 𝑂 ( (𝑘 −1)!(𝑁 −𝑘 )! ), where 𝑘 is the number of models in the dataflow and 𝑁 is the total number of devices to run the dataflow. This is the worst-case complexity for enumerating all possible device allocations for a placement strategy (i.e., the standalone placement), calculated by assigning 𝑁 devices to 𝑘 models (known as the integer partition problem [6]). For better efficiency, we cache parallelism strategies identified for each model on a number of devices 𝐴, to eliminate redundant searches for the same parallelism strategies when the model is placed on different sets of 𝐴 GPUs in different placement strategies. Though we assume 𝑁 homogeneous GPUs when running the auto mapping algorithm, Algorithm 1 can be readily extended for optimizing model mapping over heterogeneous devices, by considering heterogeneous devices in simu and auto_parallel modules [88].",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 169
    }
  },
  {
    "page_content": "7 Implementation HybridFlow is implemented in around 12k lines of Python code (LoC). Hybrid programming model. The hierarchical APIs are implemented with 1.8k LoC. The centralized single controller is built on top of Ray [50] and uses Remote Process Calls (RPC) to coordinate the execution order of different models and transfer data between models following the dataflow. These intermediate data are stored in TensorDict [57]. In our multi-controller paradigm for distributed computation, each model function runs on a separate process across various devices, with control messages relayed from each controller’s CPU process to the corresponding GPU. Our implementation supports Megatron-LM, PyTorch FSDP, and DeepSpeed as the LLM training and inference engines, and vLLM for auto- regressive generation. In vLLM, we replace the centralized KVCache manager with a distributed manager to align with the multi-controller paradigm. 3D-HybridEngine. Its main logic is implemented with 2.4k LoC on top of Megatron-LM and vLLM. We store actor model weights for training and generation stages on separate mem- ory buffers, offload generation weights to the CPU mem-",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 170
    }
  },
  {
    "page_content": "LoC on top of Megatron-LM and vLLM. We store actor model weights for training and generation stages on separate mem- ory buffers, offload generation weights to the CPU mem- ory during training, reload generation weights back to GPU memory during the transition, and use both buffers in gen- eration. We use NCCL communication primitives [35] to collect and concatenate model parameters in each micro DP group during the transition between training and generation. We offload KVCache to CPU memory after generation and reload it back to GPU in the next iteration. Auto-Mapping Algorithm is implemented with 1.9k LoC, together with three simulators for training, inference, and generation workloads. The algorithm is run before starting the RLHF dataflow on CPU, to generate device mapping and parallelism strategies for dataflow initialization.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 171
    }
  },
  {
    "page_content": "8 Evaluation 8.1 Experimental Setup Testbed. We deploy HybridFlow on a cluster of 16 machines (128 GPUs). Each machine is equipped with 8 NVIDIA A100- 80GB GPUs inter-connected with 600GB/s NVLink. The inter-machine bandwidth is 200Gbps. Our experiments use the following software versions: CUDA12.1, PyTorch 2.1.2, Megatron-core 0.6.0, NCCL 2.18.1, and vLLM 0.3.1. Models and RLHF algorithms. We run the RLHF dataflow (Figure 1) of PPO [68], ReMax [43] and Safe-RLHF [19] al- gorithms. PPO is one of the most popular algorithms for RLHF [7, 55], consisting of actor, critic, reference policy, and HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands (a) 7B (1.68×∼8.63×) (b) 13B (2.70×∼18.96×) (c) 34B (2.41×∼20.57×) (d) 70B (5.17×∼17.98×) Figure 9. PPO throughput. Numbers in parentheses are HybridFlow speedups compared with baselines. (a) 7B (1.53×∼2.56×) Figure 10. ReMax throughput. Numbers in parentheses are HybridFlow speedups compared with baselines (b) 13B (2.49×∼3.66×) (c) 34B (2.14×∼4.80×) (d) 70B (6.46×∼9.78×) (a) 7B (1.71×∼12.87×) (b) 13B (2.49×∼18.47×) (c) 34B (2.20×∼19.76×) (d) 70B (4.89×∼16.86×)",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 172
    }
  },
  {
    "page_content": "(b) 13B (2.49×∼3.66×) (c) 34B (2.14×∼4.80×) (d) 70B (6.46×∼9.78×) (a) 7B (1.71×∼12.87×) (b) 13B (2.49×∼18.47×) (c) 34B (2.20×∼19.76×) (d) 70B (4.89×∼16.86×) Figure 11. Safe-RLHF throughput. Numbers in the parentheses are HybridFlow speedups compared with the baselines",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 173
    }
  },
  {
    "page_content": "(b) 13B (2.49×∼18.47×) (c) 34B (2.20×∼19.76×) (d) 70B (4.89×∼16.86×) Figure 11. Safe-RLHF throughput. Numbers in the parentheses are HybridFlow speedups compared with the baselines reward models. Each model is a Llama [73] model with sizes ranging from 7B to 70B. Safe-RLHF has an additional cost model whose architecture and size are the same as the re- ward model and ReMax eliminates the critic model. We use mixed precision for actor and critic training, i.e., BF16 for model parameters and FP32 for gradient and optimizer states, with Adam [38] optimizer in all experiments. BF16 is used in model inference and auto-regressive generation. If not specified, the experiment results are obtained from PPO. Baselines. We compare HybridFlow with state-of-the-art RLHF systems including DeepSpeed-Chat [82] v0.14.0, Open- RLHF [30] v0.2.5, and NeMo-Aligner [17] v0.2.0 (detailed in Table 1). NeMo-Alginer doesn’t support ReMax algorithm. We do not compare HybridFlow to other frameworks such as Trlx [27], HuggingFaceDDP [79], and Collosal-Chat [15] as they are less representative and slower than the above baselines (as reported in [82]).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 174
    }
  },
  {
    "page_content": "We use RLHF throughput (tokens/sec) as the performance metric, computed by dividing the total number of tokens in prompts and responses in a global batch by one RLHF itera- tion time. All reported performance numbers are averaged over 5 training iterations after a warm-up of 10 iterations. Datasets and hyperparameters. We perform RLHF on \"Dahoas/ful-hh-rlhf\" dataset [7] of HuggingFace, which is widely used for LLM alignment [64, 85]. As the baseline systems may not incorporate continuous-batching optimiza- tion [83] during generation, for a fair comparison, we en- force the same length on all responses to be generated. In each experiment, the input prompt length and the output response length are both 1024 and the global batch size of input prompts to the actor model is 1024. The number of PPO epochs is 1 and the number of PPO update iterations per epoch is 8, aligning with previous RLHF research [31, 55, 81]. 8.2 End-to-End performance",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 175
    }
  },
  {
    "page_content": "8.2 End-to-End performance Figures 9, 10, and 11 show RLHF throughput when running PPO, ReMax, and Safe-RLHF respectively. The actor, critic, reference, and reward models in this set of experiments are of the same size, following previous practice [7, 55, 82]. The number of GPUs used in experiments of different model sizes ranges from the smallest number of GPUs to run RLHF without OOM to 128 GPUs. We do not enable offloading optimizer states [61] in the experiments for fair comparison. Overall performance. We observe that HybridFlow consis- tently outperforms the baselines across all model scales. In",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 176
    }
  },
  {
    "page_content": "8163264128# of GPUs0123Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow163264128# of GPUs012Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow3264128# of GPUs0.00.51.01.5Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow64128# of GPUs0.00.20.40.60.81.0Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow8163264128# of GPUs0123Throughput (tokens/s)1e4DS-ChatOpenRLHFHybridFlow8163264128# of GPUs0.00.51.01.52.0Throughput (tokens/s)1e4DS-ChatOpenRLHFHybridFlow163264128# of GPUs0.000.250.500.751.00Throughput (tokens/s)1e4DS-ChatOpenRLHFHybridFlow32B64128# of GPUs0.00.20.40.60.81.0Throughput (tokens/s)1e4DS-ChatOpenRLHFHybridFlow8163264128# of GPUs0123Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow163264128# of GPUs0.00.51.01.52.0Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow3264128# of GPUs0.00.51.01.5Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow64128# of GPUs0.00.20.40.60.81.0Throughput (tokens/s)1e4NeMo-AlignerDS-ChatOpenRLHFHybridFlow EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu (a) 13B (b) 34B",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 177
    }
  },
  {
    "page_content": "G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu (a) 13B (b) 34B Figure 12. Throughput of HybridFlow under different placements Figure 13. Placement comparison under 13B actor and reference policy & 70B critic and reward model.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 178
    }
  },
  {
    "page_content": "Figure 9 for PPO, HybridFlow outperforms DeepSpeed-Chat, OpenRLHF and NeMo-Aligner by 3.67× (up to 7.84×), 3.25× (up to 5.93×) and 12.52× (up to 20.57×), respectively. This is mainly because HybridFlow effectively executes generation, inference, and training in all RLHF stages by sharding the models with different parallelism strategies to fit various computation workloads. HybridFlow achieves the highest average speedup of 9.64× when training 70B models, as Hy- bridFlow reduces the transition overhead by up to 71.2% and 89.1% compared to DeepSpeed-Chat and OpenRLHF, which also incurs large inter-machine communication when train- ing with ZeRO-3. Due to the lack of KVCache in generation engine, NeMo-Aligner’s main performance bottleneck lies in the generation stage, which accounts for up to 81.2% of its RLHF iteration time. Similar results can be observed in Figures 10, 11 validating the efficiency of HybridFlow on running various RLHF algorithms. Scalability. HybridFlow achieves at least 2.09× speedup on 8 GPUs. With increasing GPUs, the strong scaling efficiency of HybridFlow on various model scales is 66.8%, computed by di- viding",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 179
    }
  },
  {
    "page_content": "viding throughput in largest scale throughput in smallest scale by max. # of GPUs min. # of GPUs [5], averaging over three algorithms and all model scales. Scal- ing to a large number of GPUs with a fixed global batch size results in smaller local batch sizes for each worker, po- tentially causing GPU underutilization. Running 7B models on 128 GPUs, HybridFlow still outperforms the best base- line OpenRLHF for 1.68×, 1.53×, and 1.71× on PPO, ReMax, and Safe-RLHF respectively. This can be attributed to Hy- bridFlow’s ability to adapt the best placement strategies for different models and cluster sizes to minimize RLHF time. OpenRLHF performs better in a larger GPU cluster but less efficiently on smaller ones. 8.3 Model Placement",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 180
    }
  },
  {
    "page_content": "8.3 Model Placement In this experiment, we implement various model placements of the PPO algorithm in HybridFlow, under the same model and cluster settings as in Sec. 8.2: (i) colocate, the placement strategy in DeepSpeed-Chat; (ii) standalone, that in Open- RLHF and; (iii) split, NeMo-Aligner’s colocation placement (actor and reference policy on the same set of devices and critic and reward model on another); (iv) hybridflow, the optimized placement obtained by Algorithm 1.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 181
    }
  },
  {
    "page_content": "Comparison of different model placements. Figure 12 reveals that optimized placement of HybridFlow under differ- ent numbers of GPUs varies. From 16 to 64 GPUs, colocating all models on the same set of devices yields the best perfor- mance. For 96 to 128 GPUs with 34B models and 96 GPUs with 13B models, the split strategy becomes optimal. The split strategy divides GPUs evenly between the two sets of models, as their sizes are equal. For 13B models on 128 GPUs, the standalone strategy achieves the highest through- put. In this case, HybridFlow allocates 64 GPUs for the actor, 32 for the critic, and 16 each for the reference and reward model. In smaller clusters, computation of all models can fully utilize GPU resources; the colocate strategy ensures maximum GPU usage in different RLHF stages. In larger clus- ters, RLHF throughput under colocate placement fails to scale up linearly as the batch size is fixed and the computation-to- communication ratio decreases with a larger DP size on more GPUs. Standalone and split strategies place models on differ- ent devices with a smaller DP size for each model in larger clusters, facilitating parallel execution of different models in",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 182
    }
  },
  {
    "page_content": "GPUs. Standalone and split strategies place models on differ- ent devices with a smaller DP size for each model in larger clusters, facilitating parallel execution of different models in the same stages. In all cases, our Algorithm 1 produces the best placement with the highest training throughput. Larger critic and reward model. We further evaluate model placements when running PPO with a 13B actor and reference policy and 70B critic and reward models (larger critic and reward models are expected to produce better align- ment [7]). Figure 13 shows that the colocate strategy still outperforms others by 44.8% on average with up to 64 GPUs. The split strategy achieves higher throughput with 96 GPUs. When scaling to 128 GPUs, the best placement obtained by Algorithm 1 colocates actor, reference, and reward models on 64 GPUs while allocating the remaining 64 GPUs to critic. On the same number of GPUs, actor and reference policy’s computation time is much smaller than critic and reward model, and colocating the reward model with actor and ref- erence policy reduces the GPU idle time in the experience preparation stage. In general, distributing actor and critic on",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 183
    }
  },
  {
    "page_content": "model, and colocating the reward model with actor and ref- erence policy reduces the GPU idle time in the experience preparation stage. In general, distributing actor and critic on different devices for parallel execution in the training stage leads to higher throughput in large clusters.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 184
    }
  },
  {
    "page_content": "8.4 3D-HybridEngine Transition time comparison. Figure 14 shows the transi- tion time between actor training and generation stages on 1624326496128# of GPUs012Throughput (tokens/s)1e4ColocateSplitStandaloneHybridFlow32486496128# of GPUs0.00.51.01.5Throughput (tokens/s)1e4ColocateSplitStandaloneHybridFlow326496128# of GPUs0.00.51.01.5Throughput (tokens/s)1e4ColocateSplitStandaloneHybridFlow HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands (a) 7B (𝑇𝑔=2, 𝑃𝑔=1, 𝑇 =8,𝑃 =1) (b) 13B (𝑇𝑔=4, 𝑃𝑔=1, 𝑇 =8,𝑃 =1) (c) 34B (𝑇𝑔=8, 𝑃𝑔=1, 𝑇 =8,𝑃 =4) (d) 70B (𝑇𝑔=8, 𝑃𝑔=1, 𝑇 =8,𝑃 =8) Figure 14. Transition time between actor training and generation. (a) 7B (b) 13B Figure 15. Time breakdown on different generation parallel sizes of the actor model on 16 GPUs.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 185
    }
  },
  {
    "page_content": "various model scales, which is the time to reshard model weights from training to generation, under the same settings in §8.2. OpenRLHF’s transition time includes weight syn- chronization time between two copies of the actor model on different devices. HybridFlow reduces the transition time by 55.2% (11.7s) on average and the transition overhead by up to 89.1% (78.2s) with 70B models, while maintaining consistent overhead across different cluster scales. This is attributed to our new parallel grouping method for the generation stage (§5.4). In baseline methods, all model parameters must be collected during transition, necessitating layer-by-layer col- lections multiple times to prevent OOM. HybridFlow enables zero memory redundancy during transition and requires only one all-gather operation per micro DP group. Transition and generation time We further validate the need to use different parallel sizes in actor training and gen- eration in HybridFlow. In this experiment, all models are colocated on the same set of GPUs, and the KVCache for generation is allocated using the remaining GPU memory (i.e., best-effort allocation). Figure 15 gives the transition and",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 186
    }
  },
  {
    "page_content": "colocated on the same set of GPUs, and the KVCache for generation is allocated using the remaining GPU memory (i.e., best-effort allocation). Figure 15 gives the transition and generation time when running RLHF on 16 GPUs with 7B and 13B models, respectively, with training parallel groups 1-8-2 (following p-t-d convention) and varying generation TP group size 𝑡𝑔 from 1 to 8. The generation PP group size remains constant at 𝑝𝑔=1 and the micro DP group size 𝑑𝑔 is computed as 8 𝑡𝑔 . We observe that applying a smaller gener- ation TP group size, 𝑡𝑔=2, for 7B models and 𝑡𝑔=4 for 13B models reduces the generation latency by 60.3% and 36.4%, respectively. Conversely, using the same TP size as training (𝑡𝑔=8), following the NeMo-Aligner approach, results in the largest generation latency due to GPU underutilization. Fur- ther reducing 𝑡𝑔 fails to achieve higher speedup, as a smaller 𝑡𝑔 necessitates maintaining a larger KVCache per GPU.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 187
    }
  },
  {
    "page_content": "Figure 16. Runtime of device mapping algorithm. The model size and # of GPUs are simultaneously scaled. 8.5 Algorithm Runtime Figure 16 shows the running time of Algorithm 1, which is significantly shorter than days of actual RLHF training. A linear growth of running time is exhibited, revealing good scalability of the device mapping algorithm with model size and cluster size. Most of the running time is spent on estimat- ing the execution latency of each model’s parallel strategies. More parallelism strategies are available for a larger model, requiring more simulations to identify the optimal one for each placement plan. Our caching of optimal parallelism strategies of the models to be reapplied across different place- ments reduces the search time for the best placement to at most half an hour.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 188
    }
  },
  {
    "page_content": "9 Discussions Fault Tolerance. HybridFlow is orthogonal to existing fault- tolerance approaches [22, 34, 49, 76, 93] and already incor- porates checkpointing. Failures can be detected by NCCL errors and silent-data-corruption by checksums. Our pro- gramming model enables the single controller to coordinate checkpoint operations via RPC, allowing the saving of model states within each ParallWorker Group. This includes sav- ing parameters of actor/critic models, dataloader IDs, and Random Number Generator (RNG) states to ensure system- wide consistency. Moreover, HybridFlow can also employ redundancy-based fault-tolerance methods, such as broad- cast parameters and CPU checkpoint, for fast recovery if enough healthy model replicas are available [76, 93]. Placement Insights. We conclude three main insights for model placement and GPU allocation in RLHF training. 1) Allocating more GPUs to the actor model can reduce the time- consuming generation latency, which cannot be parallelized with other models. 2) When each model computation can fully utilize GPU resources, colocating all the models is most effective when training on relatively small-scale clusters. 3)",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 189
    }
  },
  {
    "page_content": "with other models. 2) When each model computation can fully utilize GPU resources, colocating all the models is most effective when training on relatively small-scale clusters. 3) When scaling up to large-scale clusters (i.e., strong scaling), distributing the actor and critic models on different devices",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 190
    }
  },
  {
    "page_content": "8163264128# of GPUs05101520Time (s)OpenRLHFDS-ChatHybridFlow-VHybridFlow163264128# of GPUs0102030Time (s)OpenRLHFDS-ChatHybridFlow-VHybridFlow3264128# of GPUs0204060Time (s)OpenRLHFDS-ChatHybridFlow-VHybridFlow64128# of GPUs050100Time (s)OpenRLHFDS-ChatHybridFlow-VHybridFlowTg=8Dg=1Tg=4Dg=2Tg=2Dg=4Tg=1Dg=80255075100Time (s)generation timetransition timeTg=8Dg=1Tg=4Dg=2Tg=2Dg=4Tg=1Dg=80100200Time (s)generation timetransition time(7B,8)(7B,16)(13B,24)(13B,32)(34B,48)(34B,64)(70B,96)(70B,128)Model Size and # of GPUs101102103Time (s) EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 191
    }
  },
  {
    "page_content": "for parallel execution in the training and preparation stages would help achieve higher throughput. Resource multiplexing. HybridFlow enables colocation of models on shared devices by utilizing time-sharing for GPU computation. Recent research in DNN task scheduling has developed fine-grained resource multiplexing techniques, primarily aimed at achieving the service-level objectives of individual tasks [8, 18, 26, 26, 47, 56, 77]. Although the ResourcePool implementation supports parallel execution of collocated models, HybridFlow generally adheres to se- quential execution to prevent GPU resource contention or OOM issues as discussed in Section 2.3. Applying GPU shar- ing and heterogeneous resources in RLHF training poses distinct challenges, as it seeks to balance the computation workload and manage complex data dependencies among various tasks. Investigating fine-grained auto-mapping al- gorithms for GPU sharing in RLHF training, coupled with model offload optimization and integration of heterogeneous devices, would be a promising direction for future research. From alignment to reasoning. In RLHF for LLM alignment, the reward signal is generated by the reward model. Besides",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 192
    }
  },
  {
    "page_content": "devices, would be a promising direction for future research. From alignment to reasoning. In RLHF for LLM alignment, the reward signal is generated by the reward model. Besides alignment tasks, similar algorithms (e.g., PPO and GRPO [70]) can be applied to other domains, such as code generation and mathematical reasoning. For these tasks, a ground truth may exist for each prompt, which can be determined by assessing the correctness of the output value for each code test case and verifying the accuracy of mathematical results. Therefore, the reward model can be replaced by non-neural-network reward modules, such as a sandbox environment [87] for evaluating generated code or a reward function [14, 65] to validate mathematical results. HybridFlow can seamlessly integrate these reward modules by wrapping them as remote functions and orchestrating their execution within the single- process script, providing a flexible and efficient framework for diverse reinforcement learning applications.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 193
    }
  },
  {
    "page_content": "10 Related Work RL frameworks. There have been plenty of frameworks for RL, ranging from general-purpose RL systems design for small-scale DNNs [12, 25, 28, 39, 45, 46] to RLHF sys- tems specifically optimized for LLMs [15, 17, 30, 80, 82]. We have thoroughly examined closely related work in §2 and we discuss more RL frameworks in this section. These RL frame- works [12, 25, 28, 39, 74], similar to recent RLHF systems, use a hodgepodge of multi-controller frameworks to imple- ment their algorithms. They establish multiple long-running distributed programs with each component coordinating the execution order with hard-coded data synchronization. Gear [74] further optimized the experience replay segment of the RL pipeline. However, all these frameworks fail to support LLM training, inference, and generation in RLHF. LLM training and serving systems. TorchDDP [57] and Horovod [69] support data parallel training. ByteScheduler [58]",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 194
    }
  },
  {
    "page_content": "and DeepSpeed [60] extend data parallelism with communi- cation and memory optimizations. Numerous systems [23, 36, 48, 54, 71, 75, 89] optimized large model training through model parallelisms such as tensor parallelism and pipeline parallelism to partition models across devices. LLM serving systems [3, 16, 40, 72, 83, 92] also adopts data and model parallelism to accelerate auto-regressive generation with specialized optimizations like continuous-batching [83] and chunked-prefill [3]. Note that all the above frameworks adopt multi-controller paradigm for efficient computation. Dataflow systems. Dataflow systems like MapReduce [21], Spark [86], Dryad [33], and Naiad [51] are popular for analyt- ics and ML workloads but they lack support for dynamic task graphs. Ray [50] unifies task-parallel and actor programming models in a single dynamic task graph and implements a scal- able distributed scheduler and a global control store, which is adopted by many RL frameworks [45, 46]. Pathways [9], a closed-source project for TPUs, are designed to easily ex- press complex parallelism patterns and fine-grain control flow within a single DNN model, such as pipeline parallelism",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 195
    }
  },
  {
    "page_content": "a closed-source project for TPUs, are designed to easily ex- press complex parallelism patterns and fine-grain control flow within a single DNN model, such as pipeline parallelism and Mixture-of-Experts with sparse computation. It employs an asynchronous distributed dataflow design that enables parallel control plane execution despite data dependencies, reducing the dispatch overhead from single-controller para- digm. Its main focus lies on single-model training, requiring complex compilations of each sub-network of a DNN model. HybridFlow can integrate Pathways as a submodule to im- plement the computation of models in the RLHF dataflow.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 196
    }
  },
  {
    "page_content": "11 Conclusion HybridFlow is an RLHF framework that enables flexible rep- resentation and efficient execution of diverse RLHF algo- rithms. We propose a hybrid programming model that allows users to easily build RLHF dataflow in a few lines of code by encapsulating distributed computation of different LLMs into primitive APIs and hiding the complexity of data resharding among nodes. Our 3D-HybridEngine ensures efficient execu- tion of training and generation of the actor model, with zero memory redundancy and significantly reduced communica- tion overhead for model parameter resharding. Furthermore, our effective mapping algorithm optimizes GPU allocation and placement of models in the RLHF dataflow. Extensive experiments demonstrate that HybridFlow achieves 1.53× to 20.57× speedup compared to state-of-the-art RLHF systems under various model sizes and cluster scales.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 197
    }
  },
  {
    "page_content": "Acknowledgments We would like to thank our shepherd Y. Charlie Hu and the anonymous reviewers for their constructive feedback. We thank Xin Liu, Yangrui Chen, and Ningxin Zheng for their insightful feedback on this project. This work was supported in part by a ByteDance Research Collaboration Project, and grants from Hong Kong RGC under the contracts HKU 17204423 and C7004-22G (CRF). HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands References [1] Martín Abadi. 2016. TensorFlow: learning functions at scale. In Proceed- ings of the 21st ACM SIGPLAN international conference on functional programming. 1–1. [2] Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. 2023. Gpt-4 technical report. arXiv preprint arXiv:2303.08774 (2023). [3] Amey Agrawal, Ashish Panwar, Jayashree Mohan, Nipun Kwatra, Bhar- gav S Gulavani, and Ramachandran Ramjee. 2023. Sarathi: Efficient llm inference by piggybacking decodes with chunked prefills. arXiv preprint arXiv:2308.16369 (2023).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 198
    }
  },
  {
    "page_content": "[4] Riad Akrour, Marc Schoenauer, and Michele Sebag. 2011. Preference- based policy learning. In Machine Learning and Knowledge Discovery in Databases: European Conference, ECML PKDD 2011, Athens, Greece, September 5-9, 2011. Proceedings, Part I 11. Springer, 12–27. [5] Gene M Amdahl. 1967. Validity of the single processor approach to achieving large scale computing capabilities. In Proceedings of the April 18-20, 1967, spring joint computer conference. 483–485. [6] George E Andrews and Kimmo Eriksson. 2004. Integer partitions. Cambridge University Press. [7] Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. 2022. Training a helpful and harmless assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 (2022). [8] Zhihao Bai, Zhen Zhang, Yibo Zhu, and Xin Jin. 2020. {PipeSwitch}: Fast pipelined context switching for deep learning applications. In 14th USENIX Symposium on Operating Systems Design and Implementation (OSDI 20). 499–514.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 199
    }
  },
  {
    "page_content": "[9] Paul Barham, Aakanksha Chowdhery, Jeff Dean, Sanjay Ghemawat, Steven Hand, Daniel Hurt, Michael Isard, Hyeontaek Lim, Ruoming Pang, Sudip Roy, et al. 2022. Pathways: Asynchronous distributed dataflow for ml. Proceedings of Machine Learning and Systems 4 (2022), 430–449. [10] Eric Temple Bell. 1934. Exponential polynomials. Annals of Mathe- matics (1934), 258–277. [11] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot arXiv:2005.14165 https: Learners. CoRR abs/2005.14165 (2020). //arxiv.org/abs/2005.14165 [12] I. Caspi. 2017. Reinforcement learning coach by Intel. https://github. com/NervanaSystems/coach",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 200
    }
  },
  {
    "page_content": "[12] I. Caspi. 2017. Reinforcement learning coach by Intel. https://github. com/NervanaSystems/coach [13] Ernie Chan, Marcel Heimlich, Avi Purkayastha, and Robert Van De Geijn. 2007. Collective communication: theory, practice, and expe- rience. Concurrency and Computation: Practice and Experience 19, 13 (2007), 1749–1783. [14] Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Hee- woo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. 2021. Training verifiers to solve math word problems. arXiv preprint arXiv:2110.14168 (2021). [15] Collosal-AI Corporation. 2023. Collosal-Chat. https://github.com/ binmakeswell/ColossalChat [16] NVIDIA Corporation. 2023. TensorRT-LLM: A TensorRT Toolbox for Op- timized Large Language Model Inference. https://github.com/NVIDIA/ TensorRT-LLM [17] NVIDIA Corporation. 2024. NeMo-Aligner: Scalable toolkit for efficient model alignment. https://github.com/NVIDIA/NeMo-Aligner",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 201
    }
  },
  {
    "page_content": "[17] NVIDIA Corporation. 2024. NeMo-Aligner: Scalable toolkit for efficient model alignment. https://github.com/NVIDIA/NeMo-Aligner [18] Weihao Cui, Han Zhao, Quan Chen, Hao Wei, Zirui Li, Deze Zeng, Chao Li, and Minyi Guo. 2022. {DVABatch}: Diversity-aware {Multi- Entry} {Multi-Exit} batching for efficient processing of {DNN} ser- vices on {GPUs}. In 2022 USENIX Annual Technical Conference (USENIX ATC 22). 183–198. [19] Josef Dai, Xuehai Pan, Ruiyang Sun, Jiaming Ji, Xinbo Xu, Mickel Liu, Yizhou Wang, and Yaodong Yang. 2024. Safe RLHF: Safe Reinforcement Learning from Human Feedback. In The Twelfth International Confer- ence on Learning Representations. https://openreview.net/forum?id= TyFrPOKYXw [20] Frederica Darema. 2001. The spmd model: Past, present and future. In Recent Advances in Parallel Virtual Machine and Message Passing Interface: 8th European PVM/MPI Users’ Group Meeting Santorini/Thera, Greece, September 23–26, 2001 Proceedings 8. Springer, 1–1. [21] Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51, 1 (2008), 107–113.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 202
    }
  },
  {
    "page_content": "[21] Jeffrey Dean and Sanjay Ghemawat. 2008. MapReduce: simplified data processing on large clusters. Commun. ACM 51, 1 (2008), 107–113. [22] Assaf Eisenman, Kiran Kumar Matam, Steven Ingram, Dheevatsa Mudigere, Raghuraman Krishnamoorthi, Krishnakumar Nair, Misha Smelyanskiy, and Murali Annavaram. 2022. {Check-N-Run}: A check- pointing system for training deep learning recommendation models. In 19th USENIX Symposium on Networked Systems Design and Imple- mentation (NSDI 22). 929–943. [23] Shiqing Fan, Yi Rong, Chen Meng, Zongyan Cao, Siyu Wang, Zhen Zheng, Chuan Wu, Guoping Long, Jun Yang, Lixue Xia, et al. 2021. DAPPLE: A pipelined data parallel approach for training large models. In Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. 431–445. [24] X Yu Geoffrey, Yubo Gao, Pavel Golikov, and Gennady Pekhimenko. 2021. Habitat: A {Runtime-Based} computational performance predic- tor for deep neural network training. In 2021 USENIX Annual Technical Conference (USENIX ATC 21). 503–521.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 203
    }
  },
  {
    "page_content": "[25] Danijar Hafner, James Davidson, and Vincent Vanhoucke. 2017. Ten- sorflow agents: Efficient batched reinforcement learning in tensorflow. arXiv preprint arXiv:1709.02878 (2017). [26] Mingcong Han, Hanze Zhang, Rong Chen, and Haibo Chen. 2022. Microsecond-scale preemption for concurrent GPU-accelerated DNN inferences. In 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22). 539–558. [27] Alexander Havrilla, Maksym Zhuravinskyi, Duy Phung, Aman Tiwari, Jonathan Tow, Stella Biderman, Quentin Anthony, and Louis Castricato. 2023. trlX: A framework for large scale reinforcement learning from human feedback. In Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing. 8578–8595. [28] C. Hesse, M. Plappert, A. Radford, J. Schulman, S. Sidor, and Y. Wu. 2017. OpenAI baselines. https://github.com/openai/baselines [29] Connor Holmes, Masahiro Tanaka, Michael Wyatt, Ammar Ahmad Awan, Jeff Rasley, Samyam Rajbhandari, Reza Yazdani Aminabadi, Heyang Qin, Arash Bakhtiari, Lev Kurilenko, et al. 2024. DeepSpeed- FastGen: High-throughput Text Generation for LLMs via MII and DeepSpeed-Inference. arXiv preprint arXiv:2401.08671 (2024).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 204
    }
  },
  {
    "page_content": "[30] Jian Hu, Xibin Wu, Xianyu, Chen Su, Leon Qiu, Daoning Jiang, Qing Wang, and Weixun Wang. 2023. OpenRLHF: A Ray-based High- performance RLHF framework. https://github.com/OpenLLMAI/ OpenRLHF. [31] Shengyi Huang, Michael Noukhovitch, Arian Hosseini, Kashif Rasul, Weixun Wang, and Lewis Tunstall. 2024. The N+ Implementation Details of RLHF with PPO: A Case Study on TL; DR Summarization. arXiv preprint arXiv:2403.17031 (2024). [32] Yanping Huang, Youlong Cheng, Ankur Bapna, Orhan Firat, Dehao Chen, Mia Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, Yonghui Wu, et al. 2019. Gpipe: Efficient training of giant neural networks using pipeline parallelism. Advances in neural information processing systems 32 (2019). EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu [33] Michael Isard, Mihai Budiu, Yuan Yu, Andrew Birrell, and Dennis Fetterly. 2007. Dryad: distributed data-parallel programs from sequen- tial building blocks. In Proceedings of the 2nd ACM SIGOPS/EuroSys European conference on computer systems 2007. 59–72.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 205
    }
  },
  {
    "page_content": "[34] Insu Jang, Zhenning Yang, Zhen Zhang, Xin Jin, and Mosharaf Chowd- hury. 2023. Oobleck: Resilient distributed training of large models using pipeline templates. In Proceedings of the 29th Symposium on Operating Systems Principles. 382–395. [35] Sylvain Jeaugey. 2017. Nccl 2.0. In GPU Technology Conference (GTC), Vol. 2. 23. [36] Ziheng Jiang, Haibin Lin, Yinmin Zhong, Qi Huang, Yangrui Chen, Zhi Zhang, Yanghua Peng, Xiang Li, Cong Xie, Shibiao Nong, et al. 2024. MegaScale: Scaling Large Language Model Training to More Than 10,000 GPUs. arXiv preprint arXiv:2402.15627 (2024). [37] Timo Kaufmann, Paul Weng, Viktor Bengs, and Eyke Hüllermeier. 2023. A survey of reinforcement learning from human feedback. arXiv preprint arXiv:2312.14925 (2023). [38] Diederik P. Kingma and Jimmy Ba. 2017. Adam: A Method for Sto- chastic Optimization. arXiv:1412.6980 [cs.LG] [39] I. Kostrikov. 2017. PyTorch implementation of advantage actor critic (A2C), proximal policy optimization (PPO) and scalable trust-region method for deep reinforcement learning. https://github.com/ikostrikov/ pytorch-a2c-ppo-acktr",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 206
    }
  },
  {
    "page_content": "[40] Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph Gonzalez, Hao Zhang, and Ion Stoica. 2023. Efficient memory management for large language model serving with pagedattention. In Proceedings of the 29th Symposium on Operating Systems Principles. 611–626. [41] Harrison Lee, Samrat Phatale, Hassan Mansoor, Kellie Lu, Thomas Mesnard, Colton Bishop, Victor Carbune, and Abhinav Rastogi. 2023. Rlaif: Scaling reinforcement learning from human feedback with ai feedback. arXiv preprint arXiv:2309.00267 (2023). [42] Cheng Li. 2023. LLM-Analysis: Latency and Memory Analysis of Trans- former Models for Training and Inference. https://github.com/cli99/llm- analysis [43] Ziniu Li, Tian Xu, Yushun Zhang, Zhihang Lin, Yang Yu, Ruoyu Sun, and Zhi-Quan Luo. 2023. ReMax: A Simple, Effective, and Efficient Reinforcement Learning Method for Aligning Large Language Models. arXiv preprint arXiv: 2310.10505 (2023).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 207
    }
  },
  {
    "page_content": "[44] Zhuohan Li, Lianmin Zheng, Yinmin Zhong, Vincent Liu, Ying Sheng, Xin Jin, Yanping Huang, Zhifeng Chen, Hao Zhang, Joseph E Gon- zalez, et al. 2023. {AlpaServe}: Statistical multiplexing with model parallelism for deep learning serving. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 663–679. [45] Eric Liang, Richard Liaw, Robert Nishihara, Philipp Moritz, Roy Fox, Ken Goldberg, Joseph Gonzalez, Michael Jordan, and Ion Stoica. 2018. RLlib: Abstractions for distributed reinforcement learning. In Interna- tional conference on machine learning. PMLR, 3053–3062. [46] Eric Liang, Zhanghao Wu, Michael Luo, Sven Mika, Joseph E Gonzalez, and Ion Stoica. 2021. RLlib Flow: Distributed Reinforcement Learning is a Dataflow Problem. Advances in Neural Information Processing Systems 34 (2021), 5506–5517. [47] Yun Liang, Huynh Phung Huynh, Kyle Rupnow, Rick Siow Mong Goh, and Deming Chen. 2014. Efficient GPU spatial-temporal multitasking. IEEE Transactions on Parallel and Distributed Systems 26, 3 (2014), 748– 760.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 208
    }
  },
  {
    "page_content": "[48] Wenyan Lu, Guihai Yan, Jiajun Li, Shijun Gong, Yinhe Han, and Xi- aowei Li. 2017. Flexflow: A flexible dataflow accelerator architecture for convolutional neural networks. In 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEE, 553–564. [49] Jayashree Mohan, Amar Phanishayee, and Vijay Chidambaram. 2021. {CheckFreq}: Frequent,{Fine-Grained} {DNN} Checkpointing. In 19th USENIX Conference on File and Storage Technologies (FAST 21). 203–216. [50] Philipp Moritz, Robert Nishihara, Stephanie Wang, Alexey Tumanov, Richard Liaw, Eric Liang, Melih Elibol, Zongheng Yang, William Paul, Michael I Jordan, et al. 2018. Ray: A distributed framework for emerg- ing {AI} applications. In 13th USENIX symposium on operating systems design and implementation (OSDI 18). 561–577. [51] Derek G Murray, Frank McSherry, Rebecca Isaacs, Michael Isard, Paul Barham, and Martín Abadi. 2013. Naiad: a timely dataflow system. In Proceedings of the Twenty-Fourth ACM Symposium on Operating Systems Principles. 439–455.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 209
    }
  },
  {
    "page_content": "[52] Reiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. 2021. Webgpt: Browser-assisted question- answering with human feedback. arXiv preprint arXiv:2112.09332 (2021). [53] Deepak Narayanan, Aaron Harlap, Amar Phanishayee, Vivek Seshadri, Nikhil R Devanur, Gregory R Ganger, Phillip B Gibbons, and Matei Zaharia. 2019. PipeDream: generalized pipeline parallelism for DNN training. In Proceedings of the 27th ACM symposium on operating sys- tems principles. 1–15. [54] Deepak Narayanan, Mohammad Shoeybi, Jared Casper, Patrick LeGres- ley, Mostofa Patwary, Vijay Korthikanti, Dmitri Vainbrand, Prethvi Kashinkunti, Julie Bernauer, Bryan Catanzaro, et al. 2021. Efficient large-scale language model training on gpu clusters using megatron- lm. In Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis. 1–15.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 210
    }
  },
  {
    "page_content": "[55] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wain- wright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow instructions with human feedback. Advances in Neural Information Processing Systems 35 (2022), 27730–27744. [56] Jason Jong Kyu Park, Yongjun Park, and Scott Mahlke. 2017. Dy- namic resource management for efficient utilization of multitasking GPUs. In Proceedings of the twenty-second international conference on architectural support for programming languages and operating systems. 527–540. [57] Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. 2019. Pytorch: An imperative style, high-performance deep learning library. Advances in neural informa- tion processing systems 32 (2019).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 211
    }
  },
  {
    "page_content": "[58] Yanghua Peng, Yibo Zhu, Yangrui Chen, Yixin Bao, Bairen Yi, Chang Lan, Chuan Wu, and Chuanxiong Guo. 2019. A Generic Commu- nication Scheduler for Distributed DNN Training Acceleration. In Proceedings of the 27th ACM Symposium on Operating Systems Prin- ciples. ACM, Huntsville Ontario Canada, 16–29. https://doi.org/10. 1145/3341301.3359642 [59] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. 2020. Zero: Memory optimizations toward training trillion param- eter models. In SC20: International Conference for High Performance Computing, Networking, Storage and Analysis. IEEE, 1–16. [60] Jeff Rasley, Samyam Rajbhandari, Olatunji Ruwase, and Yuxiong He. 2020. Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 3505–3506.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 212
    }
  },
  {
    "page_content": "[61] Jie Ren, Samyam Rajbhandari, Reza Yazdani Aminabadi, Olatunji Ruwase, Shuangyan Yang, Minjia Zhang, Dong Li, and Yuxiong He. 2021. {Zero-offload}: Democratizing {billion-scale} model training. In 2021 USENIX Annual Technical Conference (USENIX ATC 21). 551–564. [62] Gian-Carlo Rota. 1964. The number of partitions of a set. The American Mathematical Monthly 71, 5 (1964), 498–504. [63] Baptiste Rozière, Jonas Gehring, Fabian Gloeckle, Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Romain Sauvestre, Tal HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands Remez, Jérémy Rapin, Artyom Kozhevnikov, Ivan Evtimov, Joanna Bit- ton, Manish Bhatt, Cristian Canton Ferrer, Aaron Grattafiori, Wenhan Xiong, Alexandre Défossez, Jade Copet, Faisal Azhar, Hugo Touvron, Louis Martin, Nicolas Usunier, Thomas Scialom, and Gabriel Synnaeve. 2023. Code Llama: Open Foundation Models for Code. arXiv preprint arXiv: 2308.12950 (2023). [64] Michael Santacroce, Yadong Lu, Han Yu, Yuanzhi Li, and Yelong Shen. 2023. Efficient RLHF: Reducing the Memory Usage of PPO. arXiv preprint arXiv: 2309.00754 (2023).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 213
    }
  },
  {
    "page_content": "[64] Michael Santacroce, Yadong Lu, Han Yu, Yuanzhi Li, and Yelong Shen. 2023. Efficient RLHF: Reducing the Memory Usage of PPO. arXiv preprint arXiv: 2309.00754 (2023). [65] Hill Kohli Saxton, Grefenstette. 2019. Analysing Mathematical Rea- soning Abilities of Neural Models. arXiv:1904.01557 (2019). [66] John Schulman, Sergey Levine, Pieter Abbeel, Michael Jordan, and Philipp Moritz. 2015. Trust region policy optimization. In International conference on machine learning. PMLR, 1889–1897. [67] John Schulman, Philipp Moritz, Sergey Levine, Michael Jordan, and Pieter Abbeel. 2018. High-Dimensional Continuous Control Using Generalized Advantage Estimation. arXiv:1506.02438 [cs.LG] [68] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347 (2017). [69] Alexander Sergeev and Mike Del Balso. 2018. Horovod: fast and easy distributed deep learning in TensorFlow. arXiv preprint arXiv:1802.05799 (2018).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 214
    }
  },
  {
    "page_content": "[69] Alexander Sergeev and Mike Del Balso. 2018. Horovod: fast and easy distributed deep learning in TensorFlow. arXiv preprint arXiv:1802.05799 (2018). [70] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Mingchuan Zhang, YK Li, Y Wu, and Daya Guo. 2024. Deepseekmath: Pushing the limits of mathematical reasoning in open language models. arXiv preprint arXiv:2402.03300 (2024). [71] Mohammad Shoeybi, Mostofa Patwary, Raul Puri, Patrick LeGresley, Jared Casper, and Bryan Catanzaro. 2019. Megatron-lm: Training multi- billion parameter language models using model parallelism. arXiv preprint arXiv:1909.08053 (2019). [72] Yixin Song, Zeyu Mi, Haotong Xie, and Haibo Chen. 2023. PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU. arXiv:2312.12456 [cs.LG]",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 215
    }
  },
  {
    "page_content": "[72] Yixin Song, Zeyu Mi, Haotong Xie, and Haibo Chen. 2023. PowerInfer: Fast Large Language Model Serving with a Consumer-grade GPU. arXiv:2312.12456 [cs.LG] [73] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Alma- hairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023. Llama 2: Open foundation and fine-tuned chat models. arXiv preprint arXiv:2307.09288 (2023). [74] Hanjing Wang, Man-Kit Sit, Congjie He, Ying Wen, Weinan Zhang, Jun Wang, Yaodong Yang, and Luo Mai. 2023. GEAR: a GPU-centric experience replay system for large reinforcement learning models. In International Conference on Machine Learning. PMLR, 36380–36390. [75] Minjie Wang, Chien-chin Huang, and Jinyang Li. 2019. Supporting very large models using automatic dataflow graph partitioning. In Proceedings of the Fourteenth EuroSys Conference 2019. 1–17. [76] Zhuang Wang, Zhen Jia, Shuai Zheng, Zhen Zhang, Xinwei Fu, TS Eu- gene Ng, and Yida Wang. 2023. Gemini: Fast failure recovery in dis- tributed training with in-memory checkpoints. In Proceedings of the 29th Symposium on Operating Systems Principles. 364–381.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 216
    }
  },
  {
    "page_content": "[77] Zhenning Wang, Jun Yang, Rami Melhem, Bruce Childers, Youtao Zhang, and Minyi Guo. 2016. Simultaneous multikernel GPU: Multi- tasking throughput processors via fine-grained sharing. In 2016 IEEE international symposium on high performance computer architecture (HPCA). IEEE, 358–369. [78] Ronald J Williams. 1992. Simple statistical gradient-following algo- rithms for connectionist reinforcement learning. Machine learning 8 (1992), 229–256. [79] Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Rémi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Syl- vain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2019. HuggingFace’s Transformers: State-of-the-art Natural Language Processing. arXiv preprint arXiv: 1910.03771 (2019). [80] Youshao Xiao, Weichang Wu, Zhenglei Zhou, Fagui Mao, Shangchun Zhao, Lin Ju, Lei Liang, Xiaolu Zhang, and Jun Zhou. 2023. An Adaptive Placement and Parallelism Framework for Accelerating RLHF Training. arXiv preprint arXiv: 2312.11819 (2023).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 217
    }
  },
  {
    "page_content": "[81] Shusheng Xu, Wei Fu, Jiaxuan Gao, Wenjie Ye, Weilin Liu, Zhiyu Mei, Guangju Wang, Chao Yu, and Yi Wu. 2024. Is dpo superior to ppo for llm alignment? a comprehensive study. arXiv preprint arXiv:2404.10719 (2024). [82] Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajb- handari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, et al. 2023. DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales. arXiv preprint arXiv:2308.01320 (2023). [83] Gyeong-In Yu, Joo Seong Jeong, Geon-Woo Kim, Soojeong Kim, and Byung-Gon Chun. 2022. Orca: A distributed serving system for {Transformer-Based} generative models. In 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22). 521–538. [84] Zhihang Yuan, Yuzhang Shang, Yang Zhou, Zhen Dong, Zhe Zhou, Chenhao Xue, Bingzhe Wu, Zhikai Li, Qingyi Gu, Yong Jae Lee, Yan Yan, Beidi Chen, Guangyu Sun, and Kurt Keutzer. 2024. LLM Inference Unveiled: Survey and Roofline Model Insights. arXiv preprint arXiv: 2402.16363 (2024).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 218
    }
  },
  {
    "page_content": "[85] Zheng Yuan, Hongyi Yuan, Chuanqi Tan, Wei Wang, Songfang Huang, and Fei Huang. 2023. Rrhf: Rank responses to align language models with human feedback without tears. arXiv preprint arXiv:2304.05302 (2023). [86] Matei Zaharia, Reynold S Xin, Patrick Wendell, Tathagata Das, Michael Armbrust, Ankur Dave, Xiangrui Meng, Josh Rosen, Shiv- aram Venkataraman, Michael J Franklin, et al. 2016. Apache spark: a unified engine for big data processing. Commun. ACM 59, 11 (2016), 56–65. [87] Chi Zhang, Guangming Sheng, Siyao Liu, Jiahao Li, Ziyuan Feng, Zherui Liu, Xin Liu, Xiaoying Jia, Yanghua Peng, Haibin Lin, and Chuan Wu. 2024. A Framework for Training Large Language Models for Code Generation via Proximal Policy Optimization. NL2Code Workshop of ACM KDD 2024 (2024). [88] Shiwei Zhang, Lansong Diao, Chuan Wu, Zongyan Cao, Siyu Wang, and Wei Lin. 2024. HAP: SPMD DNN Training on Heterogeneous GPU Clusters with Automated Program Synthesis. arXiv preprint arXiv:2401.05965 (2024).",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 219
    }
  },
  {
    "page_content": "[89] Shiwei Zhang, Lansong Diao, Chuan Wu, Siyu Wang, and Wei Lin. 2022. Accelerating large-scale distributed neural network training with SPMD parallelism. In Proceedings of the 13th Symposium on Cloud Computing. 403–418. [90] Lianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida Wang, Yuanzhong Xu, Danyang Zhuo, Eric P Xing, et al. 2022. Alpa: Automating inter-and {Intra-Operator} parallelism for distributed deep learning. In 16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22). 559–578. [91] Rui Zheng, Wei Shen, Yuan Hua, Wenbin Lai, Shihan Dou, Yuhao Zhou, Zhiheng Xi, Xiao Wang, Haoran Huang, Tao Gui, et al. 2023. Improving generalization of alignment with human preferences through group invariant learning. arXiv preprint arXiv:2310.11971 (2023). [92] Yinmin Zhong, Shengyu Liu, Junda Chen, Jianbo Hu, Yibo Zhu, Xu- anzhe Liu, Xin Jin, and Hao Zhang. 2024. DistServe: Disaggregating Prefill and Decoding for Goodput-optimized Large Language Model Serving. arXiv:2401.09670 [cs]",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 220
    }
  },
  {
    "page_content": "[93] Yuchen Zhong, Guangming Sheng, Juncheng Liu, Jinhui Yuan, and Chuan Wu. 2023. Swift: Expedited Failure Recovery for Large-Scale DNN Training. In Proceedings of the 28th ACM SIGPLAN Annual Sym- posium on Principles and Practice of Parallel Programming (Montreal, QC, Canada) (PPoPP ’23). Association for Computing Machinery, New York, NY, USA, 447–449. https://doi.org/10.1145/3572848.3577510 EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands G. Sheng, C. Zhang, Z. Ye, X. Wu, W. Zhang, R. Zhang, P. Yang, H. Lin, C. Wu Table 3. The transfer protocols in HybridFlow. Transfer Protocols Distribute function Collect function Use case ONE_TO_ALL Broadcast the data to all ranks. Gather the data from all ranks. 3D_PROTO Split the data, scatter across all DP ranks and broadcast within the group. Gather and concatenate the data from the p=-1, t=0 worker in all DP groups. All the worker methods have the same input and run the ssme codes, e.g. model initialization.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 221
    }
  },
  {
    "page_content": "Gather and concatenate the data from the p=-1, t=0 worker in all DP groups. All the worker methods have the same input and run the ssme codes, e.g. model initialization. The model is sharded among multiple workers within each data-parallel group. The output of the model only exists in the last pipeline stage and is duplicated across the data-parallel groups. This is a typical scenario in 3D parallel training in Megatron-LM, Deepspeed, etc. 3D_ALL_MICRO_DP Split the data by micro DP size, scatter across all micro DP groups and broadcast among all ranks within the group. 3D_PP_ONLY Broadcast the data to all ranks. Gather and concatenate the data from the local_rank=0 worker in all micro DP groups. Used with HybridEngine. It is used to handle the 3D-parallel scheme of the policy model, when switching between training and inference. Gather and concatenate the data from the t=0, d=0 worker in all PP groups. Used to examine weight names as they are identical in TP and DP groups. DP_PROTO Split the data into batches and scatter across all DP ranks. Gather and concatenate the data from all DP ranks. Training model in data-parallel mode. ALL_TO_ALL No operation.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 222
    }
  },
  {
    "page_content": "DP_PROTO Split the data into batches and scatter across all DP ranks. Gather and concatenate the data from all DP ranks. Training model in data-parallel mode. ALL_TO_ALL No operation. Gather the data from all ranks. Used when debugging. Users can manually define the inputs of each worker and examine their outputs respectively. A Primitive APIs in HybridFlow In HybridFlow, we implemented the primitive of each model in RLHF training by inheriting the 3DParallelWorker, FSDP Worker and ZeROWorker. The functions of these model classes are designed to decouple the distributed computation code and provide fundamental operations in RLHF for the users. This primitive design is compatible with the auto-regressive generation, forward pass, backward pass, and model update operations in the existing distributed inference and training frameworks. Users can easily customize the RLHF training dataflow (by adapting the numerical computation in the pro- vided functions) according to the algorithm’s design and benefit from reusing the underlying distributed computation implementation. We illustrate the meaning and the actual computations of these APIs in Table 4.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 223
    }
  },
  {
    "page_content": "B Transfer Protocols We implemented transfer protocols that cover all common use cases of data resharding between models in RLHF dataflow. Users can utilize these pre-defined protocols to generate any RLHF dataflow. Moreover, Users can easily define their own transfer protocols by implementing a collect function and a distribute function. Transfer protocols decoupled the compli- cated data resharding and distributed training. We denote p, t, d as the rank of the worker in pipeline-, tensor- and data- parallel group respectively. We illustrate these predefined protocols in Table 3. C Auto-Parallelism Algorithm Algorithm 2 outlines the search process of the optimal par- allelism strategy of each model. Starting from the minimal model parallelism size of each model (to prevent OOM when colocating with multiple workers), we enumerate all feasi- ble parallel configurations based on the number of GPUs and the number of GPUs per machine 𝑈 . The default num- ber of 𝑈 is set to 8. We use simu module to estimate the latency of each model based on their workload. This module Algorithm 2 Auto Parallelism Algorithm",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 224
    }
  },
  {
    "page_content": "Algorithm 2 Auto Parallelism Algorithm 1: Input: Device allocation 𝐴, minimal device allocation and model parallel size for each model in a set 𝐴𝑚𝑖𝑛, workload 𝑊 , the number of GPUs per machine 𝑈 2: Output: the parallelism strategy for the model in a set 3: Procedure auto_parallel(𝐴, 𝐴𝑚𝑖𝑛, 𝑙, 𝑊 ): 4: 𝑁𝑙 = 𝐴[𝑙] // Get device allocation of the model 5: 𝑡𝑚𝑖𝑛 = 𝐴𝑚𝑖𝑛 [𝑙].𝑡 // Get minimal model parallel size 6: 𝑝𝑚𝑖𝑛 = 𝐴𝑚𝑖𝑛 [𝑙].𝑝 7: best_para ← ∅ 8: best_para.cost ← ∞ 9: for all t ∈ {𝑡𝑚𝑖𝑛, 𝑡𝑚𝑖𝑛 + 1..., 𝑈 } do for all p ∈ {𝑝𝑚𝑖𝑛, 𝑝𝑚𝑖𝑛 + 1..., 𝑁𝑙 10: 𝑈 } do 11: 12: 13: d ← 𝑁𝑙 p×t para_plan ← (𝑝, 𝑡, 𝑑) cost ← simu(𝑝𝑎𝑟𝑎_𝑝𝑙𝑎𝑛, 𝑙,𝑊 [𝑙]) if best_para.𝑐𝑜𝑠𝑡 > cost then best_para.𝑐𝑜𝑠𝑡 ← cost best_para ← para_plan 14: 15: 16: 17: return best_para",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 225
    }
  },
  {
    "page_content": "𝑈 } do 11: 12: 13: d ← 𝑁𝑙 p×t para_plan ← (𝑝, 𝑡, 𝑑) cost ← simu(𝑝𝑎𝑟𝑎_𝑝𝑙𝑎𝑛, 𝑙,𝑊 [𝑙]) if best_para.𝑐𝑜𝑠𝑡 > cost then best_para.𝑐𝑜𝑠𝑡 ← cost best_para ← para_plan 14: 15: 16: 17: return best_para includes three simulators for training, inference, and gener- ation workload, all are analytical models following previous research [42, 84, 92]. The training and inference workload is compute-bound while the generation workload is memory- bound. For the actor model, we first find the parallelism strat- egy for training and record the memory usage in the training stage. During actor generation, KVCache requirements are calculated using the batch size and max sequence length. If the model-parallel size for the generation stage cannot accommodate both parameters and KVCache, we increase it. Then, we seek the optimal strategy with corresponding KVCache allocation by comparing the latency estimation. Developing a comprehensive autoregressive generation sim- ulator that accounts for variable KVCache sizes could further enhance the auto-mapping process in RLHF research. HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 226
    }
  },
  {
    "page_content": "HybridFlow: A Flexible and Efficient RLHF Framework EuroSys ’25, March 30-April 3, 2025, Rotterdam, Netherlands Table 4. Key functions provided in each model class. The users can use these provided functions to construct various RLHF algorithms in a few lines of code. Model APIs generate_sequence Actor Computation auto-regressive generation compute_log_prob a forward pass compute_loss a forward pass update_actor a forward, backward pass and model update Interpretation Based on a batch of prompts, the actor model generates a batch of responses and returns the log probability of each token in the responses. The actor model computes the log probability of each token in the prompts and responses. This log probability is the same as the return log probability when performing generation using the same model precision. (Optional in PPO) The actor model computes the pretrain loss based on the pertaining dataset [7, 19, 55].",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 227
    }
  },
  {
    "page_content": "The actor model computes the pretrain loss based on the pertaining dataset [7, 19, 55]. Based on the advantages, returns (calculated from compute_advantage) and pertaining loss, the actor model calculate the training loss and up- date its weights. We implement various loss for diverse RLHF algorithms including PPO [55], Safe-RLHF [19], ReMax [43], GRPO [70] and others. Critic compute_values a forward pass The critic model computes the values for each prompt and response. update_critic a forward, backward pass and model update Reference Policy compute_ref_log_prob a forward pass Reward compute_reward a forward pass - compute_advantage numerical computation Based on the values and returns, the critic computes a squared-error loss to update its weights. We also implement critic loss for diverse RLHF algorithms including PPO [55], Safe-RLHF [19], ReMax [43], GRPO [70] and others. The reference model computes the reference log probability of each token in the prompts and responses. This log probability is utilized as a benchmark to evaluate the divergence of the actor model and constrain its learning process.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 228
    }
  },
  {
    "page_content": "The reward model conducts forward computation to calculate scores for a given set of prompts and responses. The rewards could be token-level or sample-level. Based on the values rewards from the value model and reward model re- spectively, the function estimates the advantages on the given prompts and the current policy model’s responses. This computation involves no model forward passes.",
    "metadata": {
      "source": "input/2409.19256v2.pdf",
      "type": "pdf",
      "chunk_index": 229
    }
  },
  {
    "page_content": "MACHINE LEARNING 机器学习 周志华著 清华大学出版社 北 京 内 容 简 介 机器学习是计算机科学的重要分支领域.本书作为该领域的入门教材，在内容上尽可能涵盖机器学习基础 知识的各方面.全书共1 6 章，大致分为3 个部分：第 1 部 分 （第 1〜 3 章 ）介绍机器学习的基础知识；第 2 部 分 （第 4〜 1 0 章）讨论一些经典而常用的机器学习方法（决策树、神经网络、支持向量机、贝叶斯分类器、集 成学习、聚类、降维与度量学习）；第 3 部 分 （第 U 〜 1 6 章 ）为进阶知识，内容涉及特征选择与稀疏学习、 计算学习理论、半监督学习、概率图模型、规则学习以及强化学习等.每章都附有习题并介绍了相关阅读材料， 以便有兴趣的读者进一步钻研探索. 本书可作为高等院校计算机、自动化及相关专业的本科生或研究生教材，也可供对机器学习感兴趣的研究 人员和工程技术人员阅读参考. 本书封面贴有清华大学出版社防伪标签，无标签者不得销售. 版权所有，侵权必究.侵权举报电话：010-62782989 13701121933 图书在版编目（CIP）数据 机器学习/周志华著•-北京：清华大学出版社，2016 ISBN 978-7-302-42328-7 I . ①机… I I . ①周… IU .①机器学习 W.①TP181 中国版本图书馆C I P 数据核字（2015）第 287090号 责任编辑：薛 慧 封面设计：何凤霞 责任校对：刘玉霞 责任印制：宋 林 tit： http ://www. tup .com. cn, http ://www. wqbook. com 出版发行：清华大学出版社 网 地 址：北京清华大学学研大厦A 座 社 总 机：010-62770175 投稿与读者月艮务：010-62776969, c-service@tup.tsinghua.edu.cn 质量反馈：010・62772015, zhiliang@tup.tsinghua.edu.cn 邮 编：100084 邮 购：010-62786544 销：全国新华书店 印 装 者：北京亿浓世纪彩色印刷有限公司 经 开 本: 210mmx 235mm 版 印 数: 1 〜 5000 定 价：88.00 元 次: 2016年 1 月 第 1 版 BP 张：27.75 产品编号：064027-01 字 数: 626千字 印 次: 2016年 1 月 第 1 次印刷 -XZ- 刖 — »— B 这是一本面向中文读者的机器学习教科书，为了使尽可能多的读者通过本书对机器学习有所了 解，作者试图尽可能少地使用数学知识.然而，少量的概率、统计、代数、优化、逻辑知识似乎不可",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 230
    }
  },
  {
    "page_content": "次: 2016年 1 月 第 1 版 BP 张：27.75 产品编号：064027-01 字 数: 626千字 印 次: 2016年 1 月 第 1 次印刷 -XZ- 刖 — »— B 这是一本面向中文读者的机器学习教科书，为了使尽可能多的读者通过本书对机器学习有所了 解，作者试图尽可能少地使用数学知识.然而，少量的概率、统计、代数、优化、逻辑知识似乎不可 避 免 .因 此 ，本书更适合大学三年级以上的理工科本科生和研究生，以及具有类似背景的对机器学习 感兴趣的人士.为方便读者，本书附录给出了一些相关数学基础知识简介. 全 书 共 1 6 章，大体上可分为3 个部分：第 1 部分包括第1〜 3 章,介绍机器学习基础知识;第2 部 分 包 括 第 4 - 1 0 章，介绍一些经典而常用的机器学习方法；第 3 部 分 包 括 第 11〜 1 6 章，介绍一些进阶 知 识 .前 3 章之外的后续各章均相对独立，读者可根据自己的兴趣和时间情况选择使用.根据课时情 况，一个学期的本科生课程可考虑讲授前9 章 或 前 1 0 章;研究生课程则不妨使用全书. 书中除第1 章外，每章都给出了十道习题.有的习题是帮助读者巩固本章学习，有的是为了引导读 者扩展相关知识.一学期的一般课程可使用这些习题，再辅以两到三个针对具体数据集的大作业.带 星号的习题则有相当难度，有些并无现成答案，谨供富有进取心的读者启发思考. 本书在内容上尽可能涵盖机器学习基础知识的各方面，但作为机器学习入门读物且因授课时间的 考虑，很多重要、前沿的材料未能覆盖，即便覆盖到的部分也仅是管中窥豹，更多的内容留待读者在 进阶课程中学习.为便于有兴趣的读者进一步钻研探索，本书每章均介绍了一些阅读材料，谨供读者 参考. 笔者以为，对学科相关的重要人物和事件有一定了解，将会增进读者对该学科的认识.本书在每 章最后都写了一个与该章内容相关的小故事，希望有助于读者增广见闻，并且在紧张的学习过程中稍 微放松调剂一下. 书中不可避免地涉及大量外国人名，若全部译为中文，则读者在日后进一步阅读文献时或许会对 不少人名产生陌生感，不利于进一步学习.因此，本书仅对一般读者耳熟能详的名字如“图灵”等加 以直接使用，对故事中的一些主要人物给出了译名，其他则保持外文名. 机器学习发展极迅速，目前已成为一个广袤的学科，罕有人士能对其众多分支领域均有精深理解. 笔者自认才疏学浅，仅略知皮毛，更兼时间和精力所限，书中错谬之处在所难免，若蒙读者诸君不吝告 知，将不胜感激. 周志华 2015年 6 月 序 言",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 231
    }
  },
  {
    "page_content": "以直接使用，对故事中的一些主要人物给出了译名，其他则保持外文名. 机器学习发展极迅速，目前已成为一个广袤的学科，罕有人士能对其众多分支领域均有精深理解. 笔者自认才疏学浅，仅略知皮毛，更兼时间和精力所限，书中错谬之处在所难免，若蒙读者诸君不吝告 知，将不胜感激. 周志华 2015年 6 月 序 言 在人工智能界 有 一 种 说 法 ，认 为 机 器 学 习 是 人 工 智 能 领 域 中 最 能 够 体 现 智 能 的 一 个 分 支 .从 历 史 来 看 ，机 器 学 习 似 乎 也 是 人 工 智 能 中 发 展 最 快 的 分 支 之 一 .在 二 十 世 纪 八 十 年 代 的 时 候 ，符号学习可 能 还 是 机 器 学 习 的 主 流 ，而 自 从 二 十 世 纪 九 十 年 代 以 来 ，就 一 直 是 统 计 机 器 学 习 的 天 下 了 .不 知 道 是 否可 以 这 样 认 为 ：从主流为符号 机 器 学 习 发 展 到 主 流 为 统 计 机 器 学 习 ，反映了机器学习从纯粹的理论 研 究 和 模 型 研 究 发 展 到 以 解 决 现 实 生 活 中 实 际 问 题 为 目 的 的 应 用 研 究 ，这是科学 研 究 的 一 种 进 步 .有 关 机 器 学 习 的 专 著 国 内 出 版 的 不 是 很 多 .前 两 年 有 李 航 教 授 的 《统 计 学 习 方 法 》 出版，以简要的方式 介 绍 了 一 批 重 要 和 常 用 的 机 器 学 习 方 法 .此 次 周 志 华 教 授 的 鸿 篇 巨 著 《机 器 学 习 》则全面而详细地介 绍了机器学习的各个分支，既可作为教材，又可作为自学用书和科研参考书. 翻 阅 书 稿 的 过 程 引 起 了 一 些 自 己 的 思 考 ，平 时 由 于 和 机 器 学 习 界 的 朋 友 接 触 多 了 ，经常获得一些 道 听 途 说 的 信 息 以 及 专 家 们 对 机 器 学 习 现 状 及 其 发 展 前 途 的 评 论 .在 此 过 程 中 ，难免会产生一些自己 的疑问.我借此机 会 把 它 写 下 来 放 在 这 里 ，算 是 一 种 “外行 求 教 机 器 学 习 ”. 问题一：在 人 工 智 能 发 展 早 期 ，机 器 学 习 的 技 术 内 涵 几 乎 全 部 是 符 号 学 习 .可 是 从 二 十 世 纪 九 十 年 代 开 始 ，统计机器学 习 犹 如 一 匹 黑 马 横 空 出 世 ，迅速压倒并取代了符号学习的地位.人们可能会问: 在满目的统计学习期刊和会议文章面前，符 号学习是否被彻底忽略了？它还能成为机器学习的研究对",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 232
    }
  },
  {
    "page_content": "问题一：在 人 工 智 能 发 展 早 期 ，机 器 学 习 的 技 术 内 涵 几 乎 全 部 是 符 号 学 习 .可 是 从 二 十 世 纪 九 十 年 代 开 始 ，统计机器学 习 犹 如 一 匹 黑 马 横 空 出 世 ，迅速压倒并取代了符号学习的地位.人们可能会问: 在满目的统计学习期刊和会议文章面前，符 号学习是否被彻底忽略了？它还能成为机器学习的研究对 象 吗 ？它 是 否将继续在统计学习的阴影里生活并苟延残喘？对这个问题有 三 种 可 能 的 答 案 ：一是告诉 符 号 学 习 ：“你 就 是 该 退 出 历 史 舞 台 ，认 命 吧 ！”二 是 告 诉 统 计 学 习 ：“你 的 一 言 堂 应 该 关 门 了 ！”单纯 的统计学习已经走到了尽头，再 想 往 前 走 就 要 把 统 计 学 习 和 符 号 学 习 结 合 起 来 .三 是 事 物 发 展 总 会 有 “三 十 年 河 东 ，三 十 年 河 西 ，，的现象，符 号 学 习 还 有 “翻 身 ，，的日子.第一种观点我没有听人明说过, 但 是 我 想 恐 怕 有 可 能 已 经 被 许 多 人 默 认 了 .第 二 种 观 点 我 曾 听 王 珏 教 授 多 次 说 过 .他 并 不 认 为 统 计 学 习 会 衰 退 ，而 只 是 认 为 机 器 学 习 已 经 到 了 一 个 转 折 点 ，从 今 往 后 ，统计学习应该和知识的利用相结合, 这 是 一 种 “螺 旋式上升，进 入 更 高 级 的 形 式 ”，否 则 ，一统计学习可能会停留于现状而止步不前，王珏教 授 还 认 为 ：进 入 转 折 点 的 标 志 就 是 K o ller等 的 《概 率 图 模 型 》一 书 的 出 版 .至 于 第 三 种 观 点 ，恰好我 收到老朋友，美国人工智能资深学者、俄 亥 俄 大 学 Chandrasekaran教授的来信,他正好谈起符号智能 被 统 计 智 能 “打 压 ”的现象，并 且 正 好 表 达 了 河 东 河 西 的 观 点 .我 请 求 他 允 许 我 把 这 段 话 引 进 正 在 撰 写 的 序 言 中 ，他 爽 快 地 同 意 了 ，仅 仅 修 改 了 几 处 私 人 通 信 的 口 吻 .全 文 如 下 ：“最近几年,.人工智能在 很 大 程 度 上 集 中 于 统 计 学 和 大 数 据 .我 同 意 由 于 计 算 能 力 的 大 幅 提 高 ，这 些 技 术 曾 经 取 得 过 某 些 令 人 印 象 深 刻 的 成 果 .但 是 我 们 完 全 有 理 由 相 信 ，虽 然 这 些 技 术 还 会 继 续 改 进 、提 高 ，总有一天这个领",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 233
    }
  },
  {
    "page_content": "很 大 程 度 上 集 中 于 统 计 学 和 大 数 据 .我 同 意 由 于 计 算 能 力 的 大 幅 提 高 ，这 些 技 术 曾 经 取 得 过 某 些 令 人 印 象 深 刻 的 成 果 .但 是 我 们 完 全 有 理 由 相 信 ，虽 然 这 些 技 术 还 会 继 续 改 进 、提 高 ，总有一天这个领 域 （指 A I）会 对 它 们 说 再 见 ，并 转 向 更 加 基 本 的 认 知 科 学 研 究 .尽 管 钟 摆 的 摆 回 去 还 需 要 一 段 时 间 ，我 机器学习 相信定有必要 把统计技术和对认知结构的深刻理解结合起来看来，Chandrasekaraii教授也并不认 为若干年以后A I 真会回到河西，他的意见和王珏教授的意见基本一致，但不仅限于机器学习,而是涉 及整个人工智能领域.只是王珏教授强调知识，而 Chandrasekaran教授强调更加基本的“认知”. 问题二：王珏教授认为统计机器学习不会“一路顺风”的判据是：统计机器学习算法都是基于样 本数据独立同分布的假设.但是自然界现象千变万化，王 珏 教 授 认 为 “哪有那么多独立同分布?”这 就引来了下一个问题：“独立同分布”条件对于机器学习来讲真是必需的吗？独立同分布的不存在一 定是一个不可逾越的障碍吗？无独立同分布条件下的机器学习也许只是一个难题，而不是不可解问 题 .我 有 一 个 “胡思乱想”，认为前些时候出现的“迁移学习”也许会对这个问题的解决带来一线曙 光.尽管现在的迁移学习还要求迁移双方具备“独立同分布”条件，但是不同分布之间的迁移学习, 同分布和异分布之间的迁移学习也许迟早会出现？ 问题三：近年来出现了一些新的动向，例 如 “深度学习”、 “无终止学习”等等，社会上给予了 特别关注，尤其是深度学习.但它们真的代表了机器学习的新的方向吗？包括本书作者周志华教授在 内的一些学者认为：深度学习掀起的热潮也许大过它本身真正的贡献，在理论和技术上并没有太多的 创新，只不过是由于硬件技术的革命，计算机的速度大大提高了，使得人们有可能采用原来复杂度很 高的算法，从而得到比过去更精细的结果.当然这对于推动机器学习应用于实践有很大意义.但我们 不禁要斗胆问一句：深度学习是否又要取代统计学习了？事实上，确有专家已经感受到来自深度学习 的压力，指出统计学习正在被深度学习所打压，正如我们早就看到的符号学习被统计学习所打压.不 过我觉得这种打压还远没有强大到像统计学习打压符号学习的程度.这一是因为深度学习的“理论创 新 ”还不明显；二是因为目前的深度学习主要适合于神经网络,在各种机器学习方法百花盛开的今天,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 234
    }
  },
  {
    "page_content": "不禁要斗胆问一句：深度学习是否又要取代统计学习了？事实上，确有专家已经感受到来自深度学习 的压力，指出统计学习正在被深度学习所打压，正如我们早就看到的符号学习被统计学习所打压.不 过我觉得这种打压还远没有强大到像统计学习打压符号学习的程度.这一是因为深度学习的“理论创 新 ”还不明显；二是因为目前的深度学习主要适合于神经网络,在各种机器学习方法百花盛开的今天, 它的应用范围还有限，还不能直接说是连接主义方法的回归；三是因为统计学习仍然在机器学习中被 有效地普遍采用，“得道多助”，想抛弃它不容易. 问题四：机器学习研究出现以来，我们看到的主要是从符号方法到统计方法的演变,用到的数学主 要是概率统计.但是，数学之大，就像大海.难道只有统计方法适合于在机器学习方面应用吗？ 当然, 我们也看到了一些其他数学分支在机器学习上的应用的好例子，例如微分几何在流形学习上的应用, 微分方程在归纳学习上的应用.但如果和统计方法相比，它们都只能算是配角.还有的数学分支如代 数可能应用得更广，但在机器学习中代数一般是作为基础工具来使用，例如矩阵理论和特征值理论. 又如微分方程求解最终往往归结为代数问题求解.它们可以算是幕后英雄：“出头露面的是概率和统 计，埋头苦干的是代数和逻辑”.是否可以想象以数学方法为主角，以统计方法为配角的机器学习理 论呢？在这方面，流 形 学 习 已 经 “有点意思” T , 而彭实戈院士的倒排随机微分方程理论之预测金融 走势，也许是用高深数学推动新的机器学习模式的更好例子.但是从宏观的角度看,数学理论的介入 程度还远远不够.这里指的主要是深刻的、现代的数学理论，我们期待着有更多数学家的参与，开辟 机器学习的新模式、新理论、新方向. 序 言 iii 问题五：上一个问题的延续：符号机器学习时代主要以离散方法处理问题，统计机器学习时代主 要以连续方法处理问题.这两种方法之间应该没有一条鸿沟.流形学习中李群、李代数方法的引入给 我们以很好的启示.从微分流形到李群，再从李群到李代数，就是一个沟通连续和离散的过程.然而, 现有的方法在数学上并不完美.浏览流形学习的文献可知，许多论文直接把任意数据集看成微分流形, 从而就认定测地线的存在并讨论起降维来了.这样的例子也许不是个别的，足可说明数学家介入机器 学习研究之必要. 问题六：大数据时代的出现,有没有给机器学习带来本质性的影响？理论上讲，似 乎 “大数据”给 统计机器学习提供了更多的机遇，因为海量的数据更加需要统计、抽样的方法.业界人士估计，大数 据的出现将使人工智能的作用更加突出.有人把大数据处理分成三个阶段：收集、分析和预测.收集",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 235
    }
  },
  {
    "page_content": "从而就认定测地线的存在并讨论起降维来了.这样的例子也许不是个别的，足可说明数学家介入机器 学习研究之必要. 问题六：大数据时代的出现,有没有给机器学习带来本质性的影响？理论上讲，似 乎 “大数据”给 统计机器学习提供了更多的机遇，因为海量的数据更加需要统计、抽样的方法.业界人士估计，大数 据的出现将使人工智能的作用更加突出.有人把大数据处理分成三个阶段：收集、分析和预测.收集 和分析的工作相对来说已经做得相当好了，现在关注的焦点是要有科学的预测，机器学习技术在这里 不可或缺.这一点大概毋庸置疑.然而，同样是使用统计、抽样方法，同样是收集、分析和预测，大数 据时代使用这类方法和以前使用这类方法有什么本质的不同吗？量变到质变是辩证法的一个普遍规 律.那么，从前大数据时代到大数据时代,数理统计方法有没有发生本质的变化？反映到它们在机器学 习上的应用有无本质变化？大数据时代正在呼唤什么样的机器学习方法的产生？哪些机器学习方法 又是由于大数据研究的驱动而产生的呢？ 以上这些话也许说得远了，我们还是回到本书上来.本书的作者周志华教授在机器学习的许多领 域都有出色的贡献，是中国机器学习研究的领军人物之一，在国际学术界有着很高的声誉.他在机器 学习的一些重要领域，例如集成学习、半监督学习、多示例和多标记学习等方面都做出了在国际上有 重要影响的工作，其中一些可以认为是中国学者在国际上的代表性贡献.除了自身的学术研究以外, 他在推动中国的机器学习发展方面也做了许多工作.例如他和不久前刚过世的王珏教授从2002年开 始，组 织 了 系 列 化 的 “机器学习及其应用”研讨会.初在复旦，后移至南大举行，越办越兴旺，从单一 的专家报告发展到专家报告、学生论坛和张贴论文三种方式同时举行，参会者从数十人发展到数百 人 ，活动搞得有声有色，如火如荼.最近更是把研讨会推向全国高校轮流举行.他和王珏教授紧密合 作，南北呼应，人 称 “南周北王”.王珏教授的离去使我们深感悲伤.令我们欣慰的是国内不但有周志 华教授这样的机器学习领军人物，而且比周教授更年轻的许多机器学习青年才俊也成长起来了.中国 的机器学习大有希望. 怯饮妗 中国科学院数学与系统科学研究院 2015年 8 月于北京 主要符号表 标量 向量 变量集 矩阵 单位阵 样本空间或状态空间 概率分布 数 据 样 本 （数据集） 假设空间 假设集 学习算法 行向量 列向量 向量或矩阵转置 集合 集合｛•…｝中元素个数 “ 范数,p 缺省时为L 2 范数 I •) 概率质量函数,条件概率质量函数 X X X A I 彳 V D H H £ (丁，，,) (•；・；•)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 236
    }
  },
  {
    "page_content": "变量集 矩阵 单位阵 样本空间或状态空间 概率分布 数 据 样 本 （数据集） 假设空间 假设集 学习算法 行向量 列向量 向量或矩阵转置 集合 集合｛•…｝中元素个数 “ 范数,p 缺省时为L 2 范数 I •) 概率质量函数,条件概率质量函数 X X X A I 彳 V D H H £ (丁，，,) (•；・；•) (•产 { ,• • } I{ … } I II- UP P ( ) P《)，P《I •) 后・~引川)] sup(-) 口(•) sign。 概率密度函数,条件概率密度函数 函 数 / （.）对 •在 分 布 T）下的数学期望；意义明确时将 省 略 。 和（或）. 上确界 指 示 函 数 ,在 •为真和假时分别取值为1,0 符 号 函 数 ,在 • < 0, = 0, > 0 时分别取值为—1,0,1 目 录 第 1 章 绪 论 ............................ 1.1 引 言 ......................... 1 1 1.2 基本术语 .......................................................2 1 . 3 假设空间 .......................................................4 1.4 归纳偏好 .......................................................6 1 . 5 发 展 历 程 ......................................................10 1 . 6 应用现状 ......................................................13 1 . 7 阅 读 材 料 ...... ............... 16 习题 ............................................................... 19 参考文 献 ................................. 20 22 休息一会 儿 ........................... 第 2 章 模型评估与选择........................... 2 . 1 经验误差与过拟合 ........................................ 23 23",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 237
    }
  },
  {
    "page_content": "休息一会 儿 ........................... 第 2 章 模型评估与选择........................... 2 . 1 经验误差与过拟合 ........................................ 23 23 2 . 2 评 估 方 法 ......................................................24 2 . 3 性 能 度 量 ......................................................28 2.4 比较检验 .......................... 37 2 . 5 偏 差 与 方 差 ................................................... 44 2.6 阅 读 材 料 ........................................ …… ........ 46 习题 ............................................................... 48 参考文献 ........................................................... 49 休息一会儿 ...................................................... 51 第 3 章 线 性 模 型 ............ 3.1 基本形式 ...................................... 53 53 3 . 2 线性回归 ......................................................53 3.3 对数几率回归 ....................... 3 . 4 线 性 判 别 分 析 ..................... 57 60 3 . 5 多分类学习 ....................................................63 X 3 . 6 类 别 不 平 衡 问 题 ................. 3.7 阅 读 材 料 ......................... 机器学习 66 67",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 238
    }
  },
  {
    "page_content": "3 . 5 多分类学习 ....................................................63 X 3 . 6 类 别 不 平 衡 问 题 ................. 3.7 阅 读 材 料 ......................... 机器学习 66 67 习题 ................................................................69 参考文献 .......................................... 70 休息一会儿 ......................................................... 72 第 4 章 决 策 树 ........................................................ 73 4 . 1 基本流程 ..................................................... 73 4 . 2 划 分 选 择 ..................................................... 75 4 . 3 剪枝处理 ........................ 4 . 4 连 续 与 缺 失 值 .................. 4 . 5 多 变 量 决 策 树 ............................... 79 83 88 4 . 6 阅读材料 ..................................................... 92 习题 ........ 93 参考文 献 ......................................... 94 休息一 会儿 ....................................................... 95 第 5 章 神 经 网 络 .. .... ............. 97 5 . 1 神经元模型 ................................................... 97 5 . 2 感 知 机 与 多 层 网 络 ..................................... .…… 98",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 239
    }
  },
  {
    "page_content": "第 5 章 神 经 网 络 .. .... ............. 97 5 . 1 神经元模型 ................................................... 97 5 . 2 感 知 机 与 多 层 网 络 ..................................... .…… 98 5 . 3 误差逆传播算法 ......................................... 5 . 4 全局最小与局部极小 .................. 101 106 5 . 5 其 他 常 见 神 经 网 络 ............................................ 108 5 . 6 深度学习 .................................................... 113 5 . 7 阅读材料 .................................................... 115 习题 ................................ 116 参考文献 .......................................................... 117 休息一会儿 ....................................................... 120 第 6 章 支 持 向 量 机 ................................................... 121 6 . 1 间隔与支持向量 ................................ :.............121 6 . 2 对偶问题 ........ 123 6 . 3 核 函 数 ....................................................... 126 6.4 软间隔与正则化 ................ 6.5 支持向量回归 ...... 129 133 目 录 xi 6 . 6 核 方 法 .. .................................................... 137 6.7 阅读材料 ..................................................... 139",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 240
    }
  },
  {
    "page_content": "129 133 目 录 xi 6 . 6 核 方 法 .. .................................................... 137 6.7 阅读材料 ..................................................... 139 习题 .............................................................. 141 参考文献 .......................................................... 142 休息一会儿 ........................................................ 145 第 7 章 贝叶斯分类器............................................... 147 7.1 贝叶斯决策论 .................................. 147 7 . 2 极 大 似 然 估 计 .................................................149 7 . 3 朴 素 贝 叶 斯 分 类 器 ............................................. 150 7 . 4 半 朴 素 贝 叶 斯 分 类 器 .......................................... 154 7.5 贝叶斯网 ..................................................... 156 7.6 EM 算 法 ..................................................... 162 7.7 , 阅读材料 ................................................... 164 习题 .............................................................. 166 参考文献 ................................................ 167 休息一会儿 ........................................................ 169 第 8 章 集 成 学 习 ............... 171",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 241
    }
  },
  {
    "page_content": "第 8 章 集 成 学 习 ............... 171 8 . 1 个 体 与 集 成 ...................................................171 8.2 Boosting ..................................................................................................... 173 8.3 Bagging与随机森林 ........................................... 178 8.4 结合策略 ..................... 8.5 多 样 性 ..................... ....1 8 1 185 8.6 阅读材料 ..................................................... 190 习题 .............................................................. 192 参考文献 .......................................................... 193 休息一会儿 ........................................................ 196 第 9 章 聚 类 .............................................. 197 9 . 1 聚类任务 .....................................................197 9 . 2 性能度量 .....................................................197 9.3 距离计算 ................... 9.4 原型聚类 ................................... 9 . 5 密度聚类 ..................... 199 202 211 xii 9 . 6 层次聚类 ............................... 9 . 7 阅读材料 .......................... 机器学习 214 217",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 242
    }
  },
  {
    "page_content": "9 . 5 密度聚类 ..................... 199 202 211 xii 9 . 6 层次聚类 ............................... 9 . 7 阅读材料 .......................... 机器学习 214 217 习 题 ........................................................... 220 参考文献 ................................ 221 休息一会儿 ........................................................ 224 第 1 0 章 降 维 与 度 量 学 习 ........ .............. 10.1 k近邻学习 ..................... 10.2 低维嵌入 ..................... 10.3 主 成 分 分 析 ........... 1 0 . 4 核 化 线 性 降 维 ............. 1 0 . 5 流形学习 ............................. 10.6 度 量 学 习 ..................... 225 225 226 229 232 234 237 10.7 阅读材料 ................................................... 240 习 题 ...............................................................242 参考文献 ......................... 243 246 休息一会儿 ..................................... 第 I I 章 特征选择与稀疏学习................... 1 1 . 1 子集搜索与评价 .......... 11.2 过滤式选择 .............................. 1 1 . 3 包 裹 式 选 择 ..................... 11.4 嵌入式选择与L i正则化 ...... 11.5 稀疏表示与字典学习 ........... 247 247 249 250 252 254",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 243
    }
  },
  {
    "page_content": "11.2 过滤式选择 .............................. 1 1 . 3 包 裹 式 选 择 ..................... 11.4 嵌入式选择与L i正则化 ...... 11.5 稀疏表示与字典学习 ........... 247 247 249 250 252 254 1 1 . 6 压缩感知 ................................................... 257 11.7 阅读材料 .............. .260 习题 .............................................................. 262 参 考 文 献 ........................ 263 266 休 息 一 会 儿 …… .......................... 第 1 2 章 计 算 学 习 理 论 .............................. 12.1 基础知识 ....................... 12.2 PAC 学习 .................. 1 2 . 3 有限假设空间 .......... 267 267 268 270 12.4 VC 维 ....................................................... 273 目 录 12.5 Rademacher 复杂度 ...................... xiii 279 1 2 . 6 稳定性 ..................................................... 284 12.7 阅读材料 .................................................... 287 习题 .............................................................. 289 参考文献 ....................................................... ...2 9 0 休息一会儿 ........................................................ 292",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 244
    }
  },
  {
    "page_content": "第 1 3 章 半 监 督 学 习 ..................................................293 13.1 未标记样本 ................................................. 293 1 3 . 2 生 成 式 方 法 ................................................. 295 13.3 半监督SVM ........................................................................................ 298 13.4 图半监督学习 ................................................300 1 3 . 5 基于分歧的方法 ......... 304 13.6 半监督聚类 ..................................................307 13.7 阅 读 材 料 .................................................... 311 习题 .............................................................. 313 参考文献 .................. 314 休息一会儿 ........................................................ 317 第 1 4 章 概 率 图 模 型 ，.................................................319 1 4 . 1 隐马尔可夫模型 ............................................. 319 14.2 马尔可夫随机场 ............................................. 322 1 4 . 3 条 件 随 机 场 ................................................. 325 1 4 . 4 学习与推断 ................................................. 328 1 4 . 5 近似推断 ................................................... 331",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 245
    }
  },
  {
    "page_content": "1 4 . 4 学习与推断 ................................................. 328 1 4 . 5 近似推断 ................................................... 331 14.6 话题模型 ................................................. 337 14.7 阅读材料 ................ 339 习 题 .............................................................. 341 参考文献 ....................... 342 休息一会儿 ........................................................ 345 第 1 5 章 规 则 学 习 .................................................... 347 15.1 基本概念 ................................................... 347 1 5 . 2 序贯覆盖 ................................................... 349 1 5 . 3 剪枝优化 ................................................... 352 xiv 机器学习 15.4 一阶规则学习 ............................................... 354 1 5 . 5 归纳逻辑程序设计 ............. 15.6 阅 读 材 料 ........................ 习 题 ........................................ 参考文献 ............ 休息一会儿 ................ 第 1 6 章 强 化 学 习 ............. 357 363 :............. 365 366 369 16.1 任务与奖赏 ..................... 16.2 K -摇臂赌博机 ......................... 1 6 . 3 有模型学习 ...................",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 246
    }
  },
  {
    "page_content": "第 1 6 章 强 化 学 习 ............. 357 363 :............. 365 366 369 16.1 任务与奖赏 ..................... 16.2 K -摇臂赌博机 ......................... 1 6 . 3 有模型学习 ................... 16.4 免模型学习 ................................... 371 371 373 ....3 7 7 382 1 6 . 5 值 函 数 近 似 ................................................. 388 1 6 . 6 模仿学习 ................................................... 390 1 6 . 7 阅读材料 ............ 393 习题 ............... 394 参考文献 .......................................... 395 休息一会儿 ........................................................ 397 附 录 ...........................：............................ 399 A 矩阵 .......................................................... 399 B 优 化 .......................................................... 403 C 概率分布 ....... 后 记 .................. 409 417 索 引 ................................................................. 419 第 1 章 绪 论 1 . 1 弓I言 傍晚小街路面上沁出微雨后的湿润，和煦的细风吹来，抬头看看天边的晚 霞，嗯，明天又是一个好天气.走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊 响的青绿西瓜，一边满心期待着皮薄肉厚瓢甜的爽落感，一边愉快地想着，这学 期狠下了工夫,基础概念弄得清清楚楚,算法作业也是信手拈来，这门课成绩一 定差不了！ 希望各位在学期结束时有这样的感觉.作为开场，我们先大致了解一下什",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 247
    }
  },
  {
    "page_content": "傍晚小街路面上沁出微雨后的湿润，和煦的细风吹来，抬头看看天边的晚 霞，嗯，明天又是一个好天气.走到水果摊旁，挑了个根蒂蜷缩、敲起来声音浊 响的青绿西瓜，一边满心期待着皮薄肉厚瓢甜的爽落感，一边愉快地想着，这学 期狠下了工夫,基础概念弄得清清楚楚,算法作业也是信手拈来，这门课成绩一 定差不了！ 希望各位在学期结束时有这样的感觉.作为开场，我们先大致了解一下什 么 是 “机器学习”（machine learning）. 回头看第一段话,我们会发现这里涉及很多基于经验做出的预判.例如，为 什么看到微湿路面、感到和风、看到晚霞，就认为明天是好天呢？这是因为在 我们的生活经验中已经遇见过很多类似情况，头一天观察到上述特征后，第二 天天气通常会很好.为什么色泽青绿、根蒂蜷缩、敲声浊响，就能判断出是正 熟的好瓜？因为我们吃过、看过很多西瓜,所以基于色泽、根蒂、敲声这几个 特征我们就可以做出相当好的判断.类似的，我们从以往的学习经验知道,下足 了工夫、弄清了概念、做好了作业，自然会取得好成绩.可以看出，我们能做出 有效的预判，是因为我们已经积累了许多经验，而通过对经验的利用，就能对新 情况做出有效的决策. 上面对经验的利用是靠我们人类自身完成的.计算机能帮忙吗？ 机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经 [Mitchell, 1997]给出了 一个更形式化的定义：假 设 用 P 来评估计算机程序 在 某 任 务 类 T 上的性能, 若一个程序通过利用经验 E 在 T 中任务上获得了性 能改善，则我们就说关于 T 和尸，该 程 序 对E 进行 了学习. 验来改善系统自身的性能.在计算机系统中，“经 验 ”通 常 以 “数 据 ”形式存 在，因此，机器学习所研究的主要内容，是 关 于 在 计 算机上从数据中产生“模 型 \" （model）的算法，即 “学习算法”（learning algorithm）. 有了学习算法，我 们把经验数据提供给它，它就能基于这些数据产生模型；在面对新的情况时（例 如看到一个没剖开的西瓜），模型会给我们提供相应的判断（例如好瓜）.如果说 计算机科学是研究关于“算法”的学问，那么类似的，可以说机器学习是研究 关 于 “学习算法”的学问. 例如[Hand et al., 2001]. 果（例如一棵决策树），而 用 “模式”指局部性结果（例如一条规则）. 本 书 用 “模型”泛指从数据中学得的结果.有文献用“模型”指全局性结 2 第 1 章 绪 论 1 . 2 基本术语 要进行机器学习，先要有数据.假定我们收集了一批关于西瓜的数据，例",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 248
    }
  },
  {
    "page_content": "关 于 “学习算法”的学问. 例如[Hand et al., 2001]. 果（例如一棵决策树），而 用 “模式”指局部性结果（例如一条规则）. 本 书 用 “模型”泛指从数据中学得的结果.有文献用“模型”指全局性结 2 第 1 章 绪 论 1 . 2 基本术语 要进行机器学习，先要有数据.假定我们收集了一批关于西瓜的数据，例 如（色泽= 青绿；根蒂= 蜷缩；敲声= 浊响），（色泽= 乌黑；根蒂= 稍蜷；敲声 =沉 闷），（色泽= 浅白；根蒂= 硬 挺 ；敲 声 =清 脆 ），… …, 每对括号内是一条记录, 意 思 是 “取值为 这 组 记 录 的 集 合 称 为 一 个 “数据集”（data set）, 其中每条记录是关于一 个事件或对象（这里是一个西瓜）的描述，称 为 一 个 “示 例 ”（instance）或 “样 本 \" （sample）. 反映事件或对象在某方面的表现或性质的事项，例 如 “色 泽 ” “根蒂” “敲 声 \" 称 为 “属 性 \" （attribute）或 “特征”（feature）; 属性上的取 值，例 如 “青绿” \" 乌 黑 \" 称 为 “属性值”时 tribute value）. 属性张成的空 间 称 为 “属性空间\" （attribute space）、 “样本空间”（sample space）或 “输入 空间”.例 如 我 们 把 “色 泽 ” “根蒂” “敲声”作为三个坐标轴，则它们张成 一个用于描述西瓜的三维空间，每个西瓜都可在这个空间中找到自己的坐标位 置.由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个 “特征向量”（feature vector）. 一 般 地 ，令 0 = ｛叫,g , … ，宓 鬲 表 示 包 含 皿 个 示 例 的 数 据 集 ，每个 示 例 由 d 个 属 性 描 述 （例 如 上 面 的 西瓜数据使用了 3 个属性），则每个示例 Xi = （C订;电2；… ；B d）是 d 维样本空间％中的一个向量，g E 工 其 中 Xij是 g 在 第 j 个属性上的取值（例 如 上 述 第 3 个 西 瓜 在 第 2 个 属 性 上 的 值 是 “硬 挺 ”），d 称为样本g 的 “维 数 \" （dimensionality）. 从 数 据 中 学 得 模 型 的 过 程 称 为 “学 习 ”（learning）或 “训 练 ”（training）, 这个过程通过执行某个学习算法来完成.训练过程中使用的数据称为“训练",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 249
    }
  },
  {
    "page_content": "g 在 第 j 个属性上的取值（例 如 上 述 第 3 个 西 瓜 在 第 2 个 属 性 上 的 值 是 “硬 挺 ”），d 称为样本g 的 “维 数 \" （dimensionality）. 从 数 据 中 学 得 模 型 的 过 程 称 为 “学 习 ”（learning）或 “训 练 ”（training）, 这个过程通过执行某个学习算法来完成.训练过程中使用的数据称为“训练 数 据 \" （training data）, 其中每个样本称为一个“训练样本\" （training sample）, 训练样本组成的集合称为“训 练 集 \"（training set）. 学得模型对应了关于数据 的某种潜在的规律，因 此 亦 称 “假 设 \" （hypothesis）; 这种潜在规律自身,则称 为 “真相”或 “真实”（ground-truth）, 学习过程就是为了找出或逼近真相.本 书 有时将模型称为“学习器”（learner）, 可看作学习算法在给定数据和参数空 间上的实例化. 如果希望学得一个能帮助我们判断没剖开的是不是“好 瓜 ”的模型，仅 有前面的示例数据显然是不够的.要建立这样的关于“预 测 ”（prediction）的 模型，我们需获得训练样本的“结果”信息，例 如 “（（色泽= 青绿;根蒂= 蜷缩; 敲 声 =浊 响 ），好瓜）”. 这里关于示例结果的信息，例 如 “好 瓜 ”，称 为 “标 记 \" （label）; 拥有了标记信息的示例，则 称 为 “样 例 \" （example）. 一般地，用 有时整个数据集亦称一 个 “样本 ”，因为它可看 作对样本空间的一个采样; 通 过 上 下 文 可 判 断 出 “样 本”是指单个示例还是数 据集. 训 练 样 本 亦 称 “训练示 伤 （training instance）或 “训练例”. 学习算法通常有参数需 设置，使用不同的参数值 和（或）训 练 数 据 ，将产生 不同的结果. 将 “ label” 译 为 “标 记 ” 而 非 “标签”，是考 虑 到 英 文 中 “ label” 既可 用作名词、也可用作动词. 1 . 2 基本术语 3 若将标记看作对象本身 的一部分，则 “样 例 ”有 时 也 称 为 “样本”. (g,纳)表示第i个样例，其 中 班 G ，是 示 例 Xi的标记，J 是所有标记的集合, 亦 称 “标记空间”(label space)或 “输出空间”. 亦 称 “负类”. 若我们欲预测的是离散值，例 如 “好 瓜 ” “坏 瓜 ”，此类学习任务称为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 250
    }
  },
  {
    "page_content": "1 . 2 基本术语 3 若将标记看作对象本身 的一部分，则 “样 例 ”有 时 也 称 为 “样本”. (g,纳)表示第i个样例，其 中 班 G ，是 示 例 Xi的标记，J 是所有标记的集合, 亦 称 “标记空间”(label space)或 “输出空间”. 亦 称 “负类”. 若我们欲预测的是离散值，例 如 “好 瓜 ” “坏 瓜 ”，此类学习任务称为 “分 类 \" (classification);若 欲预测的是连续值，例 如 西 瓜 成 熟 度 0.95、0.37, 此 类 学 习 任 务 称 为 “回 归 ”(re g re s s io n ).对 只 涉 及 两 个 类 别 的 “二分 类 \" (binary classifcation)任务，通常称其中一个类为“正类”(positive class), 另 一 个 类 为 “反 类 ”(negative c la s s );涉 及 多 个 类 别 时 ，则 称 为 “多 分 类 \" (multi-class classification)任 务 一 般 地 ，预 测 任 务 是 希 望 通 过 对 训 练 集 ｛(叫，阳),(政,故),… ，(宓g % n )｝进行学习，建立一个从输入空间％ 到输出 空 间 y 的 映 射 / ： * 1 ” 对二分类任务，通 常 令 y = ｛- i , + i ｝或 ｛o, 1｝；对 多分类任务，IV > 2 ; 对回归任务,y = 胆肽为实数集. 亦 称 “测 试 示 例 ” (testing in s ta n c e )或 “测 试例”. 学得模型后，使用其进行预测的过程称为“测试”(testing),被预测的样本 称 为 “测试样本”(testing sam ple).例如在学得了后，对测试例必可得到其预 测 标 记 g = 否则标记信息直接形成 了簇划分；但也有例外情 况，参 见 1 3 .6节. 亦 称 “有导师学习”和 “无导师学习”. 更确切地说，是 “未见 示 例 \" (unseen instance). 现实任务中样本空间的 规模通常很大(例如2 0 个 属性,每个属性有 1 0 个可 能取值，则样本空间的规 模 已 达 1020). 我们还可以对西瓜做“聚 类 \" (clustering),即将训练集中的西瓜分成若干 组，每 组 称 为 一 个 “簇 ”(cluster);这些自动形成的簇可能对应一些潜在的概念 划分，例 如 “浅色瓜” “深 色 瓜 \" 甚 至 “本地瓜” “外地瓜”.这样的学习过 程有助于我们了解数据内在的规律，能为更深入地分析数据建立基础.需说明 的是，在聚类学习中，“浅色瓜” “本地瓜”这样的概念我们事先是不知道的,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 251
    }
  },
  {
    "page_content": "程有助于我们了解数据内在的规律，能为更深入地分析数据建立基础.需说明 的是，在聚类学习中，“浅色瓜” “本地瓜”这样的概念我们事先是不知道的, 而且学习过程中使用的训练样本通常不拥有标记信息. 根据训练数据是否拥有标记信息，学习任务可大致划分为两大类： “监督 学 习 “(supervised learning)和 “无 监 督 学 习 \"(unsupervised learning),分类 和回归是前者的代表,而聚类则是后者的代表. 需注意的是,机器学习的目标是使学得的模型能很好地适用于“新 样 本 \" 而不是仅仅在训练样本上工作得很好；即便对聚类这样的无监督学习任务，我 们也希望学得的簇划分能适用于没在训练集中出现的样本.学得模型适用于 新样本的能力，称 为 “泛 化 \" (generalization)能力.具有强泛化能力的模型能 很好地适用于整个样本空间.于是，尽管训练集通常只是样本空间的一个很小 的采样，我们仍希望它能很好地反映出样本空间的特性，否则就很难期望在训 练集上学得的模型能在整个样本空间上都工作得很好.通常假设样本空间中全 体样本服从一个未知“分 布 \" (d i s t r i b u t i o n ) 我们获得的每个样本都是独立 地从这个分布上采样获得的，即 “独立同分布\" (independent and identically distributed,简 称 汨 ⑷ .一 般 而 言 ，训练样本越多，我们得到的关于V 的信息 4 第 1 章 绪 论 越多，这样就越有可能通过学习获得具有强泛化能力的模型. 1 . 3 假设空间 归纳(induction)与演绎(deduction)是科学推理的两大基本手段.前者是从 特 殊 到 一 般 的 “泛化”(generalization)过程，即从具体的事实归结出一般性规 律；后者则是从一般到特殊的“特 化 ”(specialization)过程，即从基础原理推演 出具体状况.例如，在数学公理系统中，基于一组公理和推理规则推导出与之 相洽的定理，这是演绎；而 “从样例中学习”显然是一个归纳的过程，因此亦称 “归纳学习 ”(inductive learning). 归纳学习有狭义与广义之分，广义的归纳学习大体相当于从样例中学习, 而狭义的归纳学习则要求从训练数据中学得概念(concept),因 此 亦 称 为 “概念 学 习 ”或 “概念形成”.概念学习技术目前研究、应用都比较少，因为要学得 泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多是产生“黑 箱 ”模型.然而，对概念学习有所了解,有助于理解机器学习的一些基础思想. 概念学习中最基本的是布尔概念学习，即 对 “是 ” “不是”这样的可表示",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 252
    }
  },
  {
    "page_content": "而狭义的归纳学习则要求从训练数据中学得概念(concept),因 此 亦 称 为 “概念 学 习 ”或 “概念形成”.概念学习技术目前研究、应用都比较少，因为要学得 泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多是产生“黑 箱 ”模型.然而，对概念学习有所了解,有助于理解机器学习的一些基础思想. 概念学习中最基本的是布尔概念学习，即 对 “是 ” “不是”这样的可表示 为 0/1布尔值的目标概念的学习.举一个简单的例子，假定我们获得了这样一 个训练数据集： 表 L 1 西瓜数据集 1 2 编 号 色 泽 根 蒂 敲 声 好 瓜 蜷 是 蜷 是 否 硬 否 稍 青 乌 青 乌 缩 缩 挺 蜷 绿 黑 绿 黑 响 响 脆 闷 浊 浊 清 沉 3 4 这里要学习的目标是“好 瓜 ”.暂 且 假 设 “好瓜”可 由 “色泽” “根蒂” “敲 声 ”这三个因素完全确定，换言之，只要某个瓜的这三个属性取值明确了, 我们就能判断出它是不是好瓜.于是，我 们 学 得 的 将 是 “好瓜是某种色泽、某 种根蒂、某种敲声的瓜”这样的概念,用布尔表达式写出来则是“好 瓜 分 (色 电了呼常会普 泽=?) A (根蒂=?) A (敲声= ? ) \" ，这 里 表 示 尚 未 确 定 的 取 值 ,而 我 们 的 任 合范或 务就是通过对表1 .1 的训练集进行学习，把 确 定 下 来 . 读者可能马上发现，表 1 .1 第一行： “(色泽二青绿)A (根 蒂 =蜷 缩 )A (敲 声 =浊 响 )”不就是好瓜吗？是的，但这是一个已见过的瓜,别忘了我们学习的 目 的 是 “泛化”，即通过对训练集中瓜的学习以获得对没见过的瓜进行判断的 1 . 3 假设空间 “记 住 ” 训 练 样 本 ，就 是 所 谓 的 “机 械 学 习 ” [Cohen and Feigenbaum, 1 9 8 3 ],或 称 “死 记硬背式 学习”，参 见 L 5 节. 这 里 我 们 假 定 训 练 样 本 不 含 噪 声 ，并 且 不 考 虑 “非 青 绿 ”这 样 的 「4 操 作 .由于训练集包含正例, 因 此 0 假设自然不出现. 5 能力.如果仅仅把训练集中的瓜“记住”，今后再见到一模一样的瓜当然可判 断,但是,对没见过的瓜,例如“（色泽=浅白）A （根蒂= 蜷缩）A （敲声= 浊响）” 怎么办呢？ 我们可以把学习过程看作一个在所有假设（hypothesis）组成的空间中进行 搜索的过程,搜索目标是找到与训练集“匹配”（班）的假设，即能够将训练集中 的瓜判断正确的假设.假设的表示一旦确定，假设空间及其规模大小就确定了.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 253
    }
  },
  {
    "page_content": "断,但是,对没见过的瓜,例如“（色泽=浅白）A （根蒂= 蜷缩）A （敲声= 浊响）” 怎么办呢？ 我们可以把学习过程看作一个在所有假设（hypothesis）组成的空间中进行 搜索的过程,搜索目标是找到与训练集“匹配”（班）的假设，即能够将训练集中 的瓜判断正确的假设.假设的表示一旦确定，假设空间及其规模大小就确定了. 这里我们的假设空间由形如“（色泽= ? ） A （根蒂= ? ） A （敲声= ? ）\" 的可能取值 所 形 成 的 假 设 组 成 .例 如 色 泽 有 “青 绿 ” “乌 黑 ” “浅白”这三种可能取值; 还需考虑到，也 许 “色 泽 ”无论取什么值都合适，我 们 用 通 配 符 来 表 示 , 例 如 “好 瓜 》 （色泽= *） A （根蒂= 蜷缩）A （敲声= 浊响）”，即 “好瓜是根蒂蜷 缩 、敲声浊响的瓜，什么色泽都行”. 此外，还需考虑极端情况：有 可 能 “好 瓜 ”这个概念根本就不成立，世 界 上 没 有 “好瓜”这种东西;我们用0 表示这 个假设.这样，若 “色泽” “根蒂” “敲声”分别有3 、2 、2 种可能取值，则我 们面临的假设空间规模大小为4 x 3 x 3 + 1 = 37. 图 1.1直观地显示出了这个 西瓜问题假设空间. 1 （色 泽 = * ；根蒂= * ；敲 f = * ）] | （色 泽 = 青 绿 ；根 蒂 = * ；敲 产 | （色 泽 = 乌 黑 ；根 蒂 = * ；敲 声 = 可 …… | （色 泽 = 青 绿 ；根 蒂 = 蜷 缩 ；敲 声 = * ? || （色 泽 = 青 绿 ；根 蒂 = 硬 挺 ；敲 声 = * 5 ] …… | （色 泽 = 青 绿 ；根 蒂 二蜷 缩 ；敲 声 = 浊 响 ）|| （色 泽 = 青 绿 ；根 蒂 = 蜷 缩 ；敲 声 = 沉 闷 ）| 图 1 . 1 西瓜问题的假设空间 有 许 多 可 能 的 选 择 ，如 在 路 径 上 自 顶 向 下 与 自 底 向 上 同 时 进 行 ，在 操 作 上 只 删 除 与 正 例 不 一 致 的 假 设等. 可以有许多策略对这个假设空间进行搜索，例如自顶向下、从一般到特殊, 或是自底向上、从特殊到一般，搜索过程中可以不断删除与正例不一致的假 设、和（或）与反例一致的假设.最终将会获得与训练集一致（即对所有训练样本 能够进行正确判断）的假设,这就是我们学得的结果. 需注意的是，现实问题中我们常面临很大的假设空间，但学习过程是基于 有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与 训 练 集 一 致 的 “假设集合”，我 们 称 之 为 “版本空间”（version space）. 例如,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 254
    }
  },
  {
    "page_content": "设、和（或）与反例一致的假设.最终将会获得与训练集一致（即对所有训练样本 能够进行正确判断）的假设,这就是我们学得的结果. 需注意的是，现实问题中我们常面临很大的假设空间，但学习过程是基于 有限样本训练集进行的，因此，可能有多个假设与训练集一致，即存在着一个与 训 练 集 一 致 的 “假设集合”，我 们 称 之 为 “版本空间”（version space）. 例如, 在西瓜问题中，与 表 1.1训练集所对应的版本空间如图1.2所示. 6 第 1 章 绪 论 图 1 . 2 西瓜问题的版本空间 1 . 4 归纳偏好 通过学习得到的模型对应了假设空间中的一个假设.于是，图 1 .2 的西瓜 版本空间给我们带来一个麻烦：现在有三个与训练集一致的假设，但与它们 对应的模型在面临新样本的时候，却会产生不同的输出.例如，对 （色泽= 青绿; 根蒂= 蜷缩；敲声= 沉闷）这个新收来的瓜，如 果 我 们 采 用 的 是 “好 瓜 o （色 泽 = *） A （根蒂= 蜷缩）A （敲声= *）\" ，那么将会把新瓜判断为好瓜，而如果采 用了另外两个假设，则判断的结果将不是好瓜.那么，应该采用哪一个模型（或 假设）呢？ 若 仅 有 表 1 .1 中的训练样本，则无法断定上述三个假设中哪一个“更好”. 然而，对于一个具体的学习算法而言，它必须要产生一个模型.这时，学习算 法 本 身 的 “偏 好 ”就会起到关键的作用.例如，若我们 的 算 法 喜 欢 “尽可能特 殊 ”的模型,则它会选择“好 瓜 分 （色泽= *） A （根蒂= 蜷缩）八（敲声= 浊响）”； 但若我们的算法喜欢“尽可能一般”的模型，并且由于某种原因它更“相信” 根 蒂 ,则它会选择“好 瓜 O （色泽= *） A （根蒂= 蜷缩）八（敲声= *）” . 机器学习 算法在学习过程中对某种类型假设的偏好，称 为 “归纳偏好”（inductive bias）, 或 简 称 为 “偏好”. 任何一个有效的机器学习算法必有其归纳偏好，否则它将被假设空间中看 似 在 训 练 集 上 “等效”的假设所迷惑，而无法产生确定的学习结果.可以想象, 如果没有偏好，我们的西瓜学习算法产生的模型每次在进行预测时随机抽选 训练集上的等效假设，那 么 对 这 个 新 瓜 “（色 泽 = 青 绿 ；根蒂= 蜷缩；敲 声 =沉 闷）\"学 得 模 型 时 而 告 诉 我 们 它 是 好 的 、时而告诉我们它是不好的，这样的学 习结果显然没有意义. . 归纳偏好的作用在图1 .3 这个回归学习图示中可能更直观.这里的每个训 练样本是图中的一个点（对沙）,要学得一个与训练集一致的模型，相当于找到一",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 255
    }
  },
  {
    "page_content": "训练集上的等效假设，那 么 对 这 个 新 瓜 “（色 泽 = 青 绿 ；根蒂= 蜷缩；敲 声 =沉 闷）\"学 得 模 型 时 而 告 诉 我 们 它 是 好 的 、时而告诉我们它是不好的，这样的学 习结果显然没有意义. . 归纳偏好的作用在图1 .3 这个回归学习图示中可能更直观.这里的每个训 练样本是图中的一个点（对沙）,要学得一个与训练集一致的模型，相当于找到一 条穿过所有训练样本点的曲线.显然，对有限个样本点组成的训练集，存在着 很多条曲线与其一致.我们的学习算法必须有某种偏好，才 能 产 出 它 认 为 “正 确 ”的模型.例如，若认为相似的样本应有相似的输出（例如，在各种属性上都 尽 可 能 特 殊 即 “适用情 形尽可能少”；尽可能一 般 即 “适 用 情 形 尽 可 能 多” . 对 “根蒂”还 是 对 “敲 声” 更重视,，看起来和属 性 选 择 ，亦 称 “特 征 选 择 ”（feature selection）有 关，但需注意的是,机器学 习中的特征选择仍是基于 对训练样本的分析进行的, 而在此处我们并非基于特 征 选 择 做 出 对 “根蒂”的 重视；这 里 对 “根 蒂 ” 的 信赖可视为基于某种领域 知识而产生的归纳偏好. 关于特征选择方面的内容 参 见 第 11章. 1 . 4 归纳偏好 7 图 L 3 存在多条曲线与有限样本训练集一致 很相像的西瓜，成熟程度应该比较接近），则对应的学习算法可能偏好图L 3 中 比 较 “平滑”的曲线A 而 不 是 比 较 “崎岖”的曲线B. 归纳偏好可看作学习算法自身在一个可能很庞大的假设空间中对假设进 行 选 择 的 启 发 式 或 “价 值 观 ”. 那 么 ，有没有一般性的原则来引导算法确立 “正确的”偏好呢？ “奥卡姆剃刀\" （Occam's razor）是一种常用的、 自然科学 研究中最基本的原则，即 “若有多个假设与观察一致,则选最简单的那个”.如 果采用这个原则，并 且 假 设 我 们 认 为 “更平滑”意 味 着 “更简单”（例如曲线 A 更易于描述，其方程式是沙= - 疗 + 6）+ 1 , 而 曲 线 B 则要复杂得多），则在 图 1 .3 中我们会自然地偏好“平滑”的曲线A. 然而，奥卡姆剃刀并非唯一可行的原则.退一步说，即便假定我们是奥卡姆 剃刀的铁杆拥龛，也需注意到，奥卡姆剃刀本身存在不同的诠释，使用奥卡姆剃 刀原则并不平凡.例如对我们已经很熟悉的西瓜问题来说，“假 设 1：好 瓜 分 （色泽= *） A （根蒂= 蜷缩）A （敲声=浊响）”和 假 设 2: “好 瓜 o （色泽= *） A （根蒂= 蜷缩）八（敲声= *）”这两个假设，哪 一 个 更 “简单”呢？这个问题并不",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 256
    }
  },
  {
    "page_content": "剃刀的铁杆拥龛，也需注意到，奥卡姆剃刀本身存在不同的诠释，使用奥卡姆剃 刀原则并不平凡.例如对我们已经很熟悉的西瓜问题来说，“假 设 1：好 瓜 分 （色泽= *） A （根蒂= 蜷缩）A （敲声=浊响）”和 假 设 2: “好 瓜 o （色泽= *） A （根蒂= 蜷缩）八（敲声= *）”这两个假设，哪 一 个 更 “简单”呢？这个问题并不 简单，需借助其他机制才能解决. 事实上，归 纳 偏 好 对 应 了学习算法本身所做出的关于“什么样的模型更 好 ”的假设.在具体的现实问题中，这个假设是否成立，即算法的归纳偏好是否 与问题本身匹配,大多数时候直接决定了算法能否取得好的性能. 让我们再回头看看图1 3 假设学习算法册基于某种归纳偏好产生了对应 于 曲 线 A 的模型，学习算法观基于另一种归纳偏好产生了对应于曲线B 的模 型.基于前面讨论的平滑曲线的某种“描述简单性”，我们满怀信心地期待算 法 & 比 观 更 好 . 确 实 ，图 L4（a）显示出，与 B 相比，A 与训练集外的样本更一 致;换言之,A 的泛化能力比B 强. 8 第 1 章 绪 论 这里只用到一些非常基 础的数学知识，只准备读 第 1 章 且 有 “数学恐惧” 的读者可以跳过这个部分 而不会影响理解，只需相 信 ，上 面 这 个 看 起 来 “匪 夷所思”的结论确实是成 立的. 图 L 4 没有免费的午餐.(黑点：训练样本；白点：测试样本) 但是,且慢！虽 然 我 们 希 望 并 相 信 戏 比 现 更 好 ,但 会 不 会 出 现 图 1.4(b)的 情况：与 A 相比，B 与训练集外的样本更一致？ 很遗感这种情况完全可能出现.换言之,对于一个学习算法戏，若它在某 些问题上比学习算法备好，则必然存在另一些问题，在 那 里 观 比 好 . 有 趣 的是，这个结论对任何算法均成立，哪怕是把本书后面将要介绍的一些聪明算 法 作 为 册 而 将 “随机胡猜”这样的笨拙算法作为现.惊讶吗？让我们看看下 面这个简短的讨论： 为简单起见，假 设 样 本 空 间 X 和 假 设 空 间H 都 是 离 散 的 .令 P (用X,£.) 代表算法£ a 基于训练数据X 产生假设h 的概率，再令/代表我们希望学习的 真 实 目 标 函 数 .戏 的 “训练集外误差”，即 &在 训 练 集 之 外 的 所 有 样 本 上 的 误差为 E 加 (£a|X\") = £ E P Q ) 口仇 Q ) # 了3))P ⑷ X,£a) , (1.1) h xe^-x 其 中 !(•)是指示函数,若•为真则取值I,否则取值0. 考虑二分类问题，且真实目标函数可以是任何函数\" 1 {0,1},函数空间",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 257
    }
  },
  {
    "page_content": "误差为 E 加 (£a|X\") = £ E P Q ) 口仇 Q ) # 了3))P ⑷ X,£a) , (1.1) h xe^-x 其 中 !(•)是指示函数,若•为真则取值I,否则取值0. 考虑二分类问题，且真实目标函数可以是任何函数\" 1 {0,1},函数空间 为,{0,1}用 .对 所 有 可 能 的 ; 按均匀分布对误差求和，有 £ E U £ a | X J ) = £ E £ P Q ) 口(2 ) 壬 / ⑺ ) P 3 X £ ) f f h xex-x 若 /均 匀 分 布 ，则有一 半 的 / 对 sc的预测与h(x) 不一致. xex-x h f = E 口 宏 ) £ 口 九 | 不 £ 石 2团 xeX-X h = ；2闱 £ P Q ) £ P 3 X , 玛) xex-x h 1 . 4 归纳偏好 = 2 图 -1 £ xeX -X 9 （1.2） 式（1.2）显示出，总误差竟然与学习算法无关!对于任意两个学习算法£ Q 和 心 ，我们都有 £ 旦杷（2 |X , / ） = £ & 杷 （& | X J ） , f f （1.3） 也就是说，无 论 学 习 算 法 玛 多 聪 明 、学 习 算 法 观 多 笨 拙 ，它们的期望性能竟 严格的NFL定理证明比 然相同！这 就 是 “没有免费的午餐”定 理 （No Free Lunch Theorem ,简 称 NFL 这里的简化论述繁难得多. 定理）[Wolpert, 1996; Wolpert and Macready, 1995]. 这下子，读者对机器学习的热情可能被一盆冷水浇透了：既然所有学习算 法的期望性能都跟随机胡猜差不多，那还有什么好学的？ 我们需注意到，N F L 定理有一个重要前提：所 有 “问题”出现的机会相 同、或所有问题同等重要.但实际情形并不是这样.很多时候，我们只关注自 己正在试图解决的问题（例如某个具体应用任务），希望为它找到一个解决方案, 至于这个解决方案在别的问题、甚至在相似的问题上是否为好方案，我们并不 关心.根收口，为 了 快 速 从 A 地 到 达 B 地，如果我 们 正 在 考 虑 的A 地是南京鼓 楼 、B 地是南京新街口，那 么 “骑自行车”是很好的解决方案；这 个 方 案 对A 地是南京鼓楼、B 地是北京新街口的情形显然很糟糕，但我们对此并不关心. 事实上，上 面 N F L 定理的简短论述过程中假设了 / 的均匀分布，而实际情",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 258
    }
  },
  {
    "page_content": "关心.根收口，为 了 快 速 从 A 地 到 达 B 地，如果我 们 正 在 考 虑 的A 地是南京鼓 楼 、B 地是南京新街口，那 么 “骑自行车”是很好的解决方案；这 个 方 案 对A 地是南京鼓楼、B 地是北京新街口的情形显然很糟糕，但我们对此并不关心. 事实上，上 面 N F L 定理的简短论述过程中假设了 / 的均匀分布，而实际情 形并非如此.例如，回到我们熟悉的西瓜问题,考虑｛假 设 1 : 好 瓜 o （色泽= *） A （根蒂= 蜷缩）八（敲声 =浊 响 ）｝和 ｛假 设 2 : 好 瓜 分 （色泽= *） A （根蒂= 硬挺） A （敲 声 =清 脆 ）｝. 从 N F L 定理可知，这两个假设同样好.我们立即会想到符 合条件的例子，对好瓜（色泽= 青绿;，根蒂= 蜷缩；敲声= 浊响）是 假 设 1 更好，而 对好瓜（色泽= 乌黑；根蒂= 硬挺；敲声= 清脆）则 是 假 设 2 更好.看上去的确是 这 样 .然 而 需 注 意 到 ，“（根 蒂 = 蜷 缩 ；敲声= 浊响）”的好瓜很常见，而 “（根 蒂 =硬 挺 ;敲 声 =清 脆 ）”的好瓜罕见，甚至不存在. 所以，N F L 定理最重要的寓意，是让我们清楚地认识到，脱离具体问题，空 泛 地 谈 论 “什么学习算法更好”毫无意义，因为若考虑所有潜在的问题，则所 有学习算法都一样好.要谈论算法的相对优劣，必须要针对具体的学习问题；在 某些问题上表现好的学习算法，在另一些问题上却可能不尽如人意，学习算法 自身的归纳偏好与问题是否相配,往往会起到决定性的作用. 10 第 1 章 绪 论 1 . 5 发展历程 机器学习是人工智能(artificial intelligence)研究发展到一定阶段的必然产 物.二十世纪五十年代到七十年代初，人工智能研究处于“推理期”，那时人们 以为只要能赋予机器逻辑推理能力，机器就能具有智能.这一阶段的代表性工 作 主 要 有 A. Newell和 H. S im o n 的 “逻 辑 理 论 家 \"(Logic Theorist)程序以及 此 后 的 “通 用 问 题 求 解 \"(General Problem Solving)程 序 等 这些工作在当时 取得了令人振奋的结果.例如，“逻辑理论家”程 序 在 1952年证明了著名数学 家罗素和怀特海的名著《数学原理》中的 3 8 条定理，在 1963年证明了全部52 条定理，特别值得一提的是，定 理 2.85甚至比罗素和怀特海证明得更巧妙.A. Newell和 H. S im on因为这方面的工作获得了 1975年图灵奖.然而，随着研究 向前发展，人们逐渐认识到，仅具有逻辑推理能力是远远实现不了人工智能的.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 259
    }
  },
  {
    "page_content": "家罗素和怀特海的名著《数学原理》中的 3 8 条定理，在 1963年证明了全部52 条定理，特别值得一提的是，定 理 2.85甚至比罗素和怀特海证明得更巧妙.A. Newell和 H. S im on因为这方面的工作获得了 1975年图灵奖.然而，随着研究 向前发展，人们逐渐认识到，仅具有逻辑推理能力是远远实现不了人工智能的. E. A. Feigenbaum 等人认为，要使机器具有智能，就必须设法使机器拥有知识. 在他们的倡导下，从二十世纪七十年代中期开始，人工智能研究进入了 “知识 期 ”.在这一时期，大量专家系统问世,在很多应用领域取得了大量成果.E. A. Feigenbaum 作 为 “知识工程”之 父 在 1994年获得图灵奖.但是，人们逐渐认 识到，专家系统面临“知识工程瓶颈”，简单地说，就是由人来把知识总结出来 再教给计算机是相当困难的.于是,一些学者想到，如果机器自己能够学习知识 该多好！ 所 谓 “知识就是力量”. 1965 年，Feigenbaum 主 持研制了世界上第一个专 家系统DENDRAL. 事实上，图灵在1950年关于图灵测试的文章中，就曾提到了机器学习的可 能；二十世纪五十年代初已有机器学习的相关研究，例 如 A. S am uel著名的跳 参 见 p.22. 棋程序.五十年代中后期，基 于 神 经 网 络 的 “连 接 主 义 \"(coimectionism)学习 开始出现，代表性工作有F. R o se n b la tt的感知机(Perceptron)、B. W idrow 的 A daline等.在六七十年代，基 于 逻 辑 表 示 的 “符 号 主 义 \"(symbolism)学习技 术蓬勃发展，代表性工作有P. W in sto n 的 “结构学习系统”、R. S. Michalski 等 人 的 “基于逻辑的归纳学习系统”、E .B . H u n t等 人 的 “概念学习系统” 等；以决策理论为基础的学习技术以及强化学习技术等也得到发展，代表性工 作 有 N. J. N ilson的 “学习机器”等；二十多年后红极一时的统计学习理论的 一些奠基性结果也是在这个时期取得的. 1980年夏,在美国卡耐基梅隆大学举行了第一届机器学习研讨会(IWML); 同年， 《策略分析与信息系统》连出三期机器学习专辑；1983年 ,T io g a 出版社 出版了 R. S. Michalski、J. G. Carbonell 和 T. Mitchell 主 编 的 《机器学习：一 种人工智能途径》[Michalski et a l, 1983],对当时的机器学习研究工作进行了",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 260
    }
  },
  {
    "page_content": "同年， 《策略分析与信息系统》连出三期机器学习专辑；1983年 ,T io g a 出版社 出版了 R. S. Michalski、J. G. Carbonell 和 T. Mitchell 主 编 的 《机器学习：一 种人工智能途径》[Michalski et a l, 1983],对当时的机器学习研究工作进行了 总结；1986年，第一本机器学习专业期刊Machine Learning创刊；1989年，人 I W M L 后来发展为国际 机器学习会议ICML. 1 . 5 发展历程 11 工智能领域的权威期刊Artificial Intelligence出版机器学习专辑，刊发了当时 一些比较活跃的研究工作，其 内容后来出现在J. G. Carbonell主 编 、M IT 出 版 社 1990年 的 《机器学习：范型与方法》［Carbonell, 1990］ 一书中.总的来看, 二十世纪八十年代是机器学习成为一个独立的学科领域、各种机器学习技术 百花初绽的时期. R. S. Michalski等 人 ［Michalski et al., 1983］把机器学习研究划分为“从样 例中学习” “在问题求解和规划中学习” “通过观察和发现学习” “从指令 中学习”等种类；E. A. Feigenbaum等 人 在 著 名 的 《人工智能手册》（第三卷） ［Cohen and Feigenbaum, 1983］中，则把机器学习划分为“机械学习” “示教 学习” “类比学习”和 “归纳学习”.机 械 学 习 亦 称 “死记硬背式学习”，即 把外界输入的信息全部记录下来，在需要时原封不动地取出来使用，这实际上 没有进行真正的学习，仅是在进行信息存储与检索；示教学习和类比学习类似 于 R. S. Michalski等 人 所 说 的 “从指令中学习”和 “通过观察和发现学习”； 归 纳 学 习 相 当 于 “从样例中学习”，即从训练样例中归纳出学习结果.二十世 纪八十年代以来，被研究最多、应 用 最 广 的 是 “从样例中学习”（也就是广义 的归纳学习），它涵盖了监督学习、无监督学习等，本书大部分内容均属此范畴. 下面我们对这方面主流技术的演进做一个简单回顾. 在二十世 纪 八 十 年 代 ， “从 样 例 中 学 习 ”的一大主流是符号主义学习, 其代表包括决策树（decision tree）和基于逻辑的学习.典型的决策树学习以信 息论为基础，以信息嫡的最小化为目标，直接模拟了人类对概念进行判定的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 261
    }
  },
  {
    "page_content": "的归纳学习），它涵盖了监督学习、无监督学习等，本书大部分内容均属此范畴. 下面我们对这方面主流技术的演进做一个简单回顾. 在二十世 纪 八 十 年 代 ， “从 样 例 中 学 习 ”的一大主流是符号主义学习, 其代表包括决策树（decision tree）和基于逻辑的学习.典型的决策树学习以信 息论为基础，以信息嫡的最小化为目标，直接模拟了人类对概念进行判定的 树形流程.基于逻辑的学习的著名代表是归纳逻辑程序设计（Inductive Logic Program ming,简 称 ILP）, 可看作机器学习与逻辑程序设计的交叉，它使用一 阶逻辑（即谓词逻辑）来进行知识表示，通过修改和扩充逻辑表达式（例 如 Prolog 表达式）来完成对数据的归纳.符号主义学习占据主流地位与整个人工智能领域 的发展历程是分不开的.前面说过，人工智能在二十世纪五十到八十年代经历 了 “推理期”和 “知识期”，在 “推理期”人们基于符号知识表示、通过演绎 推理技术取得了很大成就，而 在 “知识期”人们基于符号知识表示、通过获取 和利用领域知识来建立专家系统取得了大量成果，因此，在 “学习期”的开始, 符号知识表示很自然地受到青睐.事实上，机器学习在二十世纪八十年代正是 被 视 为 “解决知识工程瓶颈问题的关键”而走上人工智能主舞台的.决策树学 习技术由于简单易用，到今天仍是最常用的机器学习技术之一.I L P 具有很强 的知识表示能力，可以较容易地表达出复杂数据关系，而且领域知识通常可方 便地通过逻辑表达式进行描述，因此,IL P 不仅可利用领域知识辅助学习，还可 参见第4 章 . ’ 这时实际是ILP的前身. 参见 第 1 5 章. 12 第 1 章 绪 论 通过学习对领域知识进行精化和增强；然而，成也萧何、败也萧何，由于表示能 力太强，直接导致学习过程面临的假设空间太大、复杂度极高，因此，问题规模 稍大就难以有效进行学习，九十年代中期后这方面的研究相对陷入低潮. 二十世纪九十年代中期之前，“从样例中学习”的另一主流技术是基于神 经网络的连接主义学习.连接主义学习在二十世纪五十年代取得了大发展，但 因为早期的很多人工智能研究者对符号表示有特别偏爱，例 如 图 灵 奖 得 主 H. Sim on曾断言人工智能是研究“对智能行为的符号化建模”，所以当时连接主 义的研究未被纳入主流人工智能研究范畴.尤其是连接主义自身也遇到了很大 的障碍，正如图灵奖得主M. Minsky和 S. P a p e rt在1969年指出，(当时的)神经 网络只能处理线性分类，甚 至 对 “异或”这么简单的问题都处理不了. 1983年,. J. J. Hopfield利用神经网络求解“流动推销员问题”这个著名的N P 难题取得",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 262
    }
  },
  {
    "page_content": "的障碍，正如图灵奖得主M. Minsky和 S. P a p e rt在1969年指出，(当时的)神经 网络只能处理线性分类，甚 至 对 “异或”这么简单的问题都处理不了. 1983年,. J. J. Hopfield利用神经网络求解“流动推销员问题”这个著名的N P 难题取得 重大进展，使得连接主义重新受到人们关注.1986年，D. E. R um elhart等人重 参 见 第 5 章. 新发明了著名的B P 算法，产生了深远影响.与符号主义学习能产生明确的概 参 见 第 6 章. 念 表 示不同，连接主义学习产生的是“黑箱”模型，因此从知识获取的角度来 看，连接主义学习技术有明显弱点；然而，由于有B P 这样有效的算法，使得它 可以在很多现实问题上发挥作用.事实上，BP 一直是被应用得最广泛的机器 学习算法之一.连接主义学习的最大局限是其“试错性”；简单地说，其学习过 程涉及大量参数，而参数的设置缺乏理论指导，主 要 靠 手 工 “调参”；夸张一点 说，参数调节上失之毫厘，学习结果可能谬以千里. 二十世纪九十年代 中期， “统 计 学 习 ”(statistical learning)闪亮登场并 迅速占据主流舞台，代表性技术是支持向量机(Support Vector M achine,简称 SVM)以 及 更 一 般 的 “核 方 法 ”(kernel m e th o d s).这方面的研究早在二十世 纪六七十年代就已开始，统 计 学 习 理 论 ［Vapnik, 1998］在那个时期也已打下 了基础，例 如 V. N. Vapnik在 1963年提出了 “支 持 向 量 ”概念，他 和 A. J. Chervonenkis在 1968年提 出V C 维，在 1974年提出了结构风险最小化原则等. 但直到九十年代中期统计学习才开始成为机器学习的主流，一方面是由于有效 的支持向量机算法在九十年代初才被提出，其优越性能到九十年代中期在文 本分类应用中才得以显现；另一方面，正是在连接主义学习技术的局限性凸显 之后，人们才把目光转向了以统计学习理论为直接支撑的统计学习技术.事实 参 见 习 题 6.5. 上，统计学习与连接主义学习有密切的联系.在支持向量机被普遍接受后，核技 巧(kernel tric k )被人们用到了机器学习的几乎每一个角落，核方法也逐渐成为 机器学习的基本内容之一. 有趣的是，二十一世纪初，连接主义学习又卷土重来，掀 起 了 以 “深度学 1 . 6 应用现状 13 参见5.6节. 习” 为名的热潮.所谓深度学习，狭 义 地 说 就 是 “很多层”的神经网络.在若 干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 263
    }
  },
  {
    "page_content": "有趣的是，二十一世纪初，连接主义学习又卷土重来，掀 起 了 以 “深度学 1 . 6 应用现状 13 参见5.6节. 习” 为名的热潮.所谓深度学习，狭 义 地 说 就 是 “很多层”的神经网络.在若 干测试和竞赛上，尤其是涉及语音、图像等复杂对象的应用中，深度学习技术 取得了优越性能.以往机器学习技术在应用中要取得好性能，对使用者的要求 较高；而深度学习技术涉及的模型复杂度非常高，以至于只要下工夫“调参”， 把参数调节好，性能往往就好.因此，深度学习虽缺乏严格的理论基础，但它显 著降低了机器学习应用者的门槛，为机器学习技术走向工程实践带来了便利. 那么，它为什么此时才热起来呢？有两个基本原因：数据大了、计算能力强了. “过拟合，，参见第2章.深度学习模型拥有大量参数，若数据样本少，则 很 容 易 “过拟合”；如此复杂的 模型、如此大的数据样本，若缺乏强力计算设备,根本无法求解.恰由于人类进 入了 “大数据时代”，数据储量与计算设备都有了大发展，才使得连接主义学 习技术焕发又一春.有趣的是，神经网络在二十世纪八十年代中期走红，与当时 I n t e lx 8 6 系列微处理器与内存条技术的广泛应用所造成的计算能力、数据访 存效率比七十年代有显著提高不无关联.深度学习此时的状况，与彼时的神经 网络何其相似. 需说明的是，机器学习现在已经发展成为一个相当大的学科领域，本节仅 是管中窥豹，很多重要技术都没有谈及，耐心的读者在读完本书后会有更全面 的了解. 1 . 6 应 用 现 状 在过去二十年中，人类收集、存储、传输、处理数据的能力取得了飞速提 升，人类社会的各个角落都积累了大量数据，亟需能有效地对数据进行分析利 用的计算机算法，而机器学习恰顺应了大时代的这个迫切需求，因此该学科领 域很自然地取得巨大发展、受到广泛关注. 今天，在计算机科学的诸多分支学科领域中，无论是多媒体、图形学，还是 网络通信、软件工程，乃至体系结构、芯片设计，都能找到机器学习技术的身 影，尤其是在计算机视觉、 自然语言处理等“计算机应用技术”领域，机器学 习已成为最重要的技术进步源泉之一. 机 器 学 习 还 为 许 多 交叉学科提供了重要的技术支撑.例如，“生物信息 学 ”试图利用信息技术来研究生命现象和规律，而基因组计划的实施和基因药 物 的 美 好愿景让人们为之心潮澎湃.生物信息学研究涉及从“生命现象”到 “规律发现”的整个过程,其间必然包括数据获取、数据管理、数据分析、仿 真实验等环节，而 “数据分析”恰是机器学习技术的舞台，各种机器学习技术 已经在这个舞台上大放异彩. 14 第 1 章 绪 论",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 264
    }
  },
  {
    "page_content": "学 ”试图利用信息技术来研究生命现象和规律，而基因组计划的实施和基因药 物 的 美 好愿景让人们为之心潮澎湃.生物信息学研究涉及从“生命现象”到 “规律发现”的整个过程,其间必然包括数据获取、数据管理、数据分析、仿 真实验等环节，而 “数据分析”恰是机器学习技术的舞台，各种机器学习技术 已经在这个舞台上大放异彩. 14 第 1 章 绪 论 N ASA-JPL的全称是美 国航空航天局喷气推进实 验室，著 名 的 “勇气”号 和 “机遇”号火星机器人 均是在这个实验室研制的. D A RP A的全称是美国 国防部先进研究计划局, 互联网、全球卫星定位系 统 等 都 源 于 DARPA启动 的研究项目. 事实上，随 着 科 学 研 究 的 基 本 手 段 从 传 统 的 “理论+ 实 验 ”走向现在的 “理论+ 实验十计算”，乃 至 出 现 “数据科 学 ”这样的提法，机器学习的重要 性日趋显著，因 为 “计算”的目的往往是数据分析，而数据科学的核心也恰是 通过分析数据来获得价值.若要列出目前计算机科学技术中最活跃、最受瞩 目的研究分支，那 么 机 器 学 习 必 居 其 中 .2001年，美 国 N A S A -JP L 的科学家 在 Science杂 志 上 专 门 撰 文 ［Mjolsness and DeCoste, 2001］指出，机器学习对 科学研究的整个过程正起到越来越大的支撑作用，其进展对科技发展意义重大. 2003年，D A R P A 启 动 P A L 计划，将机器学习的重要性上升到美国国家安全的 高度来考虑.众所周知，美国最尖端科技的研究通常是由N A S A 和 D A R PA 推 进的，而这两大机构不约而同地强调机器学习的重要性,其意义不言而喻. 2006年，卡耐基梅隆大学宣告成立世界上第一个“机器学习系”，机器学 习领域奠基人之一 T. M itchell教授出任首任系主任.2012年 3 月，美国奥巴马 政 府 启 动 “大数据研究与发展计划”，美国国家科学基金会旋即在加州大学伯 克利分校启动加强计划，强调要深入研究和整合大数据时代的三大关键技术: 机器学习提供数据分析 能力，云计算提供数据处 理能力，众包提供数据标 记能力. 机器学习、云计算、众包(crow dsourcing).显然，机器学习在大数据时代是必 不可少的核心技术,道理很简单：收集、存储、传输、管理大数据的目的，是为 了 “利用”大数据，而如果没有机器学习技术分析数据，则 “利用”无从谈起.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 265
    }
  },
  {
    "page_content": "克利分校启动加强计划，强调要深入研究和整合大数据时代的三大关键技术: 机器学习提供数据分析 能力，云计算提供数据处 理能力，众包提供数据标 记能力. 机器学习、云计算、众包(crow dsourcing).显然，机器学习在大数据时代是必 不可少的核心技术,道理很简单：收集、存储、传输、管理大数据的目的，是为 了 “利用”大数据，而如果没有机器学习技术分析数据，则 “利用”无从谈起. “数据挖掘”这个词很 早就在统计学界出现并略 带贬义，这是由于传统统 计学研究往往醉心于理论 的优美而忽视实际效用. 但最近情况发生变化，越 来越多的统计学家开始关 注现实问题，进入机器学 习和数据挖掘领域. 谈到对数据进行分析利用，很 多 人 会 想 到 “数据挖掘”(data m in in g ),这 里简单探讨一下数据挖掘与机器学习的联系.数据挖掘领域在二十世纪九十年 代形成，它受到很多学科领域的影响，其中数据库、机器学习、统计学无疑影 响 最 大 ［Zhou, 2003］. 数据挖掘是从海量数据中发掘知识,这就必然涉及对“海 量数据”的管理和分析.大体来说，数据库领域的研究为数据挖掘提供数据管 理技术，而机器学习和统计学的研究为数据挖掘提供数据分析技术.由于统计 学界的研究成果通常需要经由机器学习研究来形成有效的学习算法，之后再进 入数据挖掘领域，因此从这个意义上说，统计学主要是通过机器学习对数据挖 掘发挥影响，而机器学习领域和数据库领域则是数据挖掘的两大支撑. 今天，机器学习已经与普通人的生活密切相关.例如在天气预报、能源勘 探 、环境监测等方面，有效地利用机器学习技术对卫星和传感器发回的数据进 行分析，是提高预报和检测准确性的重要途径;在商业营销中，有效地利用机器 学习技术对销售数据、客户信息进行分析，不仅可帮助商家优化库存降低成本, 还有助于针对用户群设计特殊营销策略；……下面再举几例： 众所周知，谷歌、百度等互联网搜索引擎已开始改变人类的生活方式,例 如很多人已习惯于在出行前通过互联网搜索来了解目的地信息、寻找合适的 1 . 6 应用现状 15 例如著名机器学习教科 书 [Mitchell, 1997] 4.2 节介 绍了二十世纪九十年代早 期利用神经网络学习来控 制 自 动 驾 驶 车 的 ALVINN 系统. 酒店、餐 馆 等 .美 国 《新闻周刊》 曾对谷歌有一句话评论：“它使任何人离任 何问题的答案间的距离变得只有点击一下鼠标这么远」 显然，互联网搜索是 通过分析网络上的数据来找到用户所需的信息，在这个过程中，用户查询是输 入 、搜索结果是输出，而要建立输入与输出之间的联系，内核必然需要机器学 习技术.事实上，互联网搜索发展至今，机器学习技术的支撑居功至伟.到了今",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 266
    }
  },
  {
    "page_content": "酒店、餐 馆 等 .美 国 《新闻周刊》 曾对谷歌有一句话评论：“它使任何人离任 何问题的答案间的距离变得只有点击一下鼠标这么远」 显然，互联网搜索是 通过分析网络上的数据来找到用户所需的信息，在这个过程中，用户查询是输 入 、搜索结果是输出，而要建立输入与输出之间的联系，内核必然需要机器学 习技术.事实上，互联网搜索发展至今，机器学习技术的支撑居功至伟.到了今 天，搜索的对象、 内容日趋复杂，机器学习技术的影响更为明显，例如在进行 “图片搜索”时，无论谷歌还是百度都在使用最新潮的机器学习技术.谷歌、 百度、脸书、雅虎等公司纷纷成立专攻机器学习技术的研究团队，甚至直接以 机器学习技术命名的研究院，充分体现出机器学习技术的发展和应用，甚至在 一定程度上影响了互联网产业的走向. 再举一例.车祸是人类最凶险的杀手之一，全世界每年有上百万人丧生车 轮，仅我国每年就有约十万人死于车祸.由计算机来实现自动汽车驾驶是一个 理想的方案，因为机器上路时可以确保不是新手驾驶、不会疲劳驾驶，更不会 酒后驾驶，而且还有重要的军事用途.美国在二十世纪八十年代就开始进行这 方面研究.这里最大的困难是无法在汽车厂里事先把汽车上路后所会遇到的所 有情况都考虑到、设计出处理规则并加以编程实现,而只能根据上路时遇到的 情况即时处理.若把车载传感器接收到的信息作为输入，把方向、刹车、油门 的控制行为作为输出，则这里的关键问题恰可抽象为一个机器学习任务.2004 年 3 月，在 美 国 D A R PA 组织的自动驾驶车比赛中，斯坦福大学机器学习专家 S. T h ru n 的小组研制的参赛车用6 小 时 5 3 分钟成功走完了 132英里赛程获得 冠军.比赛路段是在内华达州西南部的山区和沙漠中，路况相当复杂,在这样的 路段上行车即使对经验丰富的人类司机来说也是一个挑战.S. T h ru n 后来到谷 歌领导自动驾驶车项目团队.值得一提的是，自动驾驶车在近几年取得了飞跃 式发展，除谷歌外，通用、奥迪、大众、宝马等传统汽车公司均投入巨资进行 研发，目前已开始有产品进入市场.2011年 6 月，美国内华达州议会通过法案, 成为美国第一个认可自动驾驶车的州，此后，夏威夷州和佛罗里达州也先后通 过类似法案.自动驾驶汽车可望在不久的将来出现在普通人的生活中，而机器 学习技术则起到了 “司机”作用. 机器学习技术甚至已影响到人类社会政治生活.2012年美国大选期间，奥 巴马麾下有一支机器学习团队，他们对各类选情数据进行分析，为奥巴马提示 下一步竞选行动.例如他们使用机器学习技术分析社交网络数据，判断出在总 统候选人第一次辩论之后哪些选民会倒戈，并根据分析的结果开发出个性化宣",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 267
    }
  },
  {
    "page_content": "过类似法案.自动驾驶汽车可望在不久的将来出现在普通人的生活中，而机器 学习技术则起到了 “司机”作用. 机器学习技术甚至已影响到人类社会政治生活.2012年美国大选期间，奥 巴马麾下有一支机器学习团队，他们对各类选情数据进行分析，为奥巴马提示 下一步竞选行动.例如他们使用机器学习技术分析社交网络数据，判断出在总 统候选人第一次辩论之后哪些选民会倒戈，并根据分析的结果开发出个性化宣 传策略，能为每位选民找出一个最有说服力的挽留理由；他们基于机器学习模 16 第 1 章 绪 论 型的分析结果提示奥巴马应去何处开展拉票活动，有些建议甚至让专业竞选顾 问大吃一惊，而结果表明去这些地方大有收获.总统选举需要大量金钱，机器 学习技术在这方面发挥了奇效.例如，机器学习模型分析出，某电影明星对某 地区某年龄段的特定人群很有吸引力，而这个群体很愿意出高价与该明星及奥 巴马共进晚餐……果然，这样一次筹资晚宴成功募集到1500万美元；最终，借 助机器学习模型，奥巴马筹到了创纪录的1 0 亿美元竞选经费.机器学习技术不 仅 有 助 于 竞 选 经 费 “开源”，还 可 帮 助 “节 流 ”，例如机器学习模型通过对不 同群体选民进行分析，建议购买了一些冷门节目的广告时段，而没有采用在昂 贵的黄金时段购买广告的传统做法，使得广告资金效率相比2008年竞选提高 了 1 4 % ;……胜选后， 《时代》周刊专门报道了这个被奥巴马称为“竞选核武 器 ”、由半监督学习研究专家R. G h a n i领导的团队. 值得一提的是,机器学习备受瞩目当然是由于它已成为智能数据分析技术 的创新源泉，但机器学习研究还有另一个不可忽视的意义，即通过建立一些关 于学习的计算模型来促进我们理解“人类如何学习”.例 如 ，P. K anerva在二 十世纪八 十 年 代 中 期 提 出 SDM (Sparse Distributed Memory)模 型 ［Kanerva, 1988］时并没有刻意模仿脑生理结构，但后来神经科学的研究发现，S D M 的稀 疏编码机制在视觉、听觉、嗅觉功能的脑皮层中广泛存在，从而为理解脑的某 些功能提供了一定的启发.自然科学研究的驱动力归结起来无外是人类对宇宙 本源、万物本质、生命本性、 自我本识的好奇，而 “人类如何学习”无疑是一 个有关自我本识的重大问题.从这个意义上说，机器学习不仅在信息科学中占 有重要地位,还具有一定的自然科学探索色彩. 1 . 7 阅读材料 ［Mitchell, 1997］是 第 一 本 机 器 学 习 专 门 性 教 材 ，［Duda et al., 2001; Al-",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 268
    }
  },
  {
    "page_content": "本源、万物本质、生命本性、 自我本识的好奇，而 “人类如何学习”无疑是一 个有关自我本识的重大问题.从这个意义上说，机器学习不仅在信息科学中占 有重要地位,还具有一定的自然科学探索色彩. 1 . 7 阅读材料 ［Mitchell, 1997］是 第 一 本 机 器 学 习 专 门 性 教 材 ，［Duda et al., 2001; Al- paydin, 2004; Flach, 2012］都是出色的入门读物. ［Hastie et al., 2009］是很好 的进阶读物，［Bishop, 2006］也很有参考价值，尤其适合于贝叶斯学习偏好者. ［Shalev-Shwartz and Ben-David, 2014］则适合于理论偏好者. ［W itten et al., 2011］是 基 于 W E K A 撰写的入门读物,有助于初学者通过W E K A 实践快速掌 握常用机器学习算法. 本 书 1 .5 和 1 .6 节 主 要 取 材 于 ［周志华, 2007］. 《机器学习：一种人工智能 途径》［Michalski et al., 1983］汇集了 2 0 位学者 撰 写 的 1 6 篇文章，是机器学习 早期最重要的文献.该书出版后产生了很大反响，Morgan K aufm ann出版社后 来 分 别 于 1986年 和 1990年出版了该书的续篇，编 为 第 二 卷 和 第 三 卷 .《人工 W E K A 是 著 名 的 免 费 机器学习算法程序库，由 新 西 兰 W a ik a to 大 学 研 究 人 员 基 于 J A V A 开发: h ttp ://w w w .cs.wai kato. ac.nz/m l/w eka/. 1 . 7 阅读材料 17 深度学习参见5 .6 节. 智能手册》系列是图灵奖得主E. A. Feigenbaum与不同学者合作编写而成，该 书 第 三 卷 [Cohen and Feigenbaum, 1983]对机器学习进行了讨论，是机器学习 早期的重要文献. [Dietterich, 1997]对机器学习领域的发展进行了评述和展望. 早期的很多文献在今天仍值得重视，一些闪光的思想在相关技术进步后可能焕 发新的活力，例 如 近 来 流 行 的 “迁 移 学 习 \"(transfer learning) [Pan and Yang, 2010],恰 似 “类比学习” (learning by analogy)在统计学习技术大发展后的升 级版；红 极 一 时 的 “深 度 学 习 \"(deep learning)在思想上并未显著超越二十世 纪八十年代中后期神经网络学习的研究.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 269
    }
  },
  {
    "page_content": "发新的活力，例 如 近 来 流 行 的 “迁 移 学 习 \"(transfer learning) [Pan and Yang, 2010],恰 似 “类比学习” (learning by analogy)在统计学习技术大发展后的升 级版；红 极 一 时 的 “深 度 学 习 \"(deep learning)在思想上并未显著超越二十世 纪八十年代中后期神经网络学习的研究. 机器学习中关于概念学习的研究开始很早，从中产生的不少思想对整个 领域都有深远影响.例如作为主流学习技术之一的决策树学习，就起源于关 于 概 念 形 成 的 树 结 构 研 究 [Hunt and Hovland, 1963]. [Winston, 1970]在著 名 的 “积木世界”研究中，将概念学习与基于泛化和特化的搜索过程联系起 来. [Simon and Lea, 1974]较早提出了 “学 习 ”是在假设空间中搜索的观点. [Mitchell, 1977]稍后提出了版本空间的概念.概念学习中有很多关于规则学习 规则学习参见第15章. 的内容. 奥卡姆剃刀原则主张选择与经验观察一致的最简单假设，它在自然科学如 物理学、天文学等领域中是一个广为沿用的基础性原则，例如 哥 白 尼 坚 持 “日 心 说 ”的理由之一就是它比托勒密的“地 心 说 ”更简单且符合天文观测.奥 卡姆剃刀在机器学习领域也有很多追随者[Blumer et al., 1996].但机器学习 中 什 么 是 “更简单的”这个问题一直困扰着研究者们，因此，对奥卡姆剃刀在 机器学习领域的作用一直存在着争议[Webb, 1996; Domingos, 1999].需注意 的是，奥卡姆剃刀并非科学研究中唯一可行的假设选择原则，例如古希腊哲学 家伊壁鸠鲁(公元前341年-前270年 )提 出 的 “多 释 原 则 \"(principle of multiple explanations),主张保留与经验观察一致的所有假设[Asmis, 1984],这与集成 集成学习参见第8 章. 学习(ensemble learning)方面的研究更加吻合. 机器学习领域最重要的国际学术会议是国际机器学习会议(ICML)、国际 神经信息处理系统会议(NIPS)和国际学习理论会议(C O L T),重要的区域性会 议主要有欧洲机器学习会议(ECML)和亚洲机器学习会议(ACM L);最重要的 国际学术期刊是 Journal of Machine Learning Research 和 Machine Learning.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 270
    }
  },
  {
    "page_content": "机器学习领域最重要的国际学术会议是国际机器学习会议(ICML)、国际 神经信息处理系统会议(NIPS)和国际学习理论会议(C O L T),重要的区域性会 议主要有欧洲机器学习会议(ECML)和亚洲机器学习会议(ACM L);最重要的 国际学术期刊是 Journal of Machine Learning Research 和 Machine Learning. 人工智能领域的重要会议如UCAL A A A I以及重要期刊如Artificial Intelli­ gence > Journal of Artificial Intelligence Research1 数据挖掘领域的重要会议 如 KDD、ICDM 以及重要期刊如 A C M Transactions on Knowledge Discovery from Data、Data Mining and Knowledge Discovery,计算机视觉与模式识别 18 第 1 章 绪 论 领域的重要会议如C V P R 以及重要期刊如IEEE Transactions on Pattern Analysis and Machine 7n力eZgevice,神经网络领域的重要期刊如Neural Com­ putation > IEEE Transactions on Neural Networks and Learning Systems 等 也经常发表机器学习方面的论文.此外，统计学领域的重要期刊如Annals of Statistics等也常有关于统计学习方面的理论文章发表. 国内不少书籍包含机器学习方面的内容,例如[陆汝铃，1996].[李航,2012] 是以统计学习为主题的读物.国内机器学习领域最主要的活动是两年一次 的中国机器学习大会(CCML)以 及 每 年 举 行 的 “机器学习及其应用”研讨 会(M LA);很多学术刊物都经常刊登有关机器学习的论文. 习题 19 习题 1.1 表 1 .1 中若只包含编号为1 和 4 的两个样例，试给出相应的版本空间. 1.2 与使用单个合取式来进行假设表示相比，使 用 “析合范式”将使得假 析合范式即多个合取式 的析取. 设空间具有更强的表示能力.例如 好 瓜 什 （（色 泽 = *） A （根蒂= 蜷缩）A （敲声= *）） V （（色泽=乌黑）八（根蒂= *） A （敲声= 沉闷）｝ 提示：注意冗余情况， 如 （A = a） V （A = *） 与 （4 = *）等价. 会 把 “（色 泽 =青 绿 ）A （根蒂= 蜷缩）A （敲 声 =清 脆 ）”以 及 “（色 泽 =",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 271
    }
  },
  {
    "page_content": "设空间具有更强的表示能力.例如 好 瓜 什 （（色 泽 = *） A （根蒂= 蜷缩）A （敲声= *）） V （（色泽=乌黑）八（根蒂= *） A （敲声= 沉闷）｝ 提示：注意冗余情况， 如 （A = a） V （A = *） 与 （4 = *）等价. 会 把 “（色 泽 =青 绿 ）A （根蒂= 蜷缩）A （敲 声 =清 脆 ）”以 及 “（色 泽 = 乌黑）A （根蒂= 硬挺）A （敲声=沉 闷 ）”都 分 类 为 “好瓜”.若使用最 多 包 含 k 个合取式的析合范式来表达表1 .1 西瓜分类问题的假设空 间，试估算共有多少种可能的假决 即不存在训练错误为0 1.3 若数据包含噪声，则假设空间中有可能不存在与所有训练样本都一致 的假设. 的假设.在此情形下，试设计一种归纳偏好用于假设选择. 1.4 * 本 章 1.4节 在 论 述 “没有免费的午餐”定理时，默认使用了 “分类错 误率，，作为性能度量来对分类器进行评估.若换用其他性能度量2 ,则 式（1.1）将改为 % e （£ a |X ,/） = £ £ P Q ）4 （h Q ） J Q ））P （/ l |X ,£ a ）, h x e X - X 试 证 明 “没有免费的午餐定理”仍成立. 1.5 试述机器学习能在互联网搜索的哪些环节起什么作用. 20 第 1 章 绪 论 参考文献 陆汝铃.(1996).人 工 智 能 (下 册 ).科学出版社,北京. 周志华.(2007). “机器 学习与数据挖掘中国计算机学会通讯,3(12):35-44. 李航.(2012).统计学习方法.清华大学出版社,北京. Alpaydin, E. (2004). Introduction to Machine Learning. MIT Press, Cambridge, MA. Asmis, E. (1984). Epicurus Scientific Method. Cornell University Press, Ithaca, NY. Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer, New York, NY. Blumer, A., A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. (1996). uOc- cam's razor? Information Processing Letters, 24(6):377-380.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 272
    }
  },
  {
    "page_content": "New York, NY. Blumer, A., A. Ehrenfeucht, D. Haussler, and M. K. Warmuth. (1996). uOc- cam's razor? Information Processing Letters, 24(6):377-380. Carbonell, J. G., ed. (1990). Machine Learning: Paradigms and Methods. MIT Press, Cambridge, MA. Cohen, P. R. and E. A. Feigenbaum, eds. (1983). The Handbook of Artificial Intelligence^ volume 3. William Kaufmann, New York, NY. Dietterich, T. G. (1997), “Machine learning research: Four current directions.55 A I Magazine118(4):97-136. Domingos, P. (1999). “The role of Occam's razor in knowledge discovery.\" Data Mining and Knowledge Discovery^ 3(4):409-425. Duda, R. O., P. E. Hart, and D. G. Stork. (2001). Pattern Classification^ 2nd edition. John Wiley & Sons, New York, NY. Flach, P. (2012). Machine Learning: The Art and Science of Algorithms that Make Sense of Data. Cambridge University Press, Cambridge, UK. Hand, D., H. Mannila, and P. Smyth. (2001). Principles of Data Mining. MIT Press, Cambridge, MA. Hastie, T., R. Tibshirani, and J. Friedman. (2009). The Elements of Statistical",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 273
    }
  },
  {
    "page_content": "Hand, D., H. Mannila, and P. Smyth. (2001). Principles of Data Mining. MIT Press, Cambridge, MA. Hastie, T., R. Tibshirani, and J. Friedman. (2009). The Elements of Statistical Learning)2nd edition. Springer, New York, NY. Hunt, E. G. and D. I. Hovland. (1963). aProgramming a model of human con­ cept formation.,5 In Computers and Thought (E. Feigenbaum and J. Feldman, eds.), 310-325, McGraw Hill, New York, NY. 参考文献 21 Kanerva, P. (1988). Sparse Distributed Memory. MIT Press, Cambridge, MA. Michalski, R. S., J. G. Carbonell, and T. M. Mitchell, eds. (1983). Machine Learning: An Artificial Intelligence Approach. Tioga, Palo Alto, CA. Mitchell, T. (1997). Machine Learning. McGraw Hill, New York, NY. Mitchell, T. M. (1977). “Version spaces: A candidate elimination approach to rule le a rn in g .In Proceedings of the 5th International Joint Conference on Artificial Intelligence (IJCAI)1 305-310, Cambridge, MA. Mjolsness, E. and D. DeCoste. (2001). “Machine learning for science: State of the art and future prospects? Science^ 293(5537):2051-2055.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 274
    }
  },
  {
    "page_content": "Mjolsness, E. and D. DeCoste. (2001). “Machine learning for science: State of the art and future prospects? Science^ 293(5537):2051-2055. Pan, S. J. and Q. Yang. (2010). “A survey of transfer learning.” IEEE Trans­ actions on Knowledge and Data Engineering^ 22(10):1345-1359. Shalev-Shwartz, S. and S. Ben-David. (2014). Understanding Machine Learn­ ing. Cambridge University Press, Cambridge, UK. Simon, H. A. and G. Lea. (1974). “Problem solving and rule induction: A unified view.\" In Knowledge and Cognition (L. W. Gregg, ed.), 105-127, Erlbaum, New York, NY. Vapnik, V. N. (1998). Statistical Learning Theory. Wiley, New York, NY. Webb, G. I. (1996), “Further experimental evidence against the utility of Oc­ cam^ razor.,, Journal of Artificial Intelligence Research1 43:397-417. Winston, P. H. (1970). “Learning structural descriptions from examples.” Tech­ nical Report AI-TR-231, AI Lab, MIT, Cambridge, MA. Witten, I. H., E. Frank, and M. A. Hall. (2011). Data Mining: Practical Ma­ chine Leaving Tools and Techniques^ 3rd edition. Elsevier, Burlington, MA.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 275
    }
  },
  {
    "page_content": "Witten, I. H., E. Frank, and M. A. Hall. (2011). Data Mining: Practical Ma­ chine Leaving Tools and Techniques^ 3rd edition. Elsevier, Burlington, MA. Wolpert, D. H. (1996). “The lack of a priori distinctions between learning al­ gorithms.55 Neural Computation1 8(7):1341-1390. Wolpert, D. H. and W. G. Macready. (1995). \"No free lunch theorems for search.” Technical Report SFI-TR-05-010, Santa Fe Institute, Sante Fe, NM. Zhou, Z.-H. (2003). uThree perspectives of data minmg.^^ Artificial Intelligence1 143(1):139-146. 22 第 1 章 绪 论 休息一会儿 这个跳棋程序实质上使 用了强化学习技术，参见 第 16章. 小故事： “机器学习”名字的由来 1952 年，阿 瑟 . 萨 缪 尔 （Arthur Samuel, 1901—1990） 在 IB M 公司研制了 一个西洋跳棋程序，这个程序具有自 学习能力，可通过对大量棋局的分析逐渐辨识出当前局面 下 的 “好棋”和 “坏棋”，从而不断提高弈棋水平，并很 快就下赢了萨缪尔自己. 1956年，萨 缪 尔 应 约 翰 ・麦卡锡 （John McCarthy, “人工智能之父”，1971年图灵奖得主）之邀，在标志着人 工智能学科诞生的达特茅斯会议上介绍这项工作.萨缪尔发明了 “机器学习” 这个词，将 其 定 义 为 “不显式编程地赋予计算机能力的研究领域”.他 的 文 章 “Some studies in machine learning using the game of checkers” 1959 年在 IBM Journal正式发表后，爱 德 华 • 费 根 鲍 姆 （Edward Feigenbaum, “知识工 程 之 父 \" 1994年图灵奖得主）为编写其巨著Computers and Thought,在 1961 年邀请萨缪尔提供一个该程序最好的对弈实例.于是，萨缪尔借机向康涅狄格",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 276
    }
  },
  {
    "page_content": "程 之 父 \" 1994年图灵奖得主）为编写其巨著Computers and Thought,在 1961 年邀请萨缪尔提供一个该程序最好的对弈实例.于是，萨缪尔借机向康涅狄格 州的跳棋冠军、 当时全美排名第四的棋手发起了挑战，结果萨缪.尔程序获胜, 在当时引起轰动. 事实上，萨缪尔跳棋程序不仅在人工智能领域产生了重大影响，还影响到 整个计算机科学的发展.早期计算机科学研究认为，计算机不可能完成事先没 有显式编程好的任务，而萨缪尔跳棋程序否证了这个假设.另外，这个程序是最 早在计算机上执行非数值计算任务,的程序之一，其逻辑指令设计思想极大地影 响了 IB M 计算机的指令集,并很快被其他计算机的设计者采用. 第 2 章 模 型 评 估 与 选 择 精度常写为百分比形式 (1 一 言 )x 100%. 这 里 所 说 的 “误差”均 指误差期望. 在后面的章节中将介绍 不同的学习算法如何最小 化经验误差. 过 拟 合 亦 称 “过配”. 欠 拟 合 亦 称 “欠配”. 学 习 能 力 是 否 “过于强 大”，是由学习算法和数 据内涵共同决定的. 2 . 1 经验误差与过拟合 通 常 我 们 把 分 类 错 误 的 样 本 数 占 样 本 总 数 的 比 例 称 为 “错 误 率 ”(error r a te ) ,即如果在m 个样本中有a 个样本分类错误，则错误率E = a / m ; 相应的, 1 —a / m 称 为 “精度”(accuracy),即 “精度= 1—错误率”.更一般地,我们把 学 习 器 的 实 际 预 测 输 出 与 样 本 的 真 实 输 出 之 间 的 差 异 称 为 “误 差 ”(error), 学 习 器 在 训 练 集 上 的 误 差 称 为 “训 练 误 差 ”(training error)或 “经验误 差 ” (empirical e rro r),在 新 样 本 上 的 误 差 称 为 “泛 化 误 差 ”(generalization e rr o r ).显然，我们希望得到泛化误差小的学习器.然而，我们事先并不知道新 样本是什么样，实际能做的是努力使经验误差最小化.在很多情况下，我们可以 学得一个经验误差很小、在训练集上表现很好的学习器，例如甚至对所有训练 样本都分类正确，即分类错误率为零，分类精度为100%,但这是不是我们想要 的学习器呢？遗憾的是,这样的学习器在多数情况下都不好. 我们实际希望的，是在新样本上能表现得很好的学习器.为了达到这个 目的，应该从训练样本中尽可能学出适用于所有潜在样本的“普 遍 规 律 \" 这 样才能在遇到新样本时做出正确的判别.然而，当学习器把训练样本学得“太",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 277
    }
  },
  {
    "page_content": "样本都分类正确，即分类错误率为零，分类精度为100%,但这是不是我们想要 的学习器呢？遗憾的是,这样的学习器在多数情况下都不好. 我们实际希望的，是在新样本上能表现得很好的学习器.为了达到这个 目的，应该从训练样本中尽可能学出适用于所有潜在样本的“普 遍 规 律 \" 这 样才能在遇到新样本时做出正确的判别.然而，当学习器把训练样本学得“太 好 ” 了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都 会具有的一般性质，这样就会导致泛化性能下降.这种现象在机器学习中称为 “过拟合\" (overfitting).与 “过拟合”相 对 的 是 “欠拟合\" (imderRtting),这 是指对训练样本的一般性质尚未学好.图2 .1 给出了关于过拟合与欠拟合的一 个便于直观理解的类比. 有多种因素可能导致过拟合,其中最常见的情况是由于学习能力过于强大, 以至于把训练样本所包含的不太一般的特性都学到了，而欠拟合则通常是由 于学习能力低下而造成的.欠拟合比较容易克服，例如在决策树学习中扩展分 支 、在神经网络学习中增加训练轮数等，而过拟合则很麻烦.在后面的学习中 我们将看到，过拟合是机器学习面临的关键障碍，各类学习算法都必然带有一 些针对过拟合的措施;然而必须认识到，过拟合是无法彻底避免的，我们所能做 的 只 是 “缓解”，或者说减小其风险.关于这一点，可大致这样理解：机器学习 面临的问题通常是N P 难甚至更难，而有效的学习算法必然是在多项式时间内 24 第 2 章 模 型 评 估 与 选 择 新 样 采 过拟合模型 分 类 结 果 ： f 不是树叶 (误 以 为 树 叶 必 须 有 锯 齿 ) .欠拟合模型 分 类 结 果 ： 是树叶 (误 以 为 绿 色 的 都 是 树 叶 ) 图 2 .1 过 拟 合 、欠 拟 合 的直观类比 运行完成，若可彻底避免过拟合，则通过经验误差最小化就能获最优解，这就意 味着我们构造性地证明了 “P =N P” ；因此，只 要 相 信 “P * NP” ，过拟合就 不可避免. 在现实任务中，我们往往有多种学习算法可供选择，甚至对同一个学习算 法，当使用不同的参数配置时，也会产生不同的模型.那么，我们该选用哪一个 学习算法、使用哪一种参数配置呢？这就是机器学习中的“模型选择”(model selection)问题.理想的解决方案当然是对候选模型的泛化误差进行评估，然后 选择泛化误差最小的那个模型.然而如上面所讨论的，我们无法直接获得泛化 误差，而训练误差又由于过拟合现象的存在而不适合作为标准，那么，在现实中 如何进行模型评估与选择呢？ 2 . 2 评估方法",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 278
    }
  },
  {
    "page_content": "学习算法、使用哪一种参数配置呢？这就是机器学习中的“模型选择”(model selection)问题.理想的解决方案当然是对候选模型的泛化误差进行评估，然后 选择泛化误差最小的那个模型.然而如上面所讨论的，我们无法直接获得泛化 误差，而训练误差又由于过拟合现象的存在而不适合作为标准，那么，在现实中 如何进行模型评估与选择呢？ 2 . 2 评估方法 在现实任务中往往还会 考 虑 时 间 开 销 、存储开 销 、可解释性等方面的因 素，这里暂且只考虑泛化 误差. 通常，我们可通过实验测试来对学习器的泛化误差进行评估并进而做出选 择 .为 此 需 使 用 一 个 “测试集”(testing set)来测试学习器对新样本的判别能 力，然后以测试集上的“测试误差”(testing error)作为泛化误差的近似.通常 我们假设测试样本也是从样本真实分布中独立同分布采样而得.但需注意的 是，测试集应该尽可能与训练集互斥，即测试样本尽量不在训练集中出现、未 在训练过程中使用过. 测试样本为什么要尽可能不出现在训练集中呢？为理解这一点，不妨考虑 这样一个场景：老师出了 1 0 道习题供同学们练习，考试时老师又用同样的这10 道题作为试题，这个考试成绩能否有效反映出同学们学得好不好呢？答案是否 定的，可能有的同学只会做这1 0 道题却能得高分.回到我们的问题上来，我们 2 . 2 评估方法 25 希望得到泛化性能强的模型，好比是希望同学们对课程学得很好、获得了对所 学 知 识 “举一反三”的能力；训练样本相当于给同学们练习的习题，测试过程 则相当于考试.显然，若测试样本被用作训练了，则得到的将是过于“乐观”的 估计结果. 可是，我 们 只 有 一 个 包 含 m 个 样 例 的 数 据 集 0 = {(①1,阴),(也 欤 )，… , 既要训练,又要测试，怎样才能做到呢？答案是：通 过 对 。 进行适当 的处理,从中产生出训练集S 和测试集T . 下面介绍几种常见的做法. 2 .2 .1 留出法 “留出法”(hold-out)直接将数据集。 划分为两个互斥的集合，其中一个 集合作为训练集S , 另一个作为测试集T , 即 0 = S U T, S n T = 0 . 在 S 上训 练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计. 以二分类任务为例,假定D 包 含 1000个样本,将其划分为S 包 含 700个样 本,T 包 含 300个样本，用 S 进行训练后，如果模型在T 上 有 9 0 个样本分类错 误，那么其错误率为(90/300) x 100% = 3 0 % ,相应的，精 度 为 1 - 30% = 70%.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 279
    }
  },
  {
    "page_content": "练出模型后，用 T 来评估其测试误差，作为对泛化误差的估计. 以二分类任务为例,假定D 包 含 1000个样本,将其划分为S 包 含 700个样 本,T 包 含 300个样本，用 S 进行训练后，如果模型在T 上 有 9 0 个样本分类错 误，那么其错误率为(90/300) x 100% = 3 0 % ,相应的，精 度 为 1 - 30% = 70%. 需注意的是，训练/测试集的划分要尽可能保持数据分布的一致性，避免 因数据划分过程引入额外的偏差而对最终结果产生影响，例如在分类任务中 至 少 要 保 持 样 本 的 类 别 比 例 相 似 .如 果 从 采 样 (sampling)的角度来看待数据 集的划分过程，则保留类别比例的采样方式通常称为“分 层 采 样 \"(stratified sa m p lin g ).例 如 通 过 对D 进行分层采样而获得含 70% 样 本 的 训 练 集S 和含 30% 样本的测试集T,若D 包含5 0 0 个正例、5 0 0 个反例，则分层采样得到的 S 应 包 含 3 5 0 个正例、3 5 0 个反例，而 T 则 包 含 150个 正 例 和 150个反例；若 S 、T 中样本类别比例差别很大，则误差估计将由于训练/测试数据分布的差异 而产生偏差. 参见习题2.1. 种划分方式对初始数据集。 进行分割.例如在上面的例子中，可以 把 0 中的样 另一个需注意的问题是，即便在给定训练/测试集的样本比例后，仍存在多 本排序，然 后 把 前 3 5 0 个正例放到训练集中，也可以把最后3 5 0 个正例放到训 练集中，……这些不同的划分将导致不同的训练/测试集，相应的，模型评估的 结果也会有差别.因此，单次使用留出法得到的估计结果往往不够稳定可靠,在 使用留出法时，一般要采用若干次随机划分、重复进行实验评估后取平均值作 为留出法的评估结果.例如进行100次随机划分,每次产生一个训练/测试集用 于实验评估，100次后就得到100个结果，而留出法返回的则是这100个结果的 平均. 此外，我 们 希 望 评 估 的 是 用 。 训练出的模型的性能，但留出法需划分训 同时可得估计结果的标 准差. 26 第 2 章 模 型 评 估 与 选 择 可 从 “偏 差 -方 差 ” (参 见 2 . 6 节)的角度来理解: 测 试 集 小 时 ，评 估 结 果 的 方差较大；训 练 集小 时，评 估结果的偏差较大. 一 般 而 言 ，测 试 集 至 少 应 含 3 0 个 样 例 ［Mitchell, 1997］.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 280
    }
  },
  {
    "page_content": "同时可得估计结果的标 准差. 26 第 2 章 模 型 评 估 与 选 择 可 从 “偏 差 -方 差 ” (参 见 2 . 6 节)的角度来理解: 测 试 集 小 时 ，评 估 结 果 的 方差较大；训 练 集小 时，评 估结果的偏差较大. 一 般 而 言 ，测 试 集 至 少 应 含 3 0 个 样 例 ［Mitchell, 1997］. 练/测试集，这就会导致一个窘境：若令训练集S 包含绝大多数样本，则训练出 的模型可能更接近于用D 训练出的模型，但 由 于T 比较小，评估结果可能不够 稳定准确；若令测试集T 多包含一些样本，则 训 练 集 S 与 。 差别更大了，被评 估的模型与用D 训练出的模型相比可能有较大差别，从而降低了评估结果的保 真性(fid elity).这个问题没有完美的解决方案，常见做法是将大约2 / 3〜 4 / 5 的 样本用于训练，剩余样本用于测试. 2 . 2 . 2 交叉验证法 “交叉验证法”(cross validation)先 将 数 据 集 D 划 分 为 k 个大小相似的 U 。2 u … u Ok, R n . ♦ = 0 (分多j ) 每 个 子 集 Di都 尽可能保持数据分布的一致性，即 从 。 中 通 过 分 层 采 样 得 到 .然 后 ，每次用 互斥子集，即 。 = k - 1 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可获得k 组训练/测试集，从 而 可 进 行k 次训练和测试，最 终 返 回 的 是 这k 个测试结果 的均值.显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于k 的取值，为强调这一点，通常把交叉验证法称为“ k 折交叉验证”(k-fold cross validation), k 最常用的取值是 1 0 ,此 时 称 为 1 0 折交叉验证；其 他 常 用 的 k 值 有 5 、2 0 等 . 图 2 .2 给出了 1 0 折交叉验证的示意图. 亦 称 “ k 倍交叉验证”. V |。 2 |。3 |。4 |。5 |。6 |。7 |。8 |。9 回 。| 训车集 |。1 | 。2 | 。3 | 。4 巨5 | 。6 | 。7 | 。8同 洌 |试 * | 功 0 | — ＞测 试 结 果 ］ |。2 |。3 |。4 |。5 |。6 |。7 回 回 ］ S — ＞测 试 结 果 2 • • • ・ I 平 均 返回 一 结 果 回 |。3 回 |。5 |。6 |。7 回 回 问 ① — ＞测 试 结 果 10 图 2.2 1 0 折交叉验证示意图",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 281
    }
  },
  {
    "page_content": "洌 |试 * | 功 0 | — ＞测 试 结 果 ］ |。2 |。3 |。4 |。5 |。6 |。7 回 回 ］ S — ＞测 试 结 果 2 • • • ・ I 平 均 返回 一 结 果 回 |。3 回 |。5 |。6 |。7 回 回 问 ① — ＞测 试 结 果 10 图 2.2 1 0 折交叉验证示意图 与留出法相似，将 数 据 集 。 划 分 为 k 个子集同样存在多种划分方式.为 减小因样本划分不同而引入的差别，k 折交叉验证通常要随机使用不同的划分 重 复 p 次，最终的评估结果是这p 次 k 折交叉验证结果的均值，例如常见的有 “ 1 0 次 1 0 折交叉验证”. 假 定 数 据 集D 中包含m 个样本，若 令 k = 小 ，则得到了交叉验证法的一 个特例：留一法(Leave-One-Out,简 称 L O O ).显然，留一法不受随机样本划分 “1 0 次 1 0 折 交 叉 验 证 法 ” 与 \" 1 0 0 次 留 出 法”都是进行了 1 0 0 次训 练/测试. 2 . 2 评估方法 27 方式的影响，因为m 个样本只有唯一的方式划分为m 个子集—— 每个子集包含 一个样本；留一法使用的训练集与初始数据集相比只少了一个样本，这就使得 在绝大多数情况下，留一法中被实际评估的模型与期望评估的用D 训练出的模 型很相似.因此，留一法的评估结果往往被认为比较准确.然而，留一法也有其 缺陷：在数据集比较大时，训 练 M 个模型的计算开销可能是难以忍受的(例如数 据 集 包 含 1 百万个样本，则 需 训 练 1 百万个模型)，而这还是在未考虑算法调参 的情况下.另外，留一法的估计结果也未必永远比其他评估方法准确；“没有免 费的午餐”定理对实验评估方法同样适用. 2 .2 .3 自助法 我们希望评估的是用0 训练出的模型.但在留出法和交叉验证法中，由于 保留了一部分样本用于测试，因此实际评估的模型所使用的训练集比。 小，这 必然会引入一些因训练样本规模不同而导致的估计偏差.留一法受训练样本规 模变化的影响较小，但计算复杂度又太高了.有没有什么办法可以减少训练样 本规模不同造成的影响，同时还能比较高效地进行实验估计呢？ “自助法”(bootstrapping)是一个比较好的解决方案，它直接以自助采样 法(bootstrap sampling)为 基 础 [Efron and Tibshirani, 1993].给定包含 m 个样 本 的 数据集。 ，我 们 对 它 进 行 采 样 产 生 数 据 集 每 次 随 机 从 。 中挑选一个 样本,将其拷贝放入少 , 然后再将该样本放回初始数据集D 中,使得该样本在",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 282
    }
  },
  {
    "page_content": "法(bootstrap sampling)为 基 础 [Efron and Tibshirani, 1993].给定包含 m 个样 本 的 数据集。 ，我 们 对 它 进 行 采 样 产 生 数 据 集 每 次 随 机 从 。 中挑选一个 样本,将其拷贝放入少 , 然后再将该样本放回初始数据集D 中,使得该样本在 下次采样时仍有可能被采到；这个过程重复执行m 次后，我们就得到了包含m 个样本的数据集D , 这就是自助采样的结果.显然，0 中有一部分样本会在D f 中多次出现，而另一部分样本不出现.可以做一个简单的估计，样 本在馆次采 样中始终不被采到的概率是(1 - * ) 7 取极限得到 / lim 7nl8 \\ 1 —— 1 \\ m m J 1 - a 0.368 , 1 e (2.1) 参 见 习 题 2 2 NFL定 理 参 见 1 .4 节. 关于样 本 复 杂 度 与 泛 化 性 能 之 间 的 关 系 ，参见第 12章. Bootstrap本 意 是 “解靴 带” ；这 里 是 在 使 用 德 国 1 8 世 纪 文 学 作 品 《吹牛 大王历 险 记 》 中解靴带自 助 的 典 故 ，因此本书译为 “自助法” .自 助 采 样 亦 称 “可 重 复 采 样 ” 或 “有 放回采样”. e 是自然常数. 即通过自助采样，初始数据集。 中约 有 36.8% 的样本未出现在采样数据集D f “\\”表示集合减法. 中.于是我们可将。 用作训练集,0 \\ D 用作测试集;这样,实际评估的模型与 期望评估的模型都使用馆个训练样本,而我们仍有数据总量约1 / 3 的、没在训 练集中出现的样本用于测试.这样的测试结果，亦 称 “包外估计”(out-of-bag estimate). 自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法 能从初始数据集中产生多个不同的训练集,这对集成学习等方法有很大的好处. 集 成 学 习 参 见 第 8 章. 然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差.因 28 第 2 章 模型评估与选择 此,在初始数据量足够时，留出法和交叉验证法更常用一些. 2.2.4调参与最终模型 大多数学习算法都有些参数(parameter)需要设定，参数配置不同，学得模 型的性能往往有显著差别.因此,在进行模型评估与选择时，除了要对适用学习 算法进行选择，还需对算法参数进行设定，这 就 是 通 常 所 说 的 “参数调节”或 简 称 “调 参 \" (parameter tuning). 读者可能马上想到，调参和算法选择没什么本质区别：对每种参数配置都",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 283
    }
  },
  {
    "page_content": "大多数学习算法都有些参数(parameter)需要设定，参数配置不同，学得模 型的性能往往有显著差别.因此,在进行模型评估与选择时，除了要对适用学习 算法进行选择，还需对算法参数进行设定，这 就 是 通 常 所 说 的 “参数调节”或 简 称 “调 参 \" (parameter tuning). 读者可能马上想到，调参和算法选择没什么本质区别：对每种参数配置都 训练出模型，然后把对应最好模型的参数作为结果.这样的考虑基本是正确的, 但有一点需注意：学习算法的很多参数是在实数范围内取值，因此,对每种参数 配置都训练出模型来是不可行的.现实中常用的做法，是对每个参数选定一个 范围和变化步长,例如在［0,0.2］范 围 内 以 0.05为步长,则实际要评估的候选参 数 值 有 5 个，最终是从这5 个候选值中产生选定值.显然，这样选定的参数值往 往 不 是 “最 佳 ”值，但这是在计算开销和性能估计之间进行折中的结果，通过 这个折中，学习过程才变得可行.事实上，即便在进行这样的折中后，调参往往 仍很困难.可以简单估算一下：假定算法有3 个参数,每个参数仅考虑5 个候选 值,这样对每一组训练/测试集就有53 = 1 2 5 个模型需考察;很多强大的学习算 法有大量参数需设定，这将导致极大的调参工程量，以至于在不少应用任务中, 例 如 大 型 “深度学习” 模型甚至有上百亿个参数. 参数调得好不好往往对最终模型性能有关键性影响. 给 定 包 含 馆 个 样 本 的 数 据 集 。 ，在模型评估与选择过程中由于需要留出 一部分数据进行评估测试,事实上我们只使用了一部.分数据训练模型.因此,在 模型选择完成后，学习算法和参数配置已选定，此时应该用数据集。 重新训练 模型.这个模型在训练过程中使用了所有m 个样本，这才是我们最终提交给用 户的模型. 另外，需注意的是，我们通常把学得模型在实际使用中遇到的数据称为测 试数据，为了加以区分，模型评估与选择中用于评估测试的数据集常称为“验 证 集 \" (validation set).例如，在研究对比不同算法的泛化性能时，我们用测试 集上的判别效果来估计模型在实际使用时的泛化能力，而把训练数据另外划分 为训练集和验证集,基于验证集上的性能来进行模型选择和调参. 2 . 3 性 能 度 量 对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需 要有衡量模型泛化能力的评价标准，这就是性能度量(performance measure). 2 . 3 性能度量 29 性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往 往会导致不同的评判结果；这 意 味 着 模 型 的 “好 坏 ”是相对的，什么样的模型",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 284
    }
  },
  {
    "page_content": "2 . 3 性 能 度 量 对学习器的泛化性能进行评估，不仅需要有效可行的实验估计方法，还需 要有衡量模型泛化能力的评价标准，这就是性能度量(performance measure). 2 . 3 性能度量 29 性能度量反映了任务需求，在对比不同模型的能力时，使用不同的性能度量往 往会导致不同的评判结果；这 意 味 着 模 型 的 “好 坏 ”是相对的，什么样的模型 是好的，不仅取决于算法和数据，还决定于任务需求. 聚类的性能度量参见第 9 章. 在预测任务中，给定样例集。 = { 3 1 ,即)，3 2 用2), . . . ，3 加 %n)},其 中 Vi 是 示 例 X i 的真实标记.要评估学习器/ 的性能,就要把学习器预测结果/(⑼ 与真实标记g 进行比较. 回归任务最常用的性能度量是“均 方 误 差 \"(mean squared error) 1 m E (/ ；0 = 万 £ ( 〃 ◎ ) —纳)2 ・ ⑵2) i=l 更一般的，对于数据分布。和概率密度函数2(•)，均方误差可描述为 E 5 0 ) = / ( / Q ) - g)2 p(x)dx . (2.3) 本节下面主要介绍分类任务中常用的性能度量. 2 .3 .1 错误率与精度 本章开头提到了错误率和精度，这是分类任务中最常用的两种性能度量, 既适用于二分类任务，也适用于多分类任务.错误率是分类错误的样本数占样 本总数的比例,精度则是分类正确的样本数占样本总数的比例.对样例集。,分 类错误率定义为 l m . (2・4) 精度则定义为 1 m - i=l acc(f; D) = = (xi) = yi) (2.5) 更一般的，对于 数据分布V 和概率密度函数◎(•),错误率与精度可分别描 述为 石(/；。) = / I ( / ( « ) * y) p (x)d x , (2.6) 30 第 2 章 模型评估与选择 查 准 率 亦 称 “准确率” ， 查 全 率 亦 称 “召回率” . acc(/; P ) = / J 〜0 1 ( / (a?) = y)p(x)dx (2.7) 2 .3 .2 查准率、查全率与F l 错误率和精度虽常用，但并不能满足所有任务需求.以西瓜问题为例，假定 瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡 量了有多少比例的瓜被判别错误.但是若我们关心的是“挑出的西瓜中有多少 比例是好瓜”，或 者 “所有好瓜中有多少比例被挑了出来”，那么错误率显然 就不够用了，这时需要使用其他的性能度量.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 285
    }
  },
  {
    "page_content": "(2.7) 2 .3 .2 查准率、查全率与F l 错误率和精度虽常用，但并不能满足所有任务需求.以西瓜问题为例，假定 瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡 量了有多少比例的瓜被判别错误.但是若我们关心的是“挑出的西瓜中有多少 比例是好瓜”，或 者 “所有好瓜中有多少比例被挑了出来”，那么错误率显然 就不够用了，这时需要使用其他的性能度量. 类似的需求在信息检索、Web搜索等应用中经常出现，例如在信息检索 中，我 们 经 常 会 关 心 “检 索 出 的 信 息 中 有 多 少 比 例 是 用 户 感 兴 趣 的 ” “用 户 感 兴 趣 的 信 息 中 有 多少被检索出来了”. “查准 率 ”(precision)与 “查全 率 ”(recall)是更为适用于此类需求的性能度量. 对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划 分为真正例(true positive)> 假正例(false positive)> 真反例(true negative)> 假反例(false negative)四种情形，令 T P 、F P 、T N 、F N 分别表示其对应的 样例数，则 显 然 有 T P + F P + T N + F N = 样 例 总 数 .分 类 结 果 的 “混淆矩 阵 \" (confusion matrix)如表 2.1 所示. 表 2 . 1 分 类 结 果 混 淆 矩 阵 真 实 情 况 预 测 结 果 正例 反例 正例 反例 TP (真正例) F N (假反例) F P (假正例) T N (真反例) 查 准 率P 与查全率R 分别定义为 L 丁尸 T P + F P 1 T P = T P + F N . (2.8) ⑵9) 查准率和查全率是一对矛盾的度量.一般来说，查准率高时，查全率往往 偏低；而查全率高时，查准率往往偏低.例如，若希望将好瓜尽可能多地选出来, 则可通过增加选瓜的数量来实现，如果将所有西瓜都选上，那么所有的好瓜也 2 . 3 性能度量 31 必然都被选上了，但这样查准率就会较低；若希望选出的瓜中好瓜比例尽可能 高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较 低.通常只有在一些简单任务中，才可能使查全率和查准率都很高. 在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面 的 是 学 习 器 认 为 “最 可 能 ”是正例的样本，排 在 最 后 的 则 是 学 习 器 认 为 “最 不可能”是正例的样本.按此顺序逐个把样本作为正例进行预测，则每次可以",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 286
    }
  },
  {
    "page_content": "高，则可只挑选最有把握的瓜，但这样就难免会漏掉不少好瓜，使得查全率较 低.通常只有在一些简单任务中，才可能使查全率和查准率都很高. 在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面 的 是 学 习 器 认 为 “最 可 能 ”是正例的样本，排 在 最 后 的 则 是 学 习 器 认 为 “最 不可能”是正例的样本.按此顺序逐个把样本作为正例进行预测，则每次可以 计算出当前的查全率、查准率.以查准率为纵轴、查全率为横轴作图，就得到 了查准率-查全率曲线，简 称 “P -R 曲线〃，显示该曲线的图称为“P -R 图”.图 2 .3 给出了一个示意图. 以 信 息 检 索 应 用 为 例 , 逐条向用 户 反 馈 其 可 能 感 兴 趣 的 信 息 ，即可计算出 查 全 率 、查准率. 亦 称 “ P R 曲 线 ” 或 “ PR 图” . 为 绘 图 方 便 和 美 观 ，示 意图显示出单调平滑曲线; 但 现 实 任 务 中 的 P -R 曲线 常 是 非 单 调 、 不平滑的, 在很多局部有上下波动. P - R 图直观地显示出学习器在样本总体上的查全率、查准率.在进行比较 时，若一个学习器的P - R 曲线被另一个学习器的曲线完全“包住”，则可断言 后者的性能优于前者，例 如 图 2 .3 中学习器A 的性能优于学习器C ; 如果两个 学习器的P - R 曲线发生了交叉，例 如 图 2 .3 中 的 A 与 B , 则难以一般性地断言 两者孰优孰劣，只能在具体的查准率或查全率条件下进行比较.然而，在很多情 形下，人们往往仍希望把学习器A 与 B 比出个高低.这时一个比较合理的判据 是 比 较 P - R 曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全 率 上取得相对“双高”的比例.但这个值不太容易估算，因此，人们设计了一些 综合考虑查准率、查全率的性能度量. “平衡点”（Break-Event P o in t,简 称 B E P ）就是这样一个度量，它 是 “查 准率= 查全率，，时的取值，例 如 图 2 .3 中学习器C 的 B E P 是 0 .6 4 ,而 基 于 BEP 的比较，可认为学习器A 优 于 B . 32 第 2 章 模 型 评 估 与 选 择 但 B E P 还 是 过 于 简 化 了 些 ，更 常 用 的 是 F 1 度量: 2 x P x R _ 2 x T P P + R = 样 例 总 数 + T P — T N ' (2.10) 在 一 些 应 用 中 ，对 查 准 率 和 查 全 率 的 重 视 程 度 有 所 不 同 .例 如 在 商 品 推 荐",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 287
    }
  },
  {
    "page_content": "但 B E P 还 是 过 于 简 化 了 些 ，更 常 用 的 是 F 1 度量: 2 x P x R _ 2 x T P P + R = 样 例 总 数 + T P — T N ' (2.10) 在 一 些 应 用 中 ，对 查 准 率 和 查 全 率 的 重 视 程 度 有 所 不 同 .例 如 在 商 品 推 荐 率与查 系 统 中 ，为 了 尽 可 能 少 打 扰 用 户 ，更 希 望 推 荐 内 容 确 是 用 户 感 兴 趣 的 ，此 时 查 准 人£ 全军的调和平均（harmonic mean）定义的： 工 」 .化 +与 . 2 \\P R ） F1 则是加权调和平均： 率 更 重 要 ；而 在 逃 犯 信 息 检 索 系 统 中 ，更 希 望 尽 可 能 少 漏 掉 逃 犯 ，此 时 查 全 率 更 重 要 .F 1 度 量 的 一 般 形 式 —— 冲 , 能 让 我 们 表 达 出 对 查 准 率 /查 全 率 的 不 同 偏 好 ,它 定 义 为 = ( 1 + 俨 ) x P x R 3 = (尸 X 尸)+ R ， (2.11) 其 中 B > 0 度 量 了 查 全 率 对 查 准 率 的 相 对 重 要 性 [VanRijsbergen, 1979]. B = 1 与算术平均（挈 ）和几 时 退 化 为 标 准 的 F 1 ; ^ > 1 时 查 全 率 有 更 大 影 响 ；B < 1 时 查 准 率 有 更 大 影 响 . 何平均（ 和平均更重视较小值• 很 多 时 候 我 们 有 多 个 二 分 类 混 淆 矩 阵 ，例 如 进 行 多 次 训 练 /测 试 ，每 次 得 到 ）相比,调 一 个 混 淆 矩 阵 ；或 是 在 多 个 数 据 集 上 进 行 训 练 /测 试 ，希 望 估 计 算 法 的 “全 局 ” 性 能 ；甚 或 是 执 行 多 分 类 任 务 ，每 两 两 类 别 的 组 合 都 对 应 一 个 混 淆 矩 阵 ；•… ・ 总 之 , 我 们 希 望 在 n 个 二 分 类 混 淆 矩 阵 上 综 合 考 察 查 准 率 和 查 全 率 . 一 种 直 接 的 做 法 是 先 在 各 混 淆 矩 阵 上 分 别 计 算 出 查 准 率 和 查 全 率 , 记 为 （马 ， 再 计 算 平 均 值 ，这 样 就 得 到 “宏 查 准 率 ”（m acro-?）、 “宏 查 全 率 ”（macro-五）, 以 及 相 应 的 “宏 F l ” （m acro-Fl）: macro-P = — 舄 , ] n n 2―2=1 macro-7^ = —",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 288
    }
  },
  {
    "page_content": "记 为 （马 ， 再 计 算 平 均 值 ，这 样 就 得 到 “宏 查 准 率 ”（m acro-?）、 “宏 查 全 率 ”（macro-五）, 以 及 相 应 的 “宏 F l ” （m acro-Fl）: macro-P = — 舄 , ] n n 2―2=1 macro-7^ = — 71 ] n 广 Z=1 Ri , (2.12) (2.13) 2 x macro-P x macro-1? macro-P + macro-E m acro-Fl = ------------- ------ ------ - -- ,(2 .1 4 ) 还 可 先 将 各 混 淆 矩 阵 的 对 应 元 素 进 行 平 均 ，得 到 T P 、F P 、T N 、F N 的 平 均 值 ，分 别 记 为 力 、FP. TN. F N , 再 基 于 这 些 平 均 值 计 算 出 “微 查 准 率 ”（micro-尸）、 “微 查 全 率 ” （micro-R）和 “微 F l \" （m icro-Fl）: mi i T P + F P ⑵ 15) 2 . 3 性能度量 micro-JZ = T P T P ^ r F N m i c r o - F l = 2 x m i c r o - F x m i c r o - R m i c r o - P + micro- 33 (2.16) ⑵ 17) 2.3.3 R O C 与 A U C 很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与 一个分类阈值(threshold)进行比较，若大于阈值则分为正类，否 则 为反类.例 如，神经网络在一般情形下是对每个测试样本预测出一个[0.0,1.0]之间的实值, 神经网络参见第5 章. 然后将这个值与0 . 5 进行比较，大 于 0 . 5 则判为正例，否则为反例.这个实值或 概率预测结果的好坏,直接决定了学习器的泛化能力.实际上,根据这个实值或 概率预测结果，我们可将测试样本进行排序，“最可能”是正例的排在最前面, “最不可能”是正例的排在最后面.这样，分类过程就相当于在这个排序中以 某 个 “截断点”(cut point)将样本分为两部分，前一部分判作正例，后一部分则 判作反例. 在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若 我 们 更 重 视 “查准率”，则可选择排序中靠前的位置进行截断；若 更 重 视 “查 全率”，则可选择靠后的位置进行截断.因此，排序本身的质量好坏，体现了综 合考虑学习器在不同任务下的“期望泛化性能”的好坏，或者说，“一般情况",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 289
    }
  },
  {
    "page_content": "判作反例. 在不同的应用任务中，我们可根据任务需求来采用不同的截断点，例如若 我 们 更 重 视 “查准率”，则可选择排序中靠前的位置进行截断；若 更 重 视 “查 全率”，则可选择靠后的位置进行截断.因此，排序本身的质量好坏，体现了综 合考虑学习器在不同任务下的“期望泛化性能”的好坏，或者说，“一般情况 下 ”泛化性能的好坏.R O C 曲线则是从这个角度出发来研究学习器泛化性能 的有力工具. R O C 全 称 是 “受试者工作特征 ”(Receiver Operating Characteristic) ® 线，它 源 于 “二 战 ”中用于敌机检测的雷达信号分析技术，二十世纪六七十 年 代 开 始 被 用 于 一 些 心 理 学 、医学检测应用中，此后被引入机器学习领域 [Spackman, 1 9 8 9 ] . 与 2.3.2节 中 介 绍 的 P - R 曲线相似，我们根据学习器的预 测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算 出两个重要量的值，分别以它们为横、纵坐标作图，就得到了 “R O C 曲线”. 与 P - R 曲线使用查准率、查全率为纵、横轴不同，R O C 曲 线 的 纵 轴 是 “真正 例 率 ”(True Positive R a t e , 简称 T P R ) , 横 轴 是 “假 正 例 率 ”(False Positive R a t e , 简 称 F P R ) , 基 于 表 2 . 1 中的符号，两者分别定义为 T P R = F P R = T P T P + F N F P T N + F P (2.18) ⑵ 19) 34 第 2章模型评估与选择 显 示 R O C 曲线的 图称为“ R O C 图”. 图 2.4(a)给出了一个示意图，显然, 对 角 线 对 应 于 “随机猜测”模型，而 点 (0, 1 ) 则对应于将所有正例排在所有反 例 之 前 的 “理想模型”. 1 -° 8- 0 6 $ 4 0 0 4 S 8 0 0 6 4 0.2 0 0.2 0.4 0.6 假正例率 0.8 1.0 (a) R O C 曲 线与AUC 0.2 0.6 假正例率 (b)基于有限样例绘制的R O C 曲线 与 AUC 图 2.4 R O C 曲 线 与A U C 示意图 现实任务中通常是利用有限个测试样例来绘制R O C S , 此时仅能获得有",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 290
    }
  },
  {
    "page_content": "0 0 4 S 8 0 0 6 4 0.2 0 0.2 0.4 0.6 假正例率 0.8 1.0 (a) R O C 曲 线与AUC 0.2 0.6 假正例率 (b)基于有限样例绘制的R O C 曲线 与 AUC 图 2.4 R O C 曲 线 与A U C 示意图 现实任务中通常是利用有限个测试样例来绘制R O C S , 此时仅能获得有 限个(真正例率,假正例率)坐标对,无法产生图2.4(a)中的光滑R O C 曲线，只能 制 髓 7 窘 燃 方 篝 绘制出如图2.4(b)所示的近似R O C 曲线.绘图过程很简单：给 定 m + 个正例和 本书到这里,介绍近;以曲 m ~ 个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大, 黑 式 u言东?更于下 即把所有样例均预测为反例，此时真正例率和假正例率均为0 , 在 坐 标 (0 ,0 )处 标记一个点.然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例 ” . 划分为正例.设前一个标记点坐标为(叫切，当前若为真正例，则对应标记点的 坐标为(叫U + 熹 );当 前 若 为 假 正 例 ，则 对 应 标 记 点 的 坐 标 为 (力 +土 ,切 ，然 后用线段连接相邻点即得. 进行学习器的比较时，与 P - R 图相似，若 一个学习器的R O C 曲线被另一 个 学 习 器 的 曲 线 完 全 “包 住 \"则 可 断 言 后 者 的 性 能 优 于 前 者 ；若两个学习器 的 R O C 曲线发生交叉,则难以一般性地断言两者孰优孰劣.此时如果一定要进 行比较，则较为合理的判据是比较R O C 曲线下的面积，即 AUC (Area Under ROC C urve),如图 2.4 所示. 从 定 义 可 知 ，A U C 可 通 过 对 R O C 曲 线 下 各 部 分 的 面 积 求 和 而 得 .假 定 R O C 曲 线 是 由 坐 标 为 ｛(劣1,加),(/242), . . . , 伊皿沙恒)｝的点按序连接而形 成Q1 = 0, xm = 1 ) ,参 见 图 2.4(b),则 A U C 可估算为 2 . 3 性能度量 35 1 772- 1 AUC = - ( 0 +i — 3 ) ，( % + % + 1 ) . (2.20) 2=1 形式化地看,A U C 考虑的是样本预测的排序质量，因此它与排序误差有紧 密 联 系 .给 定 m + 个 正 例 和m - 个反例，令 D + 和 D - 分别表示正、反例集合, 则 排 序 “损失”(loss)定义为 5 = - ^ ― E E",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 291
    }
  },
  {
    "page_content": "( 0 +i — 3 ) ，( % + % + 1 ) . (2.20) 2=1 形式化地看,A U C 考虑的是样本预测的排序质量，因此它与排序误差有紧 密 联 系 .给 定 m + 个 正 例 和m - 个反例，令 D + 和 D - 分别表示正、反例集合, 则 排 序 “损失”(loss)定义为 5 = - ^ ― E E m m x+eD+x-eD- ' f i (/3+) < / 3 -)) + # ( / 2 = /① ) ) ) ， 2 7 (2.21) 即考虑每一对正、反例，若正例的预测值小于反例，则 记 一 个 “罚分”，若相 等，则 记 0 .5 个 “罚分”.容 易 看 出 ，£r a n k 对 应 的 是 R O C 曲线之上的面积：若 一个正例在R O C 曲线上对应标记点的坐标为( g g ) , 则①恰是排序在其之前的 反例所占的比例，即假正例率.因此有 AUC = l-4 a n fc . (2.22) 2 .3 .4 代价敏感错误率与代价曲线 在现实任务中常会遇到这样的情况：不同类型的错误所造成的后果不同. 例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者, 看起来都是犯了 “一次错误”，但后者的影响是增加了进一步检查的麻烦，前 者的后果却可能是丧失了拯救生命的最佳时机；再如，门禁系统错误地把可通 行人员拦在门外，将使得用户体验不佳,但错误地把陌生人放进门内，则会造成 严重的安全事故.为权衡不同类型错误所造成的不同损失，可 为 错 误 赋 予 “非 均等代价“(unequal cost). 以 二 分 类 任 务 为 例 ，我 们 可 根 据 任 务 的 领 域 知 识 设 定 一 个 “代价矩 阵 \" (cost matrix),如 表 2.2所示，其 中 costij表 示 将 第i类样本预测为第j 类 样本的代价.一般来说，c o s % = 0 ; 若 将 第 0 类 判 别 为 第 1 类所造成的损失更 大，则 costoi > cos^io；损失程度相差越大，COS力01与 cost1 0 值的差别越大. 表 2 . 2 二分类代价矩阵 真实类别 预测类别 第 0 类 第 1 类 第 0 类 0 costoi 第 1 类 co st io 0 一般情况下，重要的是 代价比值而非绝对值，例 以口 costQi : cost io = 5 : 1 与 50 : 1 0 所起效果相当. 36 第 2 章 模型评估与选择 回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 292
    }
  },
  {
    "page_content": "真实类别 预测类别 第 0 类 第 1 类 第 0 类 0 costoi 第 1 类 co st io 0 一般情况下，重要的是 代价比值而非绝对值，例 以口 costQi : cost io = 5 : 1 与 50 : 1 0 所起效果相当. 36 第 2 章 模型评估与选择 回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价, 例如式(2.4)所定义的错误率是直接计算“错误次数”，并没有考虑不同错误会 造成不同的后果.在非均等代价下，我们所希望的不再是简单地最小化错误次 数，而 是 希 望 最 小 化 “总体代价”(total c o s t) .若 将 表 2 .2 中 的 第 0 类作为正 类 、第 1 类作为反类，令 。+ 与 分 别 代 表 样 例 集 D 的正例子集和反例子 集，则 “代价敏感”(cost-sensitive)错误率为 E (于；D; cost) = — ( £ II ( / ( g ) * yi) x costQ1 TTb \\ \\XiED+ + E U(/ ( g ) * yi) x cos力 10 j . (2.23) 类似的，可给出基于分布定义的代价敏感错误率，以及其他一些性能度量 如精度的代价敏感版本.若令cos%•中的分、3・取值不限于。、1 , 则可定义出多 分类任务的代价敏感性能度量. 参 见 习 题 2 7 在非均等代价下，R O C 曲线不能直接反映出学习器的期望总体代价，而 “代价曲线”(cost curve)则可达到该目的.代价曲线图的横轴是取值为［0,1］ 的正例概率代价 \" 规 范 化 \" (normaliza­ tion) 是将不同变化范围的 值映射到相同的固定范围 中，常 见 的 是 ［0,1］,此时亦 称 “归一化”.参 见 习 题 2.8. P(-\\-)cost = p X cost01 p X costoi + (1 — P) X COS力 10 其 中 P 是样例为正例的概率；纵轴是取值为［0J ］的归一化代价 COStn o r m = _ FNR x p x costoi + FPR x (1 — p) x cost^Q p X costoi + (1 — p) X COStxQ \" ；- 73 \\ - (2.24) (2.25) 其 中 F P R 是式(2.19)定义的假正例率,FNR = 1 - T P R 是假反例率.代价曲线 的绘制很简单：R O C 曲线上每一点对应了代价平面上的一条线段，设 R O C 曲",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 293
    }
  },
  {
    "page_content": "p X costoi + (1 — p) X COStxQ \" ；- 73 \\ - (2.24) (2.25) 其 中 F P R 是式(2.19)定义的假正例率,FNR = 1 - T P R 是假反例率.代价曲线 的绘制很简单：R O C 曲线上每一点对应了代价平面上的一条线段，设 R O C 曲 线 上 点 的 坐 标 为 (T P R ,F P R ),则可相应计算出F N R ,然后在代价平面上绘制 一 条 从 (0 ,F P R )到 (1,F N R )的线段，线段下的面积即表示了该条件下的期望 总体代价；如 此 将 R O C 曲线上的每个点转化为代价平面上的一条线段，然后 取所有线段的下界，围成的面积即为在所有条件下学习器的期望总体代价，如 图 2.5所示. 2 . 4 比较检验 1.0 5 O. RPF F N R 代价曲线 期望总体代价 0 0.5 1.0 正例概率代价 图 2 . 5 代价曲线与期望总体代价 37 、 2 . 4 比 较 检 验 有 了 实 验 评 估 方法和性能度量，看起来就能对学习器的性能进行评估比较 了：先 使 用 某 种 实 验 评 估 方 法 测 得 学 习 器 的 某 个 性 能 度 量 结 果 ，然后对这些结 果 进 行 比 较 .但 怎 么 来 做 这 个 “比较”呢？是 直 接 取 得 性 能 度 量 的 值 然 后 “比 大 小 ”吗？实 际 上 ，机 器 学 习 中 性 能 比 较 这 件 事 要 比 大 家 想 象 的 复 杂 得 多 .这 里面涉及几个重要因素：首先，我们希望比较的是泛化性能，然而通过实验评估 方法我们获得的是测试集上的性能，两者的对比结果可能未必相同；第 二 ，测试 集上的性能与测试集本 身 的 选 择 有 很 大 关 系 ，且不论使用不同大小的测试集会 得 到不同的结果，即便用相同大小的测试集,若包含的测试样例不同，测试结果 也 会有不同；第 三 ，很多机器学习算法本身有一定的随机性，即便用相同的参数 设置在同一个测试集上多次 运 行 ,其 结 果 也 会 有 不 同 .那 么 ，有没有适当的方法 对学习器的性能进行比较呢？ 统 计 假 设 检 验 (hypothesis test)为 我 们 进 行 学 习 器 性 能 比 较 提 供 了 重 要 依 据 .基 于 假 设 检 验 结 果 我 们 可 推 断 出 ，若 在 测 试 集 上 观 察 到 学 习 器 A 比 B 好,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 294
    }
  },
  {
    "page_content": "设置在同一个测试集上多次 运 行 ,其 结 果 也 会 有 不 同 .那 么 ，有没有适当的方法 对学习器的性能进行比较呢？ 统 计 假 设 检 验 (hypothesis test)为 我 们 进 行 学 习 器 性 能 比 较 提 供 了 重 要 依 据 .基 于 假 设 检 验 结 果 我 们 可 推 断 出 ，若 在 测 试 集 上 观 察 到 学 习 器 A 比 B 好, 则 A 的 泛 化 性 能 是 否 在 统 计 意 义 上 优 于 B , 以及这个结论的把握有多大.下面 支 曲 胱 E 鬻 介 我 们 先 介 绍 两 种 最 基本的假设检验,然后介绍几种常用的机器学习性能比较方 可参见[Wellek, 2010]. 法 .为 便 于 讨 论 ,本 节 默 认 以 错 误 率 为 性 能 度 量 ,用 6 表示. 2 .4 .1 假设检验 假 设 检 验 中 的 “假 设 ”是对学习器泛化错误率分 布 的 某 种 判 断 或 猜 想 ，例 如％ = 向 ，，.现 实 任 务 中 我 们并不知道学习器的泛化错误率，只能获知其测试错 误 率 4 泛化错误率与测 试 错 误 率 未 必 相 同 ，但 直 观 上 ，二者接近的可能性应比 38 第 2 章 模型评估与选择 较大，相差很远的可能性比较小.因此，可根据测试错误率估推出泛化错误率的 分布. 泛化错误率为€的学习器在一个样本上犯错的概率是6；测试错误率€意味 着 在 m 个测试样本中恰有€ x m 个被误分类.假定测试样本是从样本总体分布 中独立采样而得，那么泛化错误率为6 的学习器将其中m f 个样本误分类、其 余样本全都分类正确的概率是6m ，(l - 由此可估算出其恰将£ X 馆个 样本误分类的概率如下式所示，这也表达了在包含m 个样本的测试集上，泛化 错误率 为 €的学习器被测得测试错误率为6 的概率： P Q ) = ( m \\6 x m (2.26) 给定测试错误率，则 解 H P © e)/de = 0 可知，P(€； c)在 e = 1 时最大，上—可增 大 时 P © 6)减小.这符合二项(binomial)分布，如 图 2.6所示，若 e = 0.3,则 10 个样本中测得3 个被误分类的概率最大. a 的 常 用 取 值 有 0.05. 0 . 1 , 图 2.6 中 a 较 大是为了绘图方便. 我 们 可 使 用 “二项检验”(binomial test)来对％ W 0.3”( 即 “泛化错误率是 否 不 大 于 0 . 3 \" )这样的假设进行 检 验 .更 一 般 的 ，考 虑 假 设 ％ ( 5 ”，则在",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 295
    }
  },
  {
    "page_content": "个样本中测得3 个被误分类的概率最大. a 的 常 用 取 值 有 0.05. 0 . 1 , 图 2.6 中 a 较 大是为了绘图方便. 我 们 可 使 用 “二项检验”(binomial test)来对％ W 0.3”( 即 “泛化错误率是 否 不 大 于 0 . 3 \" )这样的假设进行 检 验 .更 一 般 的 ，考 虑 假 设 ％ ( 5 ”，则在 1 - a 的概率内所能观测到的最大错误率如下式计算.这里1 - a 反映了结论的 “置信度”(confidence),直观地来看，相 应 于 图 2.6中非阴影部分的范围. s . t . 是 “subject to” 的 简写，使左边式子在右边 条件满足时成立. 6 = m a x c s.t. m \\ / m j G2(1 — €)M - Z < a . (2.27) z=eo x m + l ' / 2 . 4 比较检验 二项检验的临界值在 R 语言中可通过qbinom (1 — £())计 算 ，在 Matlab 中是 ic d f ( ‘ B in o m ia l/, 1 — a , m , eo). R 语 言 是 面 向 统 计 计 算的开源脚本语言，参见 w w w .r-project.org. 39 此时若测试错误率€小于临界值€,则根据二项检验可得出结论:在a 的显著度 下，假 设 7 W 6 ”不能被拒绝，即 能 以 1 - a 的置信度认为，学习器的泛化错误 率 不 大 于 eo；否则该假设可被拒绝，即 在 a 的显著度下可认为学习器的泛化错 误率大于 e0 . 在很多时候我们并非仅做一次留出法估计，而是通过多次重复留出法或是 交叉验证法等进行多次训练/测试，这样会得到多个测试错误率，此时可使用 ((t检 验 \" (力-test).假定我们得到了 k 个测试错误率，€1, 熬，则平均测试 错误率〃和方差。2为 1 k :£标 , 1=1 -1 k 考 虑 到 这 k 个测试错误率可看作泛化错误率e0 的独立采样，则变量 % ( 〃 - €0 ) a Tt = --------- 服从自由度为k — 1 的 1 分布，如 图 2.7所示. (2.28) (2.29) (2.30) 概 率 密 度 Tt 图 2 . 7 1 分布示意图(k = 10) 10 对假设“〃 = 5 ”和 显 著 度 以 我们可计算出当测试错误率均值为6 0 时，在 1 - a 概率内能观测到的最大错误率，即临界值.这里考虑双边(two-tailed)假",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 296
    }
  },
  {
    "page_content": "服从自由度为k — 1 的 1 分布，如 图 2.7所示. (2.28) (2.29) (2.30) 概 率 密 度 Tt 图 2 . 7 1 分布示意图(k = 10) 10 对假设“〃 = 5 ”和 显 著 度 以 我们可计算出当测试错误率均值为6 0 时，在 1 - a 概率内能观测到的最大错误率，即临界值.这里考虑双边(two-tailed)假 设，如 图 2 .7所示，两边阴 影 部 分 各 有 a / 2 的面积；假定阴影部分范围分别为 [-OO,t_a / 2 ] 和 加 /2,OO].若 平 均 错 误 率 〃 与 6 之差|从—引位于临界值范围 40 第 2 章 模型评估与选择 临 界 值 ta / 2 在 R 语言 中可通过q t ( l —a / 2 , k — 1 ) 计 算 ，雇 M a tla b 中是 i c d f ( , T, , l - a / 2 , / c - l ) . 内，则不能拒绝假设〃 = e0 [t,Q /2，M 1 - % 否则可拒绝该假设，即在该显著度下可认为泛化错误率与60 有显著不 同.a 常用取值有0 . 0 5和 0 . 1 . 表 2 . 3 给出了一些常用临界值. 5\\ 即可认为泛化错误率为6 , 置信度为 表 2.3 双 边 t检 验 的 常 用 临 界 值 a 2 5 k 10 20 30 0.05 0.10 12.706 6.314 2.776 2.132 2.262 1.833 2.093 1.729 2.045 1.699 上面介绍的两种方法都是对关于单个学习器泛化性能的假设进行检验，而 在现实任务中，更多时候我们需对不同学习器的性能进行比较，下面将介绍适 用于此类情况的假设检验方法. 2 .4 .2 交叉验证方检验 对两个学 习 器 A 和 B , 若 我 们 使 用 k 折交叉验证法得到的测试错误率分 别 为 京 吮 … , 靖 和 田 或 ，… ,或，其 中 靖 和 e?是在相同 的 第i折训练/测 试集上得到的结果，则 可 用k 折 交 叉 验 证 “成 对 t检 验 \" （p a i r e d 力-tests）来进行 比较检验.这里的基本思想是若两个学习器的性能相同，则它们使用相同的训 练/测试集得到的测试错误率应相同，即 镇 = ef. 具体来说，对 k 折 交 叉 验 证 产 生 的 k 对测试错误率：先对每对结果求差, △° = 蜡 _ 镇 ；若两个学习器性能相同，则差值均值应为零.因此，可根据差值 Z \" … Z 来对“学 习 器 A 与 B 性能相同”这个假设做t检验，计算出差值 的均值 M 和 方 差 在 显 著 度 。下，若变量",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 297
    }
  },
  {
    "page_content": "练/测试集得到的测试错误率应相同，即 镇 = ef. 具体来说，对 k 折 交 叉 验 证 产 生 的 k 对测试错误率：先对每对结果求差, △° = 蜡 _ 镇 ；若两个学习器性能相同，则差值均值应为零.因此，可根据差值 Z \" … Z 来对“学 习 器 A 与 B 性能相同”这个假设做t检验，计算出差值 的均值 M 和 方 差 在 显 著 度 。下，若变量 Vk/^ Tt = --- a (2.31) 小于临界值加/2, 则假设不能被拒绝，即认为两个学习器的性能没有显著差 别；否则可认为两个学习器的性能有显著差别，且平均错误率较小的那个学习 器性能较优.这里加 /2, \" 1 是 自 由 度 为 k - 1 的土分布上尾部累积分布为a / 2 的临界值. ’ 欲进行有效的假设检验，一个重要前提是测试错误率均为泛化错误率的独 立 采 样 .然 而 ，通常情况下由于样本有限，在使用交叉验证等实验估计方法时, 不同轮次的训练集会有一定程度的重叠，这就使得测试错误率实际上并不独立, 会导致过高估计假设成立的概率.为缓解这一问题,可采用“5 x 2 交叉验证” 2 . 4 比较检验 41 法 [Dietterich, 1998]. 5 x 2 交叉验证是做5 次 2 折交叉验证,在每次2 折交叉验证之前随机将数 据打乱，使 得 5 次交叉验证中的数据划分不重复.对两个学习器A 和 B , 第分次 2 折交叉验证将产生两对测试错误率,我们对它们分别求差，得 到 第 1 折上的差 值 和 第 2 折 上 的 差 值 为 缓 解 测 试 错 误 率 的 非 独 立 性 ，我们仅计算第1 次 2 折交叉验证的两个结果的平均值4 = O.5(A1 + △ 汽 但 对 每 次 2 折实验的 结果都计算出其方差靖= ( △ 卜 号 i p + ( 田 - 转 町 . 变 量 (2.32) 服从自由度为5 的 t分布，其双边检验的临界值加/2, 5 当 & = 0.05时 为 2.5706, a = 0.1 时为 2.0150. 2.4.3 McNemar■检验 对二分类问题，使用留出法不仅可估计出学习器A 和 B 的测试错误率，还 可获得两学习器分类结果的差别，即两者都正确、都错误、一个正确另一个错 误的样本数，如 “列联表”(contingency table) 2.4所示. 表 2 ・ 4 两学习器分类差别列联表 算 法 B 正确 错误 算 法 A 正确 错误 600 610 601 611 若 我 们 做 的 假 设 是 两 学 习 器 性 能 相 同 ，则 应 有 eoi = e i o , 那 么 变 量",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 298
    }
  },
  {
    "page_content": "误的样本数，如 “列联表”(contingency table) 2.4所示. 表 2 ・ 4 两学习器分类差别列联表 算 法 B 正确 错误 算 法 A 正确 错误 600 610 601 611 若 我 们 做 的 假 设 是 两 学 习 器 性 能 相 同 ，则 应 有 eoi = e i o , 那 么 变 量 |eOi - e io |应当服从正态分布，且 均 值 为1 , 方 差 为 eOi + e1 0. 因此变量 = ( M — — 1产 eoi + eio (2.33) 中 文 称 为 “卡方分布” . 临 界 值 x N 在 R 语 言 中 可 通 过 q c h i s q d — CK, k —1 )计 算 ，在 Matlab 中 是 ic d f ( , Ch.isquare, , 1 — a,k- 1 ) . 这里的 k = 2 是进行比较的算法个数. 服 从 自 由 度 为 1 的 x 2 分布，即标准正态分布变量的平方.给定显著度必当以 上 变 量 值小于临界值蟾时，不能拒绝假设，即认为两学习器的性能没有显著差 别；否则拒绝假设，即认为两者性能有显著差别，且平均错误率较小的那个学习 器 性 能 较 优 .自 由 度 为 1 的 % 2 检验的临界值当a = 0.05时 为 3.8415, a = 0.1 时为 2.7055. 42 第2 章 模型评估与选择 2.4.4 Friedman检 验 与 Nemenyi后续检验 交 叉 验 证 t检 验 和 M cNemar检验都是在一个数据集上比较两个算法的 性能，而在很多时候，我们会在一组数据集上对多不算法进行比较.当有多个 算法参与比较时，一种做法是在每个数据集上分别列出两两比较的结果，而在 两两比较时可使用前述方法；另一种方法更为直接，即使用基于算法排序的 Friedman 检验. 假 定 我 们 用 。1、0 2 、。3 和 。4 四 个 数 据 集 对 算 法A、B 、C 进行比较. 首先，使用留出法或交叉验证法得到每个算法在每个数据集上的测试结果，然 后在每个数据集上根据测试性能由好到坏排序,并赋予序值1, 2 , 若算法的 测试性能相同，则平分序值.例如，在 。1 和 。3 上，A 最好、B 其次、C 最差, 而 在 D 2 上,A 最好、B 与 C 性能相同，……, 则可列出表2 .5 ,其中最后一行通 过对每一列的序值求平均，得到平均序值. 表 2 . 5 算法比较序值表 数据集 算 法 A 算 法 B 算 法 C 1 1 1 1 1 2 2.5 2 2 2.125 3 2.5 3 3 2.875 平均序值",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 299
    }
  },
  {
    "page_content": "表 2 . 5 算法比较序值表 数据集 算 法 A 算 法 B 算 法 C 1 1 1 1 1 2 2.5 2 2 2.125 3 2.5 3 3 2.875 平均序值 然后，使 用 FYiedman检验来判断这些算法是否性能都相同.若相同，则它 们的平均序值应当相同.假定我们在N 个数据集上比较k 个 算 法 ,令 n 表示第 i个算法的平均序值，为简化讨论，暂不考虑平分序值的情况，则 ：服从正态分 布,其均值和方差分别为(k + 1 )/2 和 (d _ 1 )/1 2 .变量 12N k{k + 1) 净-处驾 (2.34) 在 k 和 N 都较大时,服从自由度为k - 1 的 f 分布. 然而，上 述 这 样 的 “原 始 FYiedman检验”过于保守，现在通常使用变量 (N —1)我 T F = N(k - 1) - r x 2 ， (2.35) 2 . 4 比较检验 43 F 检验的临界值在R 语 言中可通过q f ( l — a , k — l , ( k — l ) ( N —1 ) ) 计算，在 Matlab 中是 ic d fC F 7, 1 - 其 中 由 式 (2.34)得至！J.力 服 从 自 由 度 为 k — 1 和 (k — 1)(N — 1 ) 的 F 分布, 表 2.6给出了一些常用临界值. 表 2 . 6 尸检验的常用临界值 a = 0.05 数据集 个数N 2 3 4 5 6 7 8 9 10 算法个数k 4 5 8 10 15 20 10.128 7.709 5.591 5.117 4.600 4.381 5.143 4.459 3.739 3.555 3.340 3.245 3.863 3.490 3.072 2.960 2.827 2.766 3.259 3.007 2.714 2.634 2.537 2.492 2.901 2.711 2.485 2.422 2.346 2.310 2.661 2.508 2.324 2.272 2.209 2.179 2.488 2.359 2.203 2.159 2.104 2.079 2.355 2.244 2.109 2.070 2.022 2.000 2.250 2.153 2.032 1.998 1.955 1.935 a = 0.1 数据集 个数N 4 5 8 10 15 20 2 3 4 算法个数k 6 5 7 8 9 10 5.538 4.545 3.589 3.360 3.102 2.990 3.463 3.113 2.726 2.624 2.503 2.448",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 300
    }
  },
  {
    "page_content": "2.250 2.153 2.032 1.998 1.955 1.935 a = 0.1 数据集 个数N 4 5 8 10 15 20 2 3 4 算法个数k 6 5 7 8 9 10 5.538 4.545 3.589 3.360 3.102 2.990 3.463 3.113 2.726 2.624 2.503 2.448 2.813 2.606 2.365 2.299 2.219 2.182 2.480 2.333 2.157 2.108 2.048 2.020 2.273 2.158 2.019 1.980 1.931 1.909 2.130 2.035 1.919 1.886 1.845 1.826 2.023 1.943 1.843 1.814 1.779 1.762 1.940 1.870 1.782 1.757 1.726 1.711 1.874 1.811 1.733 1.710 1.682 1.668 若 “所有算法的性能相同”这个假设被拒绝，则说明算法的性能显著不 同 .这 时 需 进 行 “后 续 检 验 ”(post-hoc test)来进一步区分各算法.常用的有 N emenyi后续检验. N emenyi检验计算出平均序值差别的临界值域 。。 = 私 产 | 尹 ， (2.36) ，在 R 语目中可通 更受 界 值 过q t u k e y Q - a \" I n f ) / 了 临 界 值 域 则 以 相 应 的 置 信 度 拒 绝 “两个算法性能相同”这一假设. s q r t ( 2 ) 计算. 表 2.7给出了 a = 0.05和 0.1时常用的qa 值.若两个算法的平均序值之差超出 表 2.7 Nemenyi检验中常用的必；值 a 2 3 4 . 5 算法个数k 6 7 8 9 10 0.05 1.960 1.645 0.1 2.344 2.052 2.569 2.728 2.850 2.949 3.031 3.102 2.291 2.459 2.589 2.693 2.780 2.855 3.164 2.920 _____________________ ______________________________._________ ； 第2 章模型评估与选择 以 表 2 . 5 中的数据为例，先根据式(2.34)和 (2.35)计 算 出 rF = 24.429,由表 2 . 6可知，它 大 于 a = 0 . 0 5时 的 F 检 验 临 界 值 5.143,因 此 拒 绝 “所有算法性",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 301
    }
  },
  {
    "page_content": "以 表 2 . 5 中的数据为例，先根据式(2.34)和 (2.35)计 算 出 rF = 24.429,由表 2 . 6可知，它 大 于 a = 0 . 0 5时 的 F 检 验 临 界 值 5.143,因 此 拒 绝 “所有算法性 能 相 同 ”这 个 假 设 .然 后 使 用 N e m e n y i 后续检验，在 表 2 . 7 中 找 到 k = 3 时 Q0.05 = 2.344,根据式(2.36)计算出临界值域C D = 1.657,由 表 2 . 5 中的平均序 值可知，算 法 A 与 B 的差距，以及算法B 与 C 的差距均未超过临界值域，而算 法 A 与 C 的差距超过临界值域，因此检验结果认为算法A 与 C 的性能显著不 同，而 算 法 A 与 B 、以及算法B 与 C 的性能没有显著差别. 上述检验比较可以直观地用F Y i e d m a n 检 验 图 显 示 .例 如 根 据 表 2 . 5 的序 值结果可绘制出图2.8,图中纵轴显示各个算法，横轴是平均序值.对每个算法, 用一个圆点显示其平均序值，以圆点为中心的横线段表示临界值域的大小.然 后就可从图中观察，若两个算法的横线段有交叠，则说明这两个算法没有显著 差别，否则即说明有显著差别.从图2 . 8 中可容易地看出，算 法 A 与 B 没有显著 差别，因为它们的横线段有交叠区域，而 算 法 A 显 著 优 于 算 法 C , 因为它们的 横线段没有交叠区域. 算法A ，———,一: 临界值域 ： 算法B 平均爆值 1 ・ 算法C 1.0 2.0 图 2.8 Friedman检验图 . 3.0 2 . 5 偏差与方差 对学习算法除了通过实验估计其泛化性能，人们往往还希望了解它“为什 么 ”具 有 这 样 的 性 能 .\"偏 差 -方 差 分 解 \" (bias-variance decomposition)是解 释学习算法泛化性能的一种重要工具. 偏差一方差分解试图对学习算法的期望泛化错误率进行拆解.我们知道，算 法在不同训练集上学得的结果很可能不同，即便这些训练集是来自同一个分布. 有丁能出现噪声使得 对测试样本X：令 U D 为8 在数据集中的标记，y 为 x 的真实标记，/ ⑶ ; 为 训 练 集 。 上学得模型/在况上的预测输出.以回归任务为例，学习算法的期望预 2 . 5 偏差与方差 45 测为 使用样本数相同的不同训练集产生的方差为 , (2.37) var(x) = E p [(/ Q ; 。) 一 f Q ) 丹 ， (2.38) 噪声为 s2 = E n \\(yD -y)2] . (2.39)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 302
    }
  },
  {
    "page_content": "练 集 。 上学得模型/在况上的预测输出.以回归任务为例，学习算法的期望预 2 . 5 偏差与方差 45 测为 使用样本数相同的不同训练集产生的方差为 , (2.37) var(x) = E p [(/ Q ; 。) 一 f Q ) 丹 ， (2.38) 噪声为 s2 = E n \\(yD -y)2] . (2.39) 期望输出与真实标记的差别称为偏差(bias),即 bias2(x) = (/(x) — y)2 . (2.40) 为便于讨论,假定噪声期望为零，即 ^ D IVD - 对 = 0 . 通过简单的多项式展开合 并，可对算法的期望泛化误差进行分解： E(f;D)=E D [ ( ; ( ^ P ) - ^ ) 2 ] = 坳 3 0 ) - / ( « ) + / ⑺ —必 : = E n [(/ Q ; D ) - /(x)) 2 ] + E p [(/(x) - t o )2 ] 由式(2.3 7 ),最后项为0. + ED [2 (/ y ⑼ ) (f Q ) - yD )] = ED [(/ (况;D) — f Q ) ) 1 + E p 口(况)—g + g - t o ) 2 ] = E n [(/ Q ; D) - f 3 ) 月 + E p [(〃 ⑼ — - t o ) 2 ] 噪声期望为0, 因此最后项为0. + 2 E P -y)(y- VD)\\ = 珈 [(/ (®； D) — /(®)) 2 ] + (f Q ) -y)2 + ^yD - ?/)2] , (2.41) 于是， E(J; D) = bias1 (□?) + var (a?) + e2 , (2.42) 也就是说,泛化误差可分解为偏差、方差与噪声之和. 回顾偏差、方 差 、噪声的含义：偏差(2.40)度量了学习算法的期望预测与 46 第 2 章 模型评估与选择 真实结果的偏离程度，即刻画了学习算法本身的拟合能力；方差(2.38)度量了同 样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的 影响；噪声(2.39)则表达了在当前任务上任何学习算法所能达到的期望泛化误 差的下界，即刻画了学习问题本身的难度.偏差-方差分解说明，泛化性能是由 学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的.给定 学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并 且使方差较小，即使得数据扰动产生的影响小.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 303
    }
  },
  {
    "page_content": "影响；噪声(2.39)则表达了在当前任务上任何学习算法所能达到的期望泛化误 差的下界，即刻画了学习问题本身的难度.偏差-方差分解说明，泛化性能是由 学习算法的能力、数据的充分性以及学习任务本身的难度所共同决定的.给定 学习任务，为了取得好的泛化性能，则需使偏差较小，即能够充分拟合数据，并 且使方差较小，即使得数据扰动产生的影响小. 一般来说，偏差与方差是有冲突的，这称为偏差-方差窘境(bias-variance dilem m a).图 2.9 给出了一个示意图.给定学习任务,假定我们能控制学习算法 的训练程度，则在训练不足时，学习器的拟合能力不够强，训练数据的扰动不足 以使学习器产生显著变化，此时偏差主导了泛化错误率；随着训练程度的加深， 学习器的拟合能力逐渐增强，训练数据发生的扰动渐渐能被学习器学到，方 差 • 逐渐主导了泛化错误率；在训练程度充足后，学习器的拟合能力已非常强，训练 数据发生的轻微扰动都会导致学习器发生显著变化，若训练数据自身的、非全 局的特性被学习器学到了，则将发生过拟合. 很 多 学 习 算 法 都 可 控 制 训 练 程 度 ，例 如 决 策 树 可 控 制 层 数 ，神 经 网 络 可 控 制 训 练 轮 数 ，集 成 学 习 方 法可控制基学习器个数. 训练程度 图 2 .9 泛 化 误 差 与 偏 差 、方差的关系示意图 2 . 6 阅读材料 自助采样法在机器学习中有重要用途，［Efron and Tibshirani, 1993］对此 进行了详细的讨论. R O C 曲 线 在 二 十 世 纪 八 十 年 代 后 期 被 引 入 机 器 学 习 ［Spackman, 1989］, A U C 则是从九十年代中期起在机器学习领域广为使用［Bradley, 1997］, 但利用 2 . 6 阅读材料 47 2.3.4节仅讨论了基于类 别的误分类代价. R O C 曲线下面积来评价模型期望性能的做法在医疗检测中早已有之[Hanley and McNeil, 1983]. [Hand and Till, 2001]将 ROC 曲线从二分类任务推广到多 分类任务. [Fawcett, 2006]综述了 R O C 曲线的用途. [Drummond and Holte, 2006]发明了代价曲线.需说明的是，机器学习过 程涉及许多类型的代价，除了误分类代价，还有测试代价、标记代价、属性代 价等，即便仅考虑误分类代价，仍可进一步划分为基于类别的误分类代价以及 基于样本的误分类代价.代价敏感学习(cost-sensitive learning) [Elkan, 2001; Zhou and Liu, 2006]专门研究非均等代价下的学习.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 304
    }
  },
  {
    "page_content": "价等，即便仅考虑误分类代价，仍可进一步划分为基于类别的误分类代价以及 基于样本的误分类代价.代价敏感学习(cost-sensitive learning) [Elkan, 2001; Zhou and Liu, 2006]专门研究非均等代价下的学习. [Dietterich, 1998]指出了常规k 折交叉验证法存在的风险，并提出了 5 x 2 交叉验证法. [Demsar, 2006]讨论了对多个算法进行比较检验的方法. [Geman et al., 1992]针对回归任务给出了偏差-方差-协方差分解(bias- variance-covariance decomposition),后来被简称为偏差-方差分解.虽然偏差 和方差确实反映了各类学习任务内在的误差决定因素，但式(2.42)这样优美的 形式仅在基于均方误差的回归任务中得以推导出.对分类任务，由于0 / 1 损失 函数的跳变性，理论上推导出偏差-方差分解很困难.已有多种方法可通过实 验对偏差和方差进行估计[Kong and Dietterich, 1995; Kohavi and Wolpert, 1996; Breiman, 1996; Friedman, 1997; Domingos, 2000]. 48 第 2 章 模型评估与选择 习题 2.1 数据 集 包 含 1000个样本，其 中 5 0 0 个正例、5 0 0 个反例，将其划分为 包 含 70% 样 本的训练集和30% 样本的测试集用于留出法评估，试估 算共有多少种划分方式. 2.2 数 据 集 包 含 100个样本，其中正、反例各一半，假定学习算法所产生 的模型是将新样本预测为训练样本数较多的类别(训练样本数相同时 进行随机猜测)，试 给 出 用 10折交叉验证法和留一法分别对错误率进 行评估所得的结果. 2.3 若学习器A 的 F 1 值比学习器B 高，试 析 A 的 B E P 值是否也比B 高. 2.4 试述真正例率(T P R )、假正例率(F P R )与查准率(P )、查全率(R)之间 的联系. 2.5 试证明式(2.22). 2.6 试述错误率与R O C 曲线的联系. 2.7 试证明任意一条R O C 曲线都有一条代价曲线与之对应，反之亦然. 2.8 M in-m ax规 范 化 和 z-score规范化是两种常用的规范化方法.令力和 x 1 分别表示变量在规范化前后的取值，相应的，令 3 n 讪 和 z 俏物表示 m a x 表示规范化后的最小值和 规范化前的最小值和最大值,味而和 x f 最大值,Z 和 /分 别 表 示 规 范 化 前 的 均 值 和 标 准 差 ，则 m in-m ax规范",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 305
    }
  },
  {
    "page_content": "2.8 M in-m ax规 范 化 和 z-score规范化是两种常用的规范化方法.令力和 x 1 分别表示变量在规范化前后的取值，相应的，令 3 n 讪 和 z 俏物表示 m a x 表示规范化后的最小值和 规范化前的最小值和最大值,味而和 x f 最大值,Z 和 /分 别 表 示 规 范 化 前 的 均 值 和 标 准 差 ，则 m in-m ax规范 化、z-score规范化分别如式⑵43)和 (2.44)所示.试析二者的优缺点. x ，= x ，m in + , X — X X — — :—— . Ox ^ m a x - ^ m in X ( x f m a x - x f m i n ) , (2.43) 小一、 (2.44) 2.9 试 述 f 检验过程. 2.10 * 试 述 在 F riedm an检验中使用式(2.34)与(2.35)的区别. 参考文献 49 参考文献 Bradley, A. P. (1997). “The use of the area under the ROC curve in the evalua­ tion of machine learning algorithms.\" Pattern Recognition^ 30(7):1145-1159. Breiman, L. (1996). “Bias, variance, and arcing classifiers.\" Technical Report 460, Statistics Department, University of California, Berkeley, CA. Demsar, J. (2006). ^Statistical comparison of classifiers over multiple data sets.\" Journal of Machine Learning Research1 7:1-30. Dietterich, T. G. (1998). Approximate statistical tests for comparing super­ vised classification learning algorithms.^^ Neural Computation1 10(7):1895- 1923. Domingos, P. (2000). “A unified bias-variance decomposition.55 In Proceedings",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 306
    }
  },
  {
    "page_content": "vised classification learning algorithms.^^ Neural Computation1 10(7):1895- 1923. Domingos, P. (2000). “A unified bias-variance decomposition.55 In Proceedings of the 17th International Conference on Machine Learning (ICML), 231-238, Stanford, CA. Drummond, C. and R. C. Holte. (2006). “Cost curves: An improved method for visualizing classifier performance.^^ Machine Learning165(1):95-130. Efron, B. and R. Tibshirani. (1993). An Introduction to the Bootstrap. Chap­ man & Hall, New York, NY. Elkan, C. (2001). “The foundations of cost-senstive learn in g .In Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI), 973-978, Seattle, WA. Fawcett, T. (2006). \"An introduction to ROC a n a ly s is .Pattern Recognition Letters, 27(8):861-874. Friedman, J. H. (1997). “On bias, variance, 0/1-loss, and the curse-of- dimensionality/ Data Mining and Knowledge Discovery, 1(1):55-77. Geman, S., E. Bienenstock, and R. Doursat. (1992). “Neural networks and the bias/variance dilemma.5, Neural Computation^ 4(l):l-58.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 307
    }
  },
  {
    "page_content": "Geman, S., E. Bienenstock, and R. Doursat. (1992). “Neural networks and the bias/variance dilemma.5, Neural Computation^ 4(l):l-58. Hand, D. J. and R. J. Till. (2001). “A simple generalisation of the area under the ROC curve for multiple class classification problems? Machine Learning1 45(2):171-186. Hanley, J. A. and B. J. McNeil. (1983). “A method of comparing the areas under receiver operating characteristic curves derived from the same cases.5, Radiology, 148(3):839-843. 50 第 2 章 模 型 评 估 与 选 择 Kohavi, R. and D. H. Wolpert. (1996). “Bias plus variance decomposition for zero-one loss functions.5, In Proceeding of the 13th International Conference on Machine Learning (ICML), 275-283, Bari, Italy. Kong, E. B. and T. G. Dietterich. (1995). “Error-correcting output coding cor­ rects bias and variance.55 In Proceedings of the 12th International Conference on Machine Learning (ICML), 313-321, Tahoe City, CA. Mitchell, T. (1997). Machine Learning. McGraw Hill, New York, NY. Spackman, K. A. (1989). “Signal detection theory: Valuable tools for evaluating",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 308
    }
  },
  {
    "page_content": "Mitchell, T. (1997). Machine Learning. McGraw Hill, New York, NY. Spackman, K. A. (1989). “Signal detection theory: Valuable tools for evaluating inductive learnmg.^^ In Proceedings of the 6th International Workshop on Machine Learning (IWML)1 160-163, Ithaca, NY. Van Rijsbergen, C. J. (1979). Information Retrieval1 2nd edition. Butterworths, London, UK. Wellek, S. (2010). Testing Statistical Hypotheses of Equivalence and Noninfe- riority1 2nd edition. Chapman & Hall/CRC, Boca Raton, FL. Zhou, Z.-H. and X.-Y. Liu. (2006), “On multi-class cost-sensitive learning.^^ In Proceeding of the 21st National Conference on Artificial Intelligence (AAAI), 567-572, Boston, WA. 休息一会儿 51 休 息 一 会 儿 1954 年 该 厂 开 始 出 版 《吉尼斯世界纪录大全》. 小故事：土检验、啤酒、 “学生”与 威 廉•戈瑟特 1899年，由于爱尔兰都柏林的吉尼斯啤酒厂热衷于聘 用剑桥、牛津的优秀毕业生，学化学的牛津毕业生威廉•戈 瑟 特 (William Gosset, 1876— 1937)到该厂就职，希望将他 的生物化学知识用于啤酒生产过程.为降低啤酒质量监控 的成本，戈瑟特发明了力检验法，1908年 在 Biometrika 表.为防止泄漏商业机密，戈瑟特发表文章时用了笔名“学生”，于是该方法被 称 为 “学生氏力检验\"(S tu d e n t's力-test). 吉 尼 斯 啤 酒 厂 是 一 家 很 有 远 见 的 企 业 ，为 保 持 技 术 人 员 的 高 水 准 ，该 厂 像 高 校 一 样 给 予 技 术 人 员 “学术假”，1906— 1907年 戈 瑟 特 得 以 到 “统",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 309
    }
  },
  {
    "page_content": "表.为防止泄漏商业机密，戈瑟特发表文章时用了笔名“学生”，于是该方法被 称 为 “学生氏力检验\"(S tu d e n t's力-test). 吉 尼 斯 啤 酒 厂 是 一 家 很 有 远 见 的 企 业 ，为 保 持 技 术 人 员 的 高 水 准 ，该 厂 像 高 校 一 样 给 予 技 术 人 员 “学术假”，1906— 1907年 戈 瑟 特 得 以 到 “统 计 学 之 父 ” 卡 尔 • 皮 尔 逊 (Karl Pearson, 1857— 1936)教授在伦敦大学学院 (University College L o n d o n ,简 称 U C L )的实验室访 问 学 习 .因 此 ，很 难 说 t 检 验 法 是 戈 瑟 特 在 啤 酒 厂 还 是 在 U C L 访 学 期 间 提 出 的 ，但 “学 生 ” 与戈 瑟 特 之 间 的 联 系 是 被 U C L 的统计学家们发现的，尤其因为皮尔逊教授恰是 Biometrika 的主编. 第 3 章 线 性 模 型 3 . 1 基本形式 给 定 由 d 个 属 性 描 述 的 示 例 x = （力1 ；g ；.•.；3 ）, 其 中 3 是 a 在 第 i个属 性 上 的 取 值 ,线 性 模 型 （linear m o d e l ）试 图 学 得 一 个 通 过 属 性 的 线 性 组 合 来 进 行 预 测 的 函 数 ，即 f（x） = W1X1 + W2X2 + • • • + WdXd + b , （3.1） 一 般 用 向 量 形 式 写 成 / （a?） = w T x + b , （3.2） 其 中 3 = （叫;仅2 ；… ；g ）. 叨 和 b 学 得 之 后 ，模型就得以确定. 线 性 模 型 形 式 简 单 、 易 于 建 模 ,但 却 蕴 涵 着 机 器 学 习 中 一 些 重 要 的 基 本 思 想 .许 多 功 能 更 为 强 大 的 非 线 性 模 型 （nonlinear m o d 叫 可 在 线 性 模 型 的 基 础 上 通 过 引 入 层 级 结 构 或 高 维 映 射 而 得 .此 外 ，由 于 付 直 观 表 达 了 各 属 性 在 预 测 中 亦 称 “可理解性” derstandability). 的 重 要 性 ，因 此 线 性 模 型 有 很 好 的 可 解 释 性 （comprehensibility）. 例 如 若 在 西 瓜 问 题 中 学 得 “/ 好 瓜 ⑺ - 0.2 • n 色泽+ 0.5 •/根蒂+ 0.3 •力敲声+ 1 ” ，则 意 味 着 可",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 310
    }
  },
  {
    "page_content": "亦 称 “可理解性” derstandability). 的 重 要 性 ，因 此 线 性 模 型 有 很 好 的 可 解 释 性 （comprehensibility）. 例 如 若 在 西 瓜 问 题 中 学 得 “/ 好 瓜 ⑺ - 0.2 • n 色泽+ 0.5 •/根蒂+ 0.3 •力敲声+ 1 ” ，则 意 味 着 可 通 过 综 合 考 虑 色 泽 、 根 蒂 和 敲 声 来 判 断 瓜 好 不 好 ，其 中 根 蒂 最 要 紧 ，而 敲 声 比 色泽更重要. 本 章 介 绍 几 种 经 典 的 线 性 模 型 .我 们 先 从 回 归 任 务 开 始 ，然 后 讨 论 二 分 类 和多分类任务. 3 . 2 线性回归 给 定 数 据 集 。 = ｛（% 阴 ），（％ 续 ）,...，（防 , 斌 ｝, 其 中 g = 出 1； & 2 ；...；立德），Vi e 国 \" 线 性 回 归 \" （linear regression）试 图 学 得 一 个 线 性 模 型 以 尽 可 能 准 确 地 预 测 实 值 输 出 标 记 . 我 们 先 考 虑 一 种 最 简 单 的 情 形 ：输 入 属 性 的 数 目 只 有 一 个 .为 便 于 讨 论 ,此 时 我 们 忽 略 关 于 属 性 的 下 标 ，即 。 = ｛（伤，依） 其 中 g e 国 对 离 散 属 性 , 若 属 性 值 间 存 在 “序 ”（order）关 系 ，可 通 过 连 续 化 将 其 转 化 为 连 续 值 ，例 如 二 54 第3 章线性模型 若将无序属性连续化, 则会不恰当地引入序关系, 对后续处理如距离计算等 造成误导，参 见 9 . 3 节. 值 属 性 “身 高 ”的 取 值 “高 ” “矮 ”可 转 化 为 ｛1.0,0.0),三 值 属 性 “高 度 ” 的 取 值 “高 ” “中” “低 ”可 转 化 为 ｛1.0,0.5,0.0｝; 若属性值间不存在序关 系，假 定 有 k 个属性值，则通常转化为k 维 向 量 ,例 如 属 性 “瓜类”的 取 值 “西 瓜 ” “南瓜” “黄瓜”可 转 化 为 (0,0,1), (0,1,0),(1,0,0). 线性回归试图学得 / ( g ) = wxi + ” 使得 / ( g ) + yi . (3.3) 如 何 确 定 仪 和 b 呢？显然，关键在于如何衡量于⑸与 y 之间的差别.2 . 3节 介 绍 过 ,均 方 误 差 (2.2)是回归任务中最常用的性能度量，因此我们可试图让均 方误差最小化，即 m (w*, b*) = arg m i n (叫 b) M m ( ^ ) - 仇产",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 311
    }
  },
  {
    "page_content": "(3.3) 如 何 确 定 仪 和 b 呢？显然，关键在于如何衡量于⑸与 y 之间的差别.2 . 3节 介 绍 过 ,均 方 误 差 (2.2)是回归任务中最常用的性能度量，因此我们可试图让均 方误差最小化，即 m (w*, b*) = arg m i n (叫 b) M m ( ^ ) - 仇产 = a r g m i n ，2 (统 —wxi — b)2 . (3.4) (皿匕)i=l 均方误差有非常好的几何意义，它对应了常用的欧几里得距离或简称“欧 氏 距 离 \" (Euclidean distance).基于均方误差最小化来进行模型求解的方法称 为 “最小二乘法”(least square m e t h o d ) . 在线性回归中，最小二乘法就是试图 找到一条直线，使所有样本到直线上的欧氏距离之和最小. 求 解 位 和 b 使 “ ) = I Z i (纳—际 一 匕产最小化的过程，称为线性回归 模 型 的 最 小 二 乘 “参 数 估 计 \" (parameter e s t i m a t i o n ) . 我们可将々纳匕)分别 对 仪 和 b 求导，得到 吗署= 2卜 玄 嵋 小 , \\ i=l z=l (w b) 8 E g b / , A = 2 \\ mb - 与 ( 纳 - w x i)\\ / S / , 然后令式(3.5)和(3.6)为零可得到 w 和 b 最优解的闭式(closed-form)解 m E %(电一可 (3.5) /o A、 (3.6) (3.7) 均方误差亦称平方损失 (square loss). w * , fe*表 示 似 和 b 的解. 最小二乘法用途很广, 不仅限于线性回归. 这 里E(w ,b)是关于仪和 b 的凸函数，当它关于“和 b 的导数均为零时，得 到 w 和 b的最优解. 对 区 间 ［a,b\\上 定 义 的 函 数 f 若 它 对 区 间 中 任 意 两 点 Xi,X2均有 了(① 1+22 ) “ o Q + A c z ) 则 称 :为 区 间 ［a ,b ］! h 的凸' . 函数. I I 形 曲 线 的 函 数 如 f3)= x2,通常是凸函数. 对实数集上的函数，可 通过求二阶导数来判别: 若二阶导数在区间上非负, 则称为凸函数；若二阶导 数在区间上恒大于0 , 则称 为严格凸函数. 3 . 2 线性回归 [ flu 」 一 £ ( 比 - 仪 陶 ， m 2=1 55 (3.8) 其中土 = * £ ◎为力的均值• m i=l 更一般的情形是如本节开头的数据集。，样 本 由 d 个属性描述.此时我们",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 312
    }
  },
  {
    "page_content": "对实数集上的函数，可 通过求二阶导数来判别: 若二阶导数在区间上非负, 则称为凸函数；若二阶导 数在区间上恒大于0 , 则称 为严格凸函数. 3 . 2 线性回归 [ flu 」 一 £ ( 比 - 仪 陶 ， m 2=1 55 (3.8) 其中土 = * £ ◎为力的均值• m i=l 更一般的情形是如本节开头的数据集。，样 本 由 d 个属性描述.此时我们 试图学得 / ( g ) = w T Xi + A 使得 f{xi) 手称\"多变量线性回 这 称 为 “多元线性回归“(multivariate linear regression). 类似的，可利用最小二乘法来对 w 和 b 进行估计.为便于讨论，我 们 把 w 和 b 吸收入向量形式w = ( w ; 6),相应的，把数据集D 表示为一个m x ( d + 1 ) 大小的矩阵 X , 其中每行对应于一个示例，该 行 前 d 个元素对应于示例的d 个 属性值,最后一个元素恒置为1 , 即 G u x 12 .• • x ld 1' 力21 N22 •,• 岔2d 1 (x[ 1、 = 星 1 ・ ・ ・ • • ① 7nd 1) \\x m V 再把标记也写成向量形式y = (阴;数；...；阴n ) ,则类似于式(3.4),有 w * = arg m i n (g — X w ) T (y — X w ) . (3.9) w 令 E ⑥= (y - X w ) T (y - X w ) , 对 w 求导得到 器 = 2 X T ( X 由 一y) . (3.10) 令上式为零可得岱最优解的闭式解，但由于涉及矩阵逆的计算，比单变量情形 要复杂一些.下面我们做一个简单的讨论. 当 X T X 为满 秩 矩 阵 (full-rank matrix)或 正 定矩阵 (positive definite m a ­ trix) 令式(3.10)为零可得 w * - ( X T X ) - 1 X T ?/ , (3.11) 其 中 ( X T X ) T 是 矩 阵 ( X T X ) 的 逆 矩 阵 .令 a = ( g ,1) ,则最终学得的多元 56 第 3 章 线 性 模 型 例 如 ，生 物 信 息 学 的 基 因芯片数据中常有成千上 万 个 属 性 ，但 往 往 只 有 几 十 、上百个样例. 回 忆 一 下 ：解 线 性 方 程 组 时 ，若因变量过多，则会 解出多组解. 归 纳 偏 好 参 见 1 .4 节;正 则 化 参 见 6.4、1 1 .4 节. 线性回归模型为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 313
    }
  },
  {
    "page_content": "= ( g ,1) ,则最终学得的多元 56 第 3 章 线 性 模 型 例 如 ，生 物 信 息 学 的 基 因芯片数据中常有成千上 万 个 属 性 ，但 往 往 只 有 几 十 、上百个样例. 回 忆 一 下 ：解 线 性 方 程 组 时 ，若因变量过多，则会 解出多组解. 归 纳 偏 好 参 见 1 .4 节;正 则 化 参 见 6.4、1 1 .4 节. 线性回归模型为 “斓 = 公 四 工 为 —1 * % . (3.12) 然而,现实任务中X T X 往往不是满秩矩阵.例如在许多任务中我们会遇到 大量的变量，其数目甚至超过样例数，导 致 X 的列数多于行数，X T X 显然不满 秩.此时可解出多个血它们都能使均方误差最小化.选择哪一个解作为输出, 将由学习算法的归纳偏好决定，常见的做法是引入正则化(regularization)项. 线性模型虽简单，却有丰富的变化.例如对于样例 Q , y ) , 7 / e R , 当我们希 望线性模型(3.2)的预测值逼近真实标记少时，就得到了线性回归模型.为便于 观察，我们把线性回归模型简写为 y = w T x + b . (3.13) 可否令模型预测值逼近g 的衍生物呢？譬如说，假设我们认为示例所对应的输 出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目 标，即 In?/ = w T x + b . (3.14) 这 就 是 “对数线性回归”(log-linear regression),它实际上是在试图让 6加”+匕 逼近沙・式(3.14)在形式上仍是线性回归，但实质上已是在求取输入空间到输出 空间的非线性函数映射，如 图 3 . 1 所示.这里的对数函数起到了将线性回归模 型的预测值与真实标记联系起来的作用. 图 3 . 1 对数线性回归示意图 3 . 3 对数几率回归 g(.)连续且充分光滑. 更一般地，考虑单调可微函数g ( ・)，令 57 y = , (3.15) 计U M 黑 黑 I S 这 样 得 到 的 模 型 称 为 “广义线性模型\" (generalized linear m o d e l ) , 其中函数 g « ) 称 为 “联系函数”出 位 f u n c t i o n ) ,显然，对数线性回归是广义线性模型在 或极大似然法进行. g 9 ) = In(-)时的特例. 3 . 3 对数几率回归 上一节讨论了如何使用线性模型进行回归学习，但若要做的是分类任务该 怎么办？答案蕴涵在式(3.15)的广义线性模型中：只需找一个单调可微函数将 分类任务的真实标记y 与线性回归模型的预测值联系起来.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 314
    }
  },
  {
    "page_content": "或极大似然法进行. g 9 ) = In(-)时的特例. 3 . 3 对数几率回归 上一节讨论了如何使用线性模型进行回归学习，但若要做的是分类任务该 怎么办？答案蕴涵在式(3.15)的广义线性模型中：只需找一个单调可微函数将 分类任务的真实标记y 与线性回归模型的预测值联系起来. 考虑二分类任务，其 输 出 标 记 y G { 0 , 1 } , 而线性回归模型产生的预测值 z = w T x + b 是实值，于是，我们需将实值2 转 换 为 0 / 1 值 .最 理 想 的 是 “单位 亦称Heaviside函数. 阶跃函数“(unit-step function) 0, z < Q ; 0.5, z = 0 ; 1, z > 0 , { (3.16) 即若预测值。大于零就判为正例，小于零则判为反例，预测值为临界值零则可 任意判别，如 图 3 . 2 所示. 图 3 . 2 单 位 阶 跃 函 数 与 对 数 几 率 函 数 58 第 3 章 线 性 模 型 但 从 图 3 .2 可看出，单位阶跃函数不连续，因此不能直接用作式(3.15)中 的 g—( • ) . 于 是 我 们 希 望 找 到 能 在 一 定 程 度 上 近 似 单 位 阶 跃 函 数 的 “替 代 函 数 ”(surrogate function), 并 希 望 它 单 调 可 微 .对 数 几 率 函 数 (logistic 简 称 “对率函数”. function)正是这样一个常用的替代函数： 注 意 对 数 几 率 函 数 与 “对数函数” ln (・)不同. Sigm oid函 数 即 形 似 S 的 函 数 .对 率 函 数 是 Sig­ moid 函数最重要的代表, 在 第 5 章将看到它在神经 网络中的重要作用. 1 广 京 『 (3」7) 从 图 3 .2 可看出，对数几率函数是一种\"Sigm oid函 数 \" 它 将 z 值转化为一个 接 近 0 或 1 的 g 值,并且其输出值在z = 0 附近变化很陡.将对数几率函数作为 9一(•)代入式(3.15),得到 y = 1 + 二3 ) - 类似于式(3.14),式(3.18)可变化为 In — = w T x 4- b . 1 - 2 / (3.18) (3.19) 若 将 y 视为样 本x 作为正例的可能性，则 1 - g 是其反例可能性,两者的比值 称 为 “几 率 ”(o d d s),反 映 了 。作为正例的相对可能性.对几率取对数则得到 “对数几率”(log o d d s,亦 称 logit) . \\ — y (3.21)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 315
    }
  },
  {
    "page_content": "In — = w T x 4- b . 1 - 2 / (3.18) (3.19) 若 将 y 视为样 本x 作为正例的可能性，则 1 - g 是其反例可能性,两者的比值 称 为 “几 率 ”(o d d s),反 映 了 。作为正例的相对可能性.对几率取对数则得到 “对数几率”(log o d d s,亦 称 logit) . \\ — y (3.21) 有 文 献 译 为 “逻辑回 归”，但 中 文 “逻 辑 ”与 logistic和 lo g it的含义相 去甚远，因此本书意译为 “对数几率回归”，简称 “对率回归”. 由 此 可 看 出 ，式(3.18)实 际 上 是 在 用 线 性 回 归 模 型 的 预 测 结 果 去 逼 近 真 实 标 记 的 对 数 几 率 ，因此，其 对 应 的 模 型 称 为 “对 数 几 率 回 归 \" (logistic regression,亦 称 logit regression).特别需注意到，虽然它的名字是“回归”，但 实际却是一种分类学习方法.这种方法有很多优点,例如它是直接对分类可能 性进行建模，无需事先假设数据分布，这样就避免了假设分布不准确所带来的 问题；它 不 是 仅预测出“类别”，而是可得到近似概率预测，这对许多需利用概 率辅助决策的任务很有用；此外，对率函数是任意阶可导的凸函数,有很好的数 学性质，现有的许多数值优化算法都可直接用于求取最优解. 3 . 3 对数几率回归 59 下面我们来看看如何确定式(3.18)中 的 w 和 6 . 若将式(3.18)中 的 y 视为类 后验概率估计p(g = 1 | 宏)，则式(3.19)可重写为 显然有 ]口呼=：叫一 % + 6 . p(y = 0 \\ x ) - 1 1 况)一 ] + e W Tx + b ， 4 = ° ㈤ = 1 + 理 % +b ・ (3.22) (3.23) (3・24) 于是，我 们 可 通 过 “极 大 似 然 法 ”(maximum likelihood method)来估计 极大似然法参见7.2节， w 和 b 给 定 数 据 集 ｛(g,纳)｝口L，对 率 回 归 模 型 最 大 化 “对 数 似 然 ”(log- likelihood) m 2(幼 b) = £ Inp(% | w, 6) , (3.25) 2=1",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 316
    }
  },
  {
    "page_content": "于是，我 们 可 通 过 “极 大 似 然 法 ”(maximum likelihood method)来估计 极大似然法参见7.2节， w 和 b 给 定 数 据 集 ｛(g,纳)｝口L，对 率 回 归 模 型 最 大 化 “对 数 似 然 ”(log- likelihood) m 2(幼 b) = £ Inp(% | w, 6) , (3.25) 2=1 即令每个样本属于其真实标记的概率越大越好.为便于讨论，令 6 = (w ;0 , X = (£C； 1 ) , 则 w T x + 6 可简写为 /3T X . 再令 01(金;万)= p(y = 1 \\ £ ；/3), po(金;万)= p(y = 0 ］花;6 ) = 1 一 01(余；万)，则式(3.2 5 ) 中的似然项可重写为 P(yi \\ % w, b) = yiP i(xi； /3) + (1 - yi)po (x i； /3) . (3.26) 将式(3.26)代入(3.25),并根据式(3.23)和(3.24)可知，最大化式(3.25)等价于 最小化 m。⑼=£ 优 色 + m (1 + 产 办 ) ) . (3.27) Z=1 式(3.27)是 关 于 万 的 高 阶 可 导 连 续 凸 函 数 ，根 据 凸 优 化 理 论 ［Boyd and Vandenberghe, 2004］, 经 典 的 数 值 优 化 算 法 如 梯 度 下 降 法 (gradient descent method) ＞牛顿法(Newton method)等都可求得其最优解，于是就得到 3* = arg min . (3.28) 以牛顿法为例，其 第 t + 1 轮迭代解的更新公式为 \" ” -(飘厂鬻, 3 60 第 3 章 线 性 模 型 其中关于万的一阶、二阶导数分别为 = 一 £ 打 （班 一P i （自;万））, 2=1 (3.30) 一夕1（金；乃））. (3.31) 3 . 4 线性判别分析 线性判别分析（Linear Discriminant A nalysis,简 称 L D A）是一种经典的线 Fi hZ 性学习方法，在二分类问题上因为最早由［Fisher, 1936］提出，亦 称 “ F isher判 尹」另V分析才再有不同，目U考 假 设 了 各 类 样 本 的 协 方 差 别分析”. 矩阵相同且满秩. L D A 的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上, 使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 317
    }
  },
  {
    "page_content": "尹」另V分析才再有不同，目U考 假 设 了 各 类 样 本 的 协 方 差 别分析”. 矩阵相同且满秩. L D A 的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上, 使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样 本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新 样本的类别.图3 .3 给出了一个二维示意图. 图 3.3 L D A 的 二 维 示 意 图 .“+ ” 、 “- ”分别代表正例和反例，椭圆表示数据簇的 外轮廓，虚线表示投影，红色实心圆和实心三角形分别表示两类样本投影后的中心点. 给 定 数 据 集 。 = {（即 统 ）} Vi e { 0 , 1 } , 令 石 、眼、乂 分 别 表 示 第 分G { 0 , 1 } 类示例的集合、均值向量、协方差矩阵.若将数据投影到直线叨上, 则两类样本的中心在直线上的投影分别为W T M O 和 W T M 1 ；若将所有样本点都 投影到直线上，则两类样本的协方差分别为伊1 2 0 % 和伊丁历也 由于直线是 3 . 4 线性判别分析 61 一维空间，因 此 ty T / z o 、w T / / i > W 丁耳)!!；和 均 为 实 数 . 欲使同类样例的投影点尽可能接近，可以让同类样例投影点的协方差尽可 能小，即也T2()叨 + 叨 1 2 % 尽可能小；而欲使异类样例的投影点尽可能远离, 可以让类中心之间的距离尽可能大，即 ||wT M o - w T Mi||i 同时考虑 二者，则可得到欲最大化的目标 j = ||付丁4 0 ― % T 从1仿 W T S QW + w T E i w = 也T (从0 — 4 1 ) ( 4 0 — 4 1 ) T ^ w T (So + E i ) w ' (3.32) 定 义 “类内散度矩阵\" (within-class scatter matrix) S w = E o 4- E i = £ (« - Mo) (a? - MO)T + £ - Mi) - MI )T (3.33) X E X Q JCC X I 以 及 “类 间 散 度 矩 阵 \"(between-class scatter matrix) Sb = (Mo - Mi) ( M o - MI )T , (3.34) 则式(3.32)可重写为 w T Sw w . (3.35) 这 就 是 L D A 欲 最 大 化 的 目 标 ，即 S b 与 % 的 “广 义 瑞 利 商 ”(generalized Rayleigh quotient).",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 318
    }
  },
  {
    "page_content": "Sb = (Mo - Mi) ( M o - MI )T , (3.34) 则式(3.32)可重写为 w T Sw w . (3.35) 这 就 是 L D A 欲 最 大 化 的 目 标 ，即 S b 与 % 的 “广 义 瑞 利 商 ”(generalized Rayleigh quotient). 若 t u 是 一 个 解 ，则对 于 任 意 常 数 a, a w 也是 式(3.35)的解. 如 何确定 w 呢？注意到式(3.35)的分子和分母都是关于w 的二次项，因此 式(3.35)的解与w 的长度无关，只与其方向有关.不失一般性，令 w T S w w = 1, 则式(3.35)等价于 ‘ m i n —w T SftW w s.t. w T S Wiw = 1 . (3.36) 拉格朗日乘子法参见附 录 B.1, 由拉格朗日乘子法，上式等价于 SbW = XSw w , (3.37) 62 第 3 章 线 性 模 型 其 中 A 是拉格朗日乘子.注意到Sbw 的方向恒为M 0 -皿, 不妨令 代入式(3.37)即得 Sbw = A (/i0 - M i )， w = S ~ 1 (JJ/O - - (3.38) (3.39) 奇 异 值 分 解 参 见 附 录 A.3. 考 虑 到 数 值 解 的 稳 定 性 ，在 实 践 中 通 常 是 对 Sw 进 行 奇 异 值 分 解 ，即 Sw = U E V T , 这 里 E 是一个实对角矩阵，其 对角线上的元素是 Sw 的奇异值，然后 再 由 S U = V E - XU T 得 到 S” . 参见习题7.5. 类数据同先验、满足高斯分布且协方差相等时,L D A 可达到最优分类. 值得一提的是，L D A 可从贝叶斯决策理论的角度来阐释，并可证明，当两 可 以 将 L D A 推广到多分类任务中..假定存在N 个类，且 第 i 类示例数为 团： 我 们 先 定 义 “全局散度矩阵” St = Sb + Sw m = £ 包 —⑷ W —4 ) T , (3.40) 其 中 M 是所有示例的均值向量.将类内散度矩阵Sw 重定义为每个类别的散度 矩阵之和，即 N Sw = S g , 2=1 (3.41) 其中 S皿 = £ (① 一 %)Q - % )T . (3.42) 由式(3.40)~(3.42)可得 x e X i Sb = S2 — Sw N = 〉： » j — i—l — 4 ) , • (3.43)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 319
    }
  },
  {
    "page_content": "N Sw = S g , 2=1 (3.41) 其中 S皿 = £ (① 一 %)Q - % )T . (3.42) 由式(3.40)~(3.42)可得 x e X i Sb = S2 — Sw N = 〉： » j — i—l — 4 ) , • (3.43) 显然，多分类L D A 可以有多种实现方法:使用Sb, S g St 三者中的任何两 个即可.常见的一种实现是采用优化目标 3 . 5 多分类学习 tr (W T S6W ) 嘴 % (W TS妙W ) ， 6 3 / 、 ⑶ 44) 其 中 W €肽dx(N-1),任(.)表示矩阵的迹(trace).式(3.44)可通过如下广义特征 值问题求解： S bW = ASw W . (3.45) W 的 闭 式 解 则 是 的 N - 1 个最大广义特征值所对应的特征向量组成的 矩阵. 若 将 W 视为一个投影矩阵，则 多 分 类 L D A 将 样本投影到N - 1 维空间, N - 1 通常远小于数据原有的属性数.于是，可通过这个投影来减小样本点的 维数，且投影过程中使用了类别信息，因此L D A 也常被视为一种经典的监督降 降 维 参 见 第 1 0 章. 维技术. 3 . 5 多分类学习 例如上一节 最 后 介 绍 的 L D A 推广. 现实中常遇到多分类学习任务.有些二分类学习方法可直接推广到多分类, 但在更多情形下，我们是基于一些基本策略，利用二分类学习器来解决多分类 问题. 通 常 称 分 类 学 习 器 为 \"分类器\" (classifier). 关于多个分类器的集成, 参 见 第 8 章. O v R 亦称 O v A ( O n e vs. All ) ,但 O v A 这个说法不严 格 ，因 为 不 可 能 把 “所有 类 ”作为反类. 亦可根 据 各 分 类 器 的 预 测置信度等信息进行集成, 参 见 8 . 4节. 不 失 一般性，考 虑 N 个 类 别 C 1 & , … ,CN , 多分类学习的基本思路是 “拆解法”，即将多分类任务拆为若干个二分类任务求解.具体来说，先对问题 进行拆分，然后为拆出的每个二分类任务训练一个分类器;在测试时，对这些分 类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分 类任务进行拆分，以及如何对多个分类器进行集成.本节主要介绍拆分策略. 最经典的拆分策略有三种： “一对一”(One vs. O n e , 简 称 O v O ) 、 “一对",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 320
    }
  },
  {
    "page_content": "“拆解法”，即将多分类任务拆为若干个二分类任务求解.具体来说，先对问题 进行拆分，然后为拆出的每个二分类任务训练一个分类器;在测试时，对这些分 类器的预测结果进行集成以获得最终的多分类结果.这里的关键是如何对多分 类任务进行拆分，以及如何对多个分类器进行集成.本节主要介绍拆分策略. 最经典的拆分策略有三种： “一对一”(One vs. O n e , 简 称 O v O ) 、 “一对 其余“(One vs. Rest,简称 O v R ) 和 \"多 对 多 \" (Many vs. M a n y , 简称 M vM). 给定数据集。 = {(«1, t/1), («2, ?/2), . . . , … ,CN }. O v O 将 这 N 个类别两两配对,从而产生N(N - 1)/2个二分类任务,例如O v O Vm)}, Vi G 将为区分类别必 和 G 训练一个分类器，该分类器把。 中 的 C e 类样例作为正 例，g 类样例作为反例.在测试阶段，新样本将同时提交给所有分类器，于是我 们将得到N ( N - 1)/2个分类结果,最终结果可通过投票产生：即把被预测得最 多的类别作为最终分类结果.图3.4给出了一个示意图. O v R 则是每次将一个类的样例作为正例、所有其他类的样例作为反例来 训 练 N 个分类器.在测试时若仅有一个分类器预测为正类，则对应的类别标记 作为最终分类结果，如 图 3.4所示.若有多个分类器预测为正类，则通常考虑各 64 第 3 章 线 性 模 型 属 于 类 Q 的 样 例 集 合 数 据 集 C ] 。 2 0 3 。4 。 / 公 来 哭 预 测 分 类 器 结 果 用 于 训 练 的 两 类 样 例 “ 十 用 于 训 练 的+两 类 样 例 叵 叵 叵 回w 叵 釐 霸 ）今于1 T C , 今于2 T C3 今 / 3 1 G 今 力 T C 3 最 终 结 果 T 。 3 国 ）=为T 。 2 分于6 T 0 3 图 3.4 O v O 与 O v R 示意图 （I G I 匕虞豆侬；|） （a | 分 类 器 2 S 合 力 T 用 禾 “一 ” 今 f2 T “一” 。 3 豳）今 / 3 1 “ + ” （叵 晦缪透|） 令 f4 T “ 一 ” 最 终 结 果 。 3 分类器的预测置信度，选择置信度最大的类别标记作为分类结果.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 321
    }
  },
  {
    "page_content": "图 3.4 O v O 与 O v R 示意图 （I G I 匕虞豆侬；|） （a | 分 类 器 2 S 合 力 T 用 禾 “一 ” 今 f2 T “一” 。 3 豳）今 / 3 1 “ + ” （叵 晦缪透|） 令 f4 T “ 一 ” 最 终 结 果 。 3 分类器的预测置信度，选择置信度最大的类别标记作为分类结果. 容易看出，O vR 只 需 训 练 N 个分类器，而 O v O 需 训 练 N （N - 1）/ 2 个分 类器，因此，OvO的存储开销和测试时间开销通常比O v R 更大.但在训练时, O v R 的每个分类器均使用全部训练样例，而 O v O 的每个分类器仅用到两个类 的样例，因此，在类别很多时，O v O 的训练时间开销通常比O v R 更小.至于预 测性能，则取决于具体的数据分布,在多数情形下两者差不多. M vM 是绛次将若干个类作为正类,若干个其他类作为反类.显然，O vO 和 O v R 是 M vM 的 特 例 .M vM 的正、反类构造必须有特殊的设计，不能随意选 取.这里我们介绍一种最常用的M vM 技术： “纠 错 输 出 码 \"（Error Correcting Output Codes,简称 ECOC）. ECOC [Dietterich and Bakiri, 1995]是将编码的思想引入类别拆分，并尽 可能在解码过程中具有容错性.E C O C 工作过程主要分为两步: • 编码：对 N 个 类 别 做 河 次 划 分 ，每次划分将一部分类别划为正类，一部 分划为反类,从而形成一个二分类训练集；这样一共产生M 个训练集,可 训 练 出 M 个分类器. ・解码：M 个分类器分别对测试样本进行预测，这些预测标记组成一个编 码.将这个预测编码与每个类别各自的编码进行比较,返回其中距离最小 的类别作为最终预测结果. 3 . 5 多分类学习 65 类 别 划 分 通 过 “编 码 矩 阵 \"(coding matrix)指定.编码矩阵有多种形式, 常 见 的 主 要 有 二 元 码 ［Dietterich and Bakiri, 1995］和 三 元 码 ［Allwein et al., 2000］. 前者将每个类别分别指定为正类和反类，后者在正、反类之外，还可指 定 “停用类”. 图 3 .5 给出了一个示意图，在 图 3.5(a)中，分 类 器 h 将 C i 类和 Q 类的样例作为正例，3 类 和 。4 类的样例作为反例；在 图 3.5(b)中，分类器",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 322
    }
  },
  {
    "page_content": "定 “停用类”. 图 3 .5 给出了一个示意图，在 图 3.5(a)中，分 类 器 h 将 C i 类和 Q 类的样例作为正例，3 类 和 。4 类的样例作为反例；在 图 3.5(b)中，分类器 A 将 Q 类 和 类 的 样 例 作 为 正 例 ，圆类的样例作为反例.在解码阶段,各分 类器的预测结果联合起来形成了测试示例的编码，该编码与各类所对应的编码 进行比较,将距离最小的编码所对应的类别作为预测结果.例如在图3 .5 (a )中, 若基于欧氏距离，预测结果将是圆. ( a ) 二元 ECOC 码 ( b ) 三 元 ECOC码 图 3.5 E C O C 编 码 示 意 图 . 分 别 表 示 学 习 器 力 将 该 类 样 本 作 为 正 、反例；三 元 码 中 “0” 表示力不使用该类样本 为 什 么 称 为 “纠错输出码”呢？这是因为在测试阶段,E C O C 编码对分类 器的错误有一定的容忍和修正能力.例如图3.5(a)中对测试示例的正确预测编 假设在预测时某个分类器出错了，例如力出错从而 码是(一1 ,+ 1 ,+ 1 ,— 导致了错误编码(-1 , - 但基于这个编码仍能产生正确的最终分 类 结 果 一 般 来 说 ,对 同 一 个 学 习 任 务 ,E C O C 编码越长,纠错能力越强.然 而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大；另一 方面,对有限类别数，可能的组合数目是有限的，码长超过一定范围后就失去了 意义. 对同等长度的编码，理论上来说,任意两个类别之间的编码距离越远，则纠 错能力越强.因此，在码长较小时可根据这个原则计算出理论最优编码.然而, 码长稍大一些就难以有效地确定最优编码，事实上这是N P 难问题.不过,通常 我们并不需获得理论最优编码，因为非最优编码在实践中往往已能产生足够好 的分类器.另一方面，并不是编码的理论性质越好，分类性能就越好，因为机器 66 第 3 章 线 性 模 型 学习问题涉及很多因素，例 如 将 多 个 类 拆 解 为 两 个 “类别子集”，不同拆解方 式所形成的两个类别子集的区分难度往往不同，即其导致的二分类问题的难度 不同；于是，一个理论纠错性质很好、但导致的二分类问题较难的编码，与另一 个理论纠错性质差一些、但导致的二分类问题较简单的编码，最终产生的模型 性能孰强孰弱很难说. 3 . 6 类别不平衡问题 前面介绍的分类学习方法都有一个共同的基本假设，即不同类别的训练样 例数目相当.如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别 很大,则会对学习过程造成困扰.例如有998个反例，但 正 例 只 有2 个 ，那么学",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 323
    }
  },
  {
    "page_content": "个理论纠错性质差一些、但导致的二分类问题较简单的编码，最终产生的模型 性能孰强孰弱很难说. 3 . 6 类别不平衡问题 前面介绍的分类学习方法都有一个共同的基本假设，即不同类别的训练样 例数目相当.如果不同类别的训练样例数目稍有差别，通常影响不大，但若差别 很大,则会对学习过程造成困扰.例如有998个反例，但 正 例 只 有2 个 ，那么学 习方法只需返回一个永远将新样本预测为反例的学习器，就 能 达 到 99.8% 的精 度;然而这样的学习器往往没有价值，因为它不能预测出任何正例. 类 别 不 平 衡 (class-imbalance)就 是 指 分 类 任 务 中 不 同 类 别 的 训 练 样 例 数 目 差 别 很 大 的 情 况 .不 失 一 般 性 ，本 节 假 定 正 类 样 例 较 少 ，反类样例较多. 在 现 实 的 分 类 学 习 任 务 中 ，我 们 经 常 会 遇 到 类 别 不 平 衡 ，例 如 在 通 过 拆 分 法解决多分类问题时，即使原始问题中不同类别的训练样例数目相当，在使 用OvR、MvM策略后产生的二分类任务仍可能出现类别不平衡现象，因此有 必要了解类别不平衡性处理的基本方法. 从线性分类器的角度讨论容易理解，在 我 们 用 y = w T x ^ b 对新样本⑦ 进 行 分类时，事 实 上 是 在 用 预 测 出 的 g 值与一个阈值进行比较，例如通常在 y > 0 .5 时判别为正例，否 则 为 反 例 .y 实际上表达了正例的可能性，几 率 击 则反映了正例可能性与反例可能性之比值，阈值设置为0 .5 恰表明分类器认为 真实正、反例可能性相同，即分类器决策规则为 若 -^ ― > 1 贝IJ预测为正例. (3.46) 1 —， 对 O v R 、M v M 来说，由 于对每个类进行了相同的 处理，其拆解出的二分类 任务中类别不平衡的影响 会相互抵消，因此通常不 需专门处理. 无偏采样意味着真实样 本总体的类别比例在训练 集中得以保持. 然而，当训练集中正、反例的数目不同时，令 团 +表 示 正 例 数 目 ，皿一表示 反例数目，则 观 测 几 率 是 冬 ，由于我们通常假设训练集是真实样本总体的无偏 采样，因此观测几率就代表了真实几率.于是，只要分类器的预测几率高于观测 几率就应判定为正例，即 若 兰 — > 贮 则 预 测 为 正 例 . 1 — y m~ (3.47) 3 . 7 阅读材料 67 但是，我们的分类器是基于式(3.46)进行决策，因此，需对其预测值进行调 整，使其在基于式(3.46)决策时，实际是在执行式(3 .4 7 ).要做到这一点很容易, 只需令 yf 1 1 — yf / 一 1",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 324
    }
  },
  {
    "page_content": "几率就应判定为正例，即 若 兰 — > 贮 则 预 测 为 正 例 . 1 — y m~ (3.47) 3 . 7 阅读材料 67 但是，我们的分类器是基于式(3.46)进行决策，因此，需对其预测值进行调 整，使其在基于式(3.46)决策时，实际是在执行式(3 .4 7 ).要做到这一点很容易, 只需令 yf 1 1 — yf / 一 1 y _ m~ 义 1 — 1/ Tn + + , 公 ，小 (3.48) 亦 称 “再平衡” (rebal­ ance). 这就是类别不平衡学习的一个基本策略—— “再 缩 放 \"(rescaling). 欠 采 样 亦 称 “下采样” (downsampling), 过 采 样 亦 称 \" 上 采 样 \" (upsam­ pling). 再缩放的思想虽简单，但实际操作却并不平凡，主 要 因 为 “训练集是真实 样本总体的 无 偏 采 样 ”这个假设往往并不成立，也就是说，我们未必能有效 地基于训练集观测几率来推断出真实几率.现有技术大体上有三类做法：第 一 类 是 直 接 对 训 练 集 里 的 反 类 样 例 进 行 “欠采样”(undersam pling),即去除 一些反例 使 得 正 、反例数目接近，然后再进行学习；第二类是对训练集里的 正 类 样 例 进 行 “过采样\" (oversampling),即增加一些正例使得正、反例数目 接近，然后 再 进 行 学 习 ；第 三 类 则 是 直 接 基 于 原 始 训 练 集 进 行 学 习 ，但在用 训练好的分类器进行预测时，将式(3.48)嵌入到其决策过程中，称 为 “阈值移 动 ”(threshold-moving). 欠采样法的时间开销通常远小于过采样法，因为前者丢弃了很多反例，使 得分类器训练集远小于初始训练集，而过采样法增加了很多正例，其训练集 大 于 初 始 训 练 集 .需 注 意 的 是 ，过采样法不能简单地对初始正例样本进行重 复采样，否则会招致严重的过拟合；过采样法的代 表 性 算 法SMOTE [Chawla et al., 2002]是通过对训练集里的正例进行插值来产生额外的正例.另一方面, 欠采样法若随机丢弃反例，可能丢失一些重要信息；欠采样法的代表性算法 EasyEnsemble [Liu et al., 2009]则是利用集成学习机制，将反例划分为若干个 集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来 看却不会丢失重要信息. 代 价 敏 感 学 习 研 究 非 均等代价下的学习.参见 2.3.4 节.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 325
    }
  },
  {
    "page_content": "欠采样法若随机丢弃反例，可能丢失一些重要信息；欠采样法的代表性算法 EasyEnsemble [Liu et al., 2009]则是利用集成学习机制，将反例划分为若干个 集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来 看却不会丢失重要信息. 代 价 敏 感 学 习 研 究 非 均等代价下的学习.参见 2.3.4 节. 值 得一提的是， \"再 缩 放 \"也 是 \"代 价 敏 感 学 习 ”(cost-sensitive leam- ing)的基础.在代价敏感学习中将式(3.48)中 的m~/m + 用 co〃+/co5厂代替即 可 ,其 中 cost+ 是将正例误分为反例的代价,cost-是将反例误分为正例的代价. 3 . 7 阅读材料 “稀疏表示\" (sparse representation)近年来很受关注，但即便对多元线性 回归这样简单的模型，获 得 具 有 最 优 “稀疏性”(sparsity)的解也并不容易.稀 疏性问题本质上对应了 Lo 范数的优化，这在通常条件下是N P 难问题.LASSO [Tibshirani, 1996]通 过 J 范数来近似Lo 范数，是求取稀疏解的重要技术. 参见 第 1 1 章. 68 第 3 章 线 性 模 型 可以证明，O vO 和 O vR 都 是 E C O C 的 特 例 ［Allwein et al., 2000］. 人们以 往希望设计通用的编码法\"C ram m er and Singer, 2002］提出要考虑问题本身 的特点，设 计 “问题依赖”的编码法，并证明寻找最优的离散编码矩阵是一个 N P 完全问题.此后，有多种问题 依 赖 的E C O C 编码法被提出，通常是通过找 出具有代表性的二分类问题来进行编码［Pujol et aL, 2006, 2008］. ［Escalera et al., 2010卜开发了一个开源E C O C 库. M vM 除了 E C O C 还 可 有 其 他 实 现 方 式 ，例 如 DAG (Directed Acyclic G raph)拆 分 法 ［Platt et al., 2000］将类别划分表达成树形结构，每个结点对应 于一个二类分类器.还有一些工作是致力于直接求解多分类问题，例如多类支 持向量机方面的一些研究［Crammer and Singer, 2001; Lee et al., 2004］. 代 价 敏 感 学 习 中 研 究 得 最 多 的 是 基 于 类 别 的 “误 分 类 代",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 326
    }
  },
  {
    "page_content": "持向量机方面的一些研究［Crammer and Singer, 2001; Lee et al., 2004］. 代 价 敏 感 学 习 中 研 究 得 最 多 的 是 基 于 类 别 的 “误 分 类 代 价 ”(misclassifcation c o s t),代 价 矩 阵 如 表 2 .2 所 示 ；本 书 在 提 及 代 价 敏 感 学习时，默认指此类情形.已经证明，对二分类任务可通过“再缩放”获得理论 最 优 解 ［Elkan, 2001］, 但对多分类任务，仅在某些特殊情形下存在闭式解［Zhou and Liu, 2006a］. 非 均等代价和类别不平衡性虽然都可借助“再缩 放 ”技术, 但 两 者 本 质 不 同 ［Zhou and Liu, 2006b］. 需注意的是，类别不平衡学习中通常 是较小类的代价更高,否则无需进行特殊处理. 多分类学习中虽然有多个类别，但每个样本仅属于一个类别.如果希望为 一个样本同时预测出多个类别标记，例 如 一 幅 图 像 可 同 时 标 注 为 “蓝 天 ”、 “白云”、 “羊 群 ”、 “自然场景”，这样的任务就不再是多分类学习，而是 “多标记学习“(multi-label learning),这是机器学习中近年来相当活跃的一个 研究领域.对多标记学习感兴趣的读者可参阅［Zhang and Zhou, 2014］. 习题 69 习题 3.1 试析在什么情形下式(3.2)中不必考虑偏置项b. 3.2 试证明，对 于 参 数 犯 对 率 回 归 的 目 标 函 数 (3.18)是非凸的，但其对数 似然函数(3.27)是凸的. 西瓜数据集3 .0 a 见 p.89 的 表 4 5 U C I数据集见 http://archive.ics.uci.edu/ml/. 3.3 编程实现对率回归，并给出西瓜数据集3 .0 a 上的结果. 3.4 选 择 两 个 U C I数据集，比 较 1 0 折交叉验证法和留一法所估计出的对 率回归的错误率. 3.5 编程实现线性判别分析，并给出西瓜数据集3 .0 a 上的结果. 线性可分是指存在线性 超平面能将不同类的样本 点分 开 .参 见 6 .3 节. 3.6 线性判别分析仅在线性可分数据上能获得理想结果，试设计一个改进 方法，使其能较好地用于非线性可分数据 3.7 令 码 长 为 9 , 类 别 数 为 4 , 试给出海明距离意义下理论最优的ECOC 二元码并证明之. 3.8* E C O C 编码能起到理想纠错作用的重要条件是：在每一位编码上出错 的概率相当且独立.试析多分类任务经E C O C 编码后产生的二类分 类器满足该条件的可能性及由此产生的影响.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 327
    }
  },
  {
    "page_content": "方法，使其能较好地用于非线性可分数据 3.7 令 码 长 为 9 , 类 别 数 为 4 , 试给出海明距离意义下理论最优的ECOC 二元码并证明之. 3.8* E C O C 编码能起到理想纠错作用的重要条件是：在每一位编码上出错 的概率相当且独立.试析多分类任务经E C O C 编码后产生的二类分 类器满足该条件的可能性及由此产生的影响. 3.9 使 用 O vR 和 MvM将多分类任务分解为二分类任务求解时,试述为何 无需专门针对类别不平衡性进行处理. 3.10* 试推导出多分类代价敏感学习(仅考虑基于类别的误分类代价)使用 “再缩放”能获得理论最优解的条件. 70 第 3 章 线 性 模 型 参考文献 Allwein, E. L., R. E. Schapire, and Y. Singer. (2000). ^Reducing multiclass to binary: A unifying approach for margin classifiers.55 Journal of Machine Learning Research, 1:113-141. Boyd, S. and L. Vandenberghe. (2004). Convex Optimization. Cambridge Uni­ versity Press, Cambridge, UK. Chawla, N. V., K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer. (2002). “SMOTE: Synthetic minority over-sampling technique.5, Journal of Artificial Intelligence Research^ 16:321-357. Crammer, K. and Y. Singer. (2001), “On the algorithmic implementation of multiclass kernel-based vector machines.,, Journal of Machine Learning Re­ search, 2:265-292. Crammer, K. and Y. Singer. (2002). “On the learnability and design of output codes for multiclass problems.\" Machine Learning^ 47(2-3):201-233.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 328
    }
  },
  {
    "page_content": "search, 2:265-292. Crammer, K. and Y. Singer. (2002). “On the learnability and design of output codes for multiclass problems.\" Machine Learning^ 47(2-3):201-233. Dietterich, T. G. and G. Bakiri. (1995). “Solving multiclass learning problems via error-correcting output codes.\" Journal of Artificial Intelligence Re­ search^ 2:263-286. Elkan, C. (2001). “The foundations of cost-sensitive learning.5, In Proceedings of the 17th International Joint Conference on Artificial Intelligence (IJCAI)1 973-978, Seattle, WA. Escalera, S., O. Pujol, and P. Radeva. (2010). “Error-correcting ouput codes library.5, Journal of Machine Learning Research^ 11:661-664. Fisher, R. A. (1936). “The use of multiple measurements in taxonomic prob­ lems.55 Annals of Eugenics1 7(2):179-188. Lee, Y., Y. Lin, and G. Wahba. (2004). “Multicategory support vector ma­ chines, theory, and application to the classification of microarray data and satellite radiance data.\" Journal of the American Statistical Association^ 99 (465):67-81.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 329
    }
  },
  {
    "page_content": "chines, theory, and application to the classification of microarray data and satellite radiance data.\" Journal of the American Statistical Association^ 99 (465):67-81. Liu, X.-Y., J. Wu, and Z.-H. Zhou. (2009). ^Exploratory undersamping for class-imbalance learning.^^ IEEE Transactions on Systems, Man, and Cyber­ netic^ - Part B: Cybernetics1 39(2):539-550. Platt, J. C., N. Cristianini, and J. Shawe-Taylor. (2000). “Large margin DAGs 参考文献 71 for multiclass classification? In Advances in Neural Information Processing Systems 12 (NIPS) (S. A. Solla, T. K. Leen, and K.-R. Muller, eds.), MIT Press, Cambridge, MA. Pujol, 0., S. Escalera, and P. Radeva. (2008). “An incremental node embedding technique for error correcting output codes.\" Pattern Recognition, 41(2):713- 725. Pujol, O., P. Radeva, and J. Vitria. (2006). ^Discriminant ECOC: A heuristic method for application dependent design of error correcting output codes.,5 IEEE Transactions on Pattern Analysis and Machine Intelligence^ 28(6): 1007-1012. Tibshirani, R. (1996). ^Regression shrinkage and selection via the LASSO.”",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 330
    }
  },
  {
    "page_content": "IEEE Transactions on Pattern Analysis and Machine Intelligence^ 28(6): 1007-1012. Tibshirani, R. (1996). ^Regression shrinkage and selection via the LASSO.” Journal of the Royal Statistical Society: Series 58(1):267-288. Zhang, M.-L. and Z.-H. Zhou. (2014). “A review on multi-label learning al­ gorithms.5, IEEE Transactions on Knowledge and Data Engineering1 26(8): 1819-1837. Zhou, Z.-H. and X.-Y. Liu. (2006a). “On multi-class cost-sensitive learn in g .In Proceeding of the 21st National Conference on Artificial Intelligence (AAAI)^ 567-572, Boston, WA. Zhou, Z.-H. and X.-Y. Liu. (2006b). “Training cost-sensitive neural networks with methods addressing the class imbalance problem.^^ IEEE Transactions on Knowledge and Data Engineering^ 18(1):63-77. 72 第 3 章 线 性 模 型 休息一会儿 小故事：关 于 “最小二乘法” 1 8 0 1年，意大利天文学家皮亚齐 发现了 1 号 小 行 星 “谷神星”，但在跟 踪观测了 4 0 天后，因谷神星转至太阳 的背后，皮亚齐失去了谷神星的位置. 许多天文学家试图重新找到谷神星，但 (1993年版德国1 0马克纸币上的高斯像) 都 徒 劳 无 获 .这 引 起 了 伟 大 的 德 国 数 学 家 高 斯 (1777— 1 8 5 5 )的注意，他发明了一种方法，根据皮亚齐的观测数据计 算出了谷神星的轨道，后来德国天文学家奥伯斯在高斯预言的时间和星空领域 重新找到了谷神星. 18 09年，高 斯 在 他 的 著 作 《天体运动论》 中发表了这种方 法，即最小二乘法.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 331
    }
  },
  {
    "page_content": "都 徒 劳 无 获 .这 引 起 了 伟 大 的 德 国 数 学 家 高 斯 (1777— 1 8 5 5 )的注意，他发明了一种方法，根据皮亚齐的观测数据计 算出了谷神星的轨道，后来德国天文学家奥伯斯在高斯预言的时间和星空领域 重新找到了谷神星. 18 09年，高 斯 在 他 的 著 作 《天体运动论》 中发表了这种方 法，即最小二乘法. 1805年，在椭圆积分、数论和几何方面都有重大贡献的法国大数学家勒让 另 两 位 是 拉 格 朗 日 和 拉 普 拉 斯 ，三 人 姓 氏 首 字 母 相 同 ，时 称 “ 3L” . 德 (1752— 1833)发 表 了 《计算彗星轨道的新方法》，其附录中描述了最小二乘 法 .勒 让 德 是 法 国 18— 1 9 世纪数学界的三驾马车之一，早已是法国科学院院 士.但勒让德的书中没有涉及最小二乘法的误差分析，高 斯 1809年的著作中包 括了这方面的内容，这对最小二乘法用于数理统计、乃至今天的机器学习有极 为重要的意义.由于高斯的这一重大贡献，以及他声称自己17 99年就已开始使 用这个方法，因此很多人将最小二乘法的发明优先权归之为高斯.当时这两位 大数学家发生了著名的优先权之争，此后有许多数学史家专门进行研究，但至 今也没弄清到底是谁最先发明了最小二乘法. 第 4 章 决 策 树 4 . 1 基本流程 亦 称 “判定树”.根 据 上下文，本 书 中 的 “决策 树 ”有时是指学习方法, 有时是指学得的树. 决 策树(decision tre e ) 是 一 类 常 见 的 机 器 学 习 方 法 .以 二 分 类 任 务 为 例 ，我 们 希 望 从 给 定 训 练 数 据 集 学 得 一 个 模 型 用 以 对 新 示 例 进 行 分 类 ，这 个 把 样 本 分 类 的 任 务 ，可 看 作 对 “当 前 样 本 属 于 正 类 吗 ?”这 个 问 题 的 “决 策 ”或 “判 定 ”过 程 .顾 名 思 义 ，决策树是基于树结构来进行决策的，这恰是人类在面临决 策 问 题 时 一 种 很 自 然 的 处 理 机 制 .例 如 ，我 们 要 对 “这 是 好 瓜 吗 ?”这样的问题 进 行 决 策 时 ，通 常 会 进 行 一 系 列 的 判 断 或 “子 决 策 ”：我 们 先 看 “它是什么颜 色 ?”，如 果 是 “青 绿 色 ”，则 我 们 再 看 “它 的 根 蒂是什么形态?”，如 果 是 “蜷 缩 ”，我 们 再 判 断 “它敲起来是什么声音?”，最 后 ，我们得出最终决策：这是个 好 瓜 .这 个 决 策 过 程 如 图 4 .1 所示. 图 4 . 1 西瓜问题的一棵决策树",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 332
    }
  },
  {
    "page_content": "色 ?”，如 果 是 “青 绿 色 ”，则 我 们 再 看 “它 的 根 蒂是什么形态?”，如 果 是 “蜷 缩 ”，我 们 再 判 断 “它敲起来是什么声音?”，最 后 ，我们得出最终决策：这是个 好 瓜 .这 个 决 策 过 程 如 图 4 .1 所示. 图 4 . 1 西瓜问题的一棵决策树 显 然 ，决 策 过 程 的 最 终 结 论 对 应 了 我 们 所 希 望 的 判 定 结 果 ，例 如 “是 ”或 “不 是 ”好 瓜 ；决 策 过 程 中 提 出 的 每 个 判 定 问 题 都 是 对 某 个 属 性 的 “测 试 ”， 例 如 “色 泽 = ? ” “根 蒂 = ? ” ；每 个 测 试 的 结 果 或 是 导 出 最 终 结 论 ，或是导出 进 一 步 的 判 定 问 题 ，其 考 虑 范 围 是 在 上 次 决 策 结 果 的 限 定 范 围 之 内 ，例如若在 “色泽= 青 绿 ”之 后 再 判 断 “根蒂= ? ”，则仅在考虑青绿色瓜的根蒂. 一 般 的 ，一 棵 决 策 树 包 含 一 个 根 结 点 、若 干 个 内 部 结 点 和若干个叶结点; 74 第 4 章 决 策 树 叶结点对应于决策结果，其他每个结点则对应于一个属性测试；每个结点包含 的样本集合根据属性测试的结果被划分到子结点中；根结点包含样本全集.从 根结点到每个叶结点的路径对应了一个判定测试序列.决策树学习的目的是为 了产生一棵泛化能力强，即处理未见示例能力强的决策树，其基本流程遵循简 单 且 直 观 的 “分 而 治 之 \"(divide-and-conquer)策略，如 图 4.2所示. 输入：训练集。 = {(Xi, 7/i),(CC2 , 2/2), . • . , 2/m)}； 递归返回，情形(1). 递归返回，情形(2). 我们将在下一节讨论如 何获得最优划分属性. 递归返回，情形(3). 从 4 中去掉a*.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 333
    }
  },
  {
    "page_content": "单 且 直 观 的 “分 而 治 之 \"(divide-and-conquer)策略，如 图 4.2所示. 输入：训练集。 = {(Xi, 7/i),(CC2 , 2/2), . • . , 2/m)}； 递归返回，情形(1). 递归返回，情形(2). 我们将在下一节讨论如 何获得最优划分属性. 递归返回，情形(3). 从 4 中去掉a*. 属性集 4 = {。1, 过程：函数 TreeGenerate(Z), A) 1：生成结点node; 2： if D 中样本全属于同一类别C then 3： 将 n o d e 标记为。类叶结点；return 4： end if 5： if A = 0 O R P 中样本在A 上取值相同then 6: 将 n o d e 标记为叶结点，其类别标记为D 中样本数最多的类;return 7： end if 8：从 4 中选择最优划分属性a*; 9： for a * 的每一个值a； do 10： 为 n o d e 生成一个分支；令 D v 表 示D 中在a * 上取值为磴的样本子集； 11: 12: 将分支结点标记为叶结点，其类别标记为D 中样本最多的类;return 13: 14： 15: 16: 输出：以 n o d e 为根结点的一棵决策树 以 TreeGenerate(B v , A \\ {a*})为分支结点 end if end for if D y 为空 then else 图 4 . 2 决策树学习基本算法 显然，决策树的生成是一个递归过程.在决策树基本算法中，有三种情形会 导致递归返回：( 1 ) 当前结点包含的样本全属于同一类别，无需划分；( 2 ) 当前 属性集为空，或是所有样本在所有属性上取值相同，无法划分；( 3 ) 当前结点包 含的样本集合为空，不能划分. 在第⑵种情形下，我们把当前结点标记为叶结点，并将其类别设定为该结 点所含样本最多的类别；在 第 ⑶ 种 情 形 下 ，同样把当前结点标记为叶结点，但 将其类别设定为其父结点所含样本最多的类别.注意这两种情形的处理实质不 同：情形⑵是在利用当前结点的后验分布，而情形⑶则是把父结点的样本分布 作为当前结点的先验分布. 4 . 2 划分选择 75 4 . 2 划分选择 由 算法4 .2 可看出，决策树学习的关键是第8 行，即如何选择最优划分属 性.一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样 本尽可能属于同一类别，即 结 点 的 “纯度”(purity)越来越高. 4 .2 .1 信息增益",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 334
    }
  },
  {
    "page_content": "作为当前结点的先验分布. 4 . 2 划分选择 75 4 . 2 划分选择 由 算法4 .2 可看出，决策树学习的关键是第8 行，即如何选择最优划分属 性.一般而言，随着划分过程不断进行，我们希望决策树的分支结点所包含的样 本尽可能属于同一类别，即 结 点 的 “纯度”(purity)越来越高. 4 .2 .1 信息增益 “信 息 病 \"(information entropy)是度量样本集合纯度最常用的一种指标. 假定当前样本集合。 中 第 k 类 样 本 所 占 的 比 例 为 也 (k = 1 ,2 ,… ，3 ) , 则 D 的信息嫡定义为 3 E nt(P ) = - £ p k log2 Pfc . k=l (4.1) 计算信息嫡时约定：若 p = 0,则 P log2 P = 0- E n t(L > )的 最 小 值 为 0, 最大底为log2 3 . E n t(D )的值越小，则 D 的纯度越高. 假定离散属性a 有 V 个 可 能 的 取 值 谓 , … ， 若 使 用a 来对样本集 D 进行划分，则会产生V 个分支结点，其 中 第v 个分支结点包含了 D 中所有在 属 性 a 上 取 值 为 淤 的 样 本 ，记 为 D \\ 我们可根据式(4 .1 )计 算 出D - 的信息嫡, 再考虑到不同的分支结点所包含的样本数不同，给分支结点赋予权重\\DV \\/\\D\\, 即样本数越多的分支结点的影响越大，于是可计算出用属性a 对样本 集D 进行 划 分 所 获 得 的 “信息增益”(information gain) Gain(Z), a) = E nt(P ) - £ 鲁 . (4.2) V=1 I I 一般而言，信息增益越大，则意味着使用属性a 来 进 行 划 分 所 获 得 的 “纯 度提升”越大.因此，我们可用信息增益来进行决策树的划分属性选择，即在图 4 .2 算 法 第 8 行 选 择 属 性 a* = a rg m a x G a in (P ,a ).著 名 的 ID 3 决策树学习算 aeA 法 ［Quinlan, 1986］就是以信息增益为准则来选择划分属性. 以 表 4 .1 中的西瓜数据集2 .0 为例，该 数 据 集 包 含17 个训练样例，用以学 习一棵能预测没剖开的是不是好瓜的决策树.显然，|川= 2 . 在决策树学习开 始时，根 结 点 包 含 。 中的所有样例，其中正例占m = 备,反 例 占 次 = 告 .于 是，根据式(4.1)可计算出根结点的信息熠为 I D 3 名 字 中 的 I D 是 It­ erative Dichotomiser (迭代 二分器)的简称.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 335
    }
  },
  {
    "page_content": "习一棵能预测没剖开的是不是好瓜的决策树.显然，|川= 2 . 在决策树学习开 始时，根 结 点 包 含 。 中的所有样例，其中正例占m = 备,反 例 占 次 = 告 .于 是，根据式(4.1)可计算出根结点的信息熠为 I D 3 名 字 中 的 I D 是 It­ erative Dichotomiser (迭代 二分器)的简称. / g E nt(P ) = — f p k log2 p fe = ~ (正 l°g2 记 + 诉 1 0g 2 17 ) = °-9 9 8 • 9 \\ & 9 、 I?— 1 \\ ' 76 第 4 章 决 策 树 表 4 . 1 西 瓜数据集2.0 \" 1 2 3 4 5 6 7 8 9 10n 12 13 14 15 16 17 色 泽 根蒂 青 缩 缩 乌 乌 缩 青 缩 缩 浅 青 蜷 蜷 蜷 蜷 挺 挺 缩 蜷 蜷 蜷 缩 缩 绿 黑 黑 绿 白 绿 黑 黑 黑 绿 白 白 绿 白 黑 白 . 绿 蜷 蜷 蜷 蜷 蜷 稍 稍 稍 稍 硬 硬 蜷 稍 稍 稍 蜷 蜷 乌 乌 乌 青 浅 浅 青 浅 乌 浅 青 敲 浊 沉 浊 沉 浊 浊 浊 浊 声 响 闷 响 闷 响 响 响 响 沉 清 清 浊 浊 沉 浊 浊 沉 闷 脆 脆 响 响 闷 响 响 闷 纹 清 清 清 清 清 清 稍 清 理 晰 晰 晰 晰 晰 晰 糊 晰 稍 清 模 模 稍 稍 清 模 稍 糊 晰 糊 糊 糊 糊 晰 糊 糊 脐 凹 凹 凹 凹 凹 稍 稍 稍 部 陷 陷 陷 陷 陷 凹 凹 凹 稍 平 平 平 凹 凹 稍 平 稍 凹 坦 坦 坦 陷 陷 凹 坦 凹 触 硬 感 滑 滑硬 滑硬 硬 滑 硬 滑 软 粘 软 粘 硬 滑 硬 软 硬 软 硬 硬 软 硬 硬 滑 粘 滑 粘 滑 滑 粘 滑 滑 师 是 是 是 是 是 是 是 是 否 否 否 否 否 否 否 否 否 然后，我 们 要 计 算 出当前属性集合｛色泽，根蒂，敲声，纹理，脐部，触感｝ 中每个属性的信息增益.以属性\"色泽”为例，它 有 3 个可能的取值：｛青绿，乌 黑，浅白｝.若使用该属 性对D 进行划分，则可得 到 3 个子集,分别记为：D 1 （色 泽 =青 绿 ），。2 （色泽= 乌黑），。3 （色 泽 =浅 白 ）. 子 集 加 包含编号为口，4, 6, 10, 13, 17｝的 6 个样例，其中正例占pi = 反 例 占 次 = | ； D 2 包含编号为｛2, 3, 7, 8, 9, 15）的 6 个样例，其中正、反例分",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 336
    }
  },
  {
    "page_content": "黑，浅白｝.若使用该属 性对D 进行划分，则可得 到 3 个子集,分别记为：D 1 （色 泽 =青 绿 ），。2 （色泽= 乌黑），。3 （色 泽 =浅 白 ）. 子 集 加 包含编号为口，4, 6, 10, 13, 17｝的 6 个样例，其中正例占pi = 反 例 占 次 = | ； D 2 包含编号为｛2, 3, 7, 8, 9, 15）的 6 个样例，其中正、反例分 别 占 01 = 柒 P2 = |； P 3 包 含编号为｛5, 11, 12, 14, 16）的 5 个样例，其中正、 反例分别占0 = 第 P2 = \" 根 据 式 （4.1）可 计 算 出 用 “色 泽 ”划分之后所获得 的 3 个分支结点的信息嫡为 E n t S = - ( 1 1 0 g 2 l + 1 1 0 g 2 = 1.000 , Ent(P 2 ) = - 俱嗝+ 6 2 2\\ 1 S 2 6 1 O ；= 0.918 , 1 Ent(D 3 ) 三 - ( 5 1 O g 2 5 4 1 4\\ + 5 1 O g 2 5j = 0.722 , 于是,根据式（4.2）可 计 算 出 属 性 “色泽”的信息增益为 4 . 2 划分选择 77 G ain（B , 色泽）= E n t（P ） - £ ^ E n t （P v ） V=1 ' I = 0.998 - g x 1.000 + 盘 x 0.918 x 0.722） = 0.109 . 类似的，我们可计算出其他属性的信息增益： G ain（jD,根蒂）= 0.143; G ain（P , 敲声）= 0.141; G ain（D , 纹理）= 0.381; G ain（P , 脐部）= 0.289; G ain（D ,触感）= 0.006. 显然，属 性 “纹理”的信息增益最大，于是它被选为划分属性.图4 .3 给出 了 基 于 “纹理”对根结点进行划分的结果，各分支结点所包含的样例子集显示 在结点中. [纹理= ? ） [｛1,2, 3,4, 5,6, 8, 10,15｝）[｛7, 9 ,1 3 ,14,17｝） [｛1 1 J 2 J 6 ｝] 图 4 . 3 基 于 “纹理”属性对根结点划分 然后，决策树学习算法将对每个分支结点做进一步划分.以图4 .3 中第一 个分支结点（“纹 理 =清 晰 ”）为例，该结点包含的样例集合。1 中有编号为｛1, 2, 3, 4, 5, 6, 8, 10, 15）的 9 个样例，可用属性集合为｛色泽，根蒂，敲声，脐部, “纹 理 ”",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 337
    }
  },
  {
    "page_content": "图 4 . 3 基 于 “纹理”属性对根结点划分 然后，决策树学习算法将对每个分支结点做进一步划分.以图4 .3 中第一 个分支结点（“纹 理 =清 晰 ”）为例，该结点包含的样例集合。1 中有编号为｛1, 2, 3, 4, 5, 6, 8, 10, 15）的 9 个样例，可用属性集合为｛色泽，根蒂，敲声，脐部, “纹 理 ” 不 再 作 为 候 选 触感｝. 基 于 p i 计算出各属性的信息增益： 划分属性. G ain（I ）1 , 色泽）= 0.043; G ain（A , 根蒂）= 0.458; G ain（Z）1 , 敲声）= 0.331; 脐部）= 0.458; G ain（A , 触感）= 0.458. “根蒂”、 “脐部”、 “触感” 3 个属性均取得了最大的信息增益，可任 选其中之一作为划分属性.类似的，对每个分支结点进行上述操作，最终得到的 决策树如图4 .4 所示. 4 .2 .2 增益率 在上面的介绍中，我们有意忽略了表4 .1 中 的 “编 号 ”这 一 列 .若 把 “编 78 第 4 章 决 策 树 图 4 . 4 在 西 瓜 数 据 集2.0上基于信息增益生成的决策树 号”也作为一个候选划分属性，则根据式(4.2)可计算出它的信息增益为0.998, 远大于其他候选划分属性.这很容易理解： “编号”将产 生 17个分支，每个分 支结点仅包含一个样本，这些分支结点的纯度已达最大.然而，这样的决策树显 然不具有泛化能力，无法对新样本进行有效预测. 实际上，信息增益准则对可取值数目较多的属性有所偏好，为减少这种 偏好可能带来的不利影响，著名的C 4.5决策树算法[Quinlan, 1993]不直接使 用信息增益，而 是 使 用 “增益率”(gain r a tio )来选择最优划分属性.采用与 式(4.2)相同的符号表示，增益率定义为 Gain_ratio(D, a) = G ：黑 砂 , 其中 1 V ⑷ = 一 宫 即 g2耨 (4.3) (44) 称 为 属 性 a 的 “固有值\" (intrinsic value) [Quinlan, 1 9 9 3 ].属 性 a 的可能 取值数目越多(即V 越大)，则 I V ( a ) 的值通常会越大.例如，对 表 4 .1 的西 瓜数据集 2 .0 ,有 IV(触感) = 0.874 (V = 2), IV(色泽)= 1.580 (V = 3), IV(编号) =4.088 (V = 17). 需注意的是，增益率准则对可取值数目较少的属性有所偏好，因 此 C4.5 算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式 4 . 3 剪枝处理",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 338
    }
  },
  {
    "page_content": "需注意的是，增益率准则对可取值数目较少的属性有所偏好，因 此 C4.5 算法并不是直接选择增益率最大的候选划分属性，而是使用了一个启发式 4 . 3 剪枝处理 79 [Quinlan, 1993]:.先从候选划分属性中找出信息增益高于平均水平的属性，再从 中选择增益率最高的. ’ 4 .2 .3 基尼指数 CART 决 策 树 [Breiman et a l, 1984]使 用 “基 尼 指 数 \"(Gini index)来选 择划分属性.采用与式(4.1)相同的符号，数 据 集 。 的纯度可用基尼值来度量： CART 是 Classification and Regression Tree 的简 称 ，这是一种著名的决策 树学习算 法，分类和回归 任务都可用. 3 G i n i ( Z ) ) = E E « k=l kf^ k 3 = 1 - £ 落 k=l (43) 直观来说，G in i(P )反映了从数据集D 中随机抽取两个样本，其类别标记 不一致的概率.因此,G ini(D )越小，则数据集D 的纯度越高. 采用与式(4.2)相同的符号表示,属性a 的基尼指数定义为 Gini_iiidex(。, a) = . (4.6) 0= 1 I 于是，我们在候选属性集合4 中，选择那个使得划分后基尼指数最小的属 性作为最优划分属性，即 a* = arg min Gmi.index(P, a). aeA 4 . 3 剪 枝 处 理 关于过拟合，参见2.1节. 剪枝(pruning)是决策树学习算法对付“过拟合”的主要手段.在决策树学 习中，为了尽可能正确分类训练样本，结点划分过程将不断重复，有时会造成决 策树分支过多，这时就可能因训练样本学得“太 好 ” 了，以致于把训练集自身 的一些特点当作所有数据都具有的一般性质而导致过拟合.因此，可通过主动 去掉一些分支来降低过拟合的风险. 决 策 树 剪 枝 的 基 本 策 略 有 “预 剪 枝 ”(prepruning)和 “后 剪 枝 \" (post- pruning) [Quinlan, 1993].预剪枝是指在决策树生成过程中，对每个结点在划 分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划 分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一棵完整的决策树, 然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能 80 第 4 章 决 策 树 带来决策树泛化性能提升，则将该子树替换为叶结点. 如何判断决策树泛化性能是否提升呢？这 可 使 用 2 .2 节 介绍的性能评估、",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 339
    }
  },
  {
    "page_content": "分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划 分并将当前结点标记为叶结点；后剪枝则是先从训练集生成一棵完整的决策树, 然后自底向上地对非叶结点进行考察，若将该结点对应的子树替换为叶结点能 80 第 4 章 决 策 树 带来决策树泛化性能提升，则将该子树替换为叶结点. 如何判断决策树泛化性能是否提升呢？这 可 使 用 2 .2 节 介绍的性能评估、 方 法 .本 节 假 定 采 用 留 出 法 ，即 预 留 一 部 分 数 据 用 作 “验 证 集 ” 以进行性 能 评 估 . 例 如 对 表 4 . 1 的 西 瓜 数 据 集 2 . 0 ,我 们 将 其 随 机 划 分 为 两 部 分 ，如 表 4 . 2 所示，编 号 为 ｛1,2,3,6,7,10,14,15,16,17｝的样例组成训练集，编号为 ｛4 ,5 ,8 ,9 ,11,12,13）的样例组成验证集. 表 4 . 2 西瓜数据集2.0划分出的训练集（双线上部）与验证集（双线下部） 居 1 2 3 6 7 10 14 15 16 17 评 4 5 8 9 11 12 13 泽 色 青 乌 乌 青 乌 青 浅 乌 浅 青 绿 黑 黑 绿 黑 绿 白 黑 白 绿 色 青 浅 乌 乌 浅 浅 青 泽 绿 白 黑 黑 白 白 绿 根 蜷 蜷 蜷 稍 稍 蒂 ， 缩 缩 缩 蜷 蜷 硬 稍 稍 蜷 蜷 挺 蜷 蜷 缩 缩 根 蜷 蜷 稍 稍 硬 蜷 稍 蒂 缩 缩 蜷 蜷 挺 缩 蜷 敲 浊 沉 浊 浊 浊 清 沉 浊 浊 沉 声 响 闷 响 响 响 脆 闷 响 响 闷 敲 沉 浊 浊 沉 清 浊 浊 声 闷 响 响 闷 脆 响 响 理 清 清 清 清 稍 晰 晰 晰 晰 糊 清 稍 清 模 稍 晰 T — 糊 二 厂p 晰 T 1 糊 ; 二 糊 E p 理纹 清 清 清 晰 晰 晰 稍 模 模 稍 糊 糊 糊 糊 部 凹 凹 凹 稍 稍 陷 陷 陷 凹 凹 平 凹 稍 平 稍 坦 陷 凹 坦 凹 部脐 凹 凹 稍 陷 陷 凹 稍 平 平 凹 凹 坦 坦 陷 感触 硬 硬 硬 软 软 滑 滑 滑 粘 粘 软 硬 软 硬 硬 粘 滑 粘 滑 滑 瓜好 是 . 是 是 是 是 否 否 否 否 否 感触 瓜好 硬 H e 硬 H e 硬 S C 硬 硬 软 硬 滑 滑 粘 滑 是 是 是 否 否 否 否 假定我们采用4.2.1节的信息增益准则来进行划分属性选择，则 从 表 4 .2 的 训练集将会生成一棵如图4 .5 所示的决策树.为便于讨论，我们对图中的部分 结点做了编号. 4 .3 .1 预剪枝",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 340
    }
  },
  {
    "page_content": "瓜好 是 . 是 是 是 是 否 否 否 否 否 感触 瓜好 硬 H e 硬 H e 硬 S C 硬 硬 软 硬 滑 滑 粘 滑 是 是 是 否 否 否 否 假定我们采用4.2.1节的信息增益准则来进行划分属性选择，则 从 表 4 .2 的 训练集将会生成一棵如图4 .5 所示的决策树.为便于讨论，我们对图中的部分 结点做了编号. 4 .3 .1 预剪枝 我们先讨论预剪枝.基于信息增益准则，我 们 会 选 取 属 性 “脐 部 ”来对训 练集进行划分，并 产 生 3 个分支，如 图 4 .6 所 示 .然 而 ，是否应该进行这个划分 呢？预剪枝要对划分前后的泛化性能进行估计. 在划分之前,所有样例集中在根结点.若不进行划分，则根据算法 4 .2 第 6 行 ，该结点将被标记为叶结点，其类别标记为训练样例数最多的类别，假设我们 4 . 3 剪枝处理 81 图 4 . 5 基 于 表 4 .2 生 成 的 未 剪 枝 决 策 树 1 验证集精度 色泽=?”划分前：71.4% 划分后：57. 1% 预剪枝决策：禁止划分 验证集精度 “根蒂二？” 划分前：71.4% 划分后：71.4% 预剪枝决策：禁止划分 图 4 . 6 基 于 表 4 .2 生 成 的 预 剪 枝 决 策 树 肝 驾 ? 段 不 唯 一 将 这 个 叶 结 点 标 记 为 “好瓜”. 用 表 4 . 2 的验证集对这个单结点决策树进行评 时 ，可任选其中一类. 估，则 编 号 为 ｛4 ,5 ,8 ｝的样例被分类正确，另 外 4 个样例分类错误，于是，验证 集精度为 x 100% = 42.9%. 在 用 属 性 “脐 部 ”划 分 之 后 ，图 4 . 6 中 的 结 点 ② 、③ 、@ 分 别 包 含 编 号 为 ｛1 ,2 ,3 ,1 4 ｝、｛6,7,15 ,1 7｝、｛10,16｝ 的训练样例，因 此 这 3 个结点分别 被 标 记 为 叶 结 点 “好 瓜 ”、 “好 瓜 ”、 “坏 瓜 ”. 此 时 ，验证集中编号为 ( 4 ,5 ,8 ,1 1 ,1 2 )的样例被分类正确，验证集精度为| x 100% = 71.4% > 42.9%. 于是，用 “脐部”进行划分得以确定. 82 第 4 章 决 策 树 然后，决策树算法应该对结点②进行划分，基于信息增益准则将挑选出划 分 属 性 “色泽”. 然而，在 使 用 “色 泽 ”划分后，编 号 为 ｛5｝的验证集样本分类 结果会由正确转为错误，使得验证集精度下降为57.1%.于是,预剪枝策略将禁 止结点②被划分. 对结点③，最优划分属性为“根蒂”，划分后验证集精度仍为71.4%.这个",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 341
    }
  },
  {
    "page_content": "82 第 4 章 决 策 树 然后，决策树算法应该对结点②进行划分，基于信息增益准则将挑选出划 分 属 性 “色泽”. 然而，在 使 用 “色 泽 ”划分后，编 号 为 ｛5｝的验证集样本分类 结果会由正确转为错误，使得验证集精度下降为57.1%.于是,预剪枝策略将禁 止结点②被划分. 对结点③，最优划分属性为“根蒂”，划分后验证集精度仍为71.4%.这个 划分不能提升验证集精度，于是,预剪枝策略禁止结点③被划分. 对结点④，其所含训练样例已属于同一类，不再进行划分. 于是，基于预剪枝策略从表4.2数据所生成的决策树如图4.6所示,其验证 集精度为71.4%.这是一棵仅有一层划分的决策树,亦称“决 策 树 桩 \"(decision stump). 对 比 图 4.6和 图 4.5可 看出，预 剪 枝 使 得 决 策 树 的 很 多 分 支 都 没 有 “展 开 ”，这不仅降低了过拟合的风险，还显著减少了决策树的训练时间开销和测 试时间开销.但另一方面，有些分支的当前划分虽不能提升泛化性能、甚至可 能导致泛化性能暂时下降，但在其基础上进行的后续划分却有可能导致性能显 著提高；预 剪 枝 基 于 “贪 心 ”本质禁止这些分支展开，给预剪枝决策树带来了 欠拟合的风险. 4 3 2 后剪枝 后剪枝先从训练集生成一棵完整决策树，例如基于表4.2的数据我们得到 如 图 4.5所示的决策树.易知，该决策树的验证集精度为42.9%. 后 剪 枝 首 先 考 察 图 4.5中 的 结 点 ⑥ .若 将 其 领 衔 的 分 支 剪 除 ，则相当于 把⑥替换为叶结点.替换后的叶结点包含编号为｛7,15｝的训练样本，于是，该 叶结点的类别标记为“好 瓜 ”，此时决策树的验证集精度提高至57.1%.于是, 后剪枝策略决定剪枝,如图4.7所示. 此种情形下验证集精度 虽无提高，但根据奥卡姆 剃刀准则，剪枝后的模型 更好.因此，实际的决策树 算法在此种情形下通常要 进行剪枝.本书为妥图的 方便，采取了不剪枝的保 守策略. 然后考察结点⑤，若将其领衔的子树替换为叶结点，则替换后的叶结点包 含 编 号 为 ｛6,7,15｝的训练样例，叶 结点类别标记为“好瓜”，此时决策树验证 集精度仍为57.1%.于是，可以不进行剪枝. 对结点②，若将其领衔的子树替换为叶结点，则替换后的叶结点包含编号 为 ｛1,2,3,14｝的训练样例，叶 结 点 标 记 为 “好瓜”.此时决策树的验证集精度 提 高 至 71.4%.于是,后剪枝策略决定剪枝. 对结点③和①，若将其领衔的子树替换为叶结点，则所得决策树的验证集 精度分别为71.4%与 42.9%,均 未 得 到 提 高 .于 是 它 们 被 保 留 .. 4 . 4 连续与缺失值",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 342
    }
  },
  {
    "page_content": "为 ｛1,2,3,14｝的训练样例，叶 结 点 标 记 为 “好瓜”.此时决策树的验证集精度 提 高 至 71.4%.于是,后剪枝策略决定剪枝. 对结点③和①，若将其领衔的子树替换为叶结点，则所得决策树的验证集 精度分别为71.4%与 42.9%,均 未 得 到 提 高 .于 是 它 们 被 保 留 .. 4 . 4 连续与缺失值 83 最终，基于后剪枝策略从表4 .2 数据所生成的决策树如图4 .7 所示，其验证 集精度为71.4%. 对 比 图 4 .7 和 图 4 .6 可看出，后剪枝决策树通常比预剪枝决策树保留了更 多的分支.一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预 剪枝决策树.但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上 地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树 和预剪枝决策树都要大得多. 4 . 4 连 续 与 缺 失 值 4 .4 .1 连续值处理 到目前为止我们仅讨论了基于离散属性来生成决策树.现实学习任务中常 会遇到连续属性，有必要讨论如何在决策树学习中使用连续属性. 由于连续属性的可取值数目不再有限，因此，不能直接根据连续属性的可 取值来对结点进行划分.止匕时，连续属性离散化技术可派上用场.最简单的策 略是采用二分法(bi-partition)对连续属性进行处理，这 正 是 C 4.5决策树算法中 采用的机制[Quinlan, 1993]. 给定样本集D 和 连 续 属 性 生 假 定 。在 。 上出现了 n 个不同的取值，将这 些值从小到大进行排序，记 为 包 \\ Q 2, . 一，〃 } . 基于划分点t可 将 D 分为子集 D - 和 D = 其 中 D - 包含那些在属性。上取值不大于t 的样本，而 D + 则包含 那些在属性a 上取值大于t的样本.显然，对相邻的属性取值出与出+ i 来说，t 84 第 4 章 决 策 树 在区间依,d + 1 ) 中取任意值所产生的划分结果相同.因此,对连续属性见 我们 可考察包含n - 1 个元素的候选划分点集合 ｛号 % \" 飞 ” 】卜 (4.7) 可将划分点设为该属性 在 训 练 集 中 出 现 的 不 大 于中位点的最大值，从而 使得最终决策树使用的划 分点都在训练集中出现过 [Quinlan, 1993]. 即 把 区 间 依 看 + 1 ) 的 中 位 点 追 料 作 为 候 选 划 分 点 .然 后 ，我们就可像离散 属性值一样来考察这些划分点，选取最优的划分点进行样本集合的划分.例如, 可对式(4.2)稍加改造： G a in (2?, a) = m ax G ain (B , a, t) = 跷 E n t ( 0 —",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 343
    }
  },
  {
    "page_content": "即 把 区 间 依 看 + 1 ) 的 中 位 点 追 料 作 为 候 选 划 分 点 .然 后 ，我们就可像离散 属性值一样来考察这些划分点，选取最优的划分点进行样本集合的划分.例如, 可对式(4.2)稍加改造： G a in (2?, a) = m ax G ain (B , a, t) = 跷 E n t ( 0 — 5 2 耨 , (4.8) 其 中 G a i n ( R a 工)是样本集D 基于 划 分 点 t 二分后的信息增益.于是，我们就 可选择使G a in (P , a, t ) 最大化的划分点. 作为一个例子，我 们 在 表 4 . 1 的西瓜数据集 2 .0 上 增 加 两 个 连 续 属 性 “密 度 ”和 “含糖率”，得 到 表 4 .3 所示的西瓜数据集3 . 0 . 下面我们用这个数据集 来生成一棵决策树. 表 4 . 3 西瓜数据集3.0 ~ i S t o ~ ~ ~ S i w 5 s ~ 含 糖 率 ~ m 1 2 3 4 5 6 7 8 3 0 1 2 3 4 5 6 7 c 1 1 1 1 L 1 1 1 青 乌 乌 青 浅 青 乌 乌 绿 黑 黑 绿 白 绿 黑 黑 乌 青 浅 浅 青 浅 乌 浅 青 黑 绿 白 白 绿 白 黑 白 绿 幡 蜷 蜷 蜷 幡 稍 稍 稍 缩 缩 缩 缩 缩 蜷 蜷 蜷 稍 硬 硬 蜷 稍 稍 稍 蜷 蜷 蜷 挺 挺 缩 蜷 蜷 蜷 缩 缩 向 浊 n C M 沉 T 浊 向 n 沉 XL 国 — 浊 向 n 浊 向 nH 浊 向 口 浊 向 口 湎 清 清 御 衡 湎 御 湖 州 闷 脆 脆 响 响 闷 响 响 闷 清 清 清 清 清 清 稍 清 晰 晰 晰 晰 晰 晰 糊 晰 稍 清 模 模 稍 稍 清 模 稍 糊 晰 糊 糊 糊 糊 晰 糊 糊 凹 凹 凹 凹 凹 稍 稍 稍 陷 陷 陷 陷 陷 凹 凹 凹 稍 平 平 平 凹 凹 稍 平 稍 凹 坦 坦 坦 陷 陷 凹 坦 凹 硬 硬 硬 硬 硬 软 软 硬 滑 滑 滑 滑 滑 粘 粘 滑 硬 软 硬 软 硬 硬 软 硬 硬 滑 粘 滑 粘 滑 滑 粘 滑 滑 0.697 0.774 0.634 0.608 0.556 0.403 0.481 0.437 0.666 0.243 0.245 0.343 0.639 0.657 0.360 0.593 0.719 0. 0. 0. 0. 0. 0. 0. 0. 46 37 26 31 21 23 14 21 0 6 4 8 5 7 9 1 0. 0. 0. 0. 0. 0. 0. 0. 0.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 344
    }
  },
  {
    "page_content": "0.697 0.774 0.634 0.608 0.556 0.403 0.481 0.437 0.666 0.243 0.245 0.343 0.639 0.657 0.360 0.593 0.719 0. 0. 0. 0. 0. 0. 0. 0. 46 37 26 31 21 23 14 21 0 6 4 8 5 7 9 1 0. 0. 0. 0. 0. 0. 0. 0. 0. 09 26 05 09 16 19 37 04 10 1 7 7 9 . 1 8 0 2 3 是 是 是 是 是 是 是 是 否 否 否 否 否 否 否 否 否 4 . 4 连续与缺失值 85 对 属 性 “密 度 \" 在 决 策 树 学 习 开 始 时 ，根 结 点 包 含 的 1 7 个 训 练 样 本 在 该 属 性 上 取 值 均 不 同 . 根 据 式 ( 4 . 7 ) , 该 属 性 的 候 选 划 分 点 集 合 包含 16 个 候 选 值 ：与 度 = {0.244, 0.294, 0.351, 0.381, 0.420, 0.459, 0.518, 0.574, 0.600, 0.621, 0.636, 0.648, 0.661, 0.681, 0.708, 0 .7 4 6 } .由式(4 .8 )可计算 出 属 性 “密度”的信息增益为0.262,对应于划分点0.381. 对 属 性 “含 糖 率 ”，其 候 选 划 分 点 集 合 也 包 含 1 6 个 候 选 值 :玲 糖 率 = {0,049, 0.074, 0.095, 0.101, 0.126, 0.155, 0.179, 0.204, 0.213, 0.226, 0.250, 0.265, 0.292, 0.344, 0.373, 0 .4 1 8 }.类似的，根据式(4.8)可计算出其信息增益为0.349, 对应于划分点0.126. 再 由 4.2.1 节可知，表 4 .3 的数据上各属性的信息增益为 Gain（3 色泽）= 0.109; 根蒂）=0.143; Gain（D ,敲声）= 0.141; Gain（。,纹理）= 0.381; Gain（D ,脐部）= 0.289; Gam（B , 触感）= 0.006; Gain。 ,密度）= 0.262; Gain。 ,含糖率）= 0.349. 于是，“纹理”被选作根结点划分属性，此后结点划分过程递归进行,最终 生成如图4 .8 所示的决策树. 例如在父结点上使用了 “密 度 W0.381” ，不 会 禁 止 在 子 结 点 上 使 用 “密 度 W0.294” .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 345
    }
  },
  {
    "page_content": "Gam（B , 触感）= 0.006; Gain。 ,密度）= 0.262; Gain。 ,含糖率）= 0.349. 于是，“纹理”被选作根结点划分属性，此后结点划分过程递归进行,最终 生成如图4 .8 所示的决策树. 例如在父结点上使用了 “密 度 W0.381” ，不 会 禁 止 在 子 结 点 上 使 用 “密 度 W0.294” . 图 4 . 8 在 西瓜数据集 3 .0 上基于信息增益生成的决策树 需注意的是，与离散属性不同，若当前结点划分属性为连续属性，该属性还 可作为其后代结点的划分属性. 4 .4 .2 缺失值处理 现实任务中常会遇到不完整样本，即样本的某些属性值缺失.例如由于诊 测成本、隐私保护等因素，患者的医疗数据在某些属性上的取值(如H IV 测试 结果)未知；尤其是在属性数目较多的情况下，往往会有大量样本出现缺失值. 如果简单地放弃不完整样本，仅使用无缺失值的样本来进行学习，显然是对数 86 第 4 章 决 策 树 据信息极大的浪费.例如，表 4 .4 是 表 4 .1 中的西瓜数据集2 .0 出现缺失值的版 本，如果放弃不完整样本，则 仅 有 编 号 ｛4, 7, 14, 16｝的 4 个样本能被使用.显 然，有必要考虑利用有缺失属性值的训练样例来进行学习. 表 4 . 4 西瓜数据集2.0a 编号 W 4 0 嬴 向 n - 黑 黑 绿 一 绿 黑 黑 乌 乌 青 青 乌 乌 蜷 蜷 蜷 蜷 蜷 稍 稍 稍 缩 缩 缩 缩 缩 蜷 蜷 蜷 - N p u l X T U I 浊 沉 一 3 沉 浊 向 口 浊 向 浊 向 口 浊 向 口 n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 乌 青 浅 浅 一 浅 乌 浅 青 黑 绿 白 白 一 白 黑 白 绿 硬 硬 蜷 稍 稍 稍 蜷 - 挺 挺 缩 蜷 蜷 蜷 缩 . _ N \\ b l 沉 清 胸 二L 腾 清 一 浊 向 沉 闪 浊 向 浊 向 沉 闪 >LU — \\ L I f l n n Of 陷 凹 陷 凹 陷 凹 陷 凹 陷 凹 一 稍 稍 凹 凹 稍 平 平 平 凹 凹 一 平 稍 凹 坦 坦 坦 陷 陷 坦 凹 清 清 清 清 清 清 稍 晰 晰 晰 晰 晰 晰 糊 . 稍 糊 横 横 稍 稍 清 模 稍 糊 糊 糊 糊 晰 糊 糊 好 瓜 . 是 是 是 是 是 是 是 是 否 否 否 否 否 否 否 否 否 硬 一 硬 硬 硬 软 软 硬 滑 一 滑 滑 滑 粘 粘 滑 硬 软 一 软 硬 硬 软 硬 硬 滑 粘 粘 滑 滑 粘 滑 滑",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 346
    }
  },
  {
    "page_content": "凹 坦 坦 坦 陷 陷 坦 凹 清 清 清 清 清 清 稍 晰 晰 晰 晰 晰 晰 糊 . 稍 糊 横 横 稍 稍 清 模 稍 糊 糊 糊 糊 晰 糊 糊 好 瓜 . 是 是 是 是 是 是 是 是 否 否 否 否 否 否 否 否 否 硬 一 硬 硬 硬 软 软 硬 滑 一 滑 滑 滑 粘 粘 滑 硬 软 一 软 硬 硬 软 硬 硬 滑 粘 粘 滑 滑 粘 滑 滑 我们需解决两个问题：( 1 ) 如何在属性值缺失的情况下进行划分属性选择? ⑵ 给 定 划 分 属 性 ，若样本在该属性上的值缺失,如何对样本进行划分？ 给定训练集D 和 属 性 血 令 £)表示D 中在属性a 上没有缺失值的样本子 集.对问题( 1 ) ,显然我们仅可根据D 来判断属性a 的优劣.假定属性。有 V■个 可 取 值 ｛* 俏 … ，产 ｝,令 力 。表 示 力 中 在 属 性 . 上取值为愣 的样本子集,D k 表 示 D 中属于第k 类 (k = 1 , 2 , , 3 ) 的样本子集，则显然有力= u 3 瓦, 根 餐 慧 翼 嘘 翼 力 = U L 加 假 定 我 们 为 每 个 样 本 出 赋 予 一 个 权 重 ” 并定义 始化为1. Wx = Pk = v W x ~ _ ^2x ebv W x f V - W x (1 WkW 3 ) , (1 J W V ) . (4.9) (4.10) (4.11) 4 . 4 连续与缺失值 87 直观地看，对 属 性 见 . 表示无缺失值样本所占的比例,pk 表示无缺失值样本中 第 k 类所占的比例，% 则表示无缺失值样本中在属性a 上取值展的样本所占 的比例.显然，£ 黑 讥 = 1, £ 乙 九 = 1. 基于上述定义，我们可将信息增益的计算式(4.2)推广为 Gain(D, a) = p x Gain(D, a) = p x (Eiit (力 )一2 / Ent ( / 0) ) , (4.12) 其中由式(4.1),有 〜 3 Ent (力)= 一 £ 讥 log2 Pk . k=l 对问题(2 ),若 样 本 %在 划 分 属 性 a 上的取值已知，则将宓划入与其取值对 应的子结点，且样本权值在子结点中保持为仅重.若样本宓在划分属性a 上的取 值未知，则 将 x 同时划入所有子结点，且样本权值在与属性值M 对应的子结点 中调整为河•馍招直观地看，这就是让同一个样本以不同的概率划入到不同的 子结点中去. C4.5算法使用了上述解决方案[Quinlan, 1993],下面我们以表4 .4 的数据 集为例来生成一棵决策树.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 347
    }
  },
  {
    "page_content": "应的子结点，且样本权值在子结点中保持为仅重.若样本宓在划分属性a 上的取 值未知，则 将 x 同时划入所有子结点，且样本权值在与属性值M 对应的子结点 中调整为河•馍招直观地看，这就是让同一个样本以不同的概率划入到不同的 子结点中去. C4.5算法使用了上述解决方案[Quinlan, 1993],下面我们以表4 .4 的数据 集为例来生成一棵决策树. 在学习开始时，根 结 点 包 含 样 本 集 。 中 全 部 1 7 个样例，各样例的权值 均 为 1 . 以 属 性 “色 泽 ”为例，该属性上无缺失值的样例子集力包含编号为 {2,3 ,4 ,6 ,7 ,8 ,9 ,1 0 ,11,12,14,15,16,17)的 14 个样例.显然，D 的信息嫡为 2 Ent(D) = — £ 讥 log2汲 k=l = - ( l 4 1 O g 2 14 + 14 1 O g 2 i 4 j = 0 -9 8 5 - 令 b\\ b 2 与力 3 分 别 表 示 在 属 性 “色 泽 ”上 取 值 为 “青绿” “乌黑”以 及 “浅白”的样本子集，有 2 E n t ( / 1) = — (% Iog2 4 + 4 b g 2 4 J = 1-000 , /2 2 ~ 2\\ 4 Ent(D ) = — ( - log2 - + - log2 - } = 0.918 , / 4 2 \\ 2 88 第 4 章 决 策 树 E nt（力3）= —（号 log2 % ； log2 = 0.000 , 因此，样本子集b 上 属 性 “色泽”的信息增益为 Gain① , 色泽）= E nt（P ） — E nt（力 ） V=1 3 ' x 1.000 + — x 0.918 + — x 0.000 4 6 （4 - \\1 4 14 14 = 0.985 - = 0.306 . 于是，样 本 集 D 上 属 性 “色泽”的信息增益为 ~ Gain（。,色泽）= p x Gain（。,色泽）= — x 0.306 = 0.252 . ， 14 17 类似地可计算出所有属性在D 上的信息增益： Gain（n , 色泽）= 0.252; Gain（B ,根蒂）= 0.171; Gain（29,敲声）= 0.145; Gain（Z）, 纹理）= 0.424; Gain（P , 脐部）= 0.289; Gain（j9 ,触I 感）= 0.006. “纹理”在所有属性中取得了最大的信息增益，被用于对根结点进行划分.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 348
    }
  },
  {
    "page_content": "14 17 类似地可计算出所有属性在D 上的信息增益： Gain（n , 色泽）= 0.252; Gain（B ,根蒂）= 0.171; Gain（29,敲声）= 0.145; Gain（Z）, 纹理）= 0.424; Gain（P , 脐部）= 0.289; Gain（j9 ,触I 感）= 0.006. “纹理”在所有属性中取得了最大的信息增益，被用于对根结点进行划分. 划分结果是使编号为｛1 ,2 ,3 ,4 ,5 ,6 ,1 5 )的 样 本 进 入 “纹理= 清晰”分支，编号 为 ｛7,9,13,14,17｝的 样 本 进 入 “纹理= 稍糊”分支,而编号为｛11,12,16｝的样 本 进 入 “纹理= 模 糊 ”分支，且样本在各子结点中的权重保持为1 . 需注意的 是，编 号 为 ｛8｝的 样 本 在 属 性 “纹 理 ”上出现了缺失值，因此它将同时进入三 个分支中，但权重在三个子结点中分别调整为孟、/ 和 青 编 号 为 ｛10｝的样 本有类似划分结果. 上述结点划分过程递归执行，最终生成的决策树如图4.9 所示. 4 . 5 多变量决策树 若我们把每个属性视为坐标空间中的一个坐标轴，则 d 个属性描述的样本 就对应了 d 维空间中的一个数据点，对样本分类则意味着在这个坐标空间中寻 找不同类样本之间的分类边界.决策树所形成的分类边界有一个明显的特点: 轴平行(axis-parallel),即它的分类边界由若干个与坐标轴平行的分段组成. 4 . 5 多变量决策树 89 ［学理二？ ） 稍糊 清晰 ［敲 最 ? ］ 沉闷 浊响 Y ■脆 丽 ） ［脐部二? -坏乱 凹 隐 稍凹 于 坦 （根蒂二?］ 稍 蜷 、 稗挺 巅 ） ［色泽= ? ］国 诃 青受 好瓜 乌 黑 、7 戋白 触感二？ ）0 5 ; 一 白 西 瓜 数 据 集 3 .0 a 是由 表 4 .3 的 西 瓜 数 据 集 3 .0 忽 略离散属性而得. 图 4 . 9 在 西瓜数据集2 .0 a上基于信息增益生成的决策树 以 表 4 .5 中 的 西 瓜 数 据 3 .0 a 为 例 ，将 它 作 为 训 练 集 可 学 得 图 4.10 所 示 的 决 策 树 ,这 棵 树 所 对 应 的 分 类 边 界 如 图 4.11 所示. 表 4 . 5 西瓜数据集3.0a ~ 1 2 3 4 5 6 7 8 9 10 11 12 1 1 1 1 4 5 6 7 O46 3 7 6 2 6 4 8 5 5 含 糖 率 ~ m 796S 6 4 7 7 S 4 3 6 O. 6 O. 08 65 O..5 3 0 / S 8 1 / 7 3 /",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 349
    }
  },
  {
    "page_content": "表 4 . 5 西瓜数据集3.0a ~ 1 2 3 4 5 6 7 8 9 10 11 12 1 1 1 1 4 5 6 7 O46 3 7 6 2 6 4 8 5 5 含 糖 率 ~ m 796S 6 4 7 7 S 4 3 6 O. 6 O. 08 65 O..5 3 0 / S 8 1 / 7 3 / O.31 2 O. 15 7 S 2 3 4 9 6 J 1 1 O. O. 66£ 0. 4 2 0. 4 0.S 4 .2 .3 6396 6 57 O 6 3 0. 5 9 3 0. 7 19 0. 6 09 2 0. 67 7 0. 05 99 0..0 6 6 1 1 9 8 1 0. .370 2 04 1 03 0. 是 是 是 是 是 是 是 是 否 否 否 否 否 否 否 否 否 显 然 ，分 类 边 界 的 每 一 段 都 是 与 坐 标 轴 平 行 的 .这 样 的 分 类 边 界 使 得 学 习 结 果 有 较 好 的 可 解 释 性 ，因 为 每 一 段 划 分 都 直 接 对 应 了 某 个 属 性 取 值 .但 在 学 习 任 务 的 真 实 分 类 边 界 比 较 复 杂 时 ，必 须 使 用 很 多 段 划 分 才 能 获 得 较 好 的 近 似 , 90 第 4 章 决 策 树 ［含糖率4 0 .126?) 图 4 . 1 0 在 西 瓜 数 据 集 3 、0 a 上生成的决策树 这样的多变量决策树亦 称 \" 斜 决 策 树 \" (oblique decision tree). 如 图 4.12所示；此时的决策树会相当复杂，由于要进行大量的属性测试，预测 时间开销会很大. 若能使用斜的划分边界，如 图 4 .1 2 中红色线段所示，则决策树模型将大为 简 化 . “多 变 量 决 策 树 \"(multivariate decision tre e )就是能实现这样的“斜划 分 ”甚至更复杂划分的决策树.以实现斜划分的多变量决策树为例，在此类决 策树中，非叶结点不再是仅对某个属性,而是对属性的线性组合进行测试;换言 之，每 个 非 叶 结 点 是 一 个 形 如 = t 的线性分类器，其 中 Wi是属性电 的 权 重 ,她 和 t可在该结点所含的样本集和属性集上学得.于是,与传统的“单 变 量 决 策 树 \"(univariate decision tr e e ) 不同，在多变量决策树的学习过程中? 不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分 4 . 5 多变量决策树 91 图 4 . 1 2 决策树对复杂分类边界的分段近似",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 350
    }
  },
  {
    "page_content": "的 权 重 ,她 和 t可在该结点所含的样本集和属性集上学得.于是,与传统的“单 变 量 决 策 树 \"(univariate decision tr e e ) 不同，在多变量决策树的学习过程中? 不是为每个非叶结点寻找一个最优划分属性，而是试图建立一个合适的线性分 4 . 5 多变量决策树 91 图 4 . 1 2 决策树对复杂分类边界的分段近似 线性分类器参见第3 章. 类 器 .例 如 对 西 瓜 数 据 3 . 0 a ,我们可学得图 4 .1 3这样的多变量决策树，其分类 边界如图 4 .1 4所示. 1—0.800义密度-0.044义含糖率 W—0.3137] 图 4 . 1 3 在西瓜数据集 3 .0 a上生成的多变量决策树 图 4 . 1 4 图 4.13多变量决策树对应的分类边界 92 第 4 章 决 策 树 4 . 6 阅读材料 决策树学习算法最著名的代表是ID3 [Quinlan, 1979, 1986]> C4.5 [Quin­ lan, 1993]和 CART [Breiman et al., 1984]. [Murthy, 1998]提供了一个关于决 策树文献的阅读指南.C4.5Rule是 一 个 将 C 4.5决策树转化为符号规则的算法 [Quinlan, 1993],决策树的每个分支可以容易地重写为一条规则，但 C4.5Rule 算法在转化过程中会进行规则前件合并、删减等操作，因此最终规则集的泛化 性能甚至可能优于原决策树. 在信息增益、增 益 率 、基尼指数之外，人们还设计了许多其他的准则用 于决策树划分选择，然 而 有 实 验 研 究 表 明 [Mingers, 1989b],这些准则虽然对 决策树的尺寸有较大影响，但对泛化性能的影响很有限. [Raileanu and Stoffel, 2004]对信息增益和基尼指数进行的理论分析也显示出，它们仅在2 % 的情况下 会有所不同.4.3 节介绍了决策树剪枝的基本策略;剪枝方法和程度对决策树泛 化性能的影响相当显著，有实验研究表明[Mingers, 1989a],在数据带有噪声时 通过剪枝甚至可将决策树的泛化性能提高25%. 多变量决策树算法主要有0C1 [Murthy et al., 1994]和 [Brodley and Ut- goff, 1995]提出的一系列算法.0 C 1 先贪心地寻找每个属性的最优权值，在局 部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界；[Brodley and Utgoff, 1995]则直接引入了线性分类器学习的最小二乘法，还有一些算法 试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 351
    }
  },
  {
    "page_content": "goff, 1995]提出的一系列算法.0 C 1 先贪心地寻找每个属性的最优权值，在局 部优化的基础上再对分类边界进行随机扰动以试图找到更好的边界；[Brodley and Utgoff, 1995]则直接引入了线性分类器学习的最小二乘法，还有一些算法 试图在决策树的叶结点上嵌入神经网络，以结合这两种学习机制的优势，例如 “感知机树”(Perceptron tree) [Utgoff, 1989b]在决策树的每个叶结点上训练 一个感知机，而 [Guo and Gelfand, 1992]则直接在叶结点上嵌入多层神经网络. 有 一 些 决 策 树学习算法可进行“增量学习\" (incremental learning),即在 接收到新样本后可对已学得的模型进行调整，而不用完全重新学习.主要机 制是通过调整分支路径上的划分属性次序来对树进行部分重构，代表性算法 有 ID4 [Schlimmer and Fisher, 1986] > ID5R [Utgoff, 1989a] > ITI [Utgoff et al., 1997]等.增量学习可有效地降低每次接收到新样本后的训练时间开销，但多步 增量学习后的模型会与基于全部数据训练而得的模型有较大差别. 本质上，各种特征选择 方法均可用于决策树的划 分属性选择.特征选择参 见 第 11章. 关于感知机和神经网络, 参见 第 5 章. 习题 93 4.1 试证明对于不含冲突数据（即特征向量完全相同但标记不同）的训练 集,必存在与训练集一致（即训练误差为0）的决策树. 4.2 试 析 使 用 “最小训练误差”作为决策树划分选择准则的缺陷. 4.3 试编程实现基于信息嫡进行划分选择的决策树算法，并 为 表 4 .3 中数 据生成一棵决策树. 4.4 试编程实现基于基尼指数进行划分选择的决策树算法，为 表 4 .2 中数 据生成预剪枝、后剪枝决策树，并与未剪枝决策树进行比较. 4.5 试编程实现基于对率回归进行划分选择的决策树算法，并 为 表 4 .3 中 数据生成一棵决策树. U C I数据集见 http://archive.ics.uci.edu/ml/. 4.6 试 选 择 4 个 UCI数据集,对上述3 种算法所产生的未剪枝、预剪枝、 统 计 显 著 性 检 验 参 见 后剪枝决策树进行实验比较，并进行适当的统计显著性检验. 2.4 节. 4.7 图 4 .2 是一个递归算法，若面临巨量数据，则决策树的层数会很深，使 用 递 归 方 法 易 导 致 “栈 ”溢 出 .试 使 用 “队 列 ”数据结构，以参数 加 如 。磔防控制树的最大深度，写出与图4 .2 等价、但不使用递归的 决策树生成算法. 4.8",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 352
    }
  },
  {
    "page_content": "统 计 显 著 性 检 验 参 见 后剪枝决策树进行实验比较，并进行适当的统计显著性检验. 2.4 节. 4.7 图 4 .2 是一个递归算法，若面临巨量数据，则决策树的层数会很深，使 用 递 归 方 法 易 导 致 “栈 ”溢 出 .试 使 用 “队 列 ”数据结构，以参数 加 如 。磔防控制树的最大深度，写出与图4 .2 等价、但不使用递归的 决策树生成算法. 4.8 * 试将决策树生成的深度优先搜索过程修改为广度优先搜索，以参数 MaxNode控制树的最大结点数，将 题 4 .7 中基于队列的决策树算法 进 行 改 写 .对 比 题 4 .7 中的算法，试析哪种方式更易于控制决策树所 需存储不超出内存. 4.9 试 将 4.4.2节对缺失值的处理机制推广到基尼指数的计算中去. 西 瓜 数 据 集 3 . 0 见 p.84 的 表 4.3. 西瓜数据集3.0 上产生的结果. 4.10 从网上下载或自己编程实现任意一种多变量决策树算法，并观察其在 94 第 4 章 决 策 树 参考文献 Breiman, L., J. Friedman, C. J. Stone, and R. A. Olshen. (1984). Classification and Regression Trees. Chapman & Hall/CRC, Boca Raton, FL. Brodley, C. E. and P. E. Utgoff. (1995). ^Multivariate decision trees.55 Machine Learning1 19(1):45-77. Guo, H. and S. B. Gelfand. (1992). ^Classification trees with neural network feature e x tra c tio n .IEEE Transactions on Neural Networks, 3(6):923-933. Mingers, J. (1989a). “An empirical comparison of pruning methods for decision tree induction.\" Machine Learning, 4(2):227-243. Mingers, J. (1989b). “An empirical comparison of selection measures for decision-tree induction.^^ Machine Learning^ 3(4):319-342.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 353
    }
  },
  {
    "page_content": "tree induction.\" Machine Learning, 4(2):227-243. Mingers, J. (1989b). “An empirical comparison of selection measures for decision-tree induction.^^ Machine Learning^ 3(4):319-342. Murthy, S. K. (1998). uAutomatic construction of decision trees from data: A multi-disciplinary survey?5 Data Mining and Knowledge Discovery1 2(4): 345-389. Murthy, S. K., S. Kasif, and S. Salzberg. (1994). \"A system for induction of oblique decision trees.\" Journal of Artificial Intelligence Research^ 2:1-32. Quinlan, J. R. (1979). ^Discovering rules by induction from large collections of ex am p les.In Expert Systems in the Micro-electronic Age (D. Michie, ed.), 168-201, Edinburgh University Press, Edinburgh, UK. Quinlan, J. R. (1986). \"Induction of decision trees.5, Machine Learning, 1(1): 81-106. Quinlan, J. R. (1993). C4.5: Programs for Machine Learning. Morgan Kauf­ mann, San Mateo, CA. Raileanu, L. E. and K. Stoffel. (2004). ^Theoretical comparison between the Gini index and information gain criteria.55 Annals of Mathematics and Arti­ ficial Intelligence^ 41(1):77-93.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 354
    }
  },
  {
    "page_content": "Gini index and information gain criteria.55 Annals of Mathematics and Arti­ ficial Intelligence^ 41(1):77-93. Schlimmer, J. C. and D. Fisher. (1986). “A case study of incremental concept induction.\" In Proceedings of the 5th National Conference on Artificial In­ telligence (AAAI), 495-501, Philadelphia, PA. Utgoff, P. E. (1989a). ^Incremental induction of decision trees.\" Machine Learning, 4(2):161-186. 休息一会儿 95 Utgoff, P. E. (1989b). “Perceptron trees: A case study in hybrid concept rep- resenations.^^ Connection Science11(4):377-391. Utgoff, P. E., N. C. Berkman, and J. A. Clouse. (1997). ^Decision tree induction based on effcient tree restructuring?5 Machine Learning^ 29(1):5-44. 休 息 一 会 儿 小故事：决策树与罗斯•昆兰 说起决策树学习，就必然要谈到澳大利亚计算机科学家 罗斯・昆兰(J. Ross Quinlan, 1943一 ). 最 初 的 决 策 树 算 法 是心理学家兼计算机科学家E. B. Hunt 1962年 在 研 究 人 类 的 概 念 学 习 过 程 时 提 出 的 CLS (Concept Learning System ),这个算法确立了决策树“分而 治之”的 学 习 策 略.罗斯•昆兰在H u n t的指导下于1968年在美国华盛顿大学 获得计算机博士学位，然后到悉尼大学任教.1978年他在学术假时到斯坦福大 学访问，选修了图灵的助手D. M ichie开设的一门研究生课程.课上有一个大 作业，要求写程序来学习出完备正确的规则，以判断国际象棋残局中一方是否 会在两步棋后被将死.昆兰写了 一个类似于C L S 的程序来完成作业，其中最重",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 355
    }
  },
  {
    "page_content": "获得计算机博士学位，然后到悉尼大学任教.1978年他在学术假时到斯坦福大 学访问，选修了图灵的助手D. M ichie开设的一门研究生课程.课上有一个大 作业，要求写程序来学习出完备正确的规则，以判断国际象棋残局中一方是否 会在两步棋后被将死.昆兰写了 一个类似于C L S 的程序来完成作业，其中最重 要的改进是引入了信息增益准则.后来他把这个工作整理出来在1979年发表, 这 就 是 ID 3 算法. 1986年 Machine Learning杂志创刊, 昆兰应邀在创刊号上重新发表了 ID3 算法，掀起了决策树研究的热潮.短短几年间众多决策树算法问世，ID4、ID5 等名字迅速被其他研究者提出的算法占用，昆兰只好将自己的ID 3 后继算法命 名 为 C 4.0,在此基础上进一步提出了著名的C 4 .5 .有趣的是，昆兰自称C4.5仅 是 对 C4.0做了些小改进，因 此 将 它 命 名 为 “第 4 .5 代分类器”，而将后续的商 C4.0 是 Classifier 4.0 的 简称. C 4 .5 在 W E K A 中的实 现 称 为 J4.8. 业化版本称为C5.0. 第 5 章 神 经 网 络 5 . 1 神经元模型 本 书 所 谈 的 是 “人工神 经 网 络 ” ，不 是 生 物 学 意 义上的神经网络. 神经网络(neural netw orks)方面的研究很早就已出现，今 天 “神经网络” 已是一个相当大的、多学科交叉的学科领域.各相关学科对神经网络的定义多 这 是 T. Kohonen 1988 年在 Neural Networks 创刊 号上给出的定义. 种多样，本书采用目前使用得最广泛的一种，即 “神经网络是由具有适应性的 简单单元组成的广泛并行互连的网络，它的组织能够模拟生物神经系统对真实 世界物体所作出的交互反应” [Kohonen, 1 9 8 8 ].我们在机器学习中谈论神经网 络 时 指 的 是 “神经网络学习”，或者说，是机器学习与神经网络这两个学科领 域的交叉部分. neuron 亦称 unit. 神经网络中最基本的成分是神经元(neuron)模型，即 上 述 定 义 中 的 “简单 单元”.在生物神经网络中，每个神经元与其他神经元相连，当 它 “兴奋”时, 就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神 亦 称 bias. 注 意 不 是 “阀 值 ” ，虽然 其 含 义 的 确 类 似 于 “阀门” . 经 元 的 电 位 超 过 了 一 个 “阈值”(threshold),那么它就会被激活，即 “兴 奋 ” 起来，向其他神经元发送化学物质. 1943",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 356
    }
  },
  {
    "page_content": "就会向相连的神经元发送化学物质，从而改变这些神经元内的电位；如果某神 亦 称 bias. 注 意 不 是 “阀 值 ” ，虽然 其 含 义 的 确 类 似 于 “阀门” . 经 元 的 电 位 超 过 了 一 个 “阈值”(threshold),那么它就会被激活，即 “兴 奋 ” 起来，向其他神经元发送化学物质. 1943 [McCulloch and Pitts, 1943]将上述情形抽象为图5 .1 所示的简单 模型，这 就 是 一 直 沿 用 至 今 的 “M - P 神经元模型”.在 这 个 模 型 中 ，神经元接 收到来自几个其他神经元传递过来的输入信号，这些输入信号通过带权重的连 接(connection)进行传递，神经元接收到的总输入值将与神经元的阈值进行比 I £ 皿g \\ 2=1 0 图 5.1 M - P 神经元模型 98 第 5 章 神 经 网 络 亦 称 “响应函数” 较，然 后 通 过 “激活函数”(activation fu n ctio n)处理以产生神经元的输出. 这 里 的 阶 跃 函 数 是 单 位 阶 跃 函 数 的 变 体 ；对 数 几 率 函 数 则 是 S igm oid函数 的 典 型 代 表 .参 见 3 .3 节. 理想中 的 激 活 函 数 是 图 5 .2 ( a ) 所示的阶跃函数，它将输入值映射为输出 值 “ 0 ” 或 “ 1” ，显 然 “ 1” 对应于神经元兴奋，“ 0 ” 对应于神经元抑制.然 而，阶 跃 函 数 具 有 不 连 续 、不 光 滑 等不太好的性质，因 此 实 际 常 用 Sigmoid 函 数 作 为 激 活 函 数 .典 型 的 Sigm oid函 数 如 图 5 .2 ( b ) 所示，它把可能在较大 范 围 内 变 化 的 输 入 值 挤 压 到 (0 , 1 ) 输出值范围内，因 此 有 时 也 称 为 “挤压函 数 ” (squashing function). ( a ) 阶跃函数 (b) S i g m o i d 函数 图 5 . 2 典 型 的 神 经 元 激 活 函 数 把许多个这样的神经元按一定的层次结构连接起来，就得到了神经网络. “模 拟 生 物 神 经 网 络 ” 是 认 知 科 学 家 对 神 经 网 络 事实上，从计算机科学的角度看，我们可以先不考虑神经网络是否真的模 所做的一个类比阐释. 拟了生物神经网络，只需将一个神经网络视为包含了许多参数的数学模型，这 例 如 1 0 个 神 经 元 两 两 连 接 ，则 有 1 0 0 个参数：90 个 连 接 权 和 1 0 个阈值. 个模型是若干个函数，例 如 y3 = 神经网络学习算法大多以数学证明为支撑.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 357
    }
  },
  {
    "page_content": "事实上，从计算机科学的角度看，我们可以先不考虑神经网络是否真的模 所做的一个类比阐释. 拟了生物神经网络，只需将一个神经网络视为包含了许多参数的数学模型，这 例 如 1 0 个 神 经 元 两 两 连 接 ，则 有 1 0 0 个参数：90 个 连 接 权 和 1 0 个阈值. 个模型是若干个函数，例 如 y3 = 神经网络学习算法大多以数学证明为支撑. g 一 % ) 相互(嵌套)代入而得.有效的 5 . 2 感知机与多层网络 感 知 机 (Perceptron)由 两 层 神 经 元 组 成 ，如 图 5 . 3 所 示 ，输入层接收外 界 输 入 信 号 后 传 递 给 输 出 层 ，输 出 层 是 M - P 神 经 元 ，亦 称 “阈值逻辑单 元 ” (threshold logic unit). 感知机能容易地实现逻辑与、或、非运算.注意到y = / ( £ 〃她◎ - 假 定 了 是 图 5 .2 中的阶跃函数，有 • “与 \" 3 A 6 2)：令 叫 = \" 2 = 1, 8 = 2 , 贝ll y = /(I • + 1 •力2 - 2),仅 5 . 2 感知机与多层网络 99 图 5 . 3 两个输入神经元的感知机网络结构示意图 在 的 = /2 = 1 时 ，y = 1 ； • \" 或 \" (的 V 6 2)：令 皿 = 加2 = 1 , 。= 0.5,则 y = /(I •3 + 1 •改 一 0.5), 当 的 = 1 或①2 = 1 时,沙= 1 ； • \" m F ” (「① 1)：令 仪 ] = —0.6, W2 = 0, 0 = —0.5,贝(J g = /(—0.6 .①]+ 0 • X2 + 0.5),当 g = 1 时 ,g = 0 ; 当力1 = 0 时 ，g = 1. 更 一 般 地 ，给 定 训 练 数 据 集 , 权 重 她 ( 。= 1,2,..., n ) 以 及 阈 值 3 可 通 过 学 习 得 到 . 阈 值 。可 看 作 一 个 固 定 输 入 为 —L 0 的 “哑 结 点 ” ( d u m m y n o d e ) 所 对 应 的 连 接 权 重 w n + b 这 样 ，权 重 和 阈 值 的 学 习 就 可 统 一 为 权 重 的 学 习 .感 知 机 学 习 规 则 非 常 简 单 ，对 训 练 样 例 (叫 切 ，若 当 前 感 知 机 的 输 出 为 力,则 感 知 机 权 g 是 a;对应于第i个输 入神经元的分量. 重 将 这 样 调 整 ： Wi — Wi + A w i > △ 奶 = rj(y - y)xi , (5.1)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 358
    }
  },
  {
    "page_content": "学 习 规 则 非 常 简 单 ，对 训 练 样 例 (叫 切 ，若 当 前 感 知 机 的 输 出 为 力,则 感 知 机 权 g 是 a;对应于第i个输 入神经元的分量. 重 将 这 样 调 整 ： Wi — Wi + A w i > △ 奶 = rj(y - y)xi , (5.1) (5.2) ?7通常设置为一个小正 数，例如0.1. 其 中 r] e (0,1)称 为 学 习 率 (learning rate).从 式 (5.1)可 看 出 ，若 感 知 机 对 训 练 样 例 (亚 沙 )预 测 正 确 ，即 0 = % 则 感 知 机 不 发 生 变 化 ，否 则 将 根 据 错 误 的 程 度 进行权重调整. 需 注 意 的 是 ，感 知 机 只 有 输 出 层 神 经 元 进 行 激 活 函 数 处 理 ，即 只 拥 有 一 层 功 能 神 经 元 (functional neuron),其 学 习 能 力 非 常 有 限 .事 实 上 ，上 述 与 、 或 、 非 问 题 都 是 线 性 可 分 (linearly separable)的 问 题 .可 以 证 明 [Minsky a n d Papert, 1969],若 两 类 模 式 是 线 性 可 分 的 ，即 存 在 一 个 线 性 超 平 面 能 将 它 们 分 开 ，如图 5.4(a)-(c)所 示 ，则 感 知 机 的 学 习 过 程 一 定 会 收 敛 (converge)而 求 得 适 当 的 权 向 量 w = (wi； W 2 ；.. .; w n + i);否 则 感 知 机 学 习 过 程 将 会 发 生 振 荡 (Huctuation), w 难 以 稳 定 下 来 ，不 能 求 得 合 适 解 ，例 如 感 知 机 甚 至 不 能 解 决 如 图 5.4(d)所 示 的 异 或 这 样 简 单 的 非 线 性 可 分 问 题 . “非线性可分”意味着 用线性超平面无法划分. 100 第 5 章 神 经 网 络 图 5 . 4 线 性 可 分 的 “与 “或” “非” 问 题 与 非 线 性 可 分 的 “异或” 问题 要解决非线性可分问题，需考虑使用多层功能神经兀.例如图 5 .5 中这个 简单的两层感知机就能解决异或问题.在图5.5(a)中，输出层与输入层之间的一 层神经元，被称为隐层或隐含层(hidden la y e r),隐含层和输出层神经元都是拥 有激活函数的功能神经元. 更一般的，常见的神经网络是形如图5 .6 所示的层级结构，每层神经元与下 一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接.这样的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 359
    }
  },
  {
    "page_content": "更一般的，常见的神经网络是形如图5 .6 所示的层级结构，每层神经元与下 一层神经元全互连，神经元之间不存在同层连接，也不存在跨层连接.这样的 神经网络结构通常称为“多层前馈神经网络\" (multi-layer feedforward neural 图 5 . 5 能解决异或问题的两层感知机 5 . 3 误差逆传播算法 1 0 1 ( a )单隐层前馈网络 ( b ) 双隐层前馈网络 图 5 . 6 多层前馈神经网络结构示意图 “前 馈 ” 并不意味着网 络 中 信 号 不 能 向 后 传 ，而 是 指 网 络 拓 扑 结 构 上 不 存 在 环 或 回 路 ;参 见 5 5 5 节. networks),其中输入层神经元接收外界输入，隐层与输出层神经元对信号进行 加工，最终结果由输出层神经元输出；换言之，输入层神经元仅是接受输入，不 进行函数处理，隐层与输出层包含功能神经元.因此，图 5.6(a)通 常 被 称 为 “两 层 网 络 ”.为 避 免 歧 义 ，本 书 称 其 为 “单隐层网络”.只 需 包 含 隐 层 ，即可称 为 多 层 网 络 .神 经 网 络 的 学 习 过 程 ，就是根据训练数据来调整神经元之间的 即神经元连接的权重. “连接权”(connection w e i g h t ) 以及每个功能神经元的阈值；换言之，神经网 络 “学 ”到的东西，蕴涵在连接权与阈值中， 5 . 3 误差逆传播算法 多层网络的学习能力比单层感 知 机 强 得 多 .欲 训 练 多 层 网 络 ，式(5.1)的 简单感知机学习规则显然不够了，需要更强大的学习算法.误差逆传播(error 亦 称 “反向传播算法” . BackPropagation,简 称 B P ) 算法就是其中最杰出的代表，它是迄今最成功的神 经网络学习算法.现实任务中使用神经网络时，大多是在使用 B P 算法进行训 练.值得指出的是，B P 算法不仅可用于多层前馈神经网络，还可用于其他类型 的神经网络，例如训练递归神经网络[Pineda, 1987].但 通 常 说 “B P 网络”时, 一般是指用B P 算法训练的多层前馈神经网络. 下 面 我 们 来 看 看 B P 算 法 究 竟 是 什 么 样 .给 定 训 练 集 。 = {(叫,力), (宓2也2 ) , ,(而,时)}, Xi e yi e R z, 即输入示例由d 个属性描述，输 出 I 维实值向量.为便于讨论，图 5.7给出了一个拥有d 个输入神经元、，个输出神 经元、q 个隐层神经元的多层前馈网络结构，其中输出层第/个神经元的阈值 用 ％ 表示，隐层第h 个神经元的阈值用=h表 示 .输入层第i个神经元与隐层第",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 360
    }
  },
  {
    "page_content": "(宓2也2 ) , ,(而,时)}, Xi e yi e R z, 即输入示例由d 个属性描述，输 出 I 维实值向量.为便于讨论，图 5.7给出了一个拥有d 个输入神经元、，个输出神 经元、q 个隐层神经元的多层前馈网络结构，其中输出层第/个神经元的阈值 用 ％ 表示，隐层第h 个神经元的阈值用=h表 示 .输入层第i个神经元与隐层第 h 个神经元之间的连接权为。加 隐 层 第 h 个神经元与输出层第j 个神经元之间 的连接权为w hj. 记 隐 层 第h 个神经元接收到的输入为ah = E t i 层 第 j 个 神 经 元 接 收 到 的 输 入 为 %= E L 1 % M 其 中 bh 为隐层第h 个神经 输出 离散属性需先进行处理: 若 属 性 值 间 存 在 “序 ” 关 系 则 可 进 行 连 续 化 ；否则 通 常 转 化 为 k 维 向 量 ,k 为 属 性 值 数 .参 见 3 . 2 节. 102 第 5 章 神 经 网 络 yi bh 第j 个输出神经元的输入 q Bj = ) : 如hjbh h=l 第 h 个隐层神经元的输入 d = ) : ^ih^i 输 出 层 隐层 输 入 层 图 5.7 B P 网络及算法中的变量符号 实 际 是 对 率 函数，参见 3.3 节. 元的输出.假设隐层和输Hi层神经元都使用图5.2(b)中 的 Sigmoid函数. 对 训 练 例 (昨 练 )，假定神经网络的输出为yk = ( 办 派 … ，/ ) ，即 第=〃%-%), 则 网 络 在( * y Q 上的均方误差为 这 里 的 1 / 2 是为了后续 求导的便利. 1 i Ek = £ 2 @ - y 界 • J=1 (5.3) (5.4) 图 5.7的网 络 中 有 (d + Z + 1) q + / 个参数需确定：输入层到隐层的d x q 个权值、隐层到输出层的q x Z 个权值、q 个隐层神经元的阈值、Z 个输出层神 经元的阈值.B P 是一个迭代学习算法，在迭代的每一轮中采用广义的感知机学 习规则对参数进行更新估计，即与式(5.1)类似，任意参数。的更新估计式为 u 一 口 + A u . (5.5) 下面我们以图5.7中隐层到输出层的连接权w h 3 为例来进行推导. 梯 度 下 降 参 见 附 录 B.4. B P 算法基于梯度下降(gradient descent)策略，以目标的负梯度方向对参 数进行调整.对式(5.4)的误差石q 给定学习率〃有 A .△ \"」= 一 〃 西 . 皿 5 6 ) 5 . 3 误差逆传播算法 103",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 361
    }
  },
  {
    "page_content": "(5.5) 下面我们以图5.7中隐层到输出层的连接权w h 3 为例来进行推导. 梯 度 下 降 参 见 附 录 B.4. B P 算法基于梯度下降(gradient descent)策略，以目标的负梯度方向对参 数进行调整.对式(5.4)的误差石q 给定学习率〃有 A .△ \"」= 一 〃 西 . 皿 5 6 ) 5 . 3 误差逆传播算法 103 注 意 到 W h j 先影响到第j 个输出层神经元的输入值% 再影响到其输出值鳍, 然后影响到E k,有 这 就 是 “链式 法 则 ”. dEk _ dEk a礁 呢 dwhj 咐 呢 dwhj , 根 据 为 的 定 义 ，显然有 普 = % . dwhj 图 5 . 2 中 的 S i g m o i d 函数有一个很好的性质: z, n ， (5.8) 产 (力 )=/3 ) ( 1 — 〃 乃 ) , (5.9) 于是根据式(5.4)和 (5.3),有 _ dEk < 9 j ~ 一 娜 •丽 = —(密 —曲 八 % - % ) = 砥 1 —谤)(若 —讲). (5.10) 将 式 (5.10)和(5.8)代 入 式 (5.7),再 代 入 式 (5.6),就得到了B P 算法中关于 w h j 的更新公式 类似可得 式(5.13)和(5.14)中 △仅加= 制 热 . (5.11) △% = - ? 最 ih = riehXi ， 2 h = ~rjeh , (5.12) (5.13) (5.14) dEk dbh dbh dah 西 . 丽 / 廊 一 向 尸 1 J 104 第 5 章 神 经 网 络 = £ \"由 g j / ( M 一)九) 3=1 I = bh (l - bh ) £ wh j gj . 3=1 (5.15) 常设置为4 = 学 习 率 〃 e (0,1)控制着算法每一轮迭代中的更新步长，若太大则容易振 荡，太小则收敛速度又会过慢.有时为了做精细调节，可令式(5.11)与(5.12)使 用 九 式 (5.13)与(5.14)使用物两者未必相等. 图 5.8给出了 B P 算法的工作流程.对每个训练样例，B P 算法执行以下操 作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出 层的结果；然后计算输出层的误差(第4 - 5 行)，再将误差逆向传播至隐层神经 元 (第 6 行),最后根据隐层神经元的误差来对连接权和阈值进行调整(第7 行).",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 362
    }
  },
  {
    "page_content": "用 九 式 (5.13)与(5.14)使用物两者未必相等. 图 5.8给出了 B P 算法的工作流程.对每个训练样例，B P 算法执行以下操 作：先将输入示例提供给输入层神经元，然后逐层将信号前传，直到产生输出 层的结果；然后计算输出层的误差(第4 - 5 行)，再将误差逆向传播至隐层神经 元 (第 6 行),最后根据隐层神经元的误差来对连接权和阈值进行调整(第7 行). 该迭代过程循环进行，直到达到某些停止条件为止，例如训练误差已达到一个 手 经 普 解 B P 过 很小的值・图5.9给 出 了 在 2 个属性、5 个样本的西瓜数据上，随着训练轮数的 . 增加，网络参数和分类边界的变化情况. 输入：训练集。={(软 ，协O K U ； 学习率0 过程： 、1：在(0,1)范围内随机初始化网络中所有连接权和阈值 for all (xk ,yk) G D d o 2： repeat 3： 4： 根据当前参数和式(5.3)计算当前样本的输出私； 5： 根据式(5.10)计算输出层神经元的梯度项外; 6： -根据式(5.15)计算隐层神经元的梯度项为； 根 据 式 更 新 连 接 权 4 方，Vih与阈值%, 7/i e n d for ■7： 8： 9： until达到停止条件 输出：连接权与阈值确定的多层前馈神经网络 图 5 . 8 误差逆传播算法 需注意的是,B P 算法的目标是要最小化训练集D 上的累积误差 1 m 石 = 石 £ & ， k=l （5.16） 但 我 们 上 面 介 绍 的 “标 准 B P 算 法 ”每次仅针对一个训练样例更新连接权 和阈值，也就是说，图 5 . 8 中算法的更新规则是基于单个的E k 推 导 而 得 .如 5 . 3 误差逆传播算法 105 科 x , 曲 ° + 根蒂 ( a ) 第 2 5 轮 ( b ) 第 50 轮 ( c ) 第 100轮 图 5 . 9 在2个属性、5个样本的西瓜数据上，B P 网络参数更新和分类边界的变化情况 果 类 似 地 推 导 出 基 于 累 积 误 差 最 小 化 的 更 新 规 则 ，就得到了累积误差逆传 播(accumulated error backpropagation)算 法 .累 积 B P 算法与标准B P 算法都 很常用.一般来说，标 准 B P 算法每次更新只针对单个样例，参数更新得非常频 繁，而且对不同样例进行更新的效果可能出现“抵消”现象.因此，为了达到同 样的累积误差极小点，标 准 B P 算法往往需进行更多次数的迭代.累积B P 算法 直接针对累积误差最小化，它在读取整个训练集D 一遍后才对参数进行更新,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 363
    }
  },
  {
    "page_content": "很常用.一般来说，标 准 B P 算法每次更新只针对单个样例，参数更新得非常频 繁，而且对不同样例进行更新的效果可能出现“抵消”现象.因此，为了达到同 样的累积误差极小点，标 准 B P 算法往往需进行更多次数的迭代.累积B P 算法 直接针对累积误差最小化，它在读取整个训练集D 一遍后才对参数进行更新, 其参数更新的频率低得多.但在很多任务中，累积误差下降到一定程度之后，进 一步下降会非常缓慢，这 时 标 准 B P 往往会更快获得较好的解，尤其是在训练 集 。 非常大时更明显. [Hornik et al., 1989]证明，只需一个包含足够多神经元的隐层，多层前馈网 络就能以任意精度逼近任意复杂度的连续函数.然而，如何设置隐层神经元的 个数仍是个未决问题，实际应用中通常靠“试错法”(trial-by-error)调整. 正是由于其强大的表示能力，B P 神经网络经常遭遇过拟合,其训练误差持 续降低，但测试误差却可能上升.有两种策略常用来缓解B P 网络的过拟合.第 一 种 策 略 是 “早停”(early stopping):将数据分成训练集和验证集，训练集用 来计算梯度、更新连接权和阈值，验证集用来估计误差，若训练集误差降低但 读取训练集一遍称为进 行了 “一轮 \" (one round, 亦称 on e e p o c h )学习. 标 准 B P 算法和累积B P 算法的区别类似于随机梯 度下降(stochastic gradient de s c e n t ,简称 S G D ) 与标准 梯度下降之间的区别. 引入正则化策略的神经 网 络 与 第 6 章 的 S V M 已 非常相似. 验证集误差升高，则停止训练，同时返回具有最小验证集误差的连接权和阈值. 第 二 种 策 略 是 “正 则 化 \"(regularization) [Barron, 1991; Girosi et al., 1995],其 基本思想是在误差目标函数中增加一个用于描述网络复杂度的部分，例如连接 106 第 5 章 神 经 网 络 增加连接权与阈值平方 和这一项后，训练过程将 会 偏 好 比 较 小 的 连 接 权 和阈值，使网络输出更加 “光滑”，从而对过拟合 有所缓解. 权与阈值的平方和.仍令E k 表 示 第 k 个训练样例上的误差，Wi表示连接权和 阈值，则误差目标函数(5.16)改变为 1 m 石 = 入 石 £ 夙 + ( 1 —入 ) £ 谛 ， (5.17) k=l i 其 中 X G (0 ,1 )用于对经验误差与网络复杂度这两项进行折中，常通过交叉验 证法来估计. 5 . 4 全 局 最 小 与 局 部 极 小 这里的讨论对其他机器 学习模型同样适用.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 364
    }
  },
  {
    "page_content": "1 m 石 = 入 石 £ 夙 + ( 1 —入 ) £ 谛 ， (5.17) k=l i 其 中 X G (0 ,1 )用于对经验误差与网络复杂度这两项进行折中，常通过交叉验 证法来估计. 5 . 4 全 局 最 小 与 局 部 极 小 这里的讨论对其他机器 学习模型同样适用. 若 用 E 表示神经网络在训练集上的误差，则它显然是关于连接权w 和阈 值 e 的函数.此时,神经网络的训练过程可看作一个参数寻优过程，即在参数空 间中，寻找一组最优参数使得E 最小. 我 们 常 会 谈 到 两 种 “最 优 ”： “局部极小”(local minimum)和 “全局最 小”(global m inim um ).对 w* 和 若 存 在 e > 0 使得 V (w;6>) € {(w;6>) | ||(w;6>) - (w*;6>*)|| W e}, 都 有 E (叫 2 ) 》 任 意 (w; 0)都 有 E (叫3)》E (w\\ 外),则(w *;。*)为全局最小解.直观地看,局 部极小解是参数空间中的某个点，其邻域点的误差函数值均不小于该点的函数 成立，则 (”* * * ) 为局部极小解；若对参数空间中的 值;全局最小解则是指参数空间中所有点的误差函数值均不小于该点的误差函 数值.两者对应的E ® * ;。*)分别称为误差函数的局部极小值和全局最小值, 显然，参数空间内梯度为零的点，只要其误差函数值小于邻点的误差函数 值，就是局部极小点；可能存在多个局部极小值，但却只会有一个全局最小值. 也就是说，“全局最小” 一 定 是 “局部极小”，反之则不成立.例如，图 5.10中 有两个局部极小，但只有其中之一是全局最小.显然，我们在参数寻优过程中是 希望找到全局最小. 基于梯度的搜索是使用最为广泛的参数寻优方法.在此类方法中，我们从 某些初始解出发,迭代寻找最优参数值.每次迭代中，我们先计算误差函数在当 前点的梯度，然后根据梯度确定搜索方向.例如，由于负梯度方向是函数值下降 感知机更新规则式(5.1) 和 B P 更 新 规 则 式 (5.11)- (5.14)都是基于梯度下降. 最快的方向，因此梯度下降法就是沿着负梯度方向搜索最优解.若误差函数在 当前点的梯度为零,则已达到局部极小，更新量将为零，这意味着参数的迭代更 新将在此停止.显然，如果误差函数仅有一个局部极小，那么此时找到的局部极 5 . 4 全局最小与局部极小 107 图 5 . 1 0 全局最小与局部极小 小就是全局最小；然而，如果误差函数具有多个局部极小，则不能保证找到的解 是全局最小.对后一种情形，我们称参数寻优陷入了局部极小，这显然不是我们 所希望的.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 365
    }
  },
  {
    "page_content": "当前点的梯度为零,则已达到局部极小，更新量将为零，这意味着参数的迭代更 新将在此停止.显然，如果误差函数仅有一个局部极小，那么此时找到的局部极 5 . 4 全局最小与局部极小 107 图 5 . 1 0 全局最小与局部极小 小就是全局最小；然而，如果误差函数具有多个局部极小，则不能保证找到的解 是全局最小.对后一种情形，我们称参数寻优陷入了局部极小，这显然不是我们 所希望的. 在现实任务中，人们常采用以下策略来试图“跳 出 ”局部极小，从而进一 步接近全局最小： • 以多组不同参数值初始化多个神经网络，按标准方法训练后，取其中误差 最小的解作为最终参数.这相当于从多个不同的初始点开始搜索，这样就 可能陷入不同的局部极小，从中进行选择有可能获得更接近全局最小的 结果. • 使 用 “模 拟 退 火 \" (simulated annealing)技 术 [Aarts and Korst, 1989]. 模拟退火在每一步都以一定的概率接受比当前解更差的结果，从而有助 于 “跳出”局部极小.在每步迭代过程中，接 受 “次优解”的概率要随着 时间的推移而逐渐降低，从而保证算法稳定. • 使用随机梯度下降.与标准梯度下降法精确计算梯度不同，随机梯度下降 法在计算梯度时加入了随机因素.于是，即便陷入局部极小点，它计算出 的梯度仍可能不为零，这样就有机会跳出局部极小继续搜索. 此外，遗传算法(genetic algorithms) [Goldberg, 1989]也常用来训练神经网 络以更好地逼近全局最小.需注意的是，上述用于跳出局部极小的技术大多是 启发式，理论上尚缺乏保障. 但是也会造成 全局最小. 108 第 5 章 神 经 网 络 5 . 5 其他常见神经网络 神经网络模型、算法繁多，本节不能详尽描述，只对特别常见的几种网络 稍作简介. 5.5.1 RBF 网络 RBF(Radial Basis F unction,径 向 基 函 数 )网 络 ［Broomhead and Lowe, 理 论 上 来 说 可 使 用 多 个 隐层，但 常 见 的 R B F 设置 是单隐层. 1988］是一种单隐层前馈神经网络，它使用径向基函数作为隐层神经元激活函 数，而输出层则是对隐层神经元输出的线性组合.假定输入为d 维向量应输出 为 实 值 ,则R B F 网络可表示为 q 以北)= £ 奶o Q c ) , (5.18) i=l 其 中 q 为隐层神经元个数,Q 和 Wi分别是第i个隐层神经元所对应的中心和权 重 是 径 向 基 函 数 ，这是某种沿径向对称的标量函数，通常定义为样本 方到数据中心q 之间欧氏距离的单调函数.常用的高斯径向基函数形如",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 366
    }
  },
  {
    "page_content": "为 实 值 ,则R B F 网络可表示为 q 以北)= £ 奶o Q c ) , (5.18) i=l 其 中 q 为隐层神经元个数,Q 和 Wi分别是第i个隐层神经元所对应的中心和权 重 是 径 向 基 函 数 ，这是某种沿径向对称的标量函数，通常定义为样本 方到数据中心q 之间欧氏距离的单调函数.常用的高斯径向基函数形如 = e 一自睡—Q 俨. (5.19) ［Park and Sandberg, 1991］证明，具有足够多隐层神经元的R B F 网络能以任意 精度逼近任意连续函数. 通常采用两步过程来训练R B F 网络：第一步，确定神经元中心Q , 常用的 方式包括随机采样、聚类等;第二步，利 用 B P 算法等来确定参数Wi和 5.5.2 ART网络 竞争型学习(competitive learning)是神经网络中一种常用的无监督学习 策略，在使用该 策 略 时 ，网络的输出神经元相互竞争，每一时刻仅有一个竞 争获胜的神经元被激活，其 他 神 经 元 的 状 态 被 抑 制 .这 种 机 制 亦 称 “胜者通 吃 (winner-take-all)原则. ART (Adaptive Resonance T h e o ry ,自适应谐振理论)网络［Carpenter and Grossberg, 1987］是竞争型学习的重要代表.该网络由比较层、识别层、识别 阈值和重置模块构成.其中「比较层负责接收输入样本，并将其传递给识别层神 模 式 类 可 认 为 是 某 类 别 的 “子类” . 经元.识别层每个神经元对应一个模式类，神经元数目可在训练过程中动态增 长以增加新的模式类. 在接收到比较层的输入信号后，识别层神经元之间相互竞争以产生获胜神 5 . 5 其他常见神经网络 109 经元.竞争的最简单方式是，计算输入向量与每个识别层神经元所对应的模式 类的代表向量之间的距离，距离最小者胜.获胜神经元将向其他识别层神经元 这 就 是 “胜 者 通 吃 ”原 则的体现. 发送信号，抑制其激活.若输入向量与获胜神经元所对应的代表向量之间的相 似度大于识别阈值，则当前输入样本将被归为该代表向量所属类别，同时，网络 连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大的 相似度，从而使该获胜神经元有更大可能获胜；若相似度不大于识别阈值,则重 置模块将在识别层增设一个新的神经元,其代表向量就设置为当前输入向量. 显然，识别阈值对ART网络的性能有重要影响.当识别阈值较高时,输入样 本将会被分成比较多、 比较精细的模式类，而如果识别阈值较低，则会产生比 较少、比较粗略的模式类.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 367
    }
  },
  {
    "page_content": "连接权将会更新，使得以后在接收到相似输入样本时该模式类会计算出更大的 相似度，从而使该获胜神经元有更大可能获胜；若相似度不大于识别阈值,则重 置模块将在识别层增设一个新的神经元,其代表向量就设置为当前输入向量. 显然，识别阈值对ART网络的性能有重要影响.当识别阈值较高时,输入样 本将会被分成比较多、 比较精细的模式类，而如果识别阈值较低，则会产生比 较少、比较粗略的模式类. ART比 较 好 地 缓 解 了 竞 争 型 学 习 中 的 “可塑性-稳定性窘境”(stability­ plasticity dilem m a),可塑性是指神经网络要有学习新知识的能力，而稳定性则 是指神经网络在学习新知识时要保持对旧知识的记忆.这就使得ART网络具有 一个很重要的优点：可进行增量学习(incremental learning)或在线学习(online learning). 早 期 的 A R T 网络只能处理布尔型输入数据，此 后 A R T 发展成了一个算法 族，包括能处理实值输入的A R T 2网络、结合模糊处理的FuzzyART网络，以 及可进行监督学习的A RTM A P网络等. 5.5.3 SOM网络 增 量 学 习 是 指 在 学 得 模 型 后 ，再 接 收 到 训 练 样 例 时，仅 需 根 据 新 样 例 对 模 型 进 行 更 新 ，不必重新训 练 整 个 模 型 ，并 且 先 前 学 得 的 有 效 信 息 不 会 被 “冲 掉 ” ；在 线 学 习 是 指 每 获 得一个新样本就进行一■次 模 型 更 新 .显 然 ，在线学习 是 增 量 学 习 的 特 例 ，而增 量 学 习 可 视 为 “批 模 式 ” (batch-mode)的在线学习. 亦 称 “自 组 织 特 征 映 射 ” (Self-Organizing Fea­ ture Map)、Kohonen 网络. SOM(Self-Organizing M a p ,自组织映射)网络［Kohonen, 1982］是一种竞 争学习型的无监督神经网络，它能将高维输入数据映射到低维空间(通常为二 维)，同时保持输入数据在高维空间的拓扑结构，即将高维空间中相似的样本点 映射到网络输出层中的邻近神经元. 如 图 5.11所示，S O M 网络中的输出层神经元以矩阵方式排列在二维空间 中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获 胜神经元，它决定了该输入向量在低维空间中的位置.SO M 的训练目标就是为 每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的. SO M 的训练过程很简单：在接收到一个训练样本后，每个输出层神经元会 计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 368
    }
  },
  {
    "page_content": "中，每个神经元都拥有一个权向量，网络在接收输入向量后，将会确定输出层获 胜神经元，它决定了该输入向量在低维空间中的位置.SO M 的训练目标就是为 每个输出层神经元找到合适的权向量，以达到保持拓扑结构的目的. SO M 的训练过程很简单：在接收到一个训练样本后，每个输出层神经元会 计算该样本与自身携带的权向量之间的距离，距离最近的神经元成为竞争获胜 者，称为最佳匹配单元(best matching u n it) .然后，最佳匹配单元及其邻近神经 元的权向量将被调整，以使得这些权向量与当前输入样本的距离缩小.这个过 程不断迭代，直至收敛. 110 第 5 章 神 经 网 络 图 5.11 S O M 网络结构 5 .5 .4 级联相关网络 一般的神经网络模型通常假定网络结构是事先固定的，训练的H的是利用 训练样本来确定合适的连接权、阈值等参数.与此不同，结构自适应网络则将 网络结构也当作学习的目标之一，并希望能在训练过程中找到最符合数据特点 的网络结构.级联相关(Cascade-Correlation)网 络 [Fahlman and Lebiere, 1990] 是结构自适应网络的重要代表. 结构自适应神经网络亦 称 \" 构 造 性 \" tiv e )神经网络. (construc- 5 . 5 , 2 节 介 绍 的 A R T 网 络 由 于 隐 层 神 经 元 数 目 可 在 训 练 过 程 中 增 长 ，因此 也 是 一 种 结 构 自 适 应 神 经 网络. (a)初始状态 (b)增加一个隐层结点 (c)增加第二个隐层结点 图 5.12 级 联 相 关 网 络 的 训 练 过 程 .新 的 隐 结 点 加 入 时 ，红 色 连 接 权 通 过 最 大 化 新 结 点 的 输出与网络误差之间的相关性来进行训练. 级联相关网络有两个主要成分： “级联”和 “相关”.级联是指建立层次 连接的层级结构.在开始训练时，网络只有输入层和输出层，处于最小拓扑结 构；随着训练的进行，如 图 5.12所示，新的隐层神经元逐渐加入，从而创建起层 级结构.当新的隐层神经元加入时，其输入端连接权值是冻结固定的.相关是 指通过最大化新神经元的输出与网络误差之间的相关性(correlation)来训练相 关的参数. 与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经 元数目，且训练速度较快，但其在数据较小时易陷入过拟合. 5 . 5 其他常见神经网络 111 5.5.5 Elman网络 亦 称 Krecursive neural 与前馈神经网络不同，“递归神经网络\" (recuirent neural networks)允许 networks” .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 369
    }
  },
  {
    "page_content": "与一般的前馈神经网络相比，级联相关网络无需设置网络层数、隐层神经 元数目，且训练速度较快，但其在数据较小时易陷入过拟合. 5 . 5 其他常见神经网络 111 5.5.5 Elman网络 亦 称 Krecursive neural 与前馈神经网络不同，“递归神经网络\" (recuirent neural networks)允许 networks” . 网络中出现环形结构，从而可让一些神经元的输出反馈回来作为输入信号.这 样的结构与信息反馈过程，使 得网络在t时刻的输出状态不仅与t时刻的输入 有关，还 与 £ - 1 时刻的网络状态有关，从而能处理与时间有关的动态变化. E lm an网 络 ［Elman, 1990］是最常用的递归神经网络之一,其结构如图5.13 所示，它的结构与多层前馈网络很相似,但隐层神经元的输出被反馈回来，与下 一时刻输入层神经元提供的信号一起，作为隐层神经元在下一时刻的输入.隐 层神经元通常采用Sigmoid激活函数，而网络的训练则常通过推广的B P 算法 进 行 ［Pineda, 1987］. 从 图 5 .1 4 ( a )可看出, Boltzm ann机是一种递归 神经网络. 图 5.13 E l m a n 网络结构 5.5.6 Boltzmann机 神 经 网 络 中 有 一 类 模 型 是 为 网 络 状 态 定 义 一 个 “能 量 ”(energy),能 量 • 最 小 化 时 网 络 达 到 理 想 状 态 ，而 网 络 的 训 练 就 是 在 最 小 化 这 个 能 量 函 数 . Boltzmann 机 ［Ackley et al., 1985］就 是 一 种 “基于能量的模型\" (energy-based m odel),常见结构如图5.14(a)所示，其神经元分为两层：显层与隐层.显层用 于表示数据的输入与输出，隐层则被理解为数据的内在表达.Boltzm ann机中 的神经元都是布尔型的，即 只 能 取0> 1 两种状态，状 态 1 表示激活，状 态 0 表 示抑制.令向量s e {0, l}n 表 示 n 个神经元的状态，Wij表示神经元i与 j 之间 的连接权，仇表示神经元i的阈值，则 状 态 向 量s 所 对 应 的 Boltzm ann机能量 定义为 n—1 n n E(s) = —〉］) ［ wijSj —〉］ 9jS% . (5.20) i=l B o ltzm a n n分 布 亦 称 \" 平 衡 态 \" (equilibrium) 或 \" 平 稳 分 布 \" (station­ ary distribution). 若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 370
    }
  },
  {
    "page_content": "定义为 n—1 n n E(s) = —〉］) ［ wijSj —〉］ 9jS% . (5.20) i=l B o ltzm a n n分 布 亦 称 \" 平 衡 态 \" (equilibrium) 或 \" 平 稳 分 布 \" (station­ ary distribution). 若网络中的神经元以任意不依赖于输入值的顺序进行更新，则网络最终将 达 到 Boltzmann分布，此时状态向量s 出现的概率将仅由其能量与所有可能状 112 第 5 章 神 经 网 络 (a) Boltzmann机 (b ) 受限Boltzmann机 图 5.14 Boltzmann 机与受限 Boltzmann 机 态向量的能量确定: P (s ) = e~E⑹ “ 即 ) . (5.21) Boltzm ann机 的 训 练 过 程 就 是 将 每 个 训 练 样 本 视 为 一 个 状 态 向 量 ，使 其 出 现 的 概 率 尽 可 能 大 .标 准 的 Boltzm ann机是一个全连接图，训练网络的 复杂度很高，这 使 其 难 以 用 于 解 决 现 实 任 务 .现 实 中 常 采 用 受 限 Boltzmann 机(Restricted Boltzmann Machine,简称 R B M ).如图 5.14(b)所示，受限 Boltz­ mann 机仅保留显层与隐层之间的连接，从 而 将 Boltzmann机结构由完全图简 化为二部图. 受限 Boltzmann 机 常 用 \" 对 比 散 度 \" (Contrastive Divergence,简称 CD)算 法 [Hinton, 2010]来 进 行 训 练 . 假 定 网 络 中 有 d 个 显 层 神 经 元 和 q 个隐层神经元，令 V 和九分别表示显层与隐层的状态向量，则由于同一层内不 存在连接，有 d P (v \\h )^ Y [ P (v i \\h) , 2=1 q P(h\\v) = l[ P ( h j \\v) . (5.22) (5.23) '阈值的更新公式可类似 获得. C D 算法对每个训练样本也先根据式(5.23)计算出隐层神经元状态的概率分布, 然后根据这个概率分布采样得到E 此后，类似地根据式(5.22)从 h 产 生 再 从 W 产 生 加 ；连接权的更新公式为 △w = rj (vhJ —⑦%” ) . (5.24) 5 . 6 深度学习 113 5 . 6 深度学习 关于学习器容量，参见 第 12章. 理论上来说，参数越多的模型复杂度越高、 “容量”(capacity)越大，这意 味着它能完成更复杂的学习任务.但一般情形下，复杂模型的训练效率低，易陷",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 371
    }
  },
  {
    "page_content": "△w = rj (vhJ —⑦%” ) . (5.24) 5 . 6 深度学习 113 5 . 6 深度学习 关于学习器容量，参见 第 12章. 理论上来说，参数越多的模型复杂度越高、 “容量”(capacity)越大，这意 味着它能完成更复杂的学习任务.但一般情形下，复杂模型的训练效率低，易陷 大型深度学习模型中甚 至有上百亿个参数. 这 里 所 说 的 “多隐层” 是指三个以上隐层；深度 学习模型通常有八九层甚 至更多隐层. 入过拟合，因此难以受到人们青睐.而随着云计算、大数据时代的到来，计算 能力的大幅提高可缓解训练低效性，训练数据的大幅增加则可降低过拟合风险, 因此，以 “深 度 学 习 \"(deep learning)为代表的复杂模型开始受到人们的关注. ・典型的深度学习模型就是很深层的神经网络.显然，对神经网络模型，提高 容量的一个简单办法是增加隐层的数目.隐层多了，相应的神经元连接权、阈 值等参数就会更多.模型复杂度也可通过单纯增加隐层神经元的数目来实现, 前面我们谈到过，单隐层的多层前馈网络已具有很强大的学习能力；但从增加 模型复杂度的角度来看，增加隐层的数目显然比增加隐层神经元的数目更有效, 因为增加隐层数不仅增加了拥有激活函数的神经元数目，还增加了激活函数嵌 套的层数.然而，多隐层神经网络难以直接用经典算法(例如标准B P 算法)进行 训练，因为误差在多隐层内逆传播时，往 往 会 “发 散 \" (diverge)而不能收敛到 稳定状态. 无 监 督 逐层训练(unsupervised layer-wise training)是多隐层网络训练的 有效手段，其基本思想是每次训练一层隐结点，训练时将上一层隐结点的输 出作为输入，而本层隐结点的输出作为下一层隐结点的输入，这 称 为 “预训 练 \" (pre-training);在预训练全部完成后，再 对 整 个 网 络 进 行 “微 调 ”(fine- tuning)训 练 .例 如 ，在深度信念网络(deep belief netw ork,简称DBN) [Hinton et al., 2006]中，每 层 都 是 一 个 受 限 Boltzm ann机，即整个网络可视为若干个 R B M 堆叠而得.在使用无监督逐层训练时，首先训练第一层，这是关于训练样 本的RBM模型,可按标准的R B M 训练;然后，将第一层预训练好的隐结点视为 第二层的输入结点，对第二层进行预训练；……各层预训练完成后，再 利 用 BP 算法等对整个网络进行训练. 事实上，“预训练+ 微调”的做法可视为将大量参数分组,对每组先找到局 部看来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 372
    }
  },
  {
    "page_content": "本的RBM模型,可按标准的R B M 训练;然后，将第一层预训练好的隐结点视为 第二层的输入结点，对第二层进行预训练；……各层预训练完成后，再 利 用 BP 算法等对整个网络进行训练. 事实上，“预训练+ 微调”的做法可视为将大量参数分组,对每组先找到局 部看来比较好的设置，然后再基于这些局部较优的结果联合起来进行全局寻优. 这样就在利用了模型大量参数所提供的自由度的同时,有效地节省了训练开销. 另 一 种 节 省 训 练 开 销 的 策 略 是 “权 共 享 \" (weight sh a rin g ),即让一组 神 经 元 使 用 相 同 的 连 接 权 .这 个 策 略 在 卷 积 神 经 网 络 (Convolutional Neural Network,简称 CNN) [LeCun and Bengio, 1995; LeCun et al., 1998]中发挥了 重 要 作 用 .以 CN N 进行手写数字识别任务为例[LeCun et al., 1998],如 图 5.15 114 第 5 章 神 经 网 络 输入层 3 2x32 卷积层 >)28x28 采样层 6 @ 1 4 x l 4 卷积层 16(ci110xl0 采样层 16(^5 x 5 卷积层 8 4 1 2 0 一 连接层 输出层 1 0 图 5 .1 5 卷 积 神 经 网 络 用 于 手 写 数 字 识 别 [LeCunetaL, 1998] 所示,网络输入是一个3 2 x 3 2 的手写数字图像,输出是其识别结果,C N N 复合 多 个 “卷积层”和 “采样层”对输入信号进行加工，然后-在连接层实现与输出 目标之间的映射.每个卷积层都包含多个特征映射(feature m a p ),每个特征映 射是一个由多个神经元构成的“平 面 ”，通过一种卷积滤波器提取输入的一种 特 征 .例 如 ，图 5 .1 5 中第一个卷积层由6 个特征映射构成，每个特征映射是一 个 2 8 x 2 8 的神经元阵列，其中每个神经元负责从5 x 5 的区域逋过卷积滤波器 提 取 局 部 特 征 .采 样 层 亦 称 为 “汇 合 ”(pooling)层，其作用是基于局部相关性 原理进行亚采样，从而在减少数据量的同时保留有用信息.例如图5 .1 5 中第一 个 采 样 层 有 6 个 1 4 x 1 4 的特征映射，其中每个神经元与上一层中对应特征映 射 的 2 义2 令B域相连，并据此计算输出.通过复合卷积层和采样层，图 5 .1 5 中的 C N N 将原始图像映射成1 2 0 维特征向量，最后通过一个由8 4 个神经元构成的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 373
    }
  },
  {
    "page_content": "连接层和输出层连接完成识别任务.CN N 可 用 B P 算法进行训练，但在训练中, 无论是卷积层还是采样层，其每一组神经元(即图5 .1 5 中 的 每 个 “平面”)都是 用相同的连接权，从而大幅减少了需要训练的参数数目. 我们可以从另一个角度来理解深度学习.无论是D B N 还 是 C N N ,其多隐 层堆叠、每层对上一层的输出进行处理的机制，可看作是在对输入信号进行 逐层加工，从而把初始的、与输出目标之间联系不太密切的输入表示，转化 成与输出目标联系更密切的表示，使得原来仅基于最后一层输出映射难以完 成的任务成为可能.换言之，通过多层处理，逐 渐 将 初 始 的 “低 层 ”特征表示 转 化 为 “高 层 ”特征表示后，用 “简单模型”即可完成复杂的分类等学习任 务 .由 此 可 将深度学 习理解为进行“特 征 学 习 \"(feature learning)或 “表示学 习 ” (representation learning). 以往在机器学习用于现实任务时，描述样本的特征通常需由人类专家来设 计，这 称 为 “特征工程”(feature engineering).众所周知，特征的好坏对泛化性 近 来 人 们 在 使 用 CNN 时 常 将 S ig m o id激 活 函 数 替换为修正线性函数 J o, = if 力 < 0, otherwise, 这 样 的 神 经 元 称 为 Re- LU(Rectified Linear Unit); 此 外 ，汇 合 层 的 操 作 常 采 用 “最 大 ” 或 “平 均 ” ， 这更接近于集成学习中的 一些操作，参 见 8 .4 节. 若将网络中前 若 干 层 处 理 都 看 作 是 在 进 行 特 征 表 示 ，只 把 最 后 一 层 处 理 看 作 是 在 进 行 “分 类 ”，则 分类使用 的 就 是 一 个 简 单 模型. 5 . 7 阅读材料 115 能有至关重要的影响，人类专家设计出好特征也并非易事；特征学习则通过机 器学习技术自身来产生好特征，这使机器学习向“全自动数据分析”又前进了 2 0 1 2 年 前 的 名 称 是 IEEE Transactions on Neu­ ral Networks. 近 来 N IP S 更偏重于机 器学习. LMS 亦称 Widrow-Hoff 规 则 或 6 规则. 一步. 5 . 7 阅读材料 [Haykin, 1998]是很好的神经网络教科书/B ishop, 1995]则偏重于机器学 习和模式识别.神经网络领域的主流学术期刊有Neural Computation> Neural",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 374
    }
  },
  {
    "page_content": "ral Networks. 近 来 N IP S 更偏重于机 器学习. LMS 亦称 Widrow-Hoff 规 则 或 6 规则. 一步. 5 . 7 阅读材料 [Haykin, 1998]是很好的神经网络教科书/B ishop, 1995]则偏重于机器学 习和模式识别.神经网络领域的主流学术期刊有Neural Computation> Neural NetworksIEEE Transactions on Neural Networks and Learning Systems; 主要国际学术会议有国际神经信息处理系统会议(N IPS)和国际神经网络联合 会议(IJC N N ),区域性国际会议主要有欧洲神经网络会议(ICANN)和亚太神经 网络会议(ICONIP). M-P神经元模型使用最为广泛，但还有一些神经元模型也受到关注，如考 虑了电位脉冲发放时间而不仅是累积电位的脉冲神经元(spiking neuron)模型 [Gerstner and Kistler, 2002]. BP 算法由[Werbos, 1974]首先提出，此 后 [Rumelhart et al., 1986a,b]重新 发明.B P 算法实质是LMS (Least Mean Square)算法的推广.LM S试图使网 络的输出均方误差最小化，可用于神经元激活函数可微的感知机学习；将 LMS 推广到由非线性可微神经元组成的多层前馈网络，就得到B P 算法，因此B P 算 法亦称广义 6 规贝(J [Chauvin and Rumelhart, 1995]. [MacKay, 1992]在贝叶斯框架下提出了自动确定神经网络正则化参数的 方法. [Gori and Tesi, 1992]对 B P 网络的局部极小问题进行了详细讨论. [Yao, 1999]综述了利用以遗传算法为代表的演化计算(evolutionary computation)技 术来生成神经网络的研究工作.对B P 算法的改进有大量研究，例如为了提速, 可在训练过程中自适应缩小学习率，即先使用较大的学习率然后逐步缩小，更 多 \"窍 门 \" (tric k )可参阅[Reed and Marks, 1998; Orr and Muller, 1998]. 关于 RBF 网络训练过程可参阅[Schwenker et al., 2001]. [Carpenter and Grossberg, 1991]介绍了 A R T 族算法.SO M 网络在聚类、高维数据可视化、",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 375
    }
  },
  {
    "page_content": "多 \"窍 门 \" (tric k )可参阅[Reed and Marks, 1998; Orr and Muller, 1998]. 关于 RBF 网络训练过程可参阅[Schwenker et al., 2001]. [Carpenter and Grossberg, 1991]介绍了 A R T 族算法.SO M 网络在聚类、高维数据可视化、 图像分割等方面有广泛应用，可参 阅 [Kohonen, 2001]. [Bengio et al., 2013]综 述了深度学习方面的研究进展. 神经网络是一种难解释的“黑箱模型”，但已有一些工作尝试改善神经 网络的可解释性，主要途径是从神经网络中抽取易于理解的符号规则，可参阅 [Tickle et al., 1998; Zhou, 2004]. 116 第 5 章 神 经 网 络 习题 5.1 试述将线性函数/ Q ) = 用作神经元激活函数的缺陷. 5.2 试述使用图5.2(b)激活函数的神经元与对率回归的联系. 5.3 对 于 图 5 .7 中 的vih,试推导出B P 算法中的更新公式(5.13). 5.4 试述式(5.6)中学习率的取值对神经网络训练的影响. 西 瓜 数 据 集 3 .0 见 p.84 的 表 4 3 5.5 试编程实现 标准B P 算 法 和 累 积B P 算法，在西瓜数据集3 .0 上分别 用这两个算法训练一个单隐层网络，并进行比较. UCI数据集见 http://archive.ics.uci.edu/ml/. 5.6 试设计一个B P 改进算法，能通过动态调整学习率显著提升收敛速度. 编程实现该算法，并 选 择 两 个 U C I数 据 集 与 标 准 B P 算法进行实验 比较. 5.7 根据式(5.18)和(5」9 ) ,试构造一个能解决异或问题的单层R B F 神经 网络. 西 瓜 数 据 集 3.0 a 见 p.89 的 表 4 5 5.8 从网上下载或自己编程实现SO M 网络，并观察其在西瓜数据集3.0a 上产生的结果. 、 5.9* 试推导用于E lm an 网络的B P 算法. 5.10 从网上下载或自己编程实现一个卷积神经网络，并在手写字符识别数 M N I5T 数据集见 http://yann.lecun.com/ exdb/mnist/. 据 M NIST上进行实验测试. 参考文献 117 参考文献 Aarts, E. and J. Korst. (1989). Simulated Annealing and Boltzmann Machines:",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 376
    }
  },
  {
    "page_content": "M N I5T 数据集见 http://yann.lecun.com/ exdb/mnist/. 据 M NIST上进行实验测试. 参考文献 117 参考文献 Aarts, E. and J. Korst. (1989). Simulated Annealing and Boltzmann Machines: A Stochastic Approach to Combinatorial Optimization and Neural Comput­ ing. John Wiley & Sons, New York, NY. Ackley, D. H., G. E. Hinton, and T. J. Sejnowski. (1985). “A learning algorithm for Boltzmann m a c h in e s .Cognitive Science19(1):147-169. Barron, A. R. (1991). “Complexity regularization with application to artifi­ cial neural networks.^^ In Nonparametric Functional Estimation and Related Topics; NATO A SI Series Volume 335 (G. Roussas, ed.), 561-576, Kluwer, Amsterdam, The Netherlands. Bengio, Y., A. Courville, and P. Vincent. (2013). ^Representation learning: A review and new perspectives.55 IEEE Transactions on Pattern Analysis and Machine Intelligence1 35(8):1798-1828. Bishop, C. M. (1995). Neural Networks for Pattern Recognition. Oxford Uni­ versity Press, New York, NY. Broomhead, D. S. and D. Lowe. (1988). ^Multivariate functional interpolation and adaptive networks?5 Complex Systems12(3):321-355.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 377
    }
  },
  {
    "page_content": "versity Press, New York, NY. Broomhead, D. S. and D. Lowe. (1988). ^Multivariate functional interpolation and adaptive networks?5 Complex Systems12(3):321-355. Carpenter, G. A. and S. Grossberg. (1987). “A massively parallel architecture for a self-organizing neural pattern recognition m a c h in e .Computer Vision, Graphics, and Image Processing1 37(1):54-115. Carpenter, G. A, and S. Grossberg, eds. (1991). Pattern Recognition by Self­ Organizing Neural Networks. MIT Press, Cambridge, MA. Chauvin, Y. and D. E. Rumelhart, eds. (1995). Backpropagation: Theory, A r­ chitecture, and Applications. Lawrence Erlbaum Associates, Hillsdale, NJ. Elman, J. L. (1990). “Finding structure in time.\" Cognitive Science1 14(2): 179-211. Fahlman, S. E. and C. Lebiere. (1990). “The cascade-correlation learning archi­ tect ure.J, Technical Report CMU-CS-90-100, School of Computer Sciences, Carnergie Mellon University, Pittsburgh, PA. Gerstner, W. and W. Kistler. (2002). Spiking Neuron Models: Single Neurons, Populations, Plasticity. Cambridge University Press, Cambridge, UK.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 378
    }
  },
  {
    "page_content": "Gerstner, W. and W. Kistler. (2002). Spiking Neuron Models: Single Neurons, Populations, Plasticity. Cambridge University Press, Cambridge, UK. Girosi, F., M. Jones, and T. Poggio. (1995). ^Regularization theory and neural 118 第 5 章 神 经 网 络 networks architectures?5 Neural Computation, 7(2):219-269. Goldberg, D. E. (1989). Genetic Algorithms in Search, Optimizaiton and Ma­ chine Learning. Addison-Wesley, Boston, MA. Gori, M. and A. Tesi. (1992), “On the problem of local minima in backpropa- gation.^^ IEEE Transactions on Pattern Analysis and Machine Intelligence1 14(1):76-86. Hay kin, S. (1998). Neural Networks: A Comprehensive Foundation, 2nd edi­ tion. Prentice-Hall, Upper Saddle River, NJ. Hinton, G. (2010). “A practical guide to training restricted Boltzmann ma- chines.^^ Technical Report UTML TR 2010-003, Department of Computer Science, University of Toronto. Hinton, G., S. Osindero, and Y.-W. Teh. (2006), “A fast learning algorithm for deep belief nets.\" Neural Computation1 18(7):1527-1554.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 379
    }
  },
  {
    "page_content": "Science, University of Toronto. Hinton, G., S. Osindero, and Y.-W. Teh. (2006), “A fast learning algorithm for deep belief nets.\" Neural Computation1 18(7):1527-1554. Hornik, K., M. Stinchcombe, and H. White. (1989). ^Multilayer feedforward networks are universal approximators.” Neural Networks, 2(5):359-366. Kohonen, T. (1982). ^Self^organized formation of topologically correct feature maps.\" Biological Cybernetics^ 43(1):59-69. Kohonen, T. (1988). “An introduction to neural computing.^^ Neural Networks) 1(1):3-16. Kohonen, T. (2001), Self-Organizing Maps, 3rd edition. Springer, Berlin. LeCun, Y. and Y. Bengio. (1995). ^Convolutional networks for images, speech, and time-series25 In The Handbook of Brain Theory and Neural Networks (M. A. Arbib, ed.), MIT Press, Cambridge, MA. LeCun, Y., L. Bottou, Y. Bengio, and P. Haffner. (1998), “Gradient-based learning applied to document recognition?5 Proceedings of the IEEE1 86(11): 2278-2324. MacKay, D. J. C. (1992). “A practical Bayesian framework for backpropagation networks.\" Neural Computation1 4(3):448-472.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 380
    }
  },
  {
    "page_content": "2278-2324. MacKay, D. J. C. (1992). “A practical Bayesian framework for backpropagation networks.\" Neural Computation1 4(3):448-472. McCulloch, W. S. and W. Pitts. (1943). UA logical calculus of the ideas im­ manent in nervous activity25 Bulletin of Mathematical Biophysics1 5(4):115- 133. Minsky, M. and S. Papert. (1969). Perceptrons. MIT Press, Cambridge, MA. 参考文献 119 Orr, G. B. and K.-R. Muller, eds. (1998). Neural Networks: Tricks of the Trade. Springer, London, UK. Park, J. and I. W. Sandberg. (1991). “Universal approximation using radial- basis-function networks.55 Neural Computation^ 3(2):246-257. Pineda, F. J. (1987). ^Generalization of Back-Propagation to recurrent neural networks?5 Physical Review Letters^ 59(19):2229-2232. Reed, R. D. and R. J. Marks. (1998). Neural Smithing: Supervised Learning in Feedforward Artificial Neural Networks. MIT Press, Cambridge, MA. Rumelhart, D. E., G. E. Hinton, and R. J. Williams. (1986a). ^Learning internal representations by error propagation.\" In Parallel Distributed Processing:",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 381
    }
  },
  {
    "page_content": "Rumelhart, D. E., G. E. Hinton, and R. J. Williams. (1986a). ^Learning internal representations by error propagation.\" In Parallel Distributed Processing: Explorations in the Micro structure of Cognition (D. E. Rumelhart and J. L. McClelland, eds.), volume 1, 318-362, MIT Press, Cambridge, MA. Rumelhart, D. E., G. E. Hinton, and R. J. Williams. (1986b). ^Learning repre­ sentations by backpropagating errors.5, Nature, 323(9):318-362. Schwenker, F., H.A. Kestler, and G. Palm. (2001). “Three learning phases for radial-basis-function n e tw o rk s .Neural Networks, 14(4-5):439-458. Tickle, A. B., R. Andrews, M. Golea, and J. Diederich. (1998). “The truth will come to light: Directions and challenges in extracting the knowledge embedded within trained artificial neural networks.5, IEEE Transactions on Neural Networks, 9(6):1057-1067. Werbos, P. (1974). Beyond regression: New tools for prediction and analysis in the behavior science. Ph.D. thesis, Harvard University, Cambridge, MA. Yao, X. (1999). “Evolving artificial neural networks.\" Proceedings of the IEEE, 87(9):1423-1447.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 382
    }
  },
  {
    "page_content": "the behavior science. Ph.D. thesis, Harvard University, Cambridge, MA. Yao, X. (1999). “Evolving artificial neural networks.\" Proceedings of the IEEE, 87(9):1423-1447. Zhou, Z.-H. (2004), “Rule extraction: Using neural networks or for neural networks?” Journal of Computer Science and Technologyy 19(2):249-253. 120 第 5 章 神 经 网 络 闵 斯 基 于 1969 年获图 灵奖. 此 书 中 有 不 少 关 于 神 经 网 络 的 真 知 灼 见 ，但 其 重 要 论 断 所 导 致 的 后 果 ，对 神 经 网 络 乃 至 人 工 智 能 整 体 的 研 究 产 生 了 极 为 残 酷 的 影 响 ，因 此 在 神 经 网 络 重 又 兴 起 后 ，该 书 受 到 很 多 批 判 . 1988年再版时, 闵斯基专门增加了一章以 作辩护. 休息一会儿 小故事：神经网络的几起几落 二十世纪四十年代M - P 神经元模型、H e b b 学习律 出现后，五十年代出现了以感知机、A daline为代表的一 系列成果，这是神经网络发展的第一个高潮期.不幸的 是，M IT 计算机科学研究的奠基人马文・闵斯基(Marvin Minsky, 1927一 ) 与 Seymour P apert 在 1969 年出版了 《感知机》一书，书中指出，单层神经网络无法解决非线 性问题，而多层网络的训练算法尚看不到希望.这个论断 直接使神经网络研究进入了 “冰河期”，美国和苏联均停止了对神经网络研究 的资助，全球该领域研究人员纷纷转行，仅剩极少数人坚持下来.哈佛大学的 Paul W erbos在 1974年 发 明 B P 算法时，正值神经网络冰河期，因此未受到应 有的重视. 1983年，加州理工学院的物理学家John Hopfield利用神经网络，在旅行商 问题这个N P 完全问题的求解上获得当时最好结果，引起了轰动.稍后，UCSD 的 David R u m e lh a rt与 James M cClelland领 导 的 P D P 小 组 出 版 了 《并行分 布处理：认知微结构的探索》一书，R u m elh art等人重新发明了 B P 算法，由于 当时正处于H opfield带来的兴奋之中，B P 算法迅速走红.这掀起了神经网络",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 383
    }
  },
  {
    "page_content": "的 David R u m e lh a rt与 James M cClelland领 导 的 P D P 小 组 出 版 了 《并行分 布处理：认知微结构的探索》一书，R u m elh art等人重新发明了 B P 算法，由于 当时正处于H opfield带来的兴奋之中，B P 算法迅速走红.这掀起了神经网络 的第二次高潮.二十世纪九十年代中期，随着统计学习理论和支持向量机的兴 起，神经网络学习的理论性质不够清楚、试错性强、在 使 用 中 充 斥 大 量 “窍 门”(trick)的弱点更为明显，于是神经网络研究又进入低谷，N IP S 会议甚至多 年不接受以神经网络为主题的论文. 2010年前后，随着计算能力的迅猛提升和大数据的涌现，神经网络研究在 “深度学习” 的名义下又重新崛起，先 是 在 Im ageN et等若干竞赛上以大优势 夺冠，此后谷歌、百度、脸书等公司纷纷投入巨资进行研发，神经网络迎来了 第三次高潮. 第 6 章 支 持 向 量 机 6 . 1 间隔与支持向量 给定训练样本集。 = {(«1,2/1), («2, 2/2), . . . , («m, 2/m)}, Vi € { - 1 , + 1 ) , 分 类学习最基本的想法就是基于训练集D 在样本空间中找到一个划分超平面,将 不同类别的样本分开.但能将训练样本分开的划分超平面可能有很多，如 图 6.1 所示，我们应该努力去找到哪一个呢？ 图 6 . 1 存在多个划分超平面将两类训练样本分开 直观上看，应该去找位于两类训练样本“正中间”的划分超平面，即 图 6.1 中红色的那个，因为该划分超平面对训练样本局部扰动的“容 忍 ”性最好.例 如，由于训练集的局限性或噪声的因素，训练集外的样本可能比图6.1中的训练 样本更接近两个类的分隔界，这将使许多划分超平面出现错误，而红色的超平 面受影响最小.换言之，这个划分超平面所产生的分类结果是最鲁棒的，对未见 示例的泛化能力最强. 在样本空间中，划分超平面可通过如下线性方程来描述： w T x + 6 = 0, (6.1) 其 中 ％ = (wi；w 2 ;...;wd ) 为法向量，决定了超平面的方向；b 为位移项，决定 了超平面与原点之间的距离.显然，划 分 超 平 面 可 被 法 向 量 也 和 位 移 b 确定, 122 第 6 章 支 持 向 量 机 参见习题6.L 下面我们将其记为( w ,6 ) .样本空间中任意点X 到超平面(w ,6 )的距离可写为 \\wT x + 61 T = ----------- 11^11 (6.2)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 384
    }
  },
  {
    "page_content": "122 第 6 章 支 持 向 量 机 参见习题6.L 下面我们将其记为( w ,6 ) .样本空间中任意点X 到超平面(w ,6 )的距离可写为 \\wT x + 61 T = ----------- 11^11 (6.2) 若 超 平 面 (W，卅 )能 将 训练样本正确分类，则总 存 在 缩 放 变 换 qw T w f 和 6 T y 使式(6.3)成立. 假 设 超 平 面 (叫 b ) 能将训练样本正确分类，即 对 于 (叫 幼 )G D 若城= + 1 , 则有 w T Xi + b > 0 ; 若 加 = 一1 , 则有 w T Xi + 6 < 0 . 令 w T Xi + b ) + 1 , % = + 1 ; w T Xi + 6 ^ - 1 , yi = -1 . (6.3) 每个样本点对应一个特 征向量. 如 图 6 .2 所示，距离超平面最近的这几个训练样本点使式(6.3)的等号成立, 它 们 被 称 为 “支持向量”(support vector),两个异类支持向量到超平面的距离 之和为 ^ 面 ( 6 -4 ) 它 被 称 为 “间隔”(margin). 欲 找 到 具 有 “最大间隔”(maximum margin)的划分超平面，也就是要找 到能满足式(6.3)中约束的参数w 和 b，使得7 最大，即 2 max 7；­ 叫 b \\\\w\\\\ s.t. yi(wT Xi + b ) 2 1 , i = 1 ,2 ,..., m. (6⑸ 6 . 2 对偶问题 间隔貌似仅与仞有关, 但 事 实 上 b 通过约束隐式 地 影 响 着w 的取值，进而 对间隔产生影响. 显然，为了最大化间隔，仅 需 最 大 化 | | M | T , 这等价于最小化 ||W||2 . 于是, 式(6⑸可重写为 mi ? | | H 『 (6.6) 123 s.t. yi(wT Xi + &) 1, z = 1, 2,..., m. 这就是支持向量机(Support Vector Machine,简 称 S V M ) 的基本型. 6 . 2 对 偶 问 题 我们希望求解式(6.6)来得到大间隔划分超平面所对应的模型 /(a?) = w T x + b , (6.7) 其 中 w 和 b 是 模 型 参 数 . 注 意 到 式 (6.6)本 身 是 1 个 凸 二 次 规 划 (convex quadratic p r o g r a m m i n g ) 问题，能 直 接 用 现 成 的 优 化 计 算 包 求 解 ，但我们可 以有更高效的办法. 参见附录B.I.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 385
    }
  },
  {
    "page_content": "/(a?) = w T x + b , (6.7) 其 中 w 和 b 是 模 型 参 数 . 注 意 到 式 (6.6)本 身 是 1 个 凸 二 次 规 划 (convex quadratic p r o g r a m m i n g ) 问题，能 直 接 用 现 成 的 优 化 计 算 包 求 解 ，但我们可 以有更高效的办法. 参见附录B.I. 对式(6.6)使用拉格朗日乘子法可得到其“对偶问题”(dual problem).具 体来说，对式(6.6)的每条约束添加拉格朗日乘子虫》0 , 则该问题的拉格朗日 函数可写为 ] m £(叫 &,«) = - | H 『+ E 。 - yilw,Xi + 6)) , 2=1 其 中 a = (ai； & 2 ；… ；oim ).令 L ( w , 4 a ) 对 t o 和匕的偏导为零可得 m % = £ OLiViXi , 1=1 m 0 = £ 总比. i=l (6.8) (6.9) (6.10) 将式(6.9)代入(6.8),即 可 将 L (叫 A a ) 中 的 秒 和 6 消去，再考虑式(6.10)的约 束，就得到式(6.6)的对偶问题 ] m 喈 E 4 - 2 i=l m m E E onajyiyjxfxj i=l 7=1 (6.11) 124 第 6 章 支 持 向 量 机 S . t . 〉〕OLiUi — 0 5 i=l a . 2 0 , E — 1 ,2 , . . . , TTL . 解 出 a 后，求 出 付 与 6 即可得到模型 /(®) = w T x + b m = £ a iy ix f x + b . (6.12) 从对偶问题(6.11)解 出 的 & 是 式 (6.8)中的拉格朗日乘子，它恰对应着训 练 样 本 ( g , % ) . 注 意到式(6.6)中有不等式约束，因 此 上 述 过 程 需 满 足 K K T 参见附录 B.I. (Karush-Kuhn-Tucker)条件，即要求 如 ［Vapnik, 1999］所述, 支持向量机这个名字强调 了此类学习器的关键是如 何从支持向量构建出解; 同时也暗示着其复杂度主 要与支持向量的数目有关. 二次规划参见附录B.2. 色 2 0 ; < %/(◎) — 1 2 0 ; (6.13) a (% / (◎ ) — 1 ) = 。.. 于是，对 任意训练样本(◎,纳)，总 有 电 = 0 或 yE Xi) = 1 . 若 必 = 0 , 则该样",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 386
    }
  },
  {
    "page_content": "二次规划参见附录B.2. 色 2 0 ; < %/(◎) — 1 2 0 ; (6.13) a (% / (◎ ) — 1 ) = 。.. 于是，对 任意训练样本(◎,纳)，总 有 电 = 0 或 yE Xi) = 1 . 若 必 = 0 , 则该样 本将不会在式(6.12)的求和中出现，也 就 不 会 对 / ( x ) 有任何影响；若色 > 0, 则必有纳/(宓£)= 1 , 所对应的样本点位于最大间隔边界上，是一个支持向量. 这显示出支持向量机的一个重要性质:训练完成后，大部分的训练样本都不需 保留，最终模型仅与支持向量有关. 那么，如何求解式(6.11)呢？不难发现，这是一个二次规划问题，可使用通 用的二次规划算法来求解；然而，该问题的规模正比于训练样本数,这会在实际 任务中造成很大的开销.为了避开这个障碍,人们通过利用问题本身的特性,提 出了很多高效算法，SM O (Sequential Minimal Optimization)是其中一个著名 的 代 表 ［Platt, 1998］. S M O 的基本思路是先固定仪之外的所有参数，然 后 求 ％ 上的极值.由于 存在约束工建1 a 沏 = 0 , 若固定以之外的其他变量，则必可由其他变量导出. 于是，S M O 每 次 选 择 两 个 变 量 仪 和 % , 并固定其他参数.这样，在参数初始化 后，S M O 不断执行如下两个步骤直至收敛： • 选取一对需更新的变量必 和 % ; 6 . 2 对偶问题 125 • 固 定 色 和 % 以外的参数，求解式(6.11)获 得 更 新 后 的 他 和 % • 注 意 到 只 需 选 取 的 色 和 ％ 中有一个不满足K K T 条件(6 .1 3 ),目标函数就 会在迭代后减小[Osuna et a l, 1997].直观来看，K K T 条件违背的程度越大，则 变量更新后可能导致的目标函数值减幅越大.于是，SM O 先选取违背K K T 条 件程度最大的变量.第二个变量应选择一个使目标函数值减小最快的变量，但 由于比较各变量所对应的目标函数值减幅的复杂度过高，因 此 SM O采用了一 个启发式：使选取的两变量所对应样本之间的间隔最大.一种直观的解释是，这 样的两个变量有很大的差别，与对两个相似的变量进行更新相比，对它们进行 更新会带给目标函数值更大的变化. ， SM O算法之所以高效，恰由于在固定其他参数后，仅优化两个参数的过程 能做到非常高效.具体来说，仅 考 虑四 和 % 时，式(6.11)中的约束可重写为 & 统 + QjVj = c , 2 0 ) o ij2 0 5 其中 C = _ £ QkVk",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 387
    }
  },
  {
    "page_content": "更新会带给目标函数值更大的变化. ， SM O算法之所以高效，恰由于在固定其他参数后，仅优化两个参数的过程 能做到非常高效.具体来说，仅 考 虑四 和 % 时，式(6.11)中的约束可重写为 & 统 + QjVj = c , 2 0 ) o ij2 0 5 其中 C = _ £ QkVk (6.14) (6.15) 是 使 £ a i y i = 0 成立的常数.用 m i=l Q4yli + QjUj = c (6.16) 消去式(6.11)中 的 变 量 %,则 得 到 一 个 关 于 色 的 单 变 量 二 次 规 划 问 题 ，仅有的 约 束 是 0 2 0 . 不难发现,这样的二次规划问题具有闭式解，于是不必调用数值 优化算法即可高效地计算出更新后的必和% . 如何 确 定 偏 移 项 b 呢？注意到对 任 意 支 持 向 量 ( g , % ) 都 有 % / ( % ) = 1, 即 Vs [ ^ ^ a i y i x l x s + b) = 1 , (6.17) 其 中 S = {〃| 以 〉0 \" = 1 ,2 ,. . . , 馆}为所有支持向量的下标集.理论上，可选 取任意支持向量并通过求解式(6.17)获 得 “但现实任务中常采用一种更鲁棒的 做法：使用所有支持向量求解的平均值 匕= 焉 E ( a 说i W x s 1 1 ses \\ ies (6.18) 126 第 6 章 支 持 向 量 机 6 . 3 核函数 在本章前面的讨论中，我们假设训练样本是线性可分的，即存在一个划分 超平面能将训练样本正确分类.然而在现实任务中，原始样本空间内也许并不 存在一个能正确划分两类样本的超平面.例如图6 .3 中 的 “异 或 ”问题就不是 线性可分的. 图 6 .3 异或问题与非线性映射 对这样的问题，可将样本从原始空间映射到一个更高维的特征空间，使得 样本在这个特征空间内线性可分.例如在图6 . 3 中，若将原始的二维空间映射 到一个合适的三维空间，就能找到一个合适的划分超平面.幸运的是，如果原始 参见 第 12章. 空间是有限维，即属性数有限，那么一定存在一个高维特征空间使样本可分. 令 6(x)表示将力映射后的特征向量，于是，在特征空间中划分超平面所对 应的模型可表示为 = w T (/)(x) + b , 其 中 仍 和 b 是模型参数.类似式( 6 .6 ) ,有 mip | ||w||2 (6.19) (6.20) s.t. y/w‘帆吟 + b ) 2 1, i = 1, 2 , . . . , m. 其对偶问题是",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 388
    }
  },
  {
    "page_content": "令 6(x)表示将力映射后的特征向量，于是，在特征空间中划分超平面所对 应的模型可表示为 = w T (/)(x) + b , 其 中 仍 和 b 是模型参数.类似式( 6 .6 ) ,有 mip | ||w||2 (6.19) (6.20) s.t. y/w‘帆吟 + b ) 2 1, i = 1, 2 , . . . , m. 其对偶问题是 ] m 噜 x £ 必 一 ] i=l m m 工 E 7=1 （g ）T。（叼 ） （6.21） 6 . 3 核函数 127 m s . t . ) : 以统= 0 , 2=1 2 0 : 2 — 1 ,2 ,・・•，7TZ • 求解式(6.21)涉及到计算0 ( g ) T ° (叼)，这 是样本© 与 X j 映射到特征空间 之后的内积.由于特征空间维数可能很高，甚至可能是无穷维，因此直接计算 0 (g )T 矶叼)通常是困难的.为了避开这个障碍，可以设想这样一个函数： 片(即叼)= 3 但 ),0(叼)〉= 0 (g )T 0 (叼 ) , (6.22) 即 g 与 X j 在特征空间的内积等于它们在原始样本空间中通过函数/< , •)计算 这称笊“核技巧”( k e r - 的结果.有了这样的函数，我们就不必直接去计算高维甚至无穷维特征空间中 si trick). 的内积，于是式(6.21)可重写为 X j ) (6.23) 1 噂 x m ] m m £ £ i= l j = l 2=1 m S . t . 〉] QiVi — 0 , z=l Q%》0 , 分—1,2, • • • , TTl . 求解后即可得到 /(x ) = w T (l)( x ) + b m = £ %%0 (g )T ° Q ) + b i= l m = £ O L iyi% ® g ) + b . (6.24) 2=1 这里的函数片(•,•)就 是 “核 函 数 \" (kernel fu n c tio n ).式(6.24)显示出模型最 优解可通过训练样本的核函数展开，这 一 展 式 亦 称 “支 持 向 量 展 式 \"(support vector expansion).. 显然，若已知合适映射0(・)的具体形式，则可写出核函数/<,•).但在现实 任务中我们通常不知道。(・)是什么形式，那么，合适的核函数是否一定存在呢? 什么样的函数能做核函数呢？我们有下面的定理： 128 第 6 章支持向量机 证明可参阅［Scholkopf ，d ^ 0 1 31 2 0 ° 2 L '",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 389
    }
  },
  {
    "page_content": "vector expansion).. 显然，若已知合适映射0(・)的具体形式，则可写出核函数/<,•).但在现实 任务中我们通常不知道。(・)是什么形式，那么，合适的核函数是否一定存在呢? 什么样的函数能做核函数呢？我们有下面的定理： 128 第 6 章支持向量机 证明可参阅［Scholkopf ，d ^ 0 1 31 2 0 ° 2 L ' 定 理 6.1 ( 核 函 数 ) 令 ％ 为 输 入 空 间 ，H - ) 是 定 义 在 北 义 无 上的对称 函 数 ，则 K 是 核 函 数 当 且 仅 当 对 于 任 意 数 据 。 = ｛叫 ，物 … ，而 ｝， \"核 矩 阵 \" (kernel matrix) K 总是半正定的： 片(叫 M i ) … 6 Q L 叼 ) … • • • • • K = 厘 叫 ) … 叼) … K (X i.X m ) ・ ・ ・ ・ • 况 1) , … K(X m i X j^ , • , X m ^ 定 理 6 .1 表 明 ，只要一个对称函数所对应的核矩阵半正定,.它就能作为核 函 数 使 用 .事 实 上 ，对 于 一 个 半 正 定 核 矩 阵 ，总 能 找 到 一 个 与 之 对 应 的 映 射 0 . 换 言 之 ，任 何 一 个 核 函 数 都 隐 式 地 定 义 了 一 个 称 为 “再 生 核 希 尔 伯 特 空 间 ”(Reproducing Kernel Hilbert Space,简称 RKHS)的特征空间. 通 过 前 面 的 讨 论 可 知 ，我 们 希 望 样 本 在 特 征 空 间 内 线 性 可 分 ，因此特征空 间 的 好 坏 对 支 持 向 量 机 的 性 能 至 关 重 要 .需 注 意 的 是 ，在不知道特征映射的形 式 时 ，我 们 并 不 知 道 什 么 样 的 核 函 数 是 合 适 的 ，而核函数也仅是隐式地定义了 叭弓赞吝二？去£譬今 这 个 特 征 空 间 .于 是 ， “核 函 数 选 择 ”成 为 支 持 向 量 机 的 最 大 变 数 • 若核函数 采用线性核，情况不明时 选 择 不 合 适 ，则 意 味 着 将 样 本 映 射 到 了 一 个 不 合 适 的 特 征 空 间 ，很可能导致性 可先尝试高斯核. 能不佳 表 6 .1 列出了几种常用的核函数. 表 6 . 1 常用核函数 名称 表达式 参数 d = 1 时退化为线性核. 高斯核亦称RBF核. 线性核 多项式核 高斯核 K(X i,X j) = x j x j X j) —",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 390
    }
  },
  {
    "page_content": "能不佳 表 6 .1 列出了几种常用的核函数. 表 6 . 1 常用核函数 名称 表达式 参数 d = 1 时退化为线性核. 高斯核亦称RBF核. 线性核 多项式核 高斯核 K(X i,X j) = x j x j X j) — M g , X j ) = exp ( - 品,晨\"3 0 > 0 为高斯核的带宽(width) d 2 1 为多项式的次数 拉普拉斯核 K(g , X j) = exp (一 Sigmoid 核 K(Xi, Xj) = ta iah(/3xjxj + O') (7 > 0 t a n h 为双曲正切函数，/3 > 0, 0 < 0 此 外 ，还可通过函数组合得到，例 如 ： • 若 K 1 和 汽2 为核函数，则 对 于 任 意 正 数 7 1 、7 2 , 其线性组合 7 1 ^ 1 + 7 2 左 2 (6.25) 6 . 4 软间隔与正则化 129 也是核函数; • 若 州 和 用 2 为核函数，则核函数的直积 用1 8 用2 ( N ) = 凡1(力，Z ) ' 2 ( / , N) (6.26) 也是核函数； • 若 修 为 核 函 数 ，则对于任意函数仪力)， 近况,N ) = 。0 ) 翅0 , N)g(z) (6.27) 也是核函数. 6 . 4 软间隔与正则化 在前面的讨论中，我们一直假定训练样本在样本空间或特征空间中是线性 可分的，即存在一个超平面能将不同类的样本完全划分开.然而，在现实任务 中往往很难确定合适的核函数使得训练样本在特征空间中线性可分；退一步说, 即便恰好找到了某个核函数使训练集在特征空间中线性可分，也很难断定这个 貌似线性可分的结果不是由于过拟合所造成的. 缓解该问题的一个办法是允许支持向量机在一些样本上出错.为此，要引 入 “软间隔”(soft m a r g i n )的概念,如图6 . 4 所示. 图 6 .4 软 间 隔 示 意 图 .红 色 圈 出 了 一 些 不 满 足 约 束 的 样 本 . 具体来说，前面介绍的支持向量机形式是要求所有样本均满足约束(6.3), 即所有样本都必须划分正确，这 称 为 “硬间隔”(hard m a r g i n ) , 而软间隔则是 130 第 6 章 支 持 向 量 机 允许某些样本不满足约束 yi(wT Xi + b ) 2 1 . (6.28) 当然，在最大化间隔的同时，不满足约束的样本应尽可能少.于是，优化目标可 写为 1 m m i n -||w||2 + C ^ 4 / 1 ( w T ^ + &) - 1) ,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 391
    }
  },
  {
    "page_content": "130 第 6 章 支 持 向 量 机 允许某些样本不满足约束 yi(wT Xi + b ) 2 1 . (6.28) 当然，在最大化间隔的同时，不满足约束的样本应尽可能少.于是，优化目标可 写为 1 m m i n -||w||2 + C ^ 4 / 1 ( w T ^ + &) - 1) , (6.29) ' i=1 其 中 。 > o 是一个常数,4 / i 是 “o / i损失函数” A)/i (%) = 1, if z < 0; 0, otherwise. 、 (6.30) 显 然 ，当 。 为 无 穷 大 时 ，式(6.29)迫 使 所 有 样 本 均 满 足 约 束 (6.28),于是 式(6.29)等价于(6.6);当 。取有限值时,式(6.29)允许一些样本不满足约束. 然而,4 / 1 非凸、非连续,数学性质不太好,使得式(6.29)不易直接求解.于 是，人们通常用其他一些函数来代替的 1 , 称 为 “替代损失”(surrogate loss). 替代损失函数一般具有较好的数学性质，如它们通常是凸的连续函数且是4 / 1 的 上 界 .图 6 . 5 给出了三种常用的替代损失函数： 对率损失是对率函数的 变形，对 率 函 数 参 见 3.3 节. 对率损失函数通常表示 为 & 3 ( • ) ,因此式(6.33)把 式(3.15)中 的 In (- )改写为 hinge 损失：能 “ ⑶ = m a x ( 0 J — z) ; 指数损失(exponential loss): texp{z} = ex p ( —z) ; 对率损失(logistic loss): 60g(z) = log(l + exp(-z)) . (6.31) (6.32) (6.33) 若 采 用 h i n g e 损失，则式(6.29)变成 1 m m i n -||w||2 + C Y 2 m a x (0,1 — yi (w T Xi 4- 6)) . 叫b 2 f 2=1 (6.34) 引 入 “松弛变量”(slack variables) & 》0 , 可将式(6.34)重写为 ] 叫 2 5 M 孙 温 2 m 仁 (6.35) 6 . 4 软间隔与正则化 131 图 6 . 5 三种常见的替代损失函数：hinge损 失 、指数损失、对率损失 s.t. T g + b ) 》 l —& & 2 0 , i = 1)2)... 这 就 是 常 用 的 “软间隔支持向量机”.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 392
    }
  },
  {
    "page_content": "] 叫 2 5 M 孙 温 2 m 仁 (6.35) 6 . 4 软间隔与正则化 131 图 6 . 5 三种常见的替代损失函数：hinge损 失 、指数损失、对率损失 s.t. T g + b ) 》 l —& & 2 0 , i = 1)2)... 这 就 是 常 用 的 “软间隔支持向量机”. 显然，式(6.35)中每个样本都有一个对应的松弛变量，用以表征该样本不满 足约束(6.28)的程度.但是，与式(6.6)相似，这仍是一个二次规划问题.于是，类 似式(6.8),通过拉格朗日乘子法可得到式(6.35)的拉格朗日函数 1 m 心= -||w||2 + C ^ 2 ^ 2=1 m m + £ % (1 - & - % (一T . 十 0) — £ 色& , (6.36) i— l i=l 其 中 > 0, > 0 是拉格朗日乘子. 令 对 w, - & 的偏导为零可得 m 钝 = 工 8 物g , 2=1 m 0 = £ 必 比 , i— l C = Q 分 + Hi . (6.37) (6.38) (6.39) 132 第 6 章 支 持 向 量 机 将式(6.37)-(6.39)代入式(6.36)即可得到式(6.35)的对偶问题 HL ] l i b IIL max £ 仪 —万 £ £ 色 % 仍 %靖 叼 2=1 j=l 2=1 (6.40) m S . t . 〉] OLiVi = 0 , 2=1 0 W , z -— 1 ,2 ,..., Tn . 将式(6.40)与硬间隔下的对偶问题(6.11)对比可看出，两者唯一的差别就在 于对偶变量的约束不同：前 者 是 0 W 后 者 是 0 W 于是，可 采 用 6.2 节中同样的算法求解式(6.40);在引入核函数后能得到与式(6.24)同样的支持向 量展式. 类似式(6.13),对软间隔支持向量机,K K T 条件要求 ✓ < %/ ( g ) — 1 + & 2 0 , 电 仅 \"(宓 /- 1 + &) = 0 , (6.41) 、& ) 。，从忐= 。­ 于是，对任意训练样本(吃，m)，总 有 ㈢ = 0 或 yif{xi) = 1 一 & . 若 & = 0 , 则 该样本不会对/(⑼有任何影响；若 Q. > 0 , 则 必 有Vif(Xi) = 1 - 即该样本 是支持向量：由式(6.39)可知，若 必 < C , 则 网 > 0 , 进 而 有 & = 0 , 即该样本",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 393
    }
  },
  {
    "page_content": "、& ) 。，从忐= 。­ 于是，对任意训练样本(吃，m)，总 有 ㈢ = 0 或 yif{xi) = 1 一 & . 若 & = 0 , 则 该样本不会对/(⑼有任何影响；若 Q. > 0 , 则 必 有Vif(Xi) = 1 - 即该样本 是支持向量：由式(6.39)可知，若 必 < C , 则 网 > 0 , 进 而 有 & = 0 , 即该样本 恰在最大间隔边界上；若 ％ = 。，则 有 M = 0 , 此 时 若 & W 1 则该样本落在最 大间隔内部，若 & > 1 则该样本被错误分类.由此可看出，软间隔支持向量机的 最终模型仅与支持向量有关，即通过采用hinge损失函数仍保持了稀疏性. 那么，能否对式(6.29)使用其他的替代损失函数呢？ 可以发现，如果使用对率损失函数6 也来替代式(6.29)中 的 0 / 1 损失函数, 则几乎就得到了对率回归模型(3 .2 7 ).实际上，支持向量机与对率回归的优化 目标相近，通常情形下它们的性能也相当.对率回归的优势主要在于其输出具 有自然的概率意义，即在给出预测标记的同时也给出了概率，而支持向量机的 输出不具有概率意义，欲得到概率输出需进行特殊处理[Platt, 2000];此外，对 率回归能直接用于多分类任务，支持向量机为此则需进行推广[Hsu and Lin, 2002].另一方面，从 图 6 .5 可看出，hinge损 失 有 一 块 “平 坦 ”的零区域，这使 6 . 5 支持向量回归 133 得支持向量机的解具有稀疏性，而对率损失是光滑的单调递减函数，不能导出 类似支持向量的概念，因此对率回归的解依赖于更多的训练样本，其预测开销 更大. 我们还可以把式(6.29)中 的 0 / 1 损失函数换成别的替代损失函数以得到 其他学习模型，这些模型的性质与所用的替代函数直接相关，但它们具有一 个共性：优 化 目 标 中 的 第 一 项 用 来 描 述 划 分 超 平 面 的 “间隔”大小，另一项 £ 黑1以/(%),%)用来表述训练集上的误差，可写为更一般的形式 min Q f m / i=l ( ) 电 ) ， (6.42) 其 中 0 ( / ) 称 为 “结构风险”(structural risk ),用于描述模型/ 的某些性质；第 二 项 仍 ) 称 为 “经验风险”(empirical risk ),用于描述模型与训练 数据的契合程度;。用于对二者进行折中.从经验风险最小化的角度来看,Q (/) 表述了我们希望获得具有何种性质的模型(例如希望获得复杂度较小的模型), 这为引入领域知识和用户意图提供了途径；另一方面，该信息有助于削减假设",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 394
    }
  },
  {
    "page_content": "数据的契合程度;。用于对二者进行折中.从经验风险最小化的角度来看,Q (/) 表述了我们希望获得具有何种性质的模型(例如希望获得复杂度较小的模型), 这为引入领域知识和用户意图提供了途径；另一方面，该信息有助于削减假设 空间，从而降低了最小化训练误差的过拟合风险.从这个角度来说，式(6.42)称 为 “正 则 化 \"(regularization)问题，。⑺ 称 为 正 则 化 项 ，。则称为正则化常数. Lp 范 数 (norm )是常用的正则化项，其 中 L2 范 数 ||w ||2 倾 向 于 w 的分量取值 尽量均衡，即非零分量个数尽量稠密，而 Lo 范数||训|o 和 L i 范数||列|1 则倾向 于 w 的分量尽量稀疏，即非零分量个数尽量少. 正 则 化 可 理 解 为 一 种 “罚函数法”，即对不希 望得到的结果施以惩罚, 从而使得优化过程趋向于 希望目标.从贝叶斯估计 的角度来看，正则化项可 认为是提供了模型的先验 概率. 参 见 1 1 .4 节. 6 . 5 支持向量回归 现 在 我 们 来 考 虑 回 归 问 题 .给 定 训 练 样 本 。 = { ( g , 力),(冗2,公),..., Vi e R , 希望学得一个形如式(6.7)的回归模型，使 得 /(⑼ 与 g 尽可 能接近，w 和 b是待确定的模型参数. 对 样 本 Q ,g ) , 传统回归模型通常直接基于模型输出/(⑼与真实输出y 之 间的差别来计算损失，当且仅当f 3 与 y 完全相同时，损失才为零.与此不同, 支持向量回归(Support Vector Regression,简 称 SVR)假设我们能容忍f(x)与 y 之间最多有6 的偏差，即仅 当 /(⑼ 与 y 之间的差别绝对值大于e 时才计算损 失 .如 图 6.6所示,这相当于以/ Q ) 为中心，构建了一个宽度为2 e 的间隔带,若 训练样本落入此间隔带，则认为是被预测正确的. 134 第 6 章支持向量机 图 6 . 6 支持向量回归示意图.红色显示出e 间隔带，落入其中的样本不计算损失. 于是，S V R 问题可形式化为 1 ■ 5 M / 十。£ w.b Z TYL z一/ 2=1 6 ( 〃电)一%) , (6.43) 其 中 C 为正则化常数，晨是 图 6 . 7 所 示 的 ，不敏感损失(『insensitive l o s s )函数 (6.44) (6.45) & ⑶ = 0, if ⑶ W c ; ⑶ — e, otherwise. 间 隔带两侧的松 弛程度 可有所不同. 引 入 松 弛 变 量 &和 也 可 将 式 (6.43)重写为 1 m",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 395
    }
  },
  {
    "page_content": "(6.43) 其 中 C 为正则化常数，晨是 图 6 . 7 所 示 的 ，不敏感损失(『insensitive l o s s )函数 (6.44) (6.45) & ⑶ = 0, if ⑶ W c ; ⑶ — e, otherwise. 间 隔带两侧的松 弛程度 可有所不同. 引 入 松 弛 变 量 &和 也 可 将 式 (6.43)重写为 1 m m h \\ 5 M H 2 + 。三 怎 + &) / i = 1 if |z| W e； otherwise. 图 6 .7 e-不敏感损失函数 6 . 5 支持向量回归 135 s.t. f(xi) 一班 W e + & , yi - /(g) W £ + 石 ， & 》 》。，。=1,2,..., tn. 类似式(6.36),通过引入拉格朗日乘子饵》0,也 》0,必 》0,出 》0 , 由拉 格朗日乘子法可得到式(6.45)的拉格朗日函数 £(叫 b, 以 & , & £ , 出向) 1 m m m = 5 M li2 + 。£ ( & + &) — £ 也&一 £ a 店 2=1 m i=l m Z=1 + £ & ( / ( ◎ ) — 纳 一c 一&) + £ 包(统一 /但 )一 6 —G) . (6.46) i=l i=l 将式(6.7)代入，再 令 L(w, 6, a, d, & £ 内阖 对 w, 6, & 和 G 的偏导为零可得 m W = £ ( 诙 - oii)Xi , 2=1 m 0 = £ ( 必 —& ) , 2=1 。 = & + , 。= 包 + 饱. (6.47) (6.48) (6.49) (6.50) 将式(6.47)-(6.50)代入式(6.46),即可得到S V R 的对偶问题 m m a x £ 明(鱼- 色) , e(鱼 + & ) (6.51) 5 i=l m m - 2 5 2 一8)(跖 一% ) w 叼 i=l j=l m S.t.) ：(&£ — a ) = 0 , i=l o w 自 w 。 . 上述过程中需满足K K T 条件，即要求 136 第 6 章 支 持 向 量 机 8 ( / ( g ) — yi — £ — &) — 0 , &式亚一f 3 i ) - € - ^ ) = o , 人 < = 0 , && = 0 , 、(C - &)& = 0 , —色 尼 = 0 . (6.52)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 396
    }
  },
  {
    "page_content": "o w 自 w 。 . 上述过程中需满足K K T 条件，即要求 136 第 6 章 支 持 向 量 机 8 ( / ( g ) — yi — £ — &) — 0 , &式亚一f 3 i ) - € - ^ ) = o , 人 < = 0 , && = 0 , 、(C - &)& = 0 , —色 尼 = 0 . (6.52) & = 0 时 & 能 取 非 零 值 ，当且仅当 可 以 看 出 ，当 且 仅 当 / ( g ) — y i - /(© ) — e — $ = 0 时也能取非零值.换言之，仅 当 样 本 (叫 比 )不 落 入 e 间 隔带中，相 应 的 必 和 M 才能取非零值.止匕外，约 束 f ( X i ) —€ — & = o 和 yi - f(x i) - 6 - ^ = 0 不能同时成立，因 此a i 和 a t 中至少有一个为零. 将式(6.47)代入(6.7),则 S V R 的解形如 m / Q ) = £ (包一 a i ) x f x + b • (6.53) i=l 落 在 6 间隔带中的样本 都 满 足 以 = 0 且 诙 = 0. 能使式(6.53)中 的 (& —电 )# 0 的样本即为S V R 的支持向量，它们必落在 e 间隔带之外.显然，SV R 的支持向量仅是训练样本的一部分，即其解仍具有稀 疏性. 由 K K T 条 件 (6.52)可看出，对每个样 本 (电 ,仇 )都 有 (。 - & = 0 且 a 0 (/(g ) — yi — e — 进而有 于是，在 得 到 以 后，若 0 < & < C , 则 必 有 & = 。, 6 = % + € — m i=l - a i ) x f x . (6.54) 因 此 在 求 解 式 (6.51)得到以后,理论上来说,可任意选取满足0 V a V C 的样 本通过式(6.54)求 得 6 . 实践中常采用一种更鲁棒的办法：选取多个(或所有)满 足 条 件 0 < & < 。 的样本求解b 后取平均值. . 若考虑特征映射形式(6.19),则相应的，式(6.47)将形如 ・ m W = £ ( & - i— l 将式(6.55)代入(6.19),则 SV R可表示为 . (6.55) 6 . 6 核方法 137 /(”) = £ ( 自一电)左(宓，© ) + b ， (6.56) i=l 其 中 K(Xi,Xj) = ° (g )T 0 (叼)为核函数. 6 . 6 核方 法",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 397
    }
  },
  {
    "page_content": "・ m W = £ ( & - i— l 将式(6.55)代入(6.19),则 SV R可表示为 . (6.55) 6 . 6 核方法 137 /(”) = £ ( 自一电)左(宓，© ) + b ， (6.56) i=l 其 中 K(Xi,Xj) = ° (g )T 0 (叼)为核函数. 6 . 6 核方 法 回 顾 式 (6.24)和(6.56)可 发 现 ，给 定 训 练 样 本 { ( % ，见 乂 也 续 ),… ， 3 m M ) } , 若 不 考 虑 偏 移 项 \" 则 无 论 SV M 还 是 S V R ,学得的模型总能表 示成核函数厘Q , g ) 的线性组合.不仅如此，事实上我们有下面这个称为“表 示定理“(representer theorem)的更一般的结论： 证 明 参 阅 [Scholkopf and Smola, 2002],其中用到了 关于实对称矩阵正定性充 要 条 件 的 Mercer定理. 定 理 6.2 (表 示 定 理 )令间为 核 函 数 K 对应的再生核希尔伯特空间，||加回 表 示 E[空间中关于九的范数，对于任意单调递增函数口： [0,oo] 负损失函数2 ： 1 [0,oo],优化问题 和任意非 min F(h) = Q(||川|回)+ 2值(宓1)，%(宓2), … 消Qm)) (6.57) 的解总可写为 m 2— 1 . (6.58) 表示定理对损失函数没有限制，对 正 则 化 项 Q 仅要求单调递增，甚至不要 求口是凸函数，意味着对于一般的损失函数和正则化项,优化问题(6.57)的最优 解无*(宏)都可表示为核函数/＜叱 g ) 的线性组合；这显示出核函数的巨大威力. 人 们 发 展 出 一 系 列 基 于 核 函 数 的 学 习 方 法 ，统 称 为 “核 方 法 ”(kernel m eth o d s).最常见的，是 通 过 “核化”(即引入核函数)来将线性学习器拓展为 非线性学习器.下面我们以线性判别分析为例来演示如何通过核化来对其进 线 性 判 别 分 析 见 3 .4 节. 行非线性拓展，从 而 得 到 “核 线 性 判 别 分 析 \"(Kernelized Linear Discriminant Analysis,简称 KLDA). 我们先假设可通过某种映射0 : X 1 F 将样本映射到一个特征空间F , 然 后 在 F 中执行线性判别分析，以求得 h(x) = w T (^)(a?) . (6.59) 138 第 6 章 支 持 向 量 机 类似于式(3.35), K L D A 的学习目标是 max J ( w ) = w",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 398
    }
  },
  {
    "page_content": "Analysis,简称 KLDA). 我们先假设可通过某种映射0 : X 1 F 将样本映射到一个特征空间F , 然 后 在 F 中执行线性判别分析，以求得 h(x) = w T (^)(a?) . (6.59) 138 第 6 章 支 持 向 量 机 类似于式(3.35), K L D A 的学习目标是 max J ( w ) = w w T s f w WT SwW (6.60) 其 中 s f 和 s t 分 别 为 训 练 样 本 在 特 征 空 间 N 中的类间散度矩阵和类内散 度 矩 阵 . 令 X 。表 示 第 分 e { 0 , 1 } 类样本的集合，其 样 本 数 为 人 ；总样本数 m = 馆0 + 6 1 . 第 E 类样本在特征空间F 中的均值为 * = 3 £ 。( ⑼ ， (661) 两个散度矩阵分别为 S f = (/4 —/ 4 ) ( / 4 - / 4 产 ； 1 S * = £ £ (。⑸ 一 谭 )(。⑸ - 好 , Z=O XEXi (6.62) (663) 通 常 我 们 难 以 知 道 映 射 。的 具 体 形 式 ，因 此 使 用 核 函 数 上 3 , 电 ) = 0(g)T° ( ⑼ 来 隐 式 地 表 达 这 个 映 射 和 特 征 空 间 F . 把 J ( w ) 作为式 (6.57)中 的损失函数幺再令□三0 , 由表示定理，函 数 h ( x ) 可写为 m 九(z).= g ) , (6.64) 于是由式(6.59)可得 i=l m w = ^ 2 J ° ( 宓 /. i=l (6.65) 令 K e J R m x m 为 核 函 数 6 所对应的核矩阵，( K W = M g , 叼 ) . 令 L G 口, 0 y x i 为 第 i 类样本的指示向量，即 u 的第j 个 分 量 为 1 当 且 仅 当 叼 e 羽, 否 则 L 的 第 •个 分 量 为 0 . 再令 M o = - - K I Q , m 0 Ai = — K l i , m i M = ( / 人 M o ~ f 人 /'人 、 i i ) (6.66) (6.67) (6.68) 人 - M 、1 T i ) ) 6 . 7 阅读材料 1 N = KKT - £ m iR i* . 2=0 于是,式(6.60)等价为 max J ( a ) = a a T M a a T N a 139 (6.69) (6.70) 求 解 方 法 参 见 3 .4 节.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 399
    }
  },
  {
    "page_content": "、 i i ) (6.66) (6.67) (6.68) 人 - M 、1 T i ) ) 6 . 7 阅读材料 1 N = KKT - £ m iR i* . 2=0 于是,式(6.60)等价为 max J ( a ) = a a T M a a T N a 139 (6.69) (6.70) 求 解 方 法 参 见 3 .4 节. 显然，使用线性判别分析求解方法即可得到a , 进而可由式(6.64)得到投影 函数无Q ). 6 . 7 阅读材料 线 性 核 SV M 迄 今 仍 是 文 本 分 类 的 首 选 技 术 .一 个 重 要 原 因 可 能 是 ：若将 每 个 单 词 作 为文本数据的 一 个 属 性 ，则该 属 性 空 间 维数很高，冗余度很大，其 描述能力 足 以 将 不 同 文 档 “打散” .关 于 打 散 ,参 见 12.4 节. 支持向量机于1995年 正 式 发 表 [Cortes and Vapnik, 1995],由于在文本分 类任务中显示出卓越性能[Joachims, 1998],很快成为机器学习的主流技术，并 直接掀起了 “统计学习”(statistical learning)在 2000年前后的高潮.但实际 上，支持向量的概念早在二十世纪六十年代就已出现，统计学习理论在七十年 代就已成型.对核函数的研究更早，M ercer定 理 [Cristianini and Shawe-Taylor, 2000]可 追 溯 到 1909年，R K H S则在四十年代就已被研究，但在统计学习兴起 后，核技巧才真正成为机器学习的通用基本技术.关于支持向量机和核方法有 很多专门书籍和介绍性文章[Cristianini and Shawe-Taylor, 2000; Burges, 1998; 邓 乃 扬 与 田 英 杰 ,2009; Scholkopf et al., 1999; Scholkopf and Smola, 2002],统 计学习理论则可参阅[Vapnik, 1995, 1998, 1999]. 支 持 向 量 机 的 求 解 通 常 是 借 助 于 凸 优 化 技 术 [Boyd and Vandenberghe, 2004],如何提高效率，使 SVM 能适用于大规模数据一直是研究重点.对线性核 S V M 已有很多成果，例如基于割平面法(cutting plane algorithm)的 SVMp e rf 具 有 线 性 复 杂 度 [Joachims, 2006],基 于 随 机 梯 度 下 降 的 Pegasos速度甚至更",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 400
    }
  },
  {
    "page_content": "S V M 已有很多成果，例如基于割平面法(cutting plane algorithm)的 SVMp e rf 具 有 线 性 复 杂 度 [Joachims, 2006],基 于 随 机 梯 度 下 降 的 Pegasos速度甚至更 快 [Shalev-Shwartz et al., 2011],而坐标下降法则在稀疏数据上有很高的效率 [Hsieh et a l, 2008].非线性核SV M 的时间复杂度在理论上不可能低于O(m 2 ), m 是样本个数. 因此研究重点是设计快速近似算法，如基于采样的CVM [Tsang et al., 2006]> 基于低秩逼近的Nystr6m 方 法 [Williams and Seeger, 2001]>基于随机傅里叶 特 征 的 方 法 [Rahimi and Recht, 2007]等.最近有研究显示，当核矩阵特征值有 很大差别时，Nystrom 方法往往优于随机傅里叶特征方法[Yang et a l, 2012]. 支持向量机是针对二分类任务设计的，对多分类任务要进行专门的推广 [Hsu and Lin, 2002],对带结构输出的任务也已有相应的算法[Tsochantaridis 140 第 6 章 支 持 向 量 机 集成学习参见第8 章. 一 致 性 亦 称 “相合性”. et al., 2005］. 支 持 向 量 回 归 的 研 究 始 于 ［Drucker et al., 1997］, ［Smola and Scholkopf, 2004］给出了一个较为全面的介绍. 核函数直接决定了支持向量机与核方法的最终性能，但遗憾的是，核函数 的选择是一个未决问题.多核学习(multiple kernel learning)使用多个核函数并 通过学习获得其最优凸组合作为最终的核函数［Lanckriet et al., 2004; Bach et al., 2004］, 这实际上是在借助集成学习机制. 替 代 损 失 函 数 在 机 器 学 习 中 被 广 泛 使 用 .但 是 ，通 过 求 解 替 代 损 失 函 数 得 到 的 是 否 仍 是 原 问 题 的 解 ？ 这 在 理 论 上 称 为 替 代 损 失 的 “一致 性 ”(consistency)问题. ［Vapnik and Chervonenkis, 1991］给出 了基于替代损 失进行经验风险最小化的一致性充要条件，［Zhang, 2004］证明了几种常见凸替 代损失函数的一致性. SV M 已有很多软件包，比较著名的有LIBSVM ［Chang and Lin, 2011］和",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 401
    }
  },
  {
    "page_content": "性 ”(consistency)问题. ［Vapnik and Chervonenkis, 1991］给出 了基于替代损 失进行经验风险最小化的一致性充要条件，［Zhang, 2004］证明了几种常见凸替 代损失函数的一致性. SV M 已有很多软件包，比较著名的有LIBSVM ［Chang and Lin, 2011］和 LIBLINEAR ［Fan et al., 2008］等. 习题 141 习题 6.1 试证明样本空间中任意点比到超平面(叫6 ) 的距离为式(6.2). LIBSVM 见 http:〃www. csie.ntu.edu.tw/~cjlin/libsvm/. 6 2 西 瓜 数 据 集 3 .0 a 见 p.89 的 表 4 5 试 使 用 LIBSVM ,在 西 瓜 数 据 集 3 .0 a 上分别用线性核和高斯核训练 一 个 SV M ,并比较其支持向量的差别. u c i 数据集见 6・3 选 择 两 个 U C I数据集，分别用线性核和高斯核训练一个SV M ,并与 http://archive.ics.uci.edu/ml/. B P 神经网络和C4.5决策树进行实验比较. 6.4 试讨论线性判别分析与线性核支持向量机在何种条件下等价. 6.5 试述高斯核SVM 与 R B F 神经网络之间的联系. 6.6 试 析 SVM 对噪声敏感的原因. 6.7 试给出式(6.52)的完整K K T 条件. 6.8 以 西 瓜 数 据 集 3 .0 a 的 “密 度 ”为输入，“含 糖 率 ”为输出，试使用 LIBSVM 训练一个 SVR. 6.9 试使用核技巧推广对率回归，产 生 “核对率回归”. 6 . 1 0 * 试设计一个能显著减少SV M 中支持向量的数目而不显著降低泛化性 能的方法. 142 第 6 章 支 持 向 量 机 参考文献 邓 乃 扬 与 田 英 杰 .(2009).支持向量机：理论、算法与拓展.科学出版社，北京. Bach, R. R., G. R. G. Lanckriet, and M. I. Jordan. (2004). “Multiple kernel learning, conic duality, and the SMO algorithm.5, In Proceedings of the 21st International Conference on Machine Learning (ICML)1 6-13, Banff, Cana­ da.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 402
    }
  },
  {
    "page_content": "learning, conic duality, and the SMO algorithm.5, In Proceedings of the 21st International Conference on Machine Learning (ICML)1 6-13, Banff, Cana­ da. Boyd, S. and L. Vandenberghe. (2004). Convex Optimization. Cambridge Uni­ versity Press, Cambridge, UK. Burges, C. J. C. (1998), “A tutorial on support vector machines for pattern recognition.55 Data Mining and Knowledge Discovery1 2(1):121-167. Chang, C.-C. and C.-J. Lin. (2011), “LLBSVM: A library for support vector machines.55 ACM Transactions on Intelligent Systems and Technology, 2(3): 27. Cortes, C. and V. N. Vapnik. (1995), “Support vector networks.^^ Machine Learning1 20(3):273-297. Cristianini, N. and J. Shawe-Taylor. (2000). An Introduction to Support Vector Machines and Other Kernel-Based Learning Methods. Cambridge University Press, Cambridge, UK. Drucker, H., C. J. C. Burges, L. Kaufman, A. J. Smola, and V. Vapnik. (1997). uSupport vector regression m ac h in es.In Advances in Neural Information Processing Systems 9 (NIPS) (M. C. Mozer, M. I. Jordan, and T. Petsche,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 403
    }
  },
  {
    "page_content": "uSupport vector regression m ac h in es.In Advances in Neural Information Processing Systems 9 (NIPS) (M. C. Mozer, M. I. Jordan, and T. Petsche, eds.), 155-161, MIT Press, Cambridge, MA. Fan, R.-E., K.-W. Chang, C.-J. Hsieh, X.-R. Wang, and C.-J. Lin. (2008). “LIBLINEAR: A library for large linear classification.,, Journal of Machine Learning Research^ 9:1871-1874. Hsieh, C.-J., K.-W. Chang, C.-J. Lin, S. S. Keerthi, and S. Sundararajan. (2008). \"A dual coordinate descent method for large-scale linear SVM.” In Proceedings of the 25th International Conference on Machine Learning (ICML). 408-415, Helsinki, Finland. Hsu, C.-W. and C.-J. Lin. (2002), “A comparison of methods for multi-class support vector machines.5, IEEE Transactions on Neural Networks, 13(2): 415-425. 参考文献 143 Joachims, T. (1998), “Text classification with support vector machines: Learn­ ing with many relevant features.” In Proceedings of the 10th European Con­ ference on Machine Learning (ECML)1137-142, Chemnitz, Germany.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 404
    }
  },
  {
    "page_content": "ing with many relevant features.” In Proceedings of the 10th European Con­ ference on Machine Learning (ECML)1137-142, Chemnitz, Germany. -Joachims, T. (2006). “Training linear SVMs in linear time.” In Proceedings of the 12th A CM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD), 217-226, Philadelphia, PA. Lanckriet, G. R. G., N. Cristianini, and M. I. Jordan P. Bartlett, L. El Ghaoui. (2004), “Learning the kernel matrix with semidefinite prog ram m in g .Jour­ nal of Machine Learning Research1 5:27-72. Osuna, E., R. Freund, and F. Girosi. (1997). “An improved training algorithm for support vector m achines.In Proceedings of the IEEE Workshop on Neu­ ral Networks for Signal Processing (NNSP), 276-285, Amelia Island, FL. Platt, J. (1998). ^Sequential minimal optimization: A fast algorithm for train­ ing support vector machines.57 Technical Report MSR-TR-98-14, Microsoft Research. Platt, J. (2000). ^Probabilities for (SV) m achines.In Advances in Large Mar­ gin Classifiers (A. Smola, P. Bartlett, B. Scholkopf, and D. Schuurmans,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 405
    }
  },
  {
    "page_content": "Research. Platt, J. (2000). ^Probabilities for (SV) m achines.In Advances in Large Mar­ gin Classifiers (A. Smola, P. Bartlett, B. Scholkopf, and D. Schuurmans, eds.), 61-74, MIT Press, Cambridge, MA. . Rahimi, A. and B. Recht. (2007). “Random features for large-scale kernel ma­ chines.,5 In Advances in Neural Information Processing Systems 20 (NIPS) (J.C. Platt, D. Koller, Y. Singer, and S. Roweis, eds.), 1177-1184, MIT Press, Cambridge, MA. Scholkopf, B., C. J, C. Burges, and A. J. Smola, eds. (1999). Advances in Kernel Methods: Support Vector Learning. MIT Press, Cambridge, MA. Scholkopf, B. and A. J. Smola, eds. (2002). Learning with Kernels: Support Vec­ tor Machines^ Regularization, Optimization and Beyond. MIT Press, Cam­ bridge, MA. Shalev-Shwartz, S., Y. Singer, N. Sr ebro, and A. Cotter. (2011). uPegasos: Pri­ mal estimated sub-gradient solver for SVM.\" Mathematical Programming^ 127(1):3-30. Smola, A. J, and B. Scholkopf. (2004). “A tutorial on support vector regres- sion.^^ Statistics and Computing, 14(3):199-222. 144 第 6 章 支 持 向 量 机",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 406
    }
  },
  {
    "page_content": "127(1):3-30. Smola, A. J, and B. Scholkopf. (2004). “A tutorial on support vector regres- sion.^^ Statistics and Computing, 14(3):199-222. 144 第 6 章 支 持 向 量 机 Tsang, I. W., J. T. Kwok, and P. Cheung. (2006), “Core vector machines: Fast SVM training on very large data sets? Journal of Machine Learning Research 6:363-392. Tsochantaridis, L, T. Joachims, T. Hofmann, and Y. Altun. (2005). “Large margin methods for structured and interdependent output v a ria b le s .Jour­ nal of Machine Learning Research, 6:1453-1484. Vapnik, V. N. (1995). The Nature of Statistical Learning Theory. Springer, New York, NY. Vapnik, V. N. (1998). Statistical Learning Theory. Wiley, New York, NY. Vapnik, V. N. (1999). “An overview of statistical learning theory.5, IEEE Trans­ actions on Neural Networks, 10(5):988-999. Vapnik, V. N. and A. J. Chervonenkis. (1991). “The necessary and sufficient conditions for consistency of the method of empirical risk.\" Pattern Recog­ nition and Image Analysis, 1(3):284-305. Williams, C. K. and M. Seeger. (2001). “Using the Nystrom method to speed",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 407
    }
  },
  {
    "page_content": "nition and Image Analysis, 1(3):284-305. Williams, C. K. and M. Seeger. (2001). “Using the Nystrom method to speed up kernel m achines.In Advances in Neural Information Processing Systems 13 (NIPS) (T. K. Leen, T. G. Dietterich, and V. Tresp, eds.), 682-688, MIT Press, Cambridge, MA. Yang, T.-B., Y.-F. Li, M. Mahdavi, R. Jin, and Z.-H. Zhou. (2012),. ^Nystrom method vs random Fourier features: A theoretical and empirical compari- son.\" In Advances in Neural Information Processing Systems 25 (NIPS) (P. Bartlett, F. C. N. Pereira, C. J. C. Burges, L. Bottou, and K. Q. Weinberger, eds.), 485-493, MIT Press, Cambridge, MA. Zhang, T. (2004). ^Statistical behavior and consistency of classification meth­ ods based on convex risk minimization (with d iscu ssio n ).Annals of Statis­ tics, 32(5):56-85. 休息一会儿 145 休息一会儿 S V M 的确与神经网络有 密 切 联 系 ：若 将 隐 层 神 经 元 数 设 置 为 训 练 样 本 数 , 且 每 个 训 练 样 本 对 应 一 个 神 经 元 中 心 ，则 以 高 斯 径向基函数为激活 函数的 R B F 网络(参见5.5.1节)恰 与 高 斯 核 S V M 的 预测函 数相同. 小故事：统计学习理论之父弗拉基米尔•瓦普尼克 弗拉基米尔・瓦普尼克(Vladimir N. Vapnik, 1936— ) 是杰出的数学家、统计学家、计算机科学家.他出生于苏 联，1958年在乌兹别克国立大学获数学硕士学位，1964年",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 408
    }
  },
  {
    "page_content": "小故事：统计学习理论之父弗拉基米尔•瓦普尼克 弗拉基米尔・瓦普尼克(Vladimir N. Vapnik, 1936— ) 是杰出的数学家、统计学家、计算机科学家.他出生于苏 联，1958年在乌兹别克国立大学获数学硕士学位，1964年 在莫斯科控制科学学院获统计学博士学位，此后一直在该校 工作并担任计算机系主任. 1990年(苏联解体的前一年)他 离开苏联来到新泽西州的美国电话电报公司贝尔实验室工作，1995年发表了 最 初 的 S V M 文章.当时神经网络正当红，因此这篇文章被权威期刊M aM加e 而g 要 求 以 “支持向量网络”的名义发表. 实际上，瓦 普 尼 克 在 1963年就已提出了支持向量的概念，1968年他与另 一位苏联数学家A. Chervonenkis提出了以他们两人的姓氏命名的“V C 维”， 1974年又提出了结构风险最小化原则，使得统计学习理论在二十世纪七十年代 就已成型.但这些工作主要是以俄文发表的，直到瓦普尼克随着东欧剧变和苏 联解体导致的苏联科学家移民潮来到美国，这方面的研究才在西方学术界引起 重视，统计学习理论、支持向量机、核方法在二十世纪末大红大紫. 瓦 普 尼 克 2002年 离 开 美 国 电 话 电 报 公 司 加 入 普 林 斯 顿 的 N E C 实验室, 2014年加盟脸书(Facebook)公司人工智能实验室. 1995年之后他还在伦敦大 学、哥伦比亚大学等校任教授.据说瓦普尼克在苏联根据一本字典自学了英语 及其发音.他有一句名言被广为传诵： “Nothing is more practical than a good theory.n 第 7 章 贝 叶 斯 分 类 器 7 . 1 贝 叶 斯决策论 贝叶斯决策论(Bayesian decision theory)是概率框架下实施决策的基本方 法.对分类任务来说,在所有相关概率都已知的理想情形下，贝叶斯决策论考虑 如何基于这些概率和误判损失来选择最优的类别标记.下面我们以多分类任务 为例来解释其基本原理. 假 设 有 N 种可能的类别标记，即 ＞ = {ci, C2,… ，CN}, % 是将一个真实 标 记 为 勺 的 样 本 误 分 类 为 &所 产 生 的 损 失 .基 于 后 验 概 率P © | x)可获得将 样 本 x 分 类 为 Ci所产生的期望损失(expected loss),即在样本x 上 的 “条件风 决 策 论 中 将 “期望损 失”称 为 “风险”(risk). 险” (conditional risk) N R © I ①)= 入行P © | x) . (7.1) 我们的任务是寻找一个判定准则M ％ 1 ， 以最小化总体风险",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 409
    }
  },
  {
    "page_content": "样 本 x 分 类 为 Ci所产生的期望损失(expected loss),即在样本x 上 的 “条件风 决 策 论 中 将 “期望损 失”称 为 “风险”(risk). 险” (conditional risk) N R © I ①)= 入行P © | x) . (7.1) 我们的任务是寻找一个判定准则M ％ 1 ， 以最小化总体风险 R[K}=^ x \\R{h (x) | x)] . (7.2) 显然，对每个样本x,若 h 能最小化条件风险R{h[x} |宓)，则总体风险R(h)也 将被最小化.这就产生了贝叶斯判定准则(Bayes decision rule):为最小化总体 风险，只需在每个样本上选择那个能使条件风险尺(c | 0 最小的类别标记，即 h*(x) = arg min R(c | x) , (7.3) c e y 此时，h*称为贝叶斯最优分类器(Bayes optimal classifier),与之对应的总体风 险 R g 称为贝叶斯风险(Bayes risk). 1 - R ( h ^ 反映了分类器所能达到的最 好性能，即通过机器学习所能产生的模型精度的理论上限. 错误率对应于 0 / 1 损失 函数,参见第6 章. 具体来说,若目标是最小化分类错误率，则误判损失人词可写为 148 % = [ °, 曲 — ； [ 1, otherwise, 第 7 章 贝叶斯分类器 (7.4) 注意，这只是从概率框 架的角度来理解机器学习; 事实上很多机器学习技术 无须准确估计出后验概率 就能准确进行分类. 此时条件风险 R(c \\ x) = 1 — P ( c | x ) , (7.5) 于是，最小化分类错误率的贝叶斯最优分类器为 拉*(况)= arg m a x F ( c | x ) , (7.6) 即对每个样本应选择能使后验概率P ( c | ⑼ 最大的类别标记. 不难看出，欲使用贝叶斯判定准则来最小化决策风险，首先要获得后验概 率 P ( c | 宏).然而，在现实任务中这通常难以直接获得.从这个角度来看，机 器学习所要实现的是基于有限的训练样本集尽可能准确地估计出后验概率 P ( c | x ) . 大体来说，主要有两种策略：给 定 期 可 通 过 直 接 建 模 P(c | x ) 来 预 测 c , 这 样 得 到 的 是 “判别式模型\" (discriminative m o d e l s ) ; 也可先对联合",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 410
    }
  },
  {
    "page_content": "器学习所要实现的是基于有限的训练样本集尽可能准确地估计出后验概率 P ( c | x ) . 大体来说，主要有两种策略：给 定 期 可 通 过 直 接 建 模 P(c | x ) 来 预 测 c , 这 样 得 到 的 是 “判别式模型\" (discriminative m o d e l s ) ; 也可先对联合 概 率 分 布 P Q , c ) 建模，然 后 再 由 此 获 得 P ( c | ⑼ ，这 样 得 到 的 是 “生成式模 型 \" (generative m o d e l s ) . 显然，前面介绍的决策树、B P 神经网络、支持向量 机等，都可归入判别式模型的范畴.对生成式模型来说，必然考虑 = 需. i ) 基于贝叶斯定理，F ( c | ⑼ 可写为 P{c | X)= P(c) P(x I c) P Q ) (7.7) (7.8) 对所有类标记均 相同. 为便于讨论，.我们假设 所有属性均为离散型.对 连续属性，可将概率质量 函数P (・)换成概率密度函 数 p4). 其中，P ( c ) 是 类 “先验”(prior)概率；P(x | c)是 样 本 z 相 对 于 类 标 记 c 的类 条件概率(class-conditional probability),或 称 为 “似然\" (likelihood); 是 用 于 归 一 化 的 “证 据 \" (evidence)因 子 .对 给 定 样 本 期 证 据 因 子 P Q ) 与类标 记无关，因此估 计 P(c |⑼ 的 问题就转化为如何基于训练数据D 来估计先验 P ( c ) 和似然 P Q | c). 类 先 验 概 率 P © 表达了样本空间中各类样本所占的比例，根据大数定律, 当训练集包含充足的独立同分布样本时,尸(c)可通过各类样本出现的频率来进 行估计. 对类条件概率 P Q , c ) 来说，由于它涉及关于x 所有属性的联合概率，直 7 . 2 极大似然估计 参 见 7 .3 节. 接根据样本出现的频率来估计将会遇到严重的困难.例如，假 设 样 本 的 d 个属 性都是二值的，则样本空间将有2d种可能的取值，在现实应用中，这个值往往 远 大 于 训 练 样 本 数 他 也 就 是 说 ，很多样本取值在训练集中根本没有出现，直 接使用频率来估计P Q | C) 显然不可行，因 为 “未被观测到”与 “出现概率为 149 零 ”通常是不同的. 7 . 2 极 大 似 然 估 计 连续分布下为概率密度 函数 p (£D | C). 估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 411
    }
  },
  {
    "page_content": "远 大 于 训 练 样 本 数 他 也 就 是 说 ，很多样本取值在训练集中根本没有出现，直 接使用频率来估计P Q | C) 显然不可行，因 为 “未被观测到”与 “出现概率为 149 零 ”通常是不同的. 7 . 2 极 大 似 然 估 计 连续分布下为概率密度 函数 p (£D | C). 估计类条件概率的一种常用策略是先假定其具有某种确定的概率分布形 式，再基于训练样本对概率分布的参数进行估计.具体地，记关于类别c 的类条 件概率为P Q | 力 假 设 尸 Q | c ) 具有确定的形式并且被参数向量0c 唯一确定, 则我们的任务就是利用训练集D 估计参数ec.为明确起见，我 们 将P(x I c ) 记 为 P(x\\仇). 从二十世纪二三十年代 开 始 出 现 了 频 率 主 义 学 派和贝叶斯学派的争论, 至今仍在继续.两派在很 多重要问题上观点不同, 甚 至 在 对 概 率 的 基 本 解 释上就有分歧.有兴趣的 读 者 可 参 阅 [Efron, 2005; Samaniego, 2010]. 事实上，概率模型的训练过程就是参数估计(parameter estimation)过程. 对于参数估计，统计学界的两个学派分别提供了不同的解决方案：频率主义学 派(Frequentist)认为参数虽然未知，但却是客观存在的固定值，因此，可通过优 化似然函数等准则来确定参数值；贝叶斯学派(Bayesian)则认为参数是未观察 到的随机变量，其本身也可有分布，因此，可假定参数服从一个先验分布，然后 基于观测到的数据来计算参数的后验分布.本节介绍源自频率主义学派的极大 似然估计(Maximum Likelihood E stim ation,简 称 M L E ),这是根据数据采样来 亦 称 “极大似然法”. 估计概率分布参数的经典方法. 令 D c 表示训练集D 中 第 c 类样本组成的集合，假设这些样本是独立同分 布的，则 参 数0c 对于数据集D c 的似然是 | %) = I J P(x | 仇 ). (7.9) xeD c 对 ec 进行极大似然估计,就是去寻找能最大化似然P(D C | & ) 的参数值ec.直 观上看，极大似然估计是试图在依所有可能的取值中，找到一个能使数据出现 的 “可能性”最大的值. 式(7.9)中的连乘操作易造成下溢，通常使用对数似然(log-likelihood) LL(ec) = log P(DC | 0C) = £ log。⑶ | ec) , (7.io) xeD c 150 第 7 章 贝叶斯分类器 此时参数ec 的极大似然估计oc 为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 412
    }
  },
  {
    "page_content": "的 “可能性”最大的值. 式(7.9)中的连乘操作易造成下溢，通常使用对数似然(log-likelihood) LL(ec) = log P(DC | 0C) = £ log。⑶ | ec) , (7.io) xeD c 150 第 7 章 贝叶斯分类器 此时参数ec 的极大似然估计oc 为 0c = arg max LL(^C) . ec (7.11) N 为正态分布，参见附 录 C.I.7. 例如，在连续属性情形下,假设概率密度函数p Q | N g 吗 ,则参数 生 和 蟾 的 极 大 似 然 估 计 为 瓦 = 方 £ X ， I cl xeD c 登 二焉 £ 3 - \" c ) 3 - MC)T , I T xeD c (7」2) (7.13) 也就是说，通 过 极 大 似 然 法 得 到 的 正 态 分 布 均 值 就 是 样 本 均 值 ，方差就是 Q - 瓦 ) 3 - MC)T 的均值,这显然是一个符合直觉的结果.在离散属性情形下, 也可通过类似的方式估计类条件概率. • 需注意的是，这种参数化的方法虽能使类条件概率估计变得相对简单，但 估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数 据分布.在现实应用中，欲做出能较好地接近潜在真实分布的假设,往往需在一 定程度上利用关于应用任务本身的经验知识，否 则 若 仅 凭 “猜测”来假设概率 分布形式，很可能产生误导性的结果. 7 . 3 朴素贝叶斯分类器 不难发现,基于贝叶斯公式(7.8)来估计后验概率P(c | ⑼ 的主要困难在于: 类 条 件 概 率 F Q | c ) 是所有属性上的联合概率，难以从有限的训练样本直接 估计而得.为避开这个障碍，朴素贝叶斯分类器(naive Bayes classifier)采用了 “属性条件独立性假设 \" (attribute conditional independence assumption): 对 已知类别，假设所有属性相互独立.换言之,假设每个属性独立地对分类结果发 生影响. 基于属性条件独立性假设，式(7.8)可重写为 ・ R c ㈤ = 舐 口 P ⑵ ㈤ ，. (7•⑷ 基于有限训练样本直接 估计联合概率，在计算上 将会遭遇组合爆炸问题, 在数据上将会遭遇样本稀 疏问题;属性数越多，问题 越严重. 7 . 3 朴素贝叶斯分类器",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 413
    }
  },
  {
    "page_content": "生影响. 基于属性条件独立性假设，式(7.8)可重写为 ・ R c ㈤ = 舐 口 P ⑵ ㈤ ，. (7•⑷ 基于有限训练样本直接 估计联合概率，在计算上 将会遭遇组合爆炸问题, 在数据上将会遭遇样本稀 疏问题;属性数越多，问题 越严重. 7 . 3 朴素贝叶斯分类器 X i 实 际 上 是 一 个 “属 性 - < ” 对 ， 例 如 “色 泽 =青 绿 ” .为 便 于 讨 论 ， 在 上 下 文 明 确 时 ，有 时我 们 用 Xi表 示 第 i 个 属 性 对 应 的 变 量 (如 “色泽”)， 有 时 直 接 用 其 指 代 0 在第 i个 属 性 上 的 取 值 (如 “青 绿 ”). 其 中 d 为属性数目，g 为 % 在 第 5 个属性上的取值. 由于对所有类别来说P Q ) 相同，因此基于式(7.6)的贝叶斯判定准则有 d 151 hnb[x} = arg max P(c) 口 P (& | c) , © i=1 (7.15) 这 就 是朴素贝叶斯分类器的表达式.. 显然，朴素贝叶斯分类器的训练过程就是基于训练集D 来估计类先验概率 F ( c ) , 并为每个属性估计条件概率P(xi \\ c). 令 D c 表示训练集D 中 第 c 类样本组成的集合，若有充足的独立同分布样 本，则可容易地估计出类先验概率 P ( c ) = 患 . (7.16) 对离散属性而言，令 D c,X i 表 示 D c 中 在 第i个属性上取值为g 的样本组成的 集合，则条件概率P{Xi | c)可估计为 P ( 0 | c ) = (7.17) 对连续属性可考虑概率密度函数,假定p ® I c) ~ N g i , 吃3 其 中 和 略 分别是第。类样本在第2 个属性上取值的均值和方差，则 有 ‘ ‘ 如 ⑷ 一 庄 分,「x p ( 2端 ) - ( 7 -1 8 ) 西 瓜 数 据 集 3.0见 p.84 表 4.3. 1” 进行分类： 下 面 我 们 用 西 瓜 数 据 集 3 .0 训练一个朴素贝叶斯分类器，对 测 试 例 “测 编 号 色 泽 根 蒂 敲 声 纹 理 脐 部 触 感 密度 含 糖 率 好 瓜 测 1 青 绿 蜷 缩 浊响 清晰 凹陷 硬滑 0.697 0.460 ? 首先估计类先验概率P ( c ) , 显然有 P (好瓜= 是 )= 再 * 0.471 , O 0 P (好瓜= 否 )= ^ 0.529 . 152 第 7 章 贝 叶 斯 分 类 器",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 414
    }
  },
  {
    "page_content": "测 1 青 绿 蜷 缩 浊响 清晰 凹陷 硬滑 0.697 0.460 ? 首先估计类先验概率P ( c ) , 显然有 P (好瓜= 是 )= 再 * 0.471 , O 0 P (好瓜= 否 )= ^ 0.529 . 152 第 7 章 贝 叶 斯 分 类 器 注意，当样本数目足够 多时才能进行有意义的概 率估计.本书仅是以西瓜 数据集3.0对估计过程做 一个简单的演示. 然 后 ，为 每 个 属 性 估 计 条 件 概 率P ⑶ | C）： 「青绿|是= 「（色 泽 = 青 绿 | 好 瓜 = 是 ）= 看= 0.375 , O P 青绿|否= P （色 泽 = 青 绿 I 好 瓜 = 否 ）= * 0.333 , 璘缩|是= 「（根 蒂 = 蜷 缩 | 好 瓜 = 是）= f = 0.375 , 珠缩। 否= P （根 蒂 = 蜷 缩 | 好 瓜 = 否）= § 弋 0.333 , O Q P 浊响|是~ P （敲 声 = 浊 响 | 好 瓜 = 是）= ? = 0.750 , 玛响|否= P （敲 声 — 浊 响 | 好 瓜 = 否）= g * 0.444 , 冷晰|是= ? （纹 理 = 清 晰 | 好 瓜 = 是 ）= ：= 0.875 , 7 冷晰|否= P （纹 理 = 清 晰 I 好 瓜 = 否）= O 9 0.222 , P 凹陷|是= 。（脐 部 = 凹 陷 | 好 瓜 = 是 ）= ? = 0.750 , P 凹陷|否= P （脐 部 = 凹 陷 | 好 瓜 = 否 ）= 黑 0.222 , O 圆滑|是= P （触 感 = 硬 滑 I 好 瓜 = 是 ）= ? = 0.750 , 8 凝滑|否= 「（触 感 = 硬 滑 I 好 瓜 = 否）= ^ 0.667 , 。密度:0.697|是 = P （密 度 = 0.697 | 好 瓜 = 是 ） _ ― 1 0.129 e x p （ （ （0.697 - 0.574）2 \\ r 0.1292— \"） * 1.959 , 0密度：0.697|否 = P （密 度 = 0.697 | 好 瓜 = 否 ） _ — 后 .0.195 e X P \\ （ （0.697 - 0.496）2 \\ J a 0」952 1 P含糖:0.460]是 = 0 （含 糖 率 = 0.460 | 好 瓜 = 是） _ _ 1 _ 一 \\/2^-0.101 e X P \\ 『 （ （0 .4 6 0 _0 .2 7 吟 2-0.101 2 — /",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 415
    }
  },
  {
    "page_content": "_ — 后 .0.195 e X P \\ （ （0.697 - 0.496）2 \\ J a 0」952 1 P含糖:0.460]是 = 0 （含 糖 率 = 0.460 | 好 瓜 = 是） _ _ 1 _ 一 \\/2^-0.101 e X P \\ 『 （ （0 .4 6 0 _0 .2 7 吟 2-0.101 2 — / 2含糖:o.46o|否 = 0 （含 糖 率 = 0.460 | 好 瓜 = 否） _ _ ] *0.108 的 （ ex （ （0-460 -0 .1 5 4 ）2、 / 2-0.108 2 * 1.203 , y 0.788 , ~ 0.066 . 7 . 3 朴素贝叶斯分类器 153 于 是 ，有 实践中常通过取对数的 方式来将“连乘”转化为 “连加”以避免数值下溢. P (好 瓜 = 是 ) X P 青绿I是 X 强 缩 |是 X 尸浊响|是X 冷 晰 |是 X P 凹陷|是 X 版 滑 I是 X p 密度：0.6971是 义 0 含糖：0.4601是 仁°.038 , P (好 瓜 = 否 )义 P 青绿|否义P 蜷缩1否 X P 浊响1否 X 尸清晰I否 X P 凹陷|否 义舄g滑|否X 0 密度：0.697|否 X P 含糖：0.460|否 6.80 X 10 5 . 由 于 0.038 > 6.80 x 10-5,因 此 朴 素 贝 叶 斯 分 类 器 将 测 试 样 本 “测 J 判 别为 “好 瓜 ”. 需 注 意 ，若 某 个 属 性 值 在 训 练 集 中 没 有 与 某 个 类 同 时 出 现 过 ，则 直 接 基 于 式 (7.17)进 行 概 率 估 计 ，再 根 据 式 (7.15)进 行 判 别 将 出 现 问 题 .例 如 ，在 使 用 西 瓜 数 据 集 3.0训 练 朴 素 贝 叶 斯 分 类 器 时 ,对 一 个 “敲 声 = 清 脆 ” 的 测 试 例 ，有 P 清脆|是= P ( 敲 声 = 清 脆 I好 瓜 = 是 ) = £ = 。， 由 于 式 (7.15)的 连 乘 式 计 算 出 的 概 率 值 为 零 ，因 此 ，无 论 该 样 本 的 其 他 属 性 是 什 么 ，哪 怕 在 其 他 属 性 上 明 显 像 好 瓜 ，分 类 的 结 果 都 将 是 “好 瓜 = 否 ”，这 显 然 不 太合理. 为 了 避 免 其 他 属 性 携 带 的 信 息 被 训 练 集 中 未 出 现 的 属 性 值 “抹 去 ”，",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 416
    }
  },
  {
    "page_content": "由 于 式 (7.15)的 连 乘 式 计 算 出 的 概 率 值 为 零 ，因 此 ，无 论 该 样 本 的 其 他 属 性 是 什 么 ，哪 怕 在 其 他 属 性 上 明 显 像 好 瓜 ，分 类 的 结 果 都 将 是 “好 瓜 = 否 ”，这 显 然 不 太合理. 为 了 避 免 其 他 属 性 携 带 的 信 息 被 训 练 集 中 未 出 现 的 属 性 值 “抹 去 ”， 在 估 计 概 率 值 时 通 常 要 进 行 “平 滑 ” (smoothing),常 用 “拉 普 拉 斯 修 正 “(Laplacian correction).具 体 来 说 ，令 N 表 示 训 练 集 D 中 可 能 的 类 别 数 ,凡 表 示 第 i个 属 性 可 能 的 取 值 数 ，则 式 (7.16)和 (7.17)分 别 修 正 为 户 二 网 + 1 © 一 I 0 + N ， … )二版需• (7.19) (7.20) 例 如 ，在 本 节 的 例 子 中 ，类 先 验 概 率 可 估 计 为 户 (好 瓜 = 是 ) = .L ( 十 / « 0.474 , 户 (好 瓜 = 否 ) = JL ( I ' Z 2 0.526 . 类 似 地 ，P 青绿I是和P 青绿I否 可 估 计 为 户青绿|是= 户 (色 泽 = 青 绿 I好 瓜 = 是 ) = W 弋 0.364 , o -r o 154 第 7 章 贝叶斯分类器 户青绿। 否= 户(色泽= 青 绿 |好 瓜 = 否 )= ~ 0.333 . 同时，上文提到的概率 冷 脆 I是可估计为 编 脆 1是= 户(敲声= 清 脆 |好 瓜 = 是 )= 岩 弋 0.091 . o -r o 拉普拉斯修正实质上假 设了属性值与类别均匀分 布，这是在朴素贝叶斯学 习过程中额外引入的关于 数据的先验. 显然，拉普拉斯修正避免了因训练集样本不充分而导致概率估值为零的问题, 并且在训练集变大时，修正过程所引入的先验(prior)的影响也会逐渐变得可忽 略，使得估值渐趋向于实际概率值. 在现实任务中朴素贝叶斯分类器有多种使用方式.例如，若任务对预测速 度要求较高，则对给定训练集，可将朴素贝叶斯分类器涉及的所有概率估值事 先计算好存储起来，这样在进行预测时只需“查表”即可进行判别；若任务数 懒惰学习参见io 」节. 据更替频繁，则 可 采 用 “懒惰学习”(lazy learning)方式，先不进行任何训练, 待收到预测请求时再根据当前数据集进行概率估值；若数据不断增加,则可在 现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可 增量学习参见5.5.2节. 实现增量学习.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 417
    }
  },
  {
    "page_content": "先计算好存储起来，这样在进行预测时只需“查表”即可进行判别；若任务数 懒惰学习参见io 」节. 据更替频繁，则 可 采 用 “懒惰学习”(lazy learning)方式，先不进行任何训练, 待收到预测请求时再根据当前数据集进行概率估值；若数据不断增加,则可在 现有估值基础上，仅对新增样本的属性值所涉及的概率估值进行计数修正即可 增量学习参见5.5.2节. 实现增量学习. 7 . 4 半 朴 素 贝 叶 斯 分 类 器 为了降低贝叶斯公式(7.8)中估计后验概率P ( c | ⑼ 的困难，朴素贝叶斯分 类器采用了属性条件独立性假设，但在现实任务中这个假设往往很难成立.于 是，人们尝试对属性条件独立性假设进行一定程度的放松，由此产生了一类称 为 “半朴素贝叶斯分类器“(semi-n疝ve B a y e s classifiers)的学习方法. 半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信 息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依 赖 关 系 .“独依赖估计\" ( O n e - D e p e n d e n t E s t i m a t o r ,简 称 O D E ) 是半朴素贝叶 斯分类器最常用的一种策略.顾名思议，所 谓 “独依赖”就是假设每个属性在 类别之外最多仅依赖于一个其他属性，即 d I x) oc F(c) P(xi I c.pai) , (7.21) 其 中 pai为属性F 所依赖的属性，称 为 电 的 父 属 性 .此 时 ，对 每 个 属 性 如 若 其 父 属 性 0 电已知，则可采用类似式(7.20)的办法来估计概率值P ( g | c.pai). 于是，问题的关键就转化为如何确定每个属性的父属性，不同的做法产生不同 7 . 4 半朴素贝叶斯分类器 155 的独依赖分类器. 最直接的做法是假设所有属性都依赖于同一个属性，称 为 “超父”(super- parent), 然 后 通 过 交 叉 验 证 等 模 型 选 择 方 法 来 确 定 超 父 属 性 ，由此形成了 SPODE (Super-Parent ODE)方法.例如，在 图 7.1(b)中，的是超父属性. 图 7 . 1 朴素贝叶斯与两种半朴素贝叶斯分类器所考虑的属性依赖关系 TAN (Tree Augmented naive Bayes) ［Friedman et al., 1997］则是在最大带 权生成树(maximum weighted spanning tree)算 法 ［Chow and Liu, 1968］的基 础上，通过以下步骤将属性间依赖关系约简为如图7.1(c)所示的树形结构：",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 418
    }
  },
  {
    "page_content": "TAN (Tree Augmented naive Bayes) ［Friedman et al., 1997］则是在最大带 权生成树(maximum weighted spanning tree)算 法 ［Chow and Liu, 1968］的基 础上，通过以下步骤将属性间依赖关系约简为如图7.1(c)所示的树形结构： ⑴计算任意两个属性之间的条件互信息(conditional mutual information) /（& , 叼 I y）= £ P （Xi,Xj | c）log g,叼；cey P （g , 叼 | c） P 3 I c）。（叼 I c） （7.22） ( 2 ) 以 属 性 为 结 点 构 建 完 全 图 ，任 意 两 个 结 点 之 间 边 的 权 重 设 为 / ( 3 , 叼 | y); ( 3 ) 构建此完全图的最大带权生成树，挑选根变量,将边置为有向； ( 4 ) 加入类别结点y , 增 加 从 y 到每个属性的有向边. 容易看出，条件互信息/(0 ,叼| y ) 刻 画 了 属 性 /和 叼 在 已 知 类 别 情 况 下 的相关性，因此，通过最大生成树算法，T A N 实际上仅保留了强相关属性之间 的依赖性. AODE (Averaged One-Dependent Estimator) ［Webb et al., 2005］是一种 集成学习参见第8章. 基于集成学习机制、更为强大的独依赖分类器.与SPO D E通过模型选择确定 超父属性不同，A O D E尝试将每个属性作为超父来构建SPO D E ,然后将那些 156 第 7 章 .贝 叶 斯 分 类 器 具有足够训练数据支撑的SPO D E集成起来作为最终结果，即 d d ㈤ a £ P (3 ⑷ J I P (叼 I C, Xi), (7.23) 2=1 j = l \\DXi\\^m, m / 默 认 设 为 30 [Webb et aL, 2005]. 其 中 D X i 是 在 第 Z个 属 性 上 取 值 为 g 的样本的集合，m f 为阈值常数.显然, AODE 需估计 F(c, & ) 和 P(Xj | c, g ) . 类似式(7.20),有 小 ) 」 向 北 ， 口 ”小 ㈤ 一 | % 」+ 吗 ' 亿 24) (725) 其 中 Ni是 第 2 个属性可能的取值数，D CjXi是 类 别 为 C且 在 第 2 个属性上取值 为 g 的样本集合，D c^ X j 是 类 别 为 c 且 在 第 i和 第 j 个属性上取值分别为g 和叼的样 本 集 合 .例 如 ，对西瓜数据集3.0 有",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 419
    }
  },
  {
    "page_content": "小 ) 」 向 北 ， 口 ”小 ㈤ 一 | % 」+ 吗 ' 亿 24) (725) 其 中 Ni是 第 2 个属性可能的取值数，D CjXi是 类 别 为 C且 在 第 2 个属性上取值 为 g 的样本集合，D c^ X j 是 类 别 为 c 且 在 第 i和 第 j 个属性上取值分别为g 和叼的样 本 集 合 .例 如 ，对西瓜数据集3.0 有 户是，浊 响 = 户(好瓜= 7E,敲 尸 = 浊 响 )= = 0.350 , 户凹陷|是，浊 响 —户(脐部= 凹卜臼 好 瓜 = 是 ,敲 尸 = 浊响 )= = 0.444 . 不难看出，与朴素贝叶斯分类器类似,A O D E 的训练过程也是“计数”，即 在训练数据集上对符合条件的样本进行计数的过程.与朴素贝叶斯分类器相 似,.AO DE无需模型选择，既能通过预计算节省预测时间，也能采取懒惰学习方 式在预测时再进行计数，并且易于实现增量学习. 既然将属性条件独立性假设放松为独依赖假设可能获得泛化性能的提升, 那么，能否通过考虑属性间的高阶依赖来进一步提升泛化性能呢？也就是说, 将式(7.23)中的属性pai替 换 为 包 含k 个属性的集合p a i , 从 而 将 O D E 拓展为 k D E .需注意的是，随 着 k 的增加，准 确 估 计 概 率P g | % p % )所需的训练样 本数量将以指数级增加.因此，若训练数据非常充分，泛化性能有可能提升；但 在有限样本条件下，则又陷入估计高阶联合概率的泥沼. “高阶依赖” 即对多个 属性依赖. 贝叶斯网是一种经典的 概率图模型.概率图模型 参见 第 1 4 章. 7 . 5 贝叶斯网 贝叶斯网(Bayesian network)亦 称 “信念网”(belief netw ork),它借助有向 无 环 图 (Directed Acyclic G rap h ,简 称 DAG)来刻画属性之间的依赖关系，并使 7 . 5 贝叶斯网 为 了 简 化 讨 论 ，本 节 假 定 所 有 属 性 均 为 离 散 型 . 对 于 连 续 属 性 ，条 件 概 率 表 可 推 广 为 条 件 概 率 密 度 函数. 157 用条件概率表(Conditional Probability T able,简 称 CPT)来描述属性的联合概 率分布. 具体来说,一个贝叶斯网B 由结构G 和 参数0 两部分构成，即 8 = G 0 ). 网 络 结 构 G 是一个有向无环图，其每个结点对应于一个属性，若两个属性有 直接依赖关系，则它们由一条边连接起来；参 数 。 定量描述这种依赖关系,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 420
    }
  },
  {
    "page_content": "157 用条件概率表(Conditional Probability T able,简 称 CPT)来描述属性的联合概 率分布. 具体来说,一个贝叶斯网B 由结构G 和 参数0 两部分构成，即 8 = G 0 ). 网 络 结 构 G 是一个有向无环图，其每个结点对应于一个属性，若两个属性有 直接依赖关系，则它们由一条边连接起来；参 数 。 定量描述这种依赖关系, 假 设 属 性 电 在 G 中 的 父 结 点 集 为队 则 0 包含了每个属性的条件概率表 % g = I G 这 里 已 将西瓜数据集的 连 续 属 性 “含 糖 率 ” 转化 为 离 散 属 性 “甜 度 ” . 作为一个例子，图 7 .2 给 出 了 西 瓜 问 题 的 一 种 贝 叶 斯 网 结 构 和 属 性 “根 蒂 ”的条件概率表.从图中网络结构可看出，“色 泽 ”直 接 依 赖 于 “好 瓜 ”和 “甜 度 ”，而 “根 蒂 ”则 直 接 依 赖 于 “甜 度 ”；进一步从条件概率表能得到 “根蒂”对 “甜度”量化依赖关系，如 P (根蒂= 硬 挺 |甜 度 = 高 )= 0 .1 等. 图 7 . 2 西瓜问题的一种贝叶斯网结构以及属性“根蒂”的条件概率表 7 .5 .1 结构 贝叶斯网结构有效地表达了属性间的条件独立性.给定父结点集，贝叶斯 网假设每个属性与它的非后裔属性独立，于 是 5 = (G, 0 ) 将 属 性 的 4 2 , . . ., 切 的联合概率分布定义为 为 ( 6 1 , 6 2 , .. .,费)= 口 为 ( 0 | = 口 纵 机 ♦ (7.26) d d 2=1 2=1 以 图 7 .2 为例，联合概率分布定义为 P ( X 1 , X 2 , X 3 , X 4 , X 5 ) = F ( X 1 ) F ( ^ 2 ) P ( X 3 I / 1 ) P ( > 4 | 劣 1 出2)召(磔 | / 2 ) , 显然，力3 和 7 4 在 给 定 叼 的 取 值 时 独 立 ，力4 和 6 5 在给定为2 的取值时独立，分 这 里并未列举出所有的 条件独立关系. 别简记为劣3 _ L 2 4 | 劣1 和 2 4 - L 6 5 | ^2. 图 7 .3 显示出贝叶斯网中三个变量之间的典型依赖关系，其中前两种在 式(7.26)中已有所体现. 158 第 7 章贝叶斯分类器 同父结构 V 型结构 顺序结构 图 7 . 3 贝叶斯网中三个变量之间的典型依赖关系 在 “同父”( c o m m o n parent)结构中，给定父结点力i 的取值，则 g 与力4",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 421
    }
  },
  {
    "page_content": "图 7 .3 显示出贝叶斯网中三个变量之间的典型依赖关系，其中前两种在 式(7.26)中已有所体现. 158 第 7 章贝叶斯分类器 同父结构 V 型结构 顺序结构 图 7 . 3 贝叶斯网中三个变量之间的典型依赖关系 在 “同父”( c o m m o n parent)结构中，给定父结点力i 的取值，则 g 与力4 条 件 独 立 .在 “顺序”结构中，给定力的值，则 g 与 z 条 件 独 立 .V 型结构(V- structure)亦 称 \"冲 撞 ”结构，给 定 子 结 点 皿 的 取 值 ，叫 与 ^ 2 必不独立；奇妙 的是，若窈的取 值 完 全 未 知 ，则 V 型结构下的与力2 却是相互独立的.我们做 一个简单的验证： P ( 如 / 2 ) = X4 = £ 「侬4 | X1,X2)P(X1)P(X2) X4 = P Q I ) P ( / 2 ) . (7.27) 对变量做积 分 或 求 和 亦 称 \" 边 际 化 \" (marginal- ization). D 是 指 “有 向 \" (direct­ ed). 同父、顺 序 和 V 型结构 的 发 现 以 及 有 向 分 离 的 提 出推动了因果发现方面的 研 究 ，参 阅 [Pearl, 1988]. 这样的独立性称为“边际独立性\" (marginal independence),记为力iJL④2. 事实上，一个变量取值的确定与否，能对另两个变量间的独立性发生影响, 这个现象并非 V 型结构所特有.例如在同父结构中，条 件 独 立 性 /3 ， 力4 | 的 成立，但 若 如 的 取 值 未 知 ，则力3 和力4 就不独立，即力3止力4 不成立；在顺序结 构中，g _L z | 但 y_[]_z不成立. 为 了 分 析 有 向 图 中 变 量 间 的 条 件 独 立 性 ，可 使 用 “有 向 分 离 ”(D- separation).我们先把有向图转变为一个无向图： • 找出有向图中的所有V 型结构，在 V 型结构的两个父结点之间加上一条 无向边； • 将所有有向边改为无向边. 也 有 译 为 “端正图”. 由 此 声 生 的 无 向 图 称 为 “道 德 图 ”(moral graph),令父结点相连的过程称为 “道 德 化 ” 的 蕴 义 ：孩 子 的 父 母 应 建 立 牢 靠 的 关 系，否则是不道德的. “道 德 化 \" (moralization) [Cowell et al., 1999]. 基于道德图能直观、迅速地找到变量间的条件独立性.假定道德图中有变 量 % a 和变量集合Z = { a } , 若变量力和y 能在图上被Z 分开，即从道德图中将",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 422
    }
  },
  {
    "page_content": "“道 德 化 ” 的 蕴 义 ：孩 子 的 父 母 应 建 立 牢 靠 的 关 系，否则是不道德的. “道 德 化 \" (moralization) [Cowell et al., 1999]. 基于道德图能直观、迅速地找到变量间的条件独立性.假定道德图中有变 量 % a 和变量集合Z = { a } , 若变量力和y 能在图上被Z 分开，即从道德图中将 7 . 5 贝叶斯网 159 变 量 集 合 Z 去除后，④和 y 分属两个连通分支，则称变量力和沙被 Z 有向分离, 出JL g | z 成 立 .例 如 ，图 7 . 2 所对应的道德图如图7 . 4 所示，从图中能容易地找 出所有的条件独立关系：2 3 力4 | / 4 - L / 5 |①2 , N 3 ， ①2 |①1 , 力3 _ L 啰5 | 3 , 的 _ L 磔| X2等. 图 7 . 4 图 7.2对应的道德图 7 .5 .2 学习 若网络结构已知，即属性间的依赖关系已知，则贝叶斯网的学习过程相对 简单，只需通过对训练样本“计数”，估计出每个结点的条件概率表即可.但在 现实应用中我们往往并不知晓网络结构，于是，贝叶斯网学习的首要任务就是 根据训练数据集来找出结构最“恰当”的 贝 叶 斯 网 .“评分搜索”是求解这一 问题的常用办法.具体来说，我们先定义一个评分函数(score function),以此来 评估贝叶斯网与训练数据的契合程度，然后基于这个评分函数来寻找结构最优 的贝叶斯网.显然，评分函数引入了关于我们希望获得什么样的贝叶斯网的归 归纳偏好参见1.4节. 纳偏好. 常用评分函数通常基于信息论准则，此类准则将学习问题看作一个数据压 缩任务，学习的目标是找到一个能以最短编码长度描述训练数据的模型，此时 编码的长度包括了描述模型自身所需的字节长度和使用该模型描述数据所需 的字节长度.对贝叶斯网学习而言，模型就是一个贝叶斯网，同时，每个贝叶斯 网描述了一个在训练数据上的概率分布，自有一套编码机制能使那些经常出 现 的 样 本有更短的编码.于是，我们应选择那个综合编码长度(包括描述网络 和编码数据)最短的贝叶斯网，这 就 是 “最小描述长度”(Minimal Description L ength,简 称 MDL)准则. 这里我们把类别也看作 一个属性，即 Xi是一个包 括示例和类别的向量. 给定训练集D = { 叫 , 狈 x m } , 贝叶斯网8 = 9 〉在 。 上的评分函 数可写为 s(B \\D ) = f(O )\\B \\-L L (B \\D ), (7.28) 160 第 7 章 贝 吐 斯 分 类 器 其中\"却是贝叶斯网的参数个数;于⑼表示描述每个参数。所需的字节数;而",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 423
    }
  },
  {
    "page_content": "这里我们把类别也看作 一个属性，即 Xi是一个包 括示例和类别的向量. 给定训练集D = { 叫 , 狈 x m } , 贝叶斯网8 = 9 〉在 。 上的评分函 数可写为 s(B \\D ) = f(O )\\B \\-L L (B \\D ), (7.28) 160 第 7 章 贝 吐 斯 分 类 器 其中\"却是贝叶斯网的参数个数;于⑼表示描述每个参数。所需的字节数;而 m 〃 ( 8 | 0 = £ l o g % ( g ) 2=1 (7.29) 是 贝 叶 斯 网 B 的 对 数 似 然 .显 然 ，式(7.28)的 第 一 项 是 计 算 编 码 贝 叶 斯 网B 所需的字节数，第 二 项 是 计 算B 所对应的概率分布PB 需多少字节来描述D. 于是，学习任务就转化为一个优化任务，即 寻 找 一 个 贝 叶 斯 网 B 使评分函数 s(B |。)最小. 若 f⑻ = 1 , 即 每 个 参 数 用1 字节描述，则 得 到 AIC (Akaike Information Criterion)评分函数 AIC(B | D) = \\B\\ - LL(B \\ JD) . (7.30) 若 f6) = 1 lo g M ,即每个参数用| lo g m 字节描述，则 得 到 BIC (Bayesian Information Criterion)评分函数 BIC(B | D) = - LL(B \\ D) . (7.31) 显然，若f⑻ = 0 , 即不计算对网络进行编码的长度，则评分函数退化为负 对数似然,相应的，学习任务退化为极大似然估计. 不 难 发 现 ，若 贝 叶 斯 网 B = (G,e)的 网 络 结 构 G 固定，则评分 函 数 s(B | D ) 的第一项为常数.此时,最小化s (8 | D ) 等价于对参数© 的极大似然 估计.由式(7.29)和(7.26)可知，参 数 9Xi^ 能直接在训练数据D 上通过经验估 计获得，即 % 凡 = I 项 )， (7.32) 即事件在训练数据上出 现的频率. 其 中 是 (•)是 。 上的经验分布.因此，为了最小化评分函数s(B | D ) , 只需对网 络结构进行搜索，而候选结构的最优参数可直接在训练集上计算得到. 不幸的是，从所有可能的网络结构空间搜索最优贝叶斯网结构是一个NP 难问题，难以快速求解.有两种常用的策略能在有限时间内求得近似解：第一 种是贪心法,例如从某个网络结构出发,每次调整一条边(增加、删除或调整方 向)，直到评分函数值不再降低为止;第二种是通过给网络结构施加约束来削减 搜索空间，例如将网络结构限定为树形结构等.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 424
    }
  },
  {
    "page_content": "不幸的是，从所有可能的网络结构空间搜索最优贝叶斯网结构是一个NP 难问题，难以快速求解.有两种常用的策略能在有限时间内求得近似解：第一 种是贪心法,例如从某个网络结构出发,每次调整一条边(增加、删除或调整方 向)，直到评分函数值不再降低为止;第二种是通过给网络结构施加约束来削减 搜索空间，例如将网络结构限定为树形结构等. 例如 TAN [Friedman et al., 1997]将结构限定为树 形(半朴素贝叶斯分类器 可看作贝叶斯网的特例). 7 . 5 贝叶斯网 161 7 .5 .3 推断 类别也可看作一个属性 变量. 更多关于推断的内容见 第 14章. 贝叶斯网训练好之后就能用来回答“查询”(q u ery ),即通过一些属性变量 的观测值来推测其他属性变量的取值.例如在西瓜问题中，若我们观测到西瓜 色泽青绿、敲声浊响、根蒂蜷缩，想知道它是否成熟、甜度如何.这样通过已 知变量观测值来推测待查询变量的过程称为“推 断 \" (inference),已知变量观 测 值 称 为 “证 据 \" (evidence). 最理想的是直接根据贝叶斯网定义的联合概率分布来精确计算后验概率, 不幸的是，这 样 的 “精确推断”已被证明是N P 难 的 [Cooper, 1990];换言之, 当网络结点较多、连接稠密时,难以进行精确推断，此 时 需 借 助 “近 似 推 断 \" 通过降低精度要求,在有限时间内求得近似解.在现实应用中，贝叶斯网的近似 变分推断也很常用，参 见 14.5节. 推断常使用吉布斯采样(Gibbs sampling)来完成，这是一种随机采样方法,我们 来看看它是如何工作的. 令 Q = ｛Ql, Q2,… ，Qn｝表示待查询变量,E = ｛瓦 ,⑼ ,… ，E k｝为证据变 量，已知其取值为e = ｛e i,段,.. .，ek｝. 目标是计算后验概率P(Q = q | E = e), 其 中 q = ｛仇,0 , . • •, M｝是待查询变量的一组取值.以西瓜问题为例，待查询变 量 为 Q = ｛好瓜，甜度｝,证 据 变 量 为E = ｛色泽，敲声，根蒂｝且已知其取值为 e = ｛青绿,浊响，蜷缩｝,查询的目标值是q = ｛是,高｝,即这是好瓜且甜度高的 概率有多大. 如 图 7.5所示，吉布斯采样算法先随机产生一个与证据E = e 一致电样本 q 0 作为初始点，然后每步从当前样本出发产生下一个样本.具体来说，在 第 t 次采样中，算 法 先 假 设 = q 2 T ,然后对非证据变量逐个进行采样改变其取值, 采样概率根据贝叶斯网B 和其他变量的当前取值(即Z = z)计算获得.假定经",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 425
    }
  },
  {
    "page_content": "如 图 7.5所示，吉布斯采样算法先随机产生一个与证据E = e 一致电样本 q 0 作为初始点，然后每步从当前样本出发产生下一个样本.具体来说，在 第 t 次采样中，算 法 先 假 设 = q 2 T ,然后对非证据变量逐个进行采样改变其取值, 采样概率根据贝叶斯网B 和其他变量的当前取值(即Z = z)计算获得.假定经 过 T 次采样得到的与q 一致的样本共有nq 个,则可近似估算出后验概率 P(Q = q | E = e » 畀 (7.33) 更多关于马尔可夫链和 吉 布 斯 采 样 的 内 容 参 见 14.5 节. 实质上，吉布斯采样是在贝叶斯网所有变量的联合状态空间与证据E = e 一 致 的 子 空 间 中 进 行 “随 机 漫 步 \"(random w a lk ) .每一步仅依赖于前一步 的状态，这 是 一 个 “马 尔 可 夫 链 ”(Markov c h a in ) .在 一 定 条 件 下 ，无论从 什么初始状态开始，马 尔 可 夫 链 第 t步 的 状 态 分 布 在 t T o o 时必收敛于一 个平稳分布(stationary distribution);对于吉布斯采样来说，这个分布恰好是 P(Q | E = e ) . 因 此 在 T 很大时，吉布斯采样相当于根据P(Q | E = e ) 采样, 从而保证了式(7.33)收 敛 于P (Q = q [ E = e). 162 第 7 章 贝 叶 斯 分 类 器 输入：贝叶斯网8 = 〈G ,@ ； 采样次数T; 证据变量E 及其取值e; 待查询变量Q 及其取值q. 除 去 变 量 Q 外的其他 变量. Z = E U Q \\{Q o}; z = eUq*- 1 \\ { Q-- 1 }; 根据B 计算分布PB {Qi [ Z = z); q-= 根据PB (QZ Z = Z) 采样廊获Qi取值； q方 = 将 q%T中的q『 用展替换 过程： 1・ n == Q 2: qW = 对Q 随机赋初值 3： for t = 1,2,... ,T do 4： for Qe € Q do 5： 6: 7： 8： 9: 10： 11： 12： 13： end if 14： end for 输出：P(Q = q | E = e) t 号 end for if q± = q then nq = nq + 1 图 7 . 5 吉布斯采样算法 需注意的是，由于马尔可夫链通常需很长时间才能趋于平稳分布，因此 吉布斯采样算法的收敛速度较慢.此外，.若贝 叶 斯 网 中 存 在 极 端 概 率 “0 ” 或",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 426
    }
  },
  {
    "page_content": "end for if q± = q then nq = nq + 1 图 7 . 5 吉布斯采样算法 需注意的是，由于马尔可夫链通常需很长时间才能趋于平稳分布，因此 吉布斯采样算法的收敛速度较慢.此外，.若贝 叶 斯 网 中 存 在 极 端 概 率 “0 ” 或 “ 1” ，则不能保证马尔可夫链存在平稳分布，此时吉布斯采样会给出错误的估 计结果. 7.6 EM算法 在前面的讨论中，我们一直假设训练样本所有属性变量的值都已被观测到, 即 训 练 样 本 是 “完 整 ”的 .但 在 现 实 应 用 中 往 往 会 遇 到 “不 完 整 ”的训练样 本，例如由于西瓜的根蒂已脱落，无 法 看 出 是 “蜷缩”还 是 “硬 挺 ”，则训练样 本 的 “根 蒂 ”属 性 变 量 值 未 知 .在 这 种 存 在 “未观测”变量的情形下，是否仍 能对模型参数进行估计呢？ 未 观 测 变 量 的 学 名 是 “隐变量\" (latent variab le).令 X 表示已观测变量 集，Z 表示隐变量集，0 表 示模型参数.若欲对0 做极大似然估计，则应最大化 对数似然 LL(e \\ X ,Z ) = ln P (X ,Z I 0 ) . (7.34) 然 而 由 于 Z 是隐变量，上式无法直接求解.此时我们可通过对Z 计算期望，来 由 于 “似然”常基于指 数族函数来定义，因此对 数 似 然 及 后 续 EM迭代过 程中一般是使用自然对数 In(-) . 7.6 EM算法 163 最大化已观测数据的对数“边 际 似 然 \"(marginal likelihood) L L (e I X) = ln P (X I ©) = In £ Z P (X ,Z |0) (7.35) 直 译 为 “期 望 最 大 化 算 法 ” ，通 常 直 接 称 E M 算 法. 这 里 仅 给 出 E M 算法的 一 般 描 述 ，具 体 例 子 参 见 9.4.3 节. EM (Expectation-Maximization)算 法 ［Dempster et al., 1977］是常用的估 计参数隐变量的利器，它是一种迭代式的方法，其基本想法是：若 参 数 9 已知, 则可根据训练数据推断出最优隐变量Z 的 值 ( E 步);反之，若Z 的值已知，则可 方便地对参数9 做极大似然估计(M 步). 于是，以初始值0 ° 为起点，对式(7.35),可迭代执行以下步骤直至收敛： • • 基 于 ⑶ 推 断 隐 变 量 Z 的期望，记 为 Z ； • 基于已观测变量X 和 公 对 参 数 0 做极大似然估计，记 为 9 计1; 这 就 是 E M 算法的原型.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 427
    }
  },
  {
    "page_content": "于是，以初始值0 ° 为起点，对式(7.35),可迭代执行以下步骤直至收敛： • • 基 于 ⑶ 推 断 隐 变 量 Z 的期望，记 为 Z ； • 基于已观测变量X 和 公 对 参 数 0 做极大似然估计，记 为 9 计1; 这 就 是 E M 算法的原型. 进一步，若 我 们 不 是 取Z 的期望，而 是 基 于 U 计 算 隐 变 量 Z 的概率分布 P (Z | X, U ) , 则 E M 算法的两个步骤是： • E 步 (E xpectation):以当前参数U 推断隐变量分布P(Z | X , ® ) 并计 算对数似然L L & | X, Z ) 关 于 Z 的期望 Q (9 I 的 = % | x e LL(Q |X , Z ) . (7.36) • M 步 (Maximization):寻找参数最大化期望似然，即 @t+ 1 = arg max Q(Q \\ €>*) . (7.37) 简要来说，E M 算法使用两个步骤交替计算：第一步是期望(E)步，利用当 前估计的参数值来计算对数似然的期望值;第二步是最大化(M)步，寻找能使 E M 算 法 的 收 敛 性 分 析 参 见 ［Wu, 1983］. E 步产生的似然期望最大化的参数值.然后，新得到的参数值重新被用于E 步, ……直至收敛到局部最优解. E M 算 法 可 看 作 用 坐 标 下 降 (coordinate descent) 法 来 最 大 化 对 数 似 然 下 界 的 过 程 .坐 标 下 降 法 参 见 附 录 B.5. 事实上，隐变量估计问题也可通过梯度下降等优化算法求解，但由于求和 的项数将随着隐变量的数目以指数级上升，会给梯度计算带来麻烦；而 E M 算 法则可看作一种非梯度优化方法. 164 第 7 章 贝 叶 斯 分 类 器 7 . 7 阅读材料 贝叶斯决策论在机器学习、模式识别等诸多关注数据分析的领域都有极 为重要的地 位 .对 贝 叶 斯 定 理 进 行 近 似 求 解 ，为机器学习算法的设计提供了 一种有效途径.为避免贝叶斯定理求解时面临的组合爆炸、样本稀疏问题，朴 素贝叶斯分类器引入了属性条件独立性假设.这个假设在现实应用中往往很 难成立，但有趣的是，朴素贝叶斯分类器在很多情形下都能获得相当好的性能 [Domingos and Pazzani, 1997; Ng and Jordan, 2002]. 一种解释是对分类任务 来说，只需各类别的条件概率排序正确、无须精准概率值即可导致正确分类结",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 428
    }
  },
  {
    "page_content": "素贝叶斯分类器引入了属性条件独立性假设.这个假设在现实应用中往往很 难成立，但有趣的是，朴素贝叶斯分类器在很多情形下都能获得相当好的性能 [Domingos and Pazzani, 1997; Ng and Jordan, 2002]. 一种解释是对分类任务 来说，只需各类别的条件概率排序正确、无须精准概率值即可导致正确分类结 果 [Domingos and Pazzani, 1997];另一种解释是，若属性间依赖对所有类别影 响相同，或依赖关系的影响能相互抵消，则属性条件独立性假设在降低计算开 销的同时不会对性能产生负面影响[Zhang, 2004].朴素贝叶斯分类器在信息检 索 领 域 尤为常用[Lewis, 1998], [McCallum and Nigam, 1998]对其在文本分类 中的两种常见用法进行了比较. 根据对属性间依赖的涉及程度，贝叶斯分类器形成了一个“谱 ”：朴素贝 叶斯分类器不考虑属性间依赖性，贝叶斯网能表示任意属性间的依赖性，二者 分 别 位 于 “谱 ”的两端；介于两者之间的则是一系列半朴素贝叶斯分类器，它 们基于各种假设和约束来对属性间的部分依赖性进行建模.一般认为，半朴素 贝 叶 斯 分 类 器 的 研 究 始 于[Kononenko, 1991]. O D E 仅考虑依赖一个父属性, 由此形成了独依赖分类器如 TAN [Friedman et al., 1997]> AODE [Webb et al., 2005] > LBR (lazy Bayesian Rule) [Zheng and Webb, 2000]等；A;DE 则考虑最 多 依 赖 k 个父属性，由此形成了 k 依赖分类器如KDB [Sahami, 1996]、NBtree [Kohavi, 1996]等. 贝叶斯分类器(Bayes Classifier)与 一 般 意 义 上 的 “贝 叶 斯 学 习 \"(Bayesian Learning)有显著区别，前者是通过最大后验概率进行单点估计，后者则是进行 分布估计.关于贝叶斯学习的内容可参阅[Bishop, 2006]. 贝叶斯网为不确定学习和推断提供了基本框架，因其强大的表示能力、 良好的可解释 性 而 广 受 关 注[Pearl, 1 9 8 8 ].贝叶斯网学习可分为结构学习和 参 数 学 习 两 部 分 .参 数 学 习 通 常 较 为 简 单 ，而 结 构 学 习 则 被 证 明 是 N P 难问 题 [Cooper, 1990; Chickering et al., 2004],人们为此提出了多种评分搜索方法",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 429
    }
  },
  {
    "page_content": "良好的可解释 性 而 广 受 关 注[Pearl, 1 9 8 8 ].贝叶斯网学习可分为结构学习和 参 数 学 习 两 部 分 .参 数 学 习 通 常 较 为 简 单 ，而 结 构 学 习 则 被 证 明 是 N P 难问 题 [Cooper, 1990; Chickering et al., 2004],人们为此提出了多种评分搜索方法 [Friedman and Goldszmidt, 1996].贝叶斯网通常被看作生成式模型，但近年来 也有不少关于贝叶斯网判别式学习的研究[Grossman and Domingos, 2004].关 J. Pearl教授因这方面的 卓 越 贡 献 而 获 得 2 0 1 1 年 图灵奖,参见第1 4 章. 贝叶斯网是经典的概率 图模型，参 见 第 1 4 章. 于贝叶斯网的更多介绍可参阅[Jensen, 1997; Heckerman, 1998]. E M 算法是最常见的隐变量估计方法,在机器学习中有极为广泛的用途,例 7 . 7 阅读材料 165 如常被用来学习高斯混合模型(Gaussian mixture m odel,简 称 G M M )的参数; 9.4节将介绍的k 均值聚类算法就是一个典型的E M 算法.更多关于E M 算法 的分析、拓展和应用可参阅[McLachlan and Krishnan, 2008]. 本章介绍的朴素贝叶斯算法和E M 算法均曾入选“数据挖掘十大算法” [W uetal., 2007]. “数据挖掘十大算法” 还 包 括 前 几 章 介 绍 的 C4.5、C A R T决 策 树 、支 持向量机 ，以及后几章将 要 介 绍 的 Ada Boost、k 均 值聚类、k 近邻算法等. 166 第 7 章 贝 叶 斯 分 类 器 习题 西 瓜 数 据 集 3 .0 见 p.84 7.1 试使用极大似然法估算西瓜数据集3 .0 中 前 3 个属性的类条件概率. 的 表 4.3. 7.2* 试证明：条件独立性假设不成立时，朴素贝叶斯分类器仍有可能产生 最优贝叶斯分类器. 7.3 试编程实现拉普拉斯修正的朴素贝叶斯分类器，并以西瓜数据集3.0 为训练集，对 p.151 “测 1” 样本进行判别. 7.4 实践中使用式(7.15)决定分类类别时,若数据的维数非常高，则概率连 乘 1。)的结果通常 会 非 常 接 近 于 0 从而导致下溢.试述防 止下溢的可能方案. 假 设 同 先 验 ；参 见 3.4 节. 别分析产生贝叶斯最优分类器. 7.5 试证明：二分类任务中两类数据满足高斯分布且方差相同时，线性判",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 430
    }
  },
  {
    "page_content": "为训练集，对 p.151 “测 1” 样本进行判别. 7.4 实践中使用式(7.15)决定分类类别时,若数据的维数非常高，则概率连 乘 1。)的结果通常 会 非 常 接 近 于 0 从而导致下溢.试述防 止下溢的可能方案. 假 设 同 先 验 ；参 见 3.4 节. 别分析产生贝叶斯最优分类器. 7.5 试证明：二分类任务中两类数据满足高斯分布且方差相同时，线性判 7.6 试 编 程 实 现 A O D E 分类器，并 以 西 瓜 数 据 集 3 .0 为训练集，对 p.151 的 “测 1 ” 样本进行判别. 7.7 给 定 d 个二值属性的二分类任务，假设对于任何先验概率项的估算 至 少 需 3 0 个样例，则在朴素贝叶斯分类器式(7.15)中估算先验概率项 P ( c ) 需 30 x 2 = 6 0 个 样 例 .试 估 计 在 A O D E 式(7.23)中估算先验概 率 项 P(c,Xi)所需的样例数(分别考虑最好和最坏情形). 7.8 考 虑 图 7 .3 ,试证明：在同父结构中，若 叼 的 取 值 未 知 ，则 C3卫力4 不成 立；在顺序结构中，g _L z | 对 但 y_\\Lz不成立. 西 瓜 数 据 集 2 .0 见 p.76 的 表 4.1. 7.9 以西瓜数据集2 .0 为训练集,试基于B IC 准则构建一个贝叶斯网. 7.10 以西瓜数据集2 .0 中 属 性 “脐 部 ”为隐变量，试 基 于 E M 算法构建一 个贝叶斯网. 参考文献 167 参考文献 Bishop, C. M. (2006). Pattern Recognition and Machine Learning. Springer, New York, NY. Chickering, D. M., D. Heckerman, and C. Meek. (2004). uLarge-sample learning of Bayesian networks is NP-hard.^^ Journal of Machine Learning Research, 5:1287-1330. Chow, C. K. and C. N. Liu. (1968). ^Approximating discrete probability distri­ butions with dependence trees?5 IEEE Transactions on Information Theory、 14(3):462-467.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 431
    }
  },
  {
    "page_content": "5:1287-1330. Chow, C. K. and C. N. Liu. (1968). ^Approximating discrete probability distri­ butions with dependence trees?5 IEEE Transactions on Information Theory、 14(3):462-467. Cooper, G. F. (1990). “The computational complexity of probabilistic inference using Bayesian belief networks.55 Artificial Intelligence^ 42(2-3):393-405. Cowell, R. G., P. Dawid, S. L. Lauritzen, and D. J. Spiegelhalter. (1999). Prob­ abilistic Networks and Expert Systems. Springer, New York, NY. Dempster, A. P., N. M. Laird, and D. B. Rubin. (1977). \"Maximum likelihood from incomplete data via the EM algorithm.\" Journal of the Royal Statistical Society - Series B, 39(1):1-38. Domingos, P. and M. Pazzani. (1997). “On the optimality of the simple Bayesian classifier under zero-one loss.\" Machine Learning^ 29(2-3):103-130. Efron, B. (2005). uBayesians, frequentists, and scientists.r Journal of the American Statistical Association^ 100(469):1-5. Friedman, N., D. Geiger, and M. Goldszmidt. (1997). “Bayesian network clas­ s if ie r s .Machine Learning^ 29(2-3):131-163.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 432
    }
  },
  {
    "page_content": "American Statistical Association^ 100(469):1-5. Friedman, N., D. Geiger, and M. Goldszmidt. (1997). “Bayesian network clas­ s if ie r s .Machine Learning^ 29(2-3):131-163. Friedman, N. and M. Goldszmidt. (1996). “Learning Bayesian networks with local structure.^^ In Proceedings of the 12th Annual Conference on Uncer­ tainty in Artificial Intelligence (UAI)1 252-262, Portland, OR. Grossman, D. and P. Domingos. (2004). “Learning Bayesian network classifiers by maximizing conditional likelihood.55 In Proceedings of the 21st Interna­ tional Conference on Machine Learning (ICML), 46-53, Banff, Canada. Heckerman, D. (1998). “A tutorial on learning with Bayesian networks.55 In Learning in Graphical Models (M. I. Jordan, ed.), 301-354, Kluwer, Dor­ drecht, The Netherlands. Jensen, F. V. (1997). An Introduction to Bayesian Networks. Springer, NY. 168 第 7 章 贝 叶 斯 分 类 器 Kohavi, R. (1996), “Scaling up the accuracy of naive-Bayes classifiers: A decision-tree hybrid.\" In Proceedings of the 2nd International Conference",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 433
    }
  },
  {
    "page_content": "168 第 7 章 贝 叶 斯 分 类 器 Kohavi, R. (1996), “Scaling up the accuracy of naive-Bayes classifiers: A decision-tree hybrid.\" In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (K D D ),202-207, Portland, OR. Kononenko, I. (1991). “Semi-naive Bayesian classifier.In Proceedings of the 6th European Working Session on Learning (EWSL), 206-219, Porto, Por­ tugal. Lewis, D. D. (1998). “Naive (Bayes) at forty: The independence assumption in information retrieval.\" In Proceedings of the 10th European Conference on Machine Learning (ECML), 4-15, Chemnitz, Germany. McCallum, A. and K. Nigam. (1998). “A comparison of event models for naive Bayes text classification.” In Working Notes of the AAAF98 Workshop on Learning for Text Cagegorization, Madison, WI. McLachlan, G. and T. Krishnan. (2008). The EM Algorithm and Extensions, 2nd edition. John Wiley & Sons, Hoboken, NJ. Ng, A. Y. and M. I. Jordan. (2002). “On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes.\" In Advances in Neural",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 434
    }
  },
  {
    "page_content": "Ng, A. Y. and M. I. Jordan. (2002). “On discriminative vs. generative classifiers: A comparison of logistic regression and naive Bayes.\" In Advances in Neural Information Processing Systems 14 (NIPS) (T. G. Dietterich, S. Becker, and Z. Ghahramani, eds.), 841-848, MIT Press, Cambridge, MA. Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, San Francisco, CA. Sahami, M. (1996). “Learning limited dependence Bayesian classifiers/ In Pro­ ceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD), 335-338, Portland, OR. Samaniego, F. J. (2010). A Comparison of the Bayesian and Frequentist Ap­ proaches to Estimation, Springer, New York, NY. Webb, G., J. Boughton, and Z. Wang. (2005). “Not so naive Bayes: Aggregating one-dependence estimators.^^ Machine Learning, 58(1):5-24. Wu, C. F. Jeff. (1983). “On the convergence properties of the EM algorithm.55 Annals of Statistics^ 11(1):95-103. Wu, X., V. Kumar, J. R. Quinlan, J. Ghosh, Q. Yang, H. Motoda, G. J. M-",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 435
    }
  },
  {
    "page_content": "Annals of Statistics^ 11(1):95-103. Wu, X., V. Kumar, J. R. Quinlan, J. Ghosh, Q. Yang, H. Motoda, G. J. M- cLachlan, A. Ng, B. Liu, P. S. Yu, Z.-H. Zhou, M. Steinbach, D. J. Hand, and D. Steinberg. (2007). “Top 10 algorithms in data mining.5, Knowledge 休息一会儿 169 and Information Systems, 14(1):1-37. Zhang, H. (2004). “The optimality of naive Bayes.5, In Proceedings of the 17th International Florida Artificial Intelligence Research Society Confer­ ence (FLAIRS), 562—567, Miami, FL. Zheng, Z. and G. I. Webb. (2000). “Lazy learning of Bayesian rules.,5 Machine Learning^ 41(1):53-84. 休 息 一 会 儿 小故事：贝叶斯之谜 英国皇家学会相当于英 国科学院，皇家学会会士 相当于科学院院士. 1763年 1 2 月 2 3 日，托 马 斯 •贝 叶 斯 (Thomas Bayes, 1701?—1761)的 遗 产 受 赠 者 R. P ric e 牧 师 在 英 国 皇 家 学 会宣读了贝叶斯的遗作《论机会学说中一个问题的求解》, 其中给出了贝叶斯定理,这一天现在被当作贝叶斯定理的诞 生日.虽然贝叶斯定理在今天已成为概率统计最经典的内容 之一，但贝叶斯本人却笼罩在谜团中. 现有资料表明，贝叶斯是一位神职人员，长期担任英国坦布里奇韦尔斯地 方教堂的牧师，他从事数学研究的目的是为了证明上帝的存在.他在1742年当 选英国皇家学会会士，但没有记录表明他此前发表过任何科学或数学论文.他 的提名是由皇家学会的重量级人物签署的，但为什么提名以及他为何能当选, 至今仍是个谜.贝叶斯的研究工作和他本人在他生活的时代很少有人关注，贝 叶斯定理出现后很快就被遗忘了，后来大数学家拉普拉斯使它重新被科学界所 熟悉，但直到二十世纪随着统计学的广泛应用才备受瞩目.贝叶斯的出生年份",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 436
    }
  },
  {
    "page_content": "的提名是由皇家学会的重量级人物签署的，但为什么提名以及他为何能当选, 至今仍是个谜.贝叶斯的研究工作和他本人在他生活的时代很少有人关注，贝 叶斯定理出现后很快就被遗忘了，后来大数学家拉普拉斯使它重新被科学界所 熟悉，但直到二十世纪随着统计学的广泛应用才备受瞩目.贝叶斯的出生年份 至今也没有清楚确定，甚至关于如今广泛流传的他的画像是不是贝叶斯本人, 也仍存在争议. 第 8 章 集 成 学 习 8 . 1 个 体 与 集 成 ensemble读 音 似 \"昂 桑 宝”而 非 “因桑宝”. 集成学 习(ensemble learning)通过构建并结合多个学习器来完成学习任 务，有 时 也 被 称 为 多 分 类 器 系 统 (multi-classifier system)＞基于委 员 会 的 学 习(committee-based learning)等. 图 8 .1 显 示 出 集 成 学 习 的 一 般 结 构 ： 先 产 生 一 组 “个 体 学 习 器 \" (individual learn er),再 用 某 种 策 略 将 它 们 结 合 起 来 .个 体 学 习 器 通 常 由一个现有的学习算法从训练数据产生，例 如 C 4.5决策树算法、B P 神经网 络算法等，此时集成中只包含同种类型的个体学习器，例 如 “决 策 树 集 成 ” 中全是决策树， “神 经 网 络 集 成 ”中全是神经网络，这 样 的 集 成 是 “同质” 的(homogeneous).同质集成中的个体学习器亦称“基学习器” (base learner), 相应的学习算法称为“基学习算法”(base learning algorithm ).集成也可包含 不同类型的个体学习器，例如同时包含决策树和神经网络，这 样 的 集 成 是 “异 质 ”的(heterogenous).异质集成中的个体学习器由不同的学习算法生成，这时 就不再有基学习算法;相应的，个体学习器一般不称为基学习器，常 称 为 “组件 学 习 器 \"(component learner)或直接称为个体学习器. 图 8 . 1 集成学习示意图 集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的 弱学习器常指泛化性能 略优于随机猜测的学习器; 例如在二分类问题上精度 略 高 于 5 0 % 的分类器. 泛 化 性 能 .这 对 “弱学习器”(weak learner)尤为明显，因此集成学习的很多理 论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器.但 需注意的是，虽然从理论上来说使用弱学习器集成足以获得好的性能，但在实 172 第 8 章 集 成 学 习",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 437
    }
  },
  {
    "page_content": "弱学习器常指泛化性能 略优于随机猜测的学习器; 例如在二分类问题上精度 略 高 于 5 0 % 的分类器. 泛 化 性 能 .这 对 “弱学习器”(weak learner)尤为明显，因此集成学习的很多理 论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器.但 需注意的是，虽然从理论上来说使用弱学习器集成足以获得好的性能，但在实 172 第 8 章 集 成 学 习 践中出于种种考虑，例如希望使用较少的个体学习器，或是重用关于常见学习 器的一些经验等，人们往往会使用比较强的学习器. 在一般经验中，如果把好坏不等的东西掺到一起，那么通常结果会是比最 坏的要好一些，比最好的要坏一些.集成学习把多个学习器结合起来,如何能获 得比最好的单一学习器更好的性能呢？ 考虑一个简单的例子：在二分类任务中，假定三个分类器在三个测试样本 上的表现如图 8 . 2 所示，其中， 表示分类正确，义表示分类错误，集成学习的结 果通过投票法(voting)产生，即 “少数服从多数”. 在 图 8 . 2 ( a ) 中，每个分类器 都 只 有 6 6 . 6 % 的精度，但集成学习却达到了 1 0 0 % ; 在 图 8.2(b)中，三个分类器 没有差别，集成之后性能没有提高；在 图 8.2(c)中，每个分类器的精度都只有 3 3 . 3 % , 集成学习的结果变得更糟.这个简单的例子显示出：要获得好的集成, 个 体 学 习 器 应 “好而不同”，即个体学习器要有一定的“准确性”，即学习器 鬻曝习器至少不差于 不能太坏，并 且 要 有 “多样性”(diversity),即学习器间具有差异. 测试例1 测试例2 测试例3 测试例1 测试例2 测试例3 X / V / V / V V 测试例1 测试例2 测试例3 / V / V / V X X X 加 加 加 / V 比 殳 加 / V X X X / V X X X / V 瓦 尼 初 V X / V 集 成 ， 〃 7 集 成 ， ， x 集 成 x x x (a)集 成 提 升 性 能 (b)集成不起作用 (c)集成起负作用 图 8 . 2 集 成 个 体 应 “好 而 不 同 ” ( 殳 表 示 第 6 个 分 类 器 ) 我们来做个简单的分析.考虑二分类问题y G 和 真 实 函 数 九 假 定基分类器的错误率为€,即对每个基分类器h i 有 P ( h i ( x ) 次 f ( x ) ) = e . (8.1) 空简化讨论，假设T 为 假设集成通过简单投票法结合 T 个基分类器，若有超过半数的基分类器正确, ■ 则集成分类就正确：",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 438
    }
  },
  {
    "page_content": "我们来做个简单的分析.考虑二分类问题y G 和 真 实 函 数 九 假 定基分类器的错误率为€,即对每个基分类器h i 有 P ( h i ( x ) 次 f ( x ) ) = e . (8.1) 空简化讨论，假设T 为 假设集成通过简单投票法结合 T 个基分类器，若有超过半数的基分类器正确, ■ 则集成分类就正确： 丁 H (x) = sign ( 鼻 殳 ⑺ ) . (8.2) 参见习题8.L 假设基分类器的错误率相互独立，则 由 H o l d i n g 不等式可知，集成的错误 率为 8.2 Boosting 173 p 3 ⑺ # / ( 〃) ) = £ [T/2」/r p \\ W e x p (—^ 7 (1 —2e)2) . (8.3) 上式显示出，随着集成中个体分类器数目T 的增大，集成的错误率将指数级下 降,最终趋向于零. 然而我们必须注意到，上面的分析有一个关键假设：基学习器的误差相互 独立.在现实任务中，个体学习器是为解决同一个问题训练出来的，它们显然不 可 能 相 互 独 立 ！事实上，个 体 学 习 器 的 “准确性”和 “多样性”本身就存在冲 突 .一 般 的 ，准确性很高之后，要增加多样性就需牺牲准确性.事实上，如何产 生 并 结 合 “好而不同”的个体学习器，恰是集成学习研究的核心. 根据个体学习器的生成方式，目前的集成学习方法大致可分为两大类，即 个体学习器间存在强依赖关系、必须串行生成的序列化方法，以及个体学习器 间不存在强依赖关系、可同时生成的并行化方法；前者的代表是B oosting,后 者的代表是Bagging和 “随机森林\" (Random Forest). 8.2 Boosting Boosting是一族可将弱学习器提升为强学习器的算法.这族算法的工作机 制类似：先从初始训练集训练出一个基学习器，再根据基学习器的表现对训练 样本分布进行调整，使得先前基学习器做错的训练样本在后续受到更多关注, 然后基于调整后的样本分布来训练下一个基学习器；如此重复进行，直至基学 习器数目达到事先指定的值T , 最终将这 T 个基学习器进行加权结合. Boosting 族算法最著名的代表是 AdaBoost [Freund and Schapire, 1997], 其描述如图8.3 所 示 ,其 中 Vi G {— / 是真实函数. A daB oost算 法 有 多 种 推 导 方 式 ，比 较 容 易 理 解 的 是 基 于 “加 性 模 型 “(additive m odel),即基学习器的线性组合 T 五 ⑺ = £ & 也 ⑺ i=l (8.4)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 439
    }
  },
  {
    "page_content": "其描述如图8.3 所 示 ,其 中 Vi G {— / 是真实函数. A daB oost算 法 有 多 种 推 导 方 式 ，比 较 容 易 理 解 的 是 基 于 “加 性 模 型 “(additive m odel),即基学习器的线性组合 T 五 ⑺ = £ & 也 ⑺ i=l (8.4) 来最小化指数损失函数(exponential loss function) [Friedman et al., 2000] 2 e x p (H I 0 ) = . (8.5) 174 第 8 章 集 成 学 习 输 入 ：训 练 集 。 = {(啊 ,阴 )，(Z2,沙2), • •• , Q m , Pm)}； 初始化样本权值分布. 基 于 分 布 Dt从数据集 。 中训练出分类器加. 估 计 ht 的误差. 确定分类器瓦的权重. 更新样本分布，其 中 a 是 规 范 化 因 子 ，以 确保 A + i 是一个分布. ' 基 学 习 算 法 公 训 练 轮 数 T. 过 程 ： 1：。1(为 = 1/m. 2: for t = 1 ,2 ,.. .. ,T do 3： ht = 4: €t = 5： if et > 0.5 then break 6： % = 熟 ( 詈 ) ；, ( 3 Q ) * /Q)); 7： 0 计 g ) = 巧 0 * [ exp'—' 十 ' / Zt [ exp(at), _ A(a?)exp(-a£/(a;)花(a1)) 一 Zt 8： end for 输 出 ：H{x} = sign( £ 着 a 也(①)) if ht(x) = f(x) if ht(x)* f[x} 图 8.3 AdaBoost算 法 若 H Q ) 能令指数损失函数最小化，则考虑式(8.5)对 H Q ) 的偏导 旌 燎 = 1 | 宓)+ 龈㈤尸(/(⑼ = - 1 | ⑼ , UI1 (叼 令式(8.6)为零可解得 H = L n °(/⑺ = 1 3 ) 因此,有 sign (H (x) ) = sign Q in 工附二方) (8.6) (8.7) 1, 尸(/(①) = 1 I ⑼ 〉P (f{x} = —1 I ⑼ 、一 1, P ( f (6)= H x ) < P (f(x ) = —1 I ⑼ argmaxP(/(a;) = y \\ x ) , 蚱{-1,1} (8.8) 这里忽略了 P(f⑸ = 1 I ①)= P(f ⑸ = -1 I 的情形.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 440
    }
  },
  {
    "page_content": "(8.6) (8.7) 1, 尸(/(①) = 1 I ⑼ 〉P (f{x} = —1 I ⑼ 、一 1, P ( f (6)= H x ) < P (f(x ) = —1 I ⑼ argmaxP(/(a;) = y \\ x ) , 蚱{-1,1} (8.8) 这里忽略了 P(f⑸ = 1 I ①)= P(f ⑸ = -1 I 的情形. 这意味着Sign ( H Q ) ) 达到了贝叶斯最优错误率.换言之，若指数损失函数最小 化，则分类错误率也将最小化；这说明指数损失函数是分类任务原本0 / 1 损失 函数的一致的(consistent)替代损失函数.由于这个替代函数有更好的数学性 替 代 损 失 函 数 的 “一致 性”参 见 6.7节. 8.2 Boosting 175 质，例如它是连续可微函数，因此我们用它替代0 /1 损失函数作为优化目标. 在 AdaBoost算 法 中 ，第一个基分类器而是通过直接将基学习算法用于初 始数据分布而得;此后迭代地生成ht 和 当 基 分 类 器 ht 基于分布A 产生后, 该基分类器的权重生 应 使 得atht 最小化指数损失函数 4 x P (atht | R ) = [ G (皿的⑺] = % ~ 人 [e- 叼 ( /( x ) = ht (ir)) + e叼 (/ Q ) * ht (®))] = e~atPx„vt (/ («) = ht (a?)) + eatPx^vt (f Q ) * ht ⑺) = 6 一%(1 —6 )+ 6必马， (8.9) 其 中 且= 匕 * / ㈤ ) • 考虑指数损失函数的导数 队 \" 1t । dat = - ^ ( 1 - 3 + 滑 匕 ， (8.10) 令式(8.10)为零可解得 宁 ) , ⑻口) 这 恰 是 图 8 .3 中算法第6 行的分类器权重更新公式. AdaBoost算 法 在 获 得 之 后 样 本 分 布 将 进 行 调 整 ，使下一轮的基学习 器 ht 能纠 正H 7 的一些错误.理想的ht 能 纠 正 区 一 的全部错误，即最小化 2 e x p ( H l + 加 I 0 ) = / ㈤ / ㈤ ( H i ㈤+ 瓦(叫 = 1 ^ ~ 0 归一〃0 印一1 3 ) 6 —/ ( 0 也3 ) ] . (8.12) 注 意 到 产 (叼 = 砥 x) = 1 , 式(8.12)可 使 用 C-/Q 泡㈤的泰勒展式近似为 4 x p ( H t_! + 也 |。) t EB” e V ⑸ m - 1 3) ( i _ / Q ) 瓦Q ) + 工2 3 y",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 441
    }
  },
  {
    "page_content": "= 1 ^ ~ 0 归一〃0 印一1 3 ) 6 —/ ( 0 也3 ) ] . (8.12) 注 意 到 产 (叼 = 砥 x) = 1 , 式(8.12)可 使 用 C-/Q 泡㈤的泰勒展式近似为 4 x p ( H t_! + 也 |。) t EB” e V ⑸ m - 1 3) ( i _ / Q ) 瓦Q ) + 工2 3 y = e - ⑸H— 3)(1 - f(x)ht(x) + I ) . (8.13) 于是，理想的基学习器 ht{x} = argm in4x P ( ^ - i +h\\D) 176 第 8 章 集 成 学 习 = arg minEa,^p (1 - f(x )h (x ) + : = arg maxEa.^p 『 ⑺ 叫 ㈤ 〃 W Q ) ] h a r g m a x E .^ 皈 行 画 本 西 / Q ) 拉Q ) , e -y(a?)Ht_i(a3) (8.14) 注 意 到 引 e V ® * - (也 是 一 个 常 数 .令 T)t 表示一个分布 _ 0 ( ⑼ 6-/(重再 1⑺ 则根据数学期望的定义,这等价于令 ht (x) = arg maxEa,^p h ㈤ H i ㈤ 产 = argm axEa；^ [ f ( x ) h ( x ) ] . h 由 f ( x \\ h{x) e { - 1 , + 1 ) ,有 (8.15) (8.16) f[x ] h { x ) = 1 — 2 K(/(a?)卢 g ) ) , (8.17) 则理想的基学习器 ht (x) = argminEo，^ [H(/(® )半必比) ) ] • (8.18) 由此可见，理 想 的 ht 将 在 分 布 A 下最小化分类误差.因此，弱分类器将基于分 布 Q 来训练,且针对A 的分类误差应小于0 .5 .这在一定程度上类似“残差逼 近 ”的思想.考虑到A 和 R + i 的关系,有 A … t + 1 ( ) = * 冷 网 ⑺ [ e - ⑺氏(叫 D (⑼ e - f ( x ) H t - i ( x ) e - f ( x ) a t ht(x) ~ k 一”所 ( 叫 = 唳 ) ” 吗 \" [ 蓝 / ] , (8.19) 8.2 Boosting 177 这恰是图8 .3 中算法第7 行的样本分布更新公式. 于是，由式(8.11)和(8.19)可见，我们从基于加性模型迭代式优化指数损失 函数的角度推导出了图8 .3 的 AdaBoost算法.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 442
    }
  },
  {
    "page_content": "~ k 一”所 ( 叫 = 唳 ) ” 吗 \" [ 蓝 / ] , (8.19) 8.2 Boosting 177 这恰是图8 .3 中算法第7 行的样本分布更新公式. 于是，由式(8.11)和(8.19)可见，我们从基于加性模型迭代式优化指数损失 函数的角度推导出了图8 .3 的 AdaBoost算法. Boosting算法要求基学习器能对特定的数据分布进行学习，这 可 通 过 “重 赋权法”(re-weighting)实施，即在训练过程的每一轮中，根据样本分布为每个 训练样本重新赋予一个权重.对无法接受带权样本的基学习算法，则可通过 “重采样法”(re-sampling)来处理，即在每一轮学习中，根据样本分布对训练 集重新进行采样，再用重采样而得的样本集对基学习器进行训练.一般而言,这 两种做法没有显著的优劣差别.需注意的是,Boosting算法在训练的每一轮都 要检查当前生成的基学习器是否满足基本条件(例如图8 .3 的 第 5 行,检查当前 基分类器是否是比随机猜测好)，一旦条件不满足，则当前基学习器即被抛弃, 且学习过程停止.在此种情形下,初始设置的学习轮数T 也许还远未达到，可能 导致最终集成中只包含很少的基学习器而性能不佳.若采用“重采样法”，则 可 获 得 “重启动”机会以避免训练过程过早停止[Kohavi and Wolpert, 1996], 即在抛弃不满足条件的当前基学习器之后，可根据当前分布重新对训练样本进 行采样，再基于新的采样结果重新训练出基学习器，从而使得学习过程可以持 续到预设的T 轮完成. 偏差/方差参见2 . 5 节. 决策树桩即单层决策树, 参 见 4 . 3 节. 集成的规模指集成中包 含的个体学习器数目. 从偏差一方差分解的角度看，Boosting主要关注降低偏差，因 此 Boosting 能基于泛化性能相当弱的学习器构建出很强的集成.我们以决策树桩为基学习 器，在 表 4 .5 的西瓜数据集3 .0 a 上 运 行 AdaBoost算法，不同规模(size)的集成 及其基学习器所对应的分类边界如图8 .4 所示. + 好 瓜 - 坏瓜 0.6 ¥ 0.4 0.2 攀 + + + 0 0.2 0.4 0.6 0.8 密度 (a) 3个基学习器 密度 (b) 5个基学习器 0 0.2 0.4 0.6 0.8 密度 (C) 11个基学习器 图 8 . 4 西 瓜 数 据 集3 .0 a 上 A daB oost集 成 规 模 为 3、5、1 1 时，集成(红色)与基学习 器(黑色)的分类边界. 178 第 8 章 集 成 学 习 8.3 Bagging与随机森林",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 443
    }
  },
  {
    "page_content": "密度 (a) 3个基学习器 密度 (b) 5个基学习器 0 0.2 0.4 0.6 0.8 密度 (C) 11个基学习器 图 8 . 4 西 瓜 数 据 集3 .0 a 上 A daB oost集 成 规 模 为 3、5、1 1 时，集成(红色)与基学习 器(黑色)的分类边界. 178 第 8 章 集 成 学 习 8.3 Bagging与随机森林 由 8.1 节可知，欲得到泛化性能强的集成,集成中的个体学习器应尽可能相 互独立；虽 然 “独 立 ”在现实任务中无法做到，但可以设法使基学习器尽可能 具有较大的差异.给定一个训练数据集，一种可能的做法是对训练样本进行采 样，产生出若干个不同的子集，再从每个数据子集中训练出一个基学习器.这 样，由于训练数据不同，我们获得的基学习器可望具有比较大的差异.然而，为 获得好的集成，我们同时还希望个体学习器不能太差.如果采样出的每个子集 都完全不同，则每个基学习器只用到了一小部分训练数据，甚至不足以进行有 效学习，这显然无法确保产生出比较好的基学习器.为解决这个问题，我们可考 虑使用相互有交叠的采样子集. 8.3.1 Bagging Bagging [Breiman, 1996a]是并行式集成学习方法最著名的代表.从名字即 可看出，它直接基于我们在2.2.3节介绍过的自助采样法(bootstrap sampling). 给定包含馆个样本的数据集，我们先随机取出一个样本放入采样集中，再把该 样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m 次随机采样操作，我们得到含小个样本的采样集,初始训练集中有的样本在采 样集里多次出现，有 的 则 从 未 出 现 .由 式 (2.1)可知，初 始 训 练 集 中 约 有 63.2% 的样本出现在采样集中. 照这样，我们可采样出T 个含m 个训练样本的采样集，然后基于每个采样 集训练出一个基学习器，再将这些基学习器进行结合.这就是Bagging的基本 流程.在对预测输出进行结合时，Bagging通常对分类任务使用简单投票法，对 回归任务使用简单平均法.若分类预测时出现两个类收到同样票数的情形，则 最简单的做法是随机选择一个，也可进一步考察学习器投票的置信度来确定最 终 胜 者 .Bagging的算法描述如图8 .5 所示. 输 入 ：训 练 集 。 = {(CC1,7/1), (a:2,1/2), . . . , Z/m)}； 基学 习 算 法 £ ； ' 训练轮数 过程 ： 1： fo r 力= 1 , 2 , ... 2： 3： e n d fo r 输出：H (x) = a r g m a x J 2 ^ 1 ht = £(D,Dbs)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 444
    }
  },
  {
    "page_content": "输 入 ：训 练 集 。 = {(CC1,7/1), (a:2,1/2), . . . , Z/m)}； 基学 习 算 法 £ ； ' 训练轮数 过程 ： 1： fo r 力= 1 , 2 , ... 2： 3： e n d fo r 输出：H (x) = a r g m a x J 2 ^ 1 ht = £(D,Dbs) d o yey = y) 图 8 .5 Bagging 算法 B ag g in g这个名字是由 Bootstrap AGGregatING 缩 写而来. 即每个基学习器使用相 同权重的投票、平均. D g 是自助采样产生的 样本分布. 8.3 Bagging与随机森林 179 假 定 基 学 习 器 的 计 算 复 杂 度 为 。(旬 ，则 B agging的 复 杂 度 大 致 为 T (O (m ) + O ( 5 ) ) , 考 虑 到 采 样 与 投 票 /平 均 过 程 的 复 杂 度 。⑶ 很 小 ，而 T 通常是一个不太大的常数，因此，训 练 一 个 Bagging集成与直接使用基学习算 为处理多分类或回归任 务,Ada Boost需进行修改; 目前已有适用的变体算法 [Zhou, 2012]. 法训练一个学习器的复杂度同阶，这 说 明 Bagging是一个很高效的集成学习算 法 .另 外 ，与 标 准 AdaBoost只适用于二分类任务不同，Bagging能不经修改地 用于多分类、回归等任务. 包外估计参见2 2 3 节. 值得一提的是，自助采样过程还给Bagging带来了另一个优点：由于每个 基学习器只使用了初始训练集中约63.2% 的样本，剩 下 约 36.8% 的样本可用作 验证集来对泛化性能进行“包外估计”(out-of-bag estimate) [Breiman, 1996a; Wolpert and Macready, 1999].为此需记录每个基学习器所使用的训练样本. 不 妨 令 A 表 示 ht 实 际 使 用 的 训 练 样 本 集 , 令 表 示 对 样 本 z 的包外预 测，即仅考虑那些未使用比训练的基学习器在宓上的预测，有 H ooh{x} = arg max = y) - g D t ) , (8.20) T 则 Bagging泛化误差的包外估计为 8 = 房 E U ( S ㈤ 加 ) . (8.21) (x,y)eD 事实上,包外样本还有许多其他用途.例如当基学习器是决策树时，可使用 包外样本来辅助剪枝，或用于估计决策树中各结点的后验概率以辅助对零训练 样本结点的处理；当基学习器是神经网络时，可使用包外样本来辅助早期停止 以减小过拟合风险.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 445
    }
  },
  {
    "page_content": "(8.20) T 则 Bagging泛化误差的包外估计为 8 = 房 E U ( S ㈤ 加 ) . (8.21) (x,y)eD 事实上,包外样本还有许多其他用途.例如当基学习器是决策树时，可使用 包外样本来辅助剪枝，或用于估计决策树中各结点的后验概率以辅助对零训练 样本结点的处理；当基学习器是神经网络时，可使用包外样本来辅助早期停止 以减小过拟合风险. 偏差/方差参见2 .5 节. 关 于 样 本 扰 动 ，参见 8 5 3 节. 从偏差-方差分解的角度看，Bagging主要关注降低方差，因此它在不剪枝 决策树、神经网络等易受样本扰动的学习器上效用更为明显.我们以基于信息 增益划分的决策树为基学习器，在 表 4 .5 的西瓜数据集3 .0 a 上 运 行 Bagging算 法，不同规模的集成及其基学习器所对应的分类边界如图8.6 所示. 8 .3 .2 随机森林 随机森林(Random F o rest,简称 RF) [Breiman, 2001a]是 Bagging 的一个 扩展变体.R F 在以决策树为基学习器构建Bagging集成的基础上，进一步在 决策树的训练过程中引入了随机属性选择.具体来说，传统决策树在选择划分 属性时是在当前结点的属性集合(假定有d 个属性)中选择一个最优属性；而在 R F 中，对基决策树的每个结点，先从该结点的属性集合中随机选择一个包含k 180 第 8 章集成学习 + 好 瓜 - 坏瓜 0.6 密度 （a） 3个 基 学 习 器 图 8 . 6 西 瓜 数 据 集 3 . 0 a 上 B a g g in g 集 成 规 模 为 3 、5 、1 1 时，集成（红色）与基学习 器（黑色）的分类边界. 个属性的子集，然后再从这个子集中选择一个最优属性用于划分.这里的参数 k 控制了随机性的引入程度：若令k = d）则基决策树的构建传统决策树相同; 若 令 k = 1 , 则是随机选择一个属性用于划分；一般情况下，推 荐 值 k = 10g2 d [Breiman, 2001a]. 随机森林简单、容易实现、计算开销小，令人惊奇的是，它在很多现实任 务中展现出强大的性能，被 誉 为 “代表集成学习技术水平的方法”.可以看出, 随机森林对Bagging只做了小改动，但 是 与 Bagging中 基 学 习 器 的 “多样性” 仅通过样本扰动（通过对初始训练集采样）而来不同，随机森林中基学习器的多 叁1 才 色 . ，属性扰 样性不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通 寺，姿儿8.5.3下. 过个体学习器之间差异度的增加而进一步提升.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 446
    }
  },
  {
    "page_content": "随机森林对Bagging只做了小改动，但 是 与 Bagging中 基 学 习 器 的 “多样性” 仅通过样本扰动（通过对初始训练集采样）而来不同，随机森林中基学习器的多 叁1 才 色 . ，属性扰 样性不仅来自样本扰动，还来自属性扰动，这就使得最终集成的泛化性能可通 寺，姿儿8.5.3下. 过个体学习器之间差异度的增加而进一步提升. 随机森林的收敛性与Bagging相 似 .如 图 8 .7 所示，随机森林的起始性能 往往相对较差，特别是在集成中只包含一个基学习器时.这很容易理解，因为通 过引入属性扰动，随机森林中个体学习器的性能往往有所降低.然而，随着个体 S 3 4 O.S O. O. O.6 O. 3 2 3 0 2 2 2 2 2 8 6 4 2 O 1 I - - 1 - - - t <-怅 想 ¥ 官 io1 基分类器数量 io2 103 （a ） g la ss数据集 基分类器数量 （b ） auto-m pg 数据集 图 8 . 7 在 两 个 U C I数据上，集成规模对随机森林与B agging的影响 8 . 4 结合策略 181 学习器数目的增加，随机森林通常会收敛到更低的泛化误差.值得一提的是，随 机森林的训练效率常优于Bagging,因为在个体决策树的构建过程中，Bagging 使 用 的 是 “确定型”决策树，在选择划分属性时要对结点的所有属性进行考察, 而随机森林使用的“随机型”决策树则只需考察一个属性子集. 8 .4 结合策略 学习器结合可能会从三个方面带来好处[Dietterich, 2000]:首先，从统计 的方面来看，由于学习任务的假设空间往往很大，可能有多个假设在训练集上 达到同等性能，此时若使用单学习器可能因误选而导致泛化性能不佳，结合多 个学习器则会减小这一风险；第二，从计算的方面来看，学习算法往往会陷入局 部极小，有的局部极小点所对应的泛化性能可能很糟糕，而通过多次运行之后 进行结合，可降低陷入糟糕局部极小点的风险；第三，从表示的方面来看，某些 学习任务的真实假设可能不在当前学习算法所考虑的假设空间中，此时若使用 单学习器则肯定无效，而通过结合多个学习器，由于相应的假设空间有所扩大, 有可能学得更好的近似.图8.8给出了一个直观示意图. 图 8 . 8 学 习 器 结 合 可 能 从 三 个 方 面 带 来 好 处 [Dietterich, 2000] 假定集成包含T 个 基 学 习 器 ｛仿油2 ,… ，访 ｝,其 中 M 在示例力上的输出 为 h《x).本节介绍几种对hi进行结合的常见策略. 8 .4 .1 平均法",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 447
    }
  },
  {
    "page_content": "有可能学得更好的近似.图8.8给出了一个直观示意图. 图 8 . 8 学 习 器 结 合 可 能 从 三 个 方 面 带 来 好 处 [Dietterich, 2000] 假定集成包含T 个 基 学 习 器 ｛仿油2 ,… ，访 ｝,其 中 M 在示例力上的输出 为 h《x).本节介绍几种对hi进行结合的常见策略. 8 .4 .1 平均法 对数值型输出h<x) e R , 最常见的结合策略是使用平均法(averaging). • 简单平均法(simple averaging) 1 1 H(x)= 亍 f h / x ) . 2 = 1 (8.22) 182 第 8 章 集 成 学 习 Breiman [1996b]在研究 Stacking回归时发现，必须 使用非负权重才能确保集 成性能优于单一最佳个体 学习器，因此在集成学习 中一般对学习器的权重施 以非负约电 例如估计出个体学习器 的误差，然后令权重大小 与误差大小成反比. • 加权平均法(weighted averaging) T H(x) = y^Wjhj(x) . i=l (8.23) 其 中 她 是 个 体 学 习 器 hi的权重，通 常 要 求 她 》o, E 她 = I. T ' 2==1 显然，简单平均法是加权平均法令Wi = 1/T的特例.加权平均法在二十世 纪五十年代已被广泛使用[Markowitz, 1952], [Perrone a n d Cooper, 1 9 9 3 ]正式 将其用于集成学习.它在集成学习中具有特别的意义，集成学习中的各种结合 方法都可视为其特例或变体.事实上，加权平均法可认为是集成学习研究的基 本出发点，对给定的基学习器，不同的集成学习方法可视为通过不同的方式来 确定加权平均法中的基学习器权重. 加权平均法的权重一般是从训练数据中学习而得，现实任务中的训练样本 通常不充分或存在噪声，这将使得学出的权重不完全可靠.尤其是对规模比较 大的集成来说，要学习的权重比较多，较容易导致过拟合.因此，实验和应用均 显示出，加权平均法未必一定优于简单平均法[ X u et al., 1992; H o et al., 1994; Kittier et al., 1998]. 一般而言，在个体学习器性能相差较大时宜使用加权平均 法，而在个体学习器性能相近时宜使用简单平均法. 8 . 4 . 2 投票法 对分类任务来说,学习器hi将从类别标记集合｛Ci, C2, • • . , CN ｝中预测出一 个标记，最常见的结合策略是使用投票法(voting).为便于讨论，我 们 将 在 样 本 x 上的预测输出表示为一个N 维 向 量 (玛 ㈤ ;宿 3 ) ; … ；",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 448
    }
  },
  {
    "page_content": "法，而在个体学习器性能相近时宜使用简单平均法. 8 . 4 . 2 投票法 对分类任务来说,学习器hi将从类别标记集合｛Ci, C2, • • . , CN ｝中预测出一 个标记，最常见的结合策略是使用投票法(voting).为便于讨论，我 们 将 在 样 本 x 上的预测输出表示为一个N 维 向 量 (玛 ㈤ ;宿 3 ) ; … ； 其 中 收 ⑺ 是 也 在 类 别 标 记 S •上的输出. • 绝对多数投票法(majority voting) ' rr( X_ \\ % H (冗)一 < T . N T if E H ( X ) > 0.5 £ £ k=i i-i 2=1 (®) ； z. (8.24) reject, otherwise. 即若某标记得票过半数,则预测为该标记；否则拒绝预测. • 相对多数投票法(plurality voting) H Q ) = C a r g m a x ^ L i M ⑺ . 3 8 . 4 结合策略 183 “多数投票法”的英文 术语使用不太一致：有文 献称为 majority vo tin g,也 有直接称为voting. 即预测为得票最多的标记，若同时有多个标记获最高票，则从中随机选取 一个. •加 权 投 票 法 (weighted voting) 五 ㈤ 二CargmaxSXi皿收Q ) . j 岱 的 与加权平均法类似，Wi是 hi的权重，通 常 她 》0 , 才 妫 = 1. T i=l 标准的绝对多数投票法(8.24)提供了 “拒绝预测”选项，这在可靠性要求 较高的学习任务中是一个很好的机制.但若学习任务要求必须提供预测结果, 则绝对多数投票法将退化为相对多数投票法.因此，在不允许拒绝预测的任务 中，绝对多数、相对多数投票法统称为“多数投票法”. 式(8.24)〜 (8.26)没有限制个体学习器输出值的类型.在现实任务中，不同 类型个体学习器可能产生不同类型的总3 ) 值，常见的有： - 类 标 记 :屈 ㈤ e {0 ,1 } ,若 hi将样本⑦预测为类别立•则取值为1 , 否则为 0 . 使用类标记的投票亦称“硬投票”(hard voting). - 类概率：屈(宏)e [0,1],相当于对后验概率P © | ⑼ 的一个估计.使用类 概率的投票亦称“软投票”(soft voting). 不 同 类 型 的 h{(x)值不能混用.对一些能在预测出类别标记的同时产生 分 类 置 信 度 的 学 习 器 ，其 分 类 置 信 度 可 转 化 为 类 概 率 使 用 .若 此 类 值 未 进",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 449
    }
  },
  {
    "page_content": "- 类概率：屈(宏)e [0,1],相当于对后验概率P © | ⑼ 的一个估计.使用类 概率的投票亦称“软投票”(soft voting). 不 同 类 型 的 h{(x)值不能混用.对一些能在预测出类别标记的同时产生 分 类 置 信 度 的 学 习 器 ，其 分 类 置 信 度 可 转 化 为 类 概 率 使 用 .若 此 类 值 未 进 行规范化，例如支持向量机 的 分 类 间 隔 值 ，则 必 须 使 用 一 些 技 术 如 P l a t t 缩 放(Platt scaling) [Platt, 2000] > 等 分 回 归 (isotonic regression) [Zadrozny and Elkan, 2001]等 进 行 “校 准 ”(calibration)后才能作为类概率使用.有趣的是, 虽然分类器估计出的类概率值一般都不太准确，但基于类概率进行结合却往往 比直接基于类标记进行结合性能更好.需注意的是，若基学习器的类型不同，则 例如异质集成中不同类 型的个体学习器. 其类概率值不能直接进行比较；在此种情形下，通常可将类概率输出转化为类 标记输出(例如将类概率输出最大的总(⑼设为1 ,其他设为0 ) 然后再投票. 8 .4 .3 学习法 当训练数据很多时，一种更为强大的结合策略是使用“学习法”，即通过 另一个学习器来进行结合.Stacking [Wolpert, 1992; Breiman, 1996b]是学习法 的典型代表.这里我们把个体学习器称为初级学习器，用于结合的学习器称为 次级学习器或元学习器(meta-learner). Stacking本身是一种著 名的集成学习方法，且有 不少集成学习算法可视为 其变体或特例.它也可看 作一种特殊的结合策略, 因此本书在此介绍. 184 第8 章集成学习 Stacking先从初始数据集训练出初级学习器，然 后 “生成” 一个新数据集 用于训练次级学习器.在这个新数据集中，初级学习器的输出被当作样例输入 特征，而初始样本的标记仍被当作样例标记.Stacking的算法描 述 如 图 8.9所 示,这里我们假定初级学习器使用不同学习算法产生，即初级集成是异质的. 输入：训练集 D = U1),侬2,g2), • • . , Jm)｝； 初级学习算法专,观,… ，£ T ； 次级学习算法£.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 450
    }
  },
  {
    "page_content": "用于训练次级学习器.在这个新数据集中，初级学习器的输出被当作样例输入 特征，而初始样本的标记仍被当作样例标记.Stacking的算法描 述 如 图 8.9所 示,这里我们假定初级学习器使用不同学习算法产生，即初级集成是异质的. 输入：训练集 D = U1),侬2,g2), • • . , Jm)｝； 初级学习算法专,观,… ，£ T ； 次级学习算法£. 过程： 1： for t = 1,2,... ,T do 2： hf = & ( 。)； 3： end for 4: D f = 0; 5： for i = 1,2,..., m do 6: 7： 8: 9： 。 = D U (Oi, & 2,… ，为r),仍)； 10: end for 11： hl = £(D); 输出：H(x) = hr for = 1,2,..., T do Zu = 3 (g); end for (x), /i2 (»)) 图 8.9 Stacking算法 在训练阶段，次级训练集是利用初级学习器产生的，若直接用初级学习器 的训练集来产生次级训练集，则过拟合风险会比较大;因此,一般是通过使用交 叉验证或留一法这样的方式，用训练初级学习器未使用的样本来产生次级学习 器 的 训 练 样 本 .以k 折交叉验证为例，初始训练集D 被随机划分为k 个大小相 似 的 集 合 。1,。2, . • •, D k. 令 D j 和 Dj = D \\ D j 分 别表示第j 折的测试集和 训 练 集 .给 定 T 个初级学习算法，初 级 学 习 器 感 )通 过 在 D j 上 使 用 第 t个学 习 算 法 而 得 .对 D j 中每个样本g , 令 尔 = 点 ) 8 , 则 由 X%所产生的次级训 练样例的示例部分为4 = (&i；& 2； .•.；& ? ) , 标记 部 分 为 y i . 于是，在整个交叉 验证过程结束后，从 这 T 个初级学习器产生的次级训练集是。 = ｛(当,%)｝黑「 然 后 D f 将用于训练次级学习器. 次级学习器的输入属性表示和次级学习算法对Stacking集成的泛化性能 有很大影响.有研究表明，将初级学习器的输出类概率作为次级学习器的输入 属性，用多响应线性回归(Multi-response Linear Regression,简 称 M L R ) 作为 次级学习算法效果较好 [Ting and Witten, 1999],在 M L R 中使用不同的属性 集 更 佳 [Seewald, 2002]. 初级学习器也可是同质 的. 使 用 初 级 学 习 算 法 & 产生初级学习器区. 生成次级训练集. 在 D 上用次级学习算",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 451
    }
  },
  {
    "page_content": "次级学习算法效果较好 [Ting and Witten, 1999],在 M L R 中使用不同的属性 集 更 佳 [Seewald, 2002]. 初级学习器也可是同质 的. 使 用 初 级 学 习 算 法 & 产生初级学习器区. 生成次级训练集. 在 D 上用次级学习算 法£产生次级学习器〃. M LR是基于线性回归的 分类器，它对每个类分别 进行线性回归，属于该类 的训练样例所对应的输出 被 置 为 1 , 其 他 类 置 为 0; 测试示例将被分给输出值 最大的类. WEKA 中的 Stack!ngC 算法就是这样实现的. 8 . 5 多样性 185 贝叶斯模型平均(Bayes Model Averaging,简 称 BMA)基于后验概率来为 不 同 模 型 赋 予 权 重 ，可 视 为 加 权 平 均 法 的 一 种 特 殊 实 现 . [Clarke, 2003]对 Stacking和 BM A 进行了比较.理论上来说，若数据生成模型恰在当前考虑的 模型中，且数据噪声很少，则 BM A 不 差 于 Stacking;然而,在现实应用中无法 确保数据生成模型一定在当前考虑的模型中，甚至可能难以用当前考虑的模型 来进行近似，因此，Stacking通常优于B M A ,因为其鲁棒性比BM A 更好，而且 BM A对模型近似误差非常敏感. 8 . 5 多样性 8 .5 .1 误差-分歧分解 8 .1 节提到，欲构建泛化能力强的集成，个 体 学 习 器 应 “好而不同”.现 在 我们来做一个简单的理论分析. 假 定 我们用个体学习器加油2,… 温丁通过加权平均法(8.23)结合产生的 集 成 来 完 成 回 归 学 习 任 务 / :肢4 1 应 对 示 例 叫 定 义 学 习 器 h i 的 “分 歧 ”(ambiguity)为 A(h i \\x ) = (hi ( x ) - H ( x ) ) 2 , (8.27) 则 集 成 的 “分歧”是 _ T | z) = 〉；_ ] 她4 ( 庆 | 宓) = £ 二 奶 ⑸ 3 ) — H 3 ) ) 2 . (8.28) 显然，这 里 的 “分歧”项表征了个体学习器在样本比上的不一致性，即在 一 定 程 度 上 反 映 了 个 体 学 习 器 的 多 样 性 .个 体 学 习 器 和 集 成 H 的平方误差 分别为 顼 殳 ㈤ = ( /Q ) - 殳3 ) ) 2 , ㈤ = ( / * (8.29) (8.30) 令 百 仇 I ⑼ = E(hi |⑼表示个体学习器误差的加权均值,有 T",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 452
    }
  },
  {
    "page_content": "一 定 程 度 上 反 映 了 个 体 学 习 器 的 多 样 性 .个 体 学 习 器 和 集 成 H 的平方误差 分别为 顼 殳 ㈤ = ( /Q ) - 殳3 ) ) 2 , ㈤ = ( / * (8.29) (8.30) 令 百 仇 I ⑼ = E(hi |⑼表示个体学习器误差的加权均值,有 T A[h | x) = £她 七 (九 | x) — E (H | x) i=l = E (h | x) - E (H | x) . (8.31) 186 第 8 章 集 成 学 习 式(8.31)对所有样本比均成立，令 p ( x ) 表示样本的概率密度，则在全样本 上有 £ 她 / A(hi | x)p(x)dx — £ 妫 / E(h1 \\ x )p (x )d x — z=i J i=i J 这 里 我 们 用 场 和 4 简 化 表 示 E(hi)和 A{hi). 类似的，个体学习器h i 在全样本上的泛化误差和分歧项分别为 E% — J E{hi [ x^p^x^dx , Ai = J A(hi \\ x )p (x)d x . 这 里 我 们 用 E 简化表示 E(H). 集成的泛化误差为 E = J E (H | x}p{x}dx . \\ x )p (x)d x . (8.32) (8.33) (8.34) (8.35) 将 式(8.33)〜 (8.35)代入式(8.32),再 令 百 = £着 仅 ㈤ 表 示 个 体 学 习 器 泛 化误差的加权均值,A = £ 窘 1奶4 表示个体学习器的加权分歧值,有 E = E - A . (8.36) 式(8.36)这个漂亮的式子明确提示出：个体学习器准确性越高、多样性越 大，则集成越好.上面这个分析首先由［Krogh and Vedelsby, 1995］给出，称为 “误差一分歧分解”(error-ambiguity decomposition). 至此，读者可能很高兴：我 们 直 接 把 百 - X 作为优化目标来求解，不就能 得到最优的集成了？遗憾的是，在 现 实 任 务 中 很 难 直 接 对 万 进 行 优 化 ，不 仅由于它们是定义在整个样本空间上，还 由 于 N 不是一个可直接操作的多样性 度量，它仅在集成构造好之后才能进行估计.此外需注意的是,上面的推导过程 只适用于回归学习，难以直接推广到分类学习任务上去. 8 .5 .2 多样性度量 亦 称 “差异性度量” . 顾名思义，多样性度量(diversity measure)是用于度量集成中个体分类器的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 453
    }
  },
  {
    "page_content": "仅由于它们是定义在整个样本空间上，还 由 于 N 不是一个可直接操作的多样性 度量，它仅在集成构造好之后才能进行估计.此外需注意的是,上面的推导过程 只适用于回归学习，难以直接推广到分类学习任务上去. 8 .5 .2 多样性度量 亦 称 “差异性度量” . 顾名思义，多样性度量(diversity measure)是用于度量集成中个体分类器的 多样性，即估算个体学习器的多样化程度.典型做法是考虑个体分类器的两两 相似/不相似性. 8 . 5 多样性 187 参见2,3.2节混淆矩阵• 『 I, + i } , 分 类 器 h ,与为的预测结果列联表(contingency table)为 给 定 数 据 集 。 = {(«1, ?/1),(0?2, ?/2), . . . , (®m, 2/m)},对 二 分 类 任 务 ，Vi € h1 = +1 hi = - 1 % = +1 hj = - 1 a b c d 其 中 ，a 表 示 儿 与 ％ 均 预 测 为 正 类 的 样 本 数 目 ；b、c、d 含 义 由 此 类 推 a + 6 + 。+ d = 馆.基于这个列联表，下面给出一些常见的多样性度量. • 不合度量(disagreement measure) h -1-(2 disij = ---- . (8.37) diSij的值域为[0,1].值越大则多样性越大. • 相关系数(correlation coefficient) Pij = ­ / - ad — be ，(a + b)(a + c)(c + d)(b + d) = . 小 cc、 (8.38) Pij的 值 域 为 [ - 1 ,1 ] .若儿与hj无关，则 值 为 0 ; 若 殳 与 hj正相关则值 为正，否则为负. • Q-统计量(Q-statistic) 八 QL ad + bc， ad — be 小 “、 网 39) Qij与相关系数pij的符号相同，且 \\Qij\\ W \\pij\\- • K - 统计量(^-statistic) ⑻4。) 其中，P1是两个分类器取得一致的概率;P2是两个分类器偶然达成一致 的概率，它们可由数据集D 估算： Pi = P2 = a + d m ， \\ (a + b)(a + c) + (c + d)(b + d) m 2 (8.41) (8.42) 若 分 类 器hi与hj 在D 上完全一致，则 K = 1 ; 若它们仅是偶然达成一致, 188 第 8 章 集 成 学 习 则 用 = 0 .凡通常为非负值，仅 在 hi与 为 达成一致的概率甚至低于偶然",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 454
    }
  },
  {
    "page_content": "Pi = P2 = a + d m ， \\ (a + b)(a + c) + (c + d)(b + d) m 2 (8.41) (8.42) 若 分 类 器hi与hj 在D 上完全一致，则 K = 1 ; 若它们仅是偶然达成一致, 188 第 8 章 集 成 学 习 则 用 = 0 .凡通常为非负值，仅 在 hi与 为 达成一致的概率甚至低于偶然 性的情况下取负值. 以上介绍的都是“成 对 型 \" (pairwise)多样性度量，它们可以容易地通过2 维 图 绘 制 出 来 .例 如 著 名 的 “公误差图”，就是将每一对分类器作为图上的一 个点，横坐标是这对分类器的《值，纵坐标是它们的平均误差，图 8.10给出了 一个例子.显然，数据点云的位置越高，则个体分类器准确性越低；点云的位置 越靠右，则个体学习器的多样性越小. 0.10 -0 .2 0 0.2 0.4 0.6 0.8 ().10L -0 .2 — 1---------- --------- - ------ '---------- 0 0.2 0.4 0.6 0.8 K, (a) AdaBoost 集成 (b) Bagging 集成 图 8 . 1 0 在 U C I数 据 集 tic-tac-toe上的小误差图. 每 个 集 成 含 5 0 棵 C 4.5决策树 8. 5 . 3多样性增强 在集成学习中需有效地生成多样性大的个体学习器.与简单地直接用初始 数据训练出个体学习器相比，如何增强多样性呢？ 一般思路是在学习过程中引 入随机性，常见做法主要是对数据样本、输入属性、输出表示、算法参数进行 扰动. • 数据样本扰动 给定初始数据集，可从中产生出不同的数据子集，再利用不同的数据子集 训练出不同的个体学习器.数据样本扰动通常是基于采样法，例 如 在 Bagging 中使用自助采样，在 A d a B o o s t 中使用序列采样.此类做法简单高效，使用最 广.对很多常见的基学习器，例如决策树、神经网络等，训练样本稍加变化就会 导致学习器有显著变动，数据样本扰动法对这样的“不稳定基学习器”很有效; 然而，有一些基学习器对数据样本的扰动不敏感，例如线性学习器、支持向量 机 、朴素贝叶斯、k 近邻学习器等，这样的基学习器称为稳定基学习器(stable base learner),对此类基学习器进行集成往往需使用输入属性扰动等其他机制. 8 . 5 多样性 189 • 输入属性扰动 子空间一般指从初始的 高维属性空间投影产生的 低维属性空间，描述低维 空间的属性是通过初始属 性投影变换而得，未必是 初始属性.参见第1 0 章.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 455
    }
  },
  {
    "page_content": "机 、朴素贝叶斯、k 近邻学习器等，这样的基学习器称为稳定基学习器(stable base learner),对此类基学习器进行集成往往需使用输入属性扰动等其他机制. 8 . 5 多样性 189 • 输入属性扰动 子空间一般指从初始的 高维属性空间投影产生的 低维属性空间，描述低维 空间的属性是通过初始属 性投影变换而得，未必是 初始属性.参见第1 0 章. 训练样本通常由一组属性描述，不 同 的 “子空间 ”(subspace,即属性子 集)提供了观察数据的不同视角.显然，从不同子空间训练出的个体学习器必然 有所不同.著名的随机子空间(random subspace)算 法 ［Ho, 1998］就依赖于输入 属性扰动，该算法从初始属性集中抽取出若干个属性子集，再基于每个属性子 集训练一个基学习器，算 法 描 述 如 图8.11所示.对包含大量冗余属性的数据, 在子空间中训练个体学习器不仅能产生多样性大的个体,还会因属性数的减少 而大幅节省时间开销，同时，由于冗余属性多，减少一些属性后训练出的个体学 习器也不至于太差.若数据只包含少量属性，或者冗余属性很少，则不宜使用输 入属性扰动法. 力小于初始属性数d. :Ft包 含 df 个随机选取 的属性，D t 仅 保 留 :Ft中 的属性. 输 入 ：训I练 集 。 = {(叫 ，组 )，(宓2,2/2),… ，0 皿沙馆)}； 基 学 习 算 法 £ ； 基 学 习 器 数 T; 子 空 间 属 性 数 成 . 过 程 ： d o 1： f o r 力= 1 , 2 , ... 2： 成) = 3 ： Dt = M a p j ? t (79) 4 ： hi = £ ( 。右) 5： e n d f o r 输 出 ：H Q ) = arg m a x £ 乙 11 (ht ( M a p 尸= ( g ) ) = y) y^y 图 8 . 1 1 随 机 于 空 间 算 法 • 输出表示扰动 此类做法的基本思路是对输出表示进行操纵以增强多样性.可对训练样本 的类标记稍作变动，如 “翻 转 法 \"(Flipping Output) ［Breiman, 2000］随机改变 一些训练样本的标记；也可对输出表示进行转化，如 “输出调制法”(Output Smearing) ［Breiman, 2000］将分类输出转化为回归输出后构建个体学习器; 还可将原任务拆解为多个可同时求解的子任务，如 E C O C 法 ［Dietterich and Bakiri, 1995］利用纠错输出码将多分类任务拆解为一系列二分类任务来训练基 学习器. • 算法参数扰动",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 456
    }
  },
  {
    "page_content": "Smearing) ［Breiman, 2000］将分类输出转化为回归输出后构建个体学习器; 还可将原任务拆解为多个可同时求解的子任务，如 E C O C 法 ［Dietterich and Bakiri, 1995］利用纠错输出码将多分类任务拆解为一系列二分类任务来训练基 学习器. • 算法参数扰动 基学习算法一般都有参数需进行设置，例如神经网络的隐层神经元数、初 始连接权值等，通过随机设置不同的参数,往往可产生差别较大的个体学习器. E C O C 参 见 3.5节. 190 第 8 章 集 成 学 习 例 如 \"负 相 关 法 \" (Negative Correlation) ［Liu and Yao, 1999］显式地通过正则 化项来强制个体神经网络使用不同的参数.对参数较少的算法，可通过将其学 习过程中某些环节用其他类似方式代替，从而达到扰动的目的，例如可将决策 树使用的属性选择机制替换成其他的属性选择机制.值得指出的是，使用单一 学习器时通常需使用交叉验证等方法来确定参数值，这事实上已使用了不同参 数训练出多个学习器，只不过最终仅选择其中一个学习器进行使用，而集成学 习则相当于把这些学习器都利用起来；由此也可看出，集成学习技术的实际计 算开销并不比使用单一学习器大很多. ;不 同 的 多 样 性 增 强 机 制 可 同 时 使 用 ，例 如 & 3.2节介绍的随机森林中同 时使用了数据样本扰动和输入属性扰动，有些方法甚至同时使用了更多机制 ［Zhou, 2012］. 8 . 6 阅读材料 集 成 学 习 方 面 的 主 要 推 荐 读 物 是 ［Zhou, 2012］, 本章提及的所有内容在 该书中都有更深入详细的介绍. ［Kuncheva, 2004; Rokach, 2010b］可供参考. ［Schapire and Freund, 2012］则是专门关于 Boosting 的著作. Boosting 源 于 ［Schapire, 1990］对 ［Kearns and Valiant, 1989］提 出 的 “弱 学习是否等价于强学习”这 个 重 要 理 论 问 题 的 构 造 性 证 明 .最 初 的 Boosting 算法仅有理论意义,经数年努力后［Freund and Schapire, 1997］提 出 AdaBoost, 并因此获得理论计算机科学方面的重要奖项—— 哥德尔奖 .不 同 集 成 学 习 方 法的工作机理和理论性质往往有显著不同，例如从偏差-方差分解的角度看,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 457
    }
  },
  {
    "page_content": "学习是否等价于强学习”这 个 重 要 理 论 问 题 的 构 造 性 证 明 .最 初 的 Boosting 算法仅有理论意义,经数年努力后［Freund and Schapire, 1997］提 出 AdaBoost, 并因此获得理论计算机科学方面的重要奖项—— 哥德尔奖 .不 同 集 成 学 习 方 法的工作机理和理论性质往往有显著不同，例如从偏差-方差分解的角度看, Boosting主要关注降低偏差，而 Bagging主 要 关 注 降 低 方 差 .MultiBoosting ［Webb, 2000］等方法尝试将二者的优点加以结合.关于Boosting和 Bagging已 有很多理论研究结果，可 参 阅 ［Zhou, 2012］第 2〜 3 章. 8.2 节给出的 AdaBoost 推 导 源 于 “统 计 视 角 ”(statistical view) ［Fried­ man et al., 2000］, 此 派 理 论 认 为 A daB oost实质上是基于 加 性 模 型(additive model)以类似牛顿迭代法来优化指数损失函数.受此启发，通过将迭代优化过 程替换为其他优化方法，产生了 GradientBoosting ［Friedman, 2001］＞ LPBoost ［Demiriz et al., 2008］等变体算法.然而,这派理论产生的推论与AdaBoost实际 行为有相当大的差别［Mease and Wyner, 2008］, 尤其是它不能解释AdaBoost 为什么没有过拟合这个重要现象，因此不少人认为，统计视角本身虽很有意义, 但其阐释的是一个与A daB oost相似的学习过程而并非AdaBoost本 身 . “间 隔理论\" (margin theory) ［Schapire et al., 1998］能直观地解释这个重要现象, 这个现象的严格表述是 “为 什 么 Ada B oost在训 练误差达到零之后继续训 练 仍 能 提 高 泛 化 性 能 ”； 若一直训练下去，过拟合 最终仍会出现. 8 . 6 阅读材料 191 对并行化集成的修剪亦 称 “选择性集成” (selec­ tive e n s e m b le ),但现在一 般将选择性集成用作集成 修剪的同义语，亦 称 “集 成选择” (ensemble selec­ tion). 但 过 去 15年中一直存有争论，直到最近的研究结果使它最终得以确立，并对新 型学习方法的设计给出了启示;相关内容可参阅［Zhou, 2014］. 本章仅介绍了最基本的几种结合方法，常见的还有基于D -S 证据理论的方",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 458
    }
  },
  {
    "page_content": "tion). 但 过 去 15年中一直存有争论，直到最近的研究结果使它最终得以确立，并对新 型学习方法的设计给出了启示;相关内容可参阅［Zhou, 2014］. 本章仅介绍了最基本的几种结合方法，常见的还有基于D -S 证据理论的方 法 、动态分类器选择、混合专家(mixture of experts)等.本章仅介绍了成对型 多样性度量. ［Kuncheva and Whitaker, 2003; Tang et al., 2006］显示出，现有 多样性度量都存在显著缺陷.如何理解多样性，被认为是集成学习中的圣杯问 题.关于结合方法和多样性方面的内容,可参阅［Zhou, 2012］第 4〜 5 章. 在集成产生之后再试图通过去除一些个体学习器来获得较小的集成，称 为集成修剪(ensemble p ru n in g ).这有助于减小模型的存储开销和预测时间开 销.早期研究主要针对序列化集成进行，减小集成规模后常导致泛化性能下降 ［Rokach, 2010a］; ［Zhou et al., 2002］揭示出对并行化集成进行修剪能在减小规 模的同时提升泛化性能，并催生了基于优化的集成修剪技术.这方面的内容可 参 阅 ［Zhou, 2012］第 6 章. 关于聚类、半监督学习、代价敏感学习等任务中集成学习的内容，可参阅 ［Zhou, 2012］第 7 ~ 8 章.事实上，集成学习已被广泛用于几乎所有的学习任务. 著名数据挖掘竞赛KDDCup历年的冠军几乎都使用了集成学习. 由于集成包含多个学习器，即便个体学习器有较好的可解释性，集成仍是 黑箱模型.已有一些工作试图改善集成的可解释性「例如将集成转化为单模 型 、从集成中抽取符号规则等，这方面的研究衍生出了能产生性能超越集成 的单学习器的“二 次 学 习 \"(twice-learning)技术，例 如 NeC4.5算 法 ［Zhou and Jiang, 2004］. 可视化技术也对改善可解释性有一定帮助.可参阅［Zhou, 2012］ 第 8 章. 192 第 8 章 集 成 学 习 习题 8.1 假设抛硬币正面朝上的概率为p , 反 面朝上的概率为1 - R 令 H 5 ) 代 表 抛n 次硬币所得正面朝上的次数，则 最 多 k 次正面朝上的概率为 产(口⑺ W k) = X —⑼2 . (8.43) i = C / 对 6 > 0, k = (p — 5 ) n ,有 Hoeffding 不等式 P(H (n) W (p — 6)九)W e - 2 j2 n . (8.44) 试推导出式(8.3).",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 459
    }
  },
  {
    "page_content": "代 表 抛n 次硬币所得正面朝上的次数，则 最 多 k 次正面朝上的概率为 产(口⑺ W k) = X —⑼2 . (8.43) i = C / 对 6 > 0, k = (p — 5 ) n ,有 Hoeffding 不等式 P(H (n) W (p — 6)九)W e - 2 j2 n . (8.44) 试推导出式(8.3). 8.2 对 于 0 / 1 损失函数来说，指数损失函数并非仅有的一致替代函数.考 虑式(8.5),试证明：任意损失 函 数2(—/ Q ) H Q ) ) , 若 对 于 H Q ) 在区 间 ［- 8 ⑼ (3 > 0 ) 上单调递减，则 2 是 0 /1 损失函数的一致替代函数. 西瓜数据集3 . 0 a 见 p.89 表 4.5. 8.3 从网上下载或自己编程实现A daB oost,以不剪枝决策树为基学习器, 在西瓜数据集3 .0 a 上训练一个AdaBoost集成，并 与 图 8.4 进行比较. 8.4 GradientBoosting ［Friedman, 2001］是一种常用的 Boosting 算法，试 析其 与AdaB oost的异同. 8.5 试 编程实现B agging,以决策树桩为基学习器，在 西 瓜 数 据 集3 .0 a 上 训练一个Bagging集成，并 与 图 8.6进行比较. 8.6 试 析 Bagging通常为何难以提升朴素贝叶斯分类器的性能. 8.7 试析随机森林为何比决策树Bagging集成的训练速度更快. 8.8 MultiBoosting 算 法 ［Webb, 2000］将 AdaBoost 作为 Bagging 的基学 习器，Iterative Bagging 算 法 ［Breiman, 2001b］则是将 Bagging 作为 AdaBoost的基学习器.试比较二者的优缺点. 8.9 * 试设计一种可视的多样性度量，对 习 题 8 .3 和 习 题 8 .5 中得到的集成 进行评估，并与公误差图比较. 8.10 * 试设计一种能提升k 近邻分类器性能的集成学习算法. 参考文献 193 参考文献 Breiman, L. (1996a). “Bagging predictors?5 Machine Learning, 24(2):123-140. Breiman, L. (1996b). ^Stacked regressions.55 Machine Learning^ 24(1):49-64.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 460
    }
  },
  {
    "page_content": "参考文献 193 参考文献 Breiman, L. (1996a). “Bagging predictors?5 Machine Learning, 24(2):123-140. Breiman, L. (1996b). ^Stacked regressions.55 Machine Learning^ 24(1):49-64. Breiman, L. (2000). ^Randomizing outputs to increase prediction accuracy.55 Machine Learning, 40(3):113-120. Breiman, L. (2001a). ^Random forests.^^ Machine Learning, 45(1):5-32. Breiman, L. (2001b). “Using iterated bagging to debias regressions.55 Machine Learning, 45(3):261-277. Clarke, B. (2003). ^Comparing Bayes model averaging and stacking when mod­ el approximation error cannot be ignored?5 Journal of Machine Learning Research1 4:683-712. Demiriz, A., K. P. Bennett, and J. Shawe-Taylor. (2008). “Linear programming Boosting via column generation.\" Machine Learning1 46(1-3):225-254. Dietterich, T. G. (2000). “Ensemble methods in machine learning.55 In Pro­ ceedings of the 1st International Workshop on Multiple Classifier Systems (MCS), 1-15, Cagliari, Italy. Dietterich, T. G. and G. Bakiri. (1995). “Solving multiclass learning problems via error-correcting output codes.55 Journal of Artificial Intelligence Re­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 461
    }
  },
  {
    "page_content": "Dietterich, T. G. and G. Bakiri. (1995). “Solving multiclass learning problems via error-correcting output codes.55 Journal of Artificial Intelligence Re­ search, 2:263-286. Freund, Y. and R. E. Schapire. (1997). “A decision-theoretic generalization of on-line learning and an application to boosting?5 Journal of Computer and System Sciences155(1):119-139. Friedman, J., T. Hastie, and R. Tibshirani. (2000). uAdditive logistic regres­ sion: A statistical view of boosting (with discussions)/5 Annals of Statistics, 28(2):337-407. Friedman, J. H. (2001). “Greedy function approximation: A gradient Boosting machine.” Annals of Statistics1 29(5):1189-1232. Ho, T. K. (1998). “The random subspace method for constructing decision forests.\" IEEE Transactions on Pattern Analysis and Machine Intelligence^ 20(8):832-844. Ho, T. K., J. J. Hull, and S. N. Srihari. (1994). “Decision combination in multi- 194 第 8 章 集 成 学 习 pie classifier systems.^^ IEEE Transaction on Pattern Analysis and Machine Intelligence1 16(1):66-75.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 462
    }
  },
  {
    "page_content": "194 第 8 章 集 成 学 习 pie classifier systems.^^ IEEE Transaction on Pattern Analysis and Machine Intelligence1 16(1):66-75. Kearns, M. and L. G. Valiant. (1989). ^Cryptographic limitations on learning Boolean formulae and finite automata.\" In Proceedings of the 21st Annual ACM Symposium on Theory of Computing (STOC), 433-444, Seattle, WA. Kittier, J., M. Hatef, R. Duin, and J. Matas. (1998). “On combining classifiers.” IEEE Transactions on Pattern Analysis and Machine Intelligence^ 20(3): 226-239. Kohavi, R. and D. H. Wolpert. (1996). “Bias plus variance decomposition for. zero-one loss functions.55 In Proceedings of the 13th International Conference on Machine Learning (ICML), 275-283, Bari, Italy. Krogh, A. and J. Vedelsby. (1995). <cNeural network ensembles, cross validation, and active learning.\" In Advances in Neural Information Processing Systems 7 (NIPS) (G. Tesauro, D. S. Touretzky, and T. K. Leen, eds.), 231-238, MIT Press, Cambridge, MA. Kuncheva, L. I. (2004). Combining Pattern Classifiers: Methods and Algo­ rithms. John Wiley & Sons, Hoboken, NJ.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 463
    }
  },
  {
    "page_content": "Press, Cambridge, MA. Kuncheva, L. I. (2004). Combining Pattern Classifiers: Methods and Algo­ rithms. John Wiley & Sons, Hoboken, NJ. Kuncheva, L. I. and C. J. Whitaker. (2003). “Measures of diversity in classifi­ er ensembles and their relationship with the ensemble accuracy?5 Machine Learning, 51(2):181-207. Liu, Y. and X. Yao. (1999). “Ensemble learning via negative correlation.^^ Neu­ ral Networks, 12(10):1399-1404. Markowitz, H. (1952). “Portfolio selection.” Journal of Finance1 7(1):77-91. Mease, D. and A. Wyner. (2008). “Evidence contrary to the statistical view of boosting (with d isc u ssio n s).Journal of Machine Learning Research1 9: 131-201. Perrone, M. P. and L. N. Cooper. (1993). “When networks disagree: Ensemble method for neural networks.55 In Artificial Neural Networks for Speech and Vision (R. J. Mammone, ed.), 126-142, Chapman & Hall, New York, NY. Platt, J. C. (2000). ^Probabilities for SV m achines.In Advances in Large Mar­ gin Classifiers (A. J. Smola, P. L. Bartlett, B. Scholkopf, and D. Schuurmans, eds.), 61-74, MIT Press, Cambridge, MA. 参考文献",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 464
    }
  },
  {
    "page_content": "gin Classifiers (A. J. Smola, P. L. Bartlett, B. Scholkopf, and D. Schuurmans, eds.), 61-74, MIT Press, Cambridge, MA. 参考文献 195 Rokach, L. (2010a). “Ensemble-based classifiers.\" Artificial Intelligence Revie叫 33(1):1-39. Rokach, L. (2010b). Pattern Classification Using Ensemble Methods. World Scientific, Singapore. Schapire, R. E. (1990). “The strength of weak learnability.55 Machine Learning^ 5(2):197-227. Schapire, R. E. and Y. Freund. (2012). Boosting: Foundations and Algorithms. MIT Press, Cambridge, MA. Schapire, R. E., Y. Freund, P. Bartlett, and W. S. Lee. (1998). “Boosting the margin: A new explanation for the effectiveness of voting methods.55 Annals of Statistics, 26(5):1651-1686. Seewald, A. K. (2002). \"How to make Stacking better and faster while also tak­ ing care of an unknown weakness?5 In Proceedings of the 19th International Conference on Machine Learning (ICML)1 554-561, Sydney, Australia. Tang, E. K., P. N. Suganthan, and X. Yao. (2006). “An analysis of diversity measures.55 Machine Learning1 65(1):247-271.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 465
    }
  },
  {
    "page_content": "Tang, E. K., P. N. Suganthan, and X. Yao. (2006). “An analysis of diversity measures.55 Machine Learning1 65(1):247-271. Ting, K. M. and I. H. Witten. (1999). “Issues in stacked generalization.,5 Jour­ nal of Artificial Intelligence Research1 10:271-289. Webb, G. I. (2000). uMultiBoosting: A technique for combining boosting and wagging.\" Machine Learning, 40(2):159-196. Wolpert, D. H. (1992). “Stacked generalization.\" Neural Networks1 5(2):241- 260. Wolpert, D. H. and W. G. Macready. (1999). “An efficient method to estimate Bagging's generalization error.^^ Machine Learning, 35(1):41-55. 1 Xu, L., A. Krzyzak, and C. Y. Suen. (1992). “Methods of combining multiple classifiers and their applications to handwriting rec o g n itio n .IEEE Trans­ actions on Systems, Man, and Cybernetics1 22(3):418-435. Zadrozny, B. and C. Elkan. (2001). “Obtaining calibrated probability esti­ mates from decision trees and naive Bayesian classifiers.55 In Proceedings of the 18th International Conference on Machine Learning (ICML), 609-616, Williamstown, MA.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 466
    }
  },
  {
    "page_content": "mates from decision trees and naive Bayesian classifiers.55 In Proceedings of the 18th International Conference on Machine Learning (ICML), 609-616, Williamstown, MA. Zhou, Z.-H. (2012). Ensemble Methods: Foundations and Algorithms. 196 第 8 章 集 成 学 习 Chapman & Hall/CRC, Boca Raton, FL. Zhou, Z.-H. (2014). “Large margin distribution learning.5, In Proceedings of the 6th IAPR International Workshop on Artificial Neural Networks in Pattern Recognition (ANNPR), 1-11, Montreal, Canada. Zhou, Z.-H. and Y. Jiang. (2004). uNeC4.5: Neural ensemble based C4.5.” IEEE Transactions on Knowledge and Data Engineering^ 16(6):770-773. Zhou, Z.-H., J. Wu, and W. Tang. (2002). uEnsembling neural networks: Many could be better than all.” Artificial Intelligence1 137(1-2):239-263. 休 息 一 会 儿 小故事：老当益壮的李奥•布瑞曼 李 奥 • 布 瑞 曼 (Leo Breiman, 1928-2005)是二十世纪 伟 大 的 统 计 学 家 .他 在 二 十 世 纪 末 公 开 宣 称 ，统计学界把 统计搞成了抽象数学，这偏离了初衷，统计学本该是关于预 测、解释和处理数据的学问.他自称与机器学习走得更近， 因为这一行是在处理有挑战的数据问题.事实上,布瑞曼是 一位卓越的机器学习学家,他不仅是CA R T决策树的作者，还对集成学习有三 大贡献:Bagging、随机森林以及关于Boosting的理论探讨.有趣的是，这些都 是 在 他 1993年从加州大学伯克利分校统计系退休后完成的.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 467
    }
  },
  {
    "page_content": "统计搞成了抽象数学，这偏离了初衷，统计学本该是关于预 测、解释和处理数据的学问.他自称与机器学习走得更近， 因为这一行是在处理有挑战的数据问题.事实上,布瑞曼是 一位卓越的机器学习学家,他不仅是CA R T决策树的作者，还对集成学习有三 大贡献:Bagging、随机森林以及关于Boosting的理论探讨.有趣的是，这些都 是 在 他 1993年从加州大学伯克利分校统计系退休后完成的. 布瑞曼早年在加州理工学院获物理学士学位，然后打算到哥伦比亚大学念 哲学，但哲学系主任告诉他，自己最优秀的两个博士生没找到工作，于是布瑞曼 改学数学，先后在哥伦比亚大学和加州大学伯克利分校获得数学硕士、博士学 位.他先是研究概率论,但在加州大学洛杉矶分校(UCLA)做了 7 年教授后他厌 倦了概率论，于是主动辞职.为了向概率论告别，辞职后他把自己关在家里半年 写了本关于概率论的书，然后他到工业界做了 1 3 年咨询，再回到加州大学伯克 利分校统计系做教授.布瑞曼的经历极为丰富，他 曾 在 U C IA 学术假期间主动 到联合国教科文组织工作，被安排到非洲利比里亚统计失学儿童数.他是一位 业余雕塑家，甚至还与人合伙在墨西哥开过制冰厂.他自认为一生最重要的研 究成果—— 随机森林,是7 0 多岁时做出来的. 第 9 章 聚 类 9 . 1 聚类任务 常 见 的 无 监 督 学 习 任 务 还 有 密 度 估 计 (densi­ ty estimation)、异常检测 (anomaly detection)等. 在 “无 监 督 学 习 \" (unsupervised learning)中，训 练 样 本 的 标 记 信 息 是 未 知 的 ，目 标 是 通 过 对 无 标 记 训 练 样 本 的 学 习 来 揭 示 数 据 的 内 在 性 质 及 规 律 ，为 进 一 步 的 数 据 分 析 提 供 基 础 .此 类 学 习 任 务 中 研 究 最 多 、应 用 最 广 的 是 “聚 类 ”(clustering). 聚类试图将数据集中的样本 划 分 为 若 干 个 通 常 是 不 相 交 的 子 集 ,每 个 子 集 对聚类算法而言，样本 簇 亦 称 “类”. 称 为 一 个 “簇 ”(c lu s te r).通 过 这 样 的 划 分 ，每 个 簇 可 能 对 应 于 一 些 潜 在 的 概 念(类别)，如 “浅 色 瓜 ” “深 色 瓜 ”， “有 籽 瓜 ” “无 籽 瓜 ”，甚 至 “本 地 瓜 ” 聚类任务中也可使用有 标记训练样本，如 9 .4 .2 与 1 3 .6 节，但样本的类标记 与聚类产生的簇有所不同. “外 地 瓜 ”等 ；需说明的是，这些概念对聚类算法而言事先是未知的，聚类过程",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 468
    }
  },
  {
    "page_content": "聚类任务中也可使用有 标记训练样本，如 9 .4 .2 与 1 3 .6 节，但样本的类标记 与聚类产生的簇有所不同. “外 地 瓜 ”等 ；需说明的是，这些概念对聚类算法而言事先是未知的，聚类过程 仅能自动形成簇结构，簇所对应的概念语义需由使用者来把握和命名. 形 式 化 地 说 ，假 定 样 本 集 D = {xi,X2,...,xm } 包 含 m 个无标记样本, 每 个 样 本 / = ( g i ；/ ⑵ . ・ . ；/ 配 )是 一 个 九 维 特 征 向 量 ，则 聚 类 算 法 将 样 本 集 。 划 分 为 k 个 不 相 交 的 簇 { a 1 1 = 1,2；. . . / } , 其 中 〃 次 。 且 。 = u 3 a 相 应 地 ，我 们 用 ％ e 口,2 , . . . , 册 表 示 样 本 叼 的 “簇标 。 记 \" (cluster la b e l),即 叼 £ C Xj. 于 是 ，聚 类 的 结 果 可 用 包 含 m 个元素的簇标 记向 A — (Ai J 入2； • • • j 入m )表 聚 类 既 能 作 为 一 个 单 独 过 程 ，用 于 找 寻 数 据 内 在 的 分 布 结 构 ，也可作为分 类 等 其 他 学 习 任 务 的 前 驱 过 程 .例 如 ，在 一 些 商 业 应 用 中 需 对 新 用 户 的 类 型 进 行 判 别 ，但 定 义 “用 户 类 型 ”对 商 家 来 说 却 可 能 不 太 容 易 ，此时往往可先对用 户 数 据 进 行 聚 类 ，根 据 聚 类 结 果 将 每 个 簇 定 义 为 一 个 类 ，然后再基于这些类训 练分类模型,用于判别新用户的类型. 基 于 不 同 的 学 习 策 略 ，人 们 设 计 出 多 种 类 型 的 聚 类 算 法 .本 章 后 半 部 分 将 对 不 同 类 型 的 代 表 性 算 法 进 行 介 绍 ，但 在 此 之 前 ，我 们 先 讨 论聚类算法涉及的 两个 基 本 问 题 一一性能度量和距离计算. 9 . 2 性能度量 聚 类 性 能 度 量 亦 称 聚 类 “有 效 性 指 标 ”(validity in d e x ).与监督学习中的 198 监督学习中的性能度量 参 见 2 .3 节. 第 9 章 聚 类 性能度量作用相似,对聚类结果，我们需通过某种性能度量来评估其好坏；另一 方面，若明确了最终将要使用的性能度量，则可直接将其作为聚类过程的优化 目标，从而更好地得到符合要求的聚类结果. 聚 类 是 将 样 本 集 。 划分为若干互不相交的子集，即 样 本 簇 .那 么 ，什么",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 469
    }
  },
  {
    "page_content": "198 监督学习中的性能度量 参 见 2 .3 节. 第 9 章 聚 类 性能度量作用相似,对聚类结果，我们需通过某种性能度量来评估其好坏；另一 方面，若明确了最终将要使用的性能度量，则可直接将其作为聚类过程的优化 目标，从而更好地得到符合要求的聚类结果. 聚 类 是 将 样 本 集 。 划分为若干互不相交的子集，即 样 本 簇 .那 么 ，什么 样的聚类结果比较好呢？直观上看，我 们 希 望 “物以类聚”，即同一簇的样本 尽可能彼此相似，不同簇的样本尽可能不同.换言之，聚 类 结 果 的 “簇内相似 度 ”(intra-cluster similarity)高 且 “簇间相似度”(inter-cluster similarity)低. 聚 类 性 能 度 量 大 致 有 两 类 . 一 类 是 将 聚 类 结 果 与 某 个 “参 考 模 例如将领域专家给出的 划分结果作为参考模型. 型 ”(reference model)进 行 比 较 ，称 为 “夕卜部指标” (external in d e x );另一 类是直接考察聚类结果而不利用任何参考模型，称 为 “内部指标”(internal index). 通 常 k r s. 对 数 据 集 。 = {皿 ,畋 ,… ，x m ] , 假定通过聚类给出的簇划分为C = { 5 , 。2 ,… ，以卜参考模型给出的簇划分为C* = { Q , C玄… ,C；) . 相应地，令 》与 A*分别表示与C 和 C*对应的簇标记向量.我们将样本两两配对考虑，定义 a = |S S |, S S = {(g,叼 ) | % = Aj, A* = & ,E < J)}, b=\\SD\\, SD = { ( ^ , ^-) | A, = A; , A* A*, z < J)}, c= \\D S\\, D S = {(xi.X j) | A, AJ , A* = A*,z < j)}, DD = { ( ^ ,x j) | A, AJ , A* A*3 < j)}, (9.1) (9.2) (9.3) (9.4) 其 中 集 合 S S 包 含 了 在 C 中 隶 属 于 相 同 簇 且 在 C * 中也隶属于相同簇的样 本对，集 合 S D 包 含 了 在 C 中 隶 属 于 相 同 簇 但 在 C * 中隶属于不同簇的样本 对，... 由 于 每 个 样 本 对 (xi.X j) (i < j ) 仅 能 出 现 在 一 个 集 合 中 ，因此有 a + b + c + d = m (m — 1)/2 成立.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 470
    }
  },
  {
    "page_content": "本对，集 合 S D 包 含 了 在 C 中 隶 属 于 相 同 簇 但 在 C * 中隶属于不同簇的样本 对，... 由 于 每 个 样 本 对 (xi.X j) (i < j ) 仅 能 出 现 在 一 个 集 合 中 ，因此有 a + b + c + d = m (m — 1)/2 成立. 基于式(9.1)〜 (9.4)可导出下面这些常用的聚类性能度量外部指标： • Jaccard 系数(Jaccard Coefficient,简称 JC) JC = — I - a + b + c . • FM 指数(Fowlkes and Mallows In d ex ,简称 FMI) FMI = a a + c (9.5) ⑼6) 9 . 3 距离计算 • R a n d 指数(Rand Index,简称 RI) 2(a + d) m (m — 1) 显然，上述性能度量的结果值均在［0,1］区间，值越大越好. 考虑聚类结果的簇划分C = ｛。1 , … ，以 ｝,定义 199 (9.7) 叫 ⑹ 二 |C| ( | C | - 1 J £ 依 5 | 。| d i s t M 叼 ) ， (9.8) diam(C) = m a x K i < j X |C | dist(g,叼 ) , dmin(G, 5 ) = miiigwa,叼w Q dist(g,叼 ) , dcen(Ci,Cj) = dist(/i-2, /Zj) 5 (9.9) (9.10) (9.11) 度 器 量 需 提 客 以 其 中 ，dist《,.)用 于 计 算 两 个 样 本 之 间 的 距 离 ；儿 代 表 簇 。 的 中 心 点 〃 = R 点 £ 长 沟 。产 • 显 然 ，a v g ( C )对 应 于 簇 。 内样本间的平均距离，d i a m ( C ) 对 \" 应于簇、片内样本间的最远距离，d m in(G，a ) 对 应 于 簇 Ci与 簇 5 最近样本间 的距离，dee式Ci, 5 ) 对应于簇G 与 簇 5 中心点间的距离. 基于式(9.8)〜 (9.U)可导出下面这些常用的聚类性能度量内部指标： • D B 指数(Davies-Bouldin Index,简称 DBI) D B I 另 自 m a x i n g 尸+学。叫 k j/ \\ deen ( 从 强 / • D u n n 指数(Dunn Index,简称 DI) D I = min [ m i n ( 长 2 [ f diam(Q) J J 显然,D B I 的值越小越好,而D I 则相反,值越大越好. (9.12)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 471
    }
  },
  {
    "page_content": "D B I 另 自 m a x i n g 尸+学。叫 k j/ \\ deen ( 从 强 / • D u n n 指数(Dunn Index,简称 DI) D I = min [ m i n ( 长 2 [ f diam(Q) J J 显然,D B I 的值越小越好,而D I 则相反,值越大越好. (9.12) (9.13) 9 .3 距 离 计 算 对 函 数 dist(・「)，若 它 是 一 个 “距离度量”(distance measure),则需满足一 些基本性质： 非负性：dist(g,叼 ) ) 0 ; 同一性：dist( % 叼 ) = 0 当且仅 当xi = Xj ; (9.14) (9.15) 200 第 9 章 聚 类 直递性常被直接称为 ；三角不等式”. 对称性：d i s t ( g , 叼 ) = d i s t (叼,g ) ; 直递性：d i s t ( g , 叼 ) W dist(g, g ) + dist(磔，叼 ) . (9.16) (9.17) 给 定 样 本 Xi = (/”;/⑵ ...；/讪 )与 Xj = (叼1；叼2；… ；巧九)，最常用的是 “闵可夫斯基距离”( M i n k o w s k i distance) 式(9.18)即为Xi — Xj的 Lp ^巳数 | |«Dj — Xj ||p. \\ 1 \\ P d i s t m k Q e , 叼 ) = I ) : |力讪- x ju\\P I / / 九、 (9.18) p T 8 时则得到切比雪 夫距离. 对 0 2 1 , 式(9.18)显然满足式(9.14)~(9.17)的距离度量基本性质. 0 = 2 时,闵可夫斯基距离即欧氏距离(Euc l i d e a n distance) diste d (Xi, Xj) = |\\Xi—叼 |12 = 、〉: \\x iu ~ x ju^ • (9.19) \\ u=l n 亦称“街区距离”(city block distance). p = 1 时，闵可夫斯基距离即曼哈顿距离( M a n h a t t a n distance) d i s t m a n ) = | \\ *^i —g j 111 — 〉］ \\^iu —①加 | . (9.20) n u=l 我 们 常 将 属 性 划 分 为 “连 续 属 性 \" (continuous attribute)和 “离散属 属性亦F “簪 々 性 ”(categorical attribute),前者在定义域上有无穷多个可能的取值，后者在定",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 472
    }
  },
  {
    "page_content": "d i s t m a n ) = | \\ *^i —g j 111 — 〉］ \\^iu —①加 | . (9.20) n u=l 我 们 常 将 属 性 划 分 为 “连 续 属 性 \" (continuous attribute)和 “离散属 属性亦F “簪 々 性 ”(categorical attribute),前者在定义域上有无穷多个可能的取值，后者在定 ,性 (numerical attribute), “离散属性”亦称“列名 义域上是有限个取值.然而，在讨论距离计算时，属性上是否定义了 “序 ”关 (nominal attribute).系更为重要.例如定义域为口, 2 , 3 ) 的离散属性与连续属性的性质更接近一些, 能直接在属性值上计算距离： “1 ” 与 “2 ” 比较接近、与 “3 ” 比较远，这样的 属 性 称 为 “有序属性” (ordinal attribute);而定义域为｛飞机,火车,轮船｝这样 的离散属性则不能直接在属性值上计算距离，称 为 “无序属性”(non-ordinal a ttribute).显然，闵可夫斯基距离可用于有序属性. 对无序属性可采用 V D M (Val u e Difference Metric) [Stanfill a n d Wal t z , 1 9 8 6 ] . 令 m u ,a表示在属性u 上 取 值 为 a 的样本数,m g 表示在第 i 个样本簇 中在属性u 上取值为a 的样本数，k 为样本簇数，则 属 性 u 上两个离散值a 与b 之 间 的 V D M 距离为 V D M , (a, b) = £ k 2=1 p m u ,b ⑼ 21) 样本类别已知时“通常 设置为类别数. 9 . 3 距离计算 201 于 是 ，将 闵 可 夫 斯 基 距 离 和 V D M 结 合 即 可 处 理 混 合 属 性 .假 定 有 &个 有 序 属 性 、几 个 无 序 属 性 ，不失一般性，令有序属性排列在无序属性之前，则 \\ p \\^iu —叼 十 ) [ V D M p ( g 〃,叼〃)I n . u—nc-\\-l ) (9.22) S 当 样 本 空 间 中 不 同 属 性 的 重 要 性 不 同 时 ，可 使 用 “加 权 距 离 ”(weighted distance).以加权闵可夫斯基距离为例： d i s t w m k ( g ,①j) ~ — XjX F + . . . + W n \\xin — Xjn 。、 (9.23)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 473
    }
  },
  {
    "page_content": "n . u—nc-\\-l ) (9.22) S 当 样 本 空 间 中 不 同 属 性 的 重 要 性 不 同 时 ，可 使 用 “加 权 距 离 ”(weighted distance).以加权闵可夫斯基距离为例： d i s t w m k ( g ,①j) ~ — XjX F + . . . + W n \\xin — Xjn 。、 (9.23) 其 中 权 重 助 2 0 (E = 1,2,...,切 表 征 不 同 属 性 的 重 要 性 ，通 常 £ 建 1 Wi = 1. 需 注 意 的 是 ，通 常 我 们 是 基 于 某 种 形 式 的 距 离 来 定 义 “相 似 度 度 量 ”(similarity m e a s u r e ) , 距 离 越 大 ，相 似 度 越 小 . 然 而 ，用 于 相 似 度 度 量 的 距 离 未 必 一 定 要 满 足 距 离 度 量 的 所 有 基 本 性 质 ，尤 其 是 直 递 性 (9.17).例如在 某些任务中我们可能希望有这样的相似度度量： “人 ，， “马 ，，分 别 与 “人 马 ，， 相 似 ，但 “人 ”与 “马 ”很 不 相 似 ；要 达 到 这 个 目 的 ，可 以 令 “人 ” “马 ”与 “人 马 ”之间的距离都比较小，但 “人 ”与 “马 ”之间的距离 很大，如 图 9 . 1 所 示 ，此 时 该 距 离 不 再 满 足 直 递 性 ；这 样 的 距 离 称 为 “非 度 量 距 离 ”(non-metric distance).此 外 ，本 节 介 绍 的 距 离 计 算 式 都 是 事 先 定 义 好 的 ，但 在 不 少 现 实 任 务 中 ，有 必 要 基 于 数 据 样 本 来 确 定 合 适 的 距 离 计 算 式 ，这 可 通 过 “距离度量学 参 见 10.6节. 习 “(distance metric leaming)来实现. 这 个 例 子 中 ，从 数 学 上 看 ，令 d3 = 3 即可满足直 递 性 ;但 从语义上看，d3 应 远 大 于 d i 与 d2. d] + d2 V 不满足直递性 图 9 . 1 非度量距离的一个例子 202 第 9 章 聚 类 9 . 4 原 型 聚 类 “原 型 ”是指样本空间 中具有代表性的点. 原 型 聚 类 亦 称 “基于原型的聚类”(prototype-based clustering),此类算法 假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用.通常情形下, 算法先对原型进行初始化，然后对原型进行迭代更新求解.采用不同的原型表",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 474
    }
  },
  {
    "page_content": "202 第 9 章 聚 类 9 . 4 原 型 聚 类 “原 型 ”是指样本空间 中具有代表性的点. 原 型 聚 类 亦 称 “基于原型的聚类”(prototype-based clustering),此类算法 假设聚类结构能通过一组原型刻画，在现实聚类任务中极为常用.通常情形下, 算法先对原型进行初始化，然后对原型进行迭代更新求解.采用不同的原型表 示、不同的求解方式,将产生不同的算法.下面介绍几种著名的原型聚类算法. 9.4。 k 均值算法 给 定 样 本 集D = {cei, ®2, • • •, <(k 均 值 \" (k-means)算法针对聚类所 得簇划分C = 0 , • • . , 以}最小化平方误差 石 = £ £ 眠 一 也 信 (9.24) £=1 宓€。£ 其 中 也 = 扁 £ 咤a ⑦是 簇 Ci的均值向量.直观来看，式 ⑼ 2 4 ) 在一定程度上 刻画了簇内瘁本围绕,簇均值向量的紧密程度,E 值越小则簇内样本相似度越高. 最小化式(9.24)并不容易，找到它的最优解需考察样本集D 所有可能的簇 划分，这是一 个 N P 难问题[Aloise et al., 2 0 0 9 ] .因 此 k 均值算法采用了贪心策 略，通过迭代优化来近似求解式( 9 .2 4 ) .算法流 程 如 图 9 .2 所示，其 中 第 1 行对 均值向量进行初始化，在 第 4 - 8 行 与 第 9 - 1 6 行依次对当前簇划分及均值向量迭 代更新,若迭代更新后聚类结果保持不变,则在第1 8 行将当前簇划分结果返回. 下 面 以 表 9 .1 的 西瓜数据集 4 .0 为 例 来 演 示k 均值算法的学习过程.为方 便叙述，我们将 编 号 为 E 的样本称为g , 这 是 一 个 包 含 “密 度 ”与 “含糖率” 两个属性值的二维向量. p.89的 西 瓜 数 据 集 3.0a 表 9.1 西 瓜 数 据 集 4.0 样 本 9 ~ 2 1 的 类 别 是 “好 瓜 = 否 ” ，其 他 样 本 的 类 别 是 “好 瓜 = 是 ” . 由于本节使用无标记样本， 因此类别 标 记 信 息 未 在 表 中给出. . 编号 密度 含糖率 编号 密度 含糖率 编号 密度 含糖率 0.232 0.245 0.343 0.346 0.312 0.639 0.657 0.437 0.360 0.369 0.489 0.593 0.472 0.719 0.359 0.376 0.445 0.339 0.282 0.459 0.057 0.099 0.161 0.198 0.370 0.042 0.103 0.188 0.241 0.257",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 475
    }
  },
  {
    "page_content": "0.057 0.099 0.161 0.198 0.370 0.042 0.103 0.188 0.241 0.257 0.697 0.774 0.634 0.608 0.556 0.403 0.481 0.437 0.666 0.243 0.460 0.376 0.264 0.318 0.215 0.237 0.149 0.211 0.091 0.267 0.748 0.714 0.483 0.478 0.525 0.751 0.532 0.473 0.725 0.446 21 22 23 24 25 26 27 28 29 30 11 12 13 14 15 16 17 18 19 20 1 2 3 4 5 6 7 8 9 10 9 . 4 原型聚类 203 输入：样本集0 = ｛叫 ， … ,Xm ]\\ 聚类簇数 为避免运行时间过长, 通常设置一个最大运行轮 数或最小调整幅度阈值, 若达到最大轮数或调整幅 度小于阈值，则停止运行. 计算样本Xj与各均值向量也 (14 公4 k)的距离：dji = \\\\xj-/ | 2 ； 根据距离最近的均值向量确比Xj的簇标记：Xj = a r g m i n 记｛1 2 . .#｝如 ； 将样本叼划入相应的簇：% U ｛叼 ｝； % = 过程： 1：从 。 中随机选择k 个样本作为初始均值向量 2： repeat 3： 令 G = 0 (1 W £ W k) for J = 1,2,..., m do 4 ： 5: 6： 7： 8: 9： 10： end for for i = 1,2,..., A; do 计算新均值向量：M = 志 £ 尤 & 电 if 山丰 p，i then else 保持当前均值向量不变 将当前均值向量也更新为以 11： 12: 13: 14: 15: 16： 17： 输出：簇划分C = ｛GL, G , … ，以 ｝ end for u n til 当前均值向量均未更新 end if 图 9.2 k 均值算法 假 定 聚 类 簇 数 k = 3 , 算 法 开 始 时 随 机 选 取 三 个 样 本 W 6 , 叫 2 , 宓2 7 作为初始 均值向量，即 Mi = (0.403; 0.237),4 2 = (0.343; 0.099),网 = (0.532; 0.472). 考 察 样 本 叫 = (0.697; 0.460),它 与 当 前 均 值 向 量 如 加 2,4 3 的距离分别为 0.369,0.506, 0.166,因 此 叫 将 被 划 入 簇 。3中 .类 似 的 ，对数据集中的所有样本 考 察一遍后，可得当前簇划分为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 476
    }
  },
  {
    "page_content": "考 察 样 本 叫 = (0.697; 0.460),它 与 当 前 均 值 向 量 如 加 2,4 3 的距离分别为 0.369,0.506, 0.166,因 此 叫 将 被 划 入 簇 。3中 .类 似 的 ，对数据集中的所有样本 考 察一遍后，可得当前簇划分为 C1 = ｛宓5,比6,现7,磔 ,% 9, ® 1 0 ? 比 13,g 4 , 叫 5,叫 7,叫 8,比 19,力20, « 2 3 ) ； 。2 = ｛^ 1 1 , « 1 2 , ^ 1 6 ｝； 。3 = ｛宓 1,宓2,况3, ®4, ® 2 1 , ® 2 2 , 比24,% 25,比26,2 2 7 , 2 2 8 , 宓29,重3。｝・ 于 是 ，可 从 。1、。2 、。3 分别求出新的均值向量 以 = (0.473; 0 .214),出 = (0.394; 0.066),鼻 = (0.623; 0.388). 更 新 当 前 均 值 向 量 后 ，不 断 重 复 上 述 过 程 ，如 图 9 .3 所 示 ，第五轮迭代产生的结 果与第四轮迭代相同，于是算法停止,得到最终的簇划分. 204 第 9 章 聚 类 可 看 作 通 过 聚 类 来 形 成 类 别 “子 类 ” 结 构 ，每个 子类对应一个聚类簇. 图 9 . 3 西瓜数据集4.0上 k 均值算法（k = 3）在各轮迭代后的结果.样本点与均值向 量 分 别 用 ― 与 表 示 ，红色虚线显示出簇划分. 9.4.2学习向量量化 与 k 均值算法类似，\"学习向量量化”（Learning Vector Quantization,简 称 L V Q ）也是试图找到一组原型向量来刻画聚类结构，但与一般聚类算法不同 的是，L V Q 假设数据样本带有类别标记，学习过程利用样本的这些监督信息来 辅助聚类. 给定样本集。 = ｛（叫 网 ），（宓2,92）,...，（而 , 以 ）｝,每 个 样 本 叼 是 由 E 个 属性描述的特征向量（叼1；叼2；… ；叼4），yj e y 是 样 本Xj的类别标记.L V Q 的 目标是学得一组n 维原型向量 ｛pi,p 2 , 簇 标 记ti e y. 每个原型向量代表一个聚类簇, L V Q 算 法描述如图 9.4所 示 .算 法 第 1 行先对原型向量进行初始化，例如 对 第 q 个簇可从类别标记为tq 的样本中随机选取一个作为原型向量.算法第 9 . 4 原型聚类 205 输入：样本集。 = ｛（X1, 7/1）,（0:2, ?/2）, . • • , （® m , 原型向量个数Q , 各原型向量预设的类别标记｛大1\"2, • . • , % ｝； 学习率7/ G （0 , 1 ）.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 477
    }
  },
  {
    "page_content": "对 第 q 个簇可从类别标记为tq 的样本中随机选取一个作为原型向量.算法第 9 . 4 原型聚类 205 输入：样本集。 = ｛（X1, 7/1）,（0:2, ?/2）, . • • , （® m , 原型向量个数Q , 各原型向量预设的类别标记｛大1\"2, • . • , % ｝； 学习率7/ G （0 , 1 ）. 过程： 1：初始化一组原型向量｛P 1 , P 2 , … ，P q ｝ 2： repeat 从样本集D 随机选取样本（叼,% ）； 计算样本 Xj 与 “ （1 W 。4 Q ）的距离：dji = \\\\xj - Pi||2 ； 找出与Xj距离最近的原型向量3*, z* = arg m i n 记口,2,…,办办; if yj = % then = R * + 〃 •（叼 一口*） else Pf = Pi* 一 个 （叼一 Pe*） Xj与的类别相同. Xj与Pi*的类别不同. 如达到最大迭代轮数. 3: 4: 5&: 7&: 9: 0: 上 1 1 end if 将原型向量R * 更新为P， 12： u n t il满足停止秦件 输出：原型向量｛m , P 2 , … ，P q ｝ 图 9 . 4 学习向量量化算法 第 5 行是竞争学习的 “胜者为王”策略.SOM 是基于无标记样本的聚类 算法，而LVQ可看作SOM 基于监督信息的扩展.关 于竞争学习与SOM,参见 552 和 553 节. 2 ~ 1 2 行 对 原 型 向 量 进 行 迭 代 优 化 .在 每 一 轮 迭 代 中 ，算法随机选取一个有标记 训 练 样 本 ，找 出 与 其 距 离 最 近 的 原 型 向 量 ，并 根 据 两 者 的 类 别 标 记 是 否 一 致 来 对 原 型 向 量 进 行 相 应 的 更 新 .在 第 1 2 行 中 ，若 算 法 的 停 止 条 件 已 满 足 （例如已 达 到 最 大 迭 代 轮 数 ，或 原 型 向 量 更 新很小甚至不再更新），则将当前原型向量作 为最终结果返回. 显 然 ，L V Q 的 关 键 是 第 6 - 1 0 行 ，即 如 何 更 新 原 型 向 量 .直 观 上 看 ，对样本 X j , 若 最 近 的 原 型 向 量 与 叼 的 类 别 标 记 相 同 ，则 令 R * 向 X j 的方向靠拢, 如 第 7 行 所 示 ，此 时 新 原 型 向 量 为 ， pf =Pi^ +r)-(叼 - m * ) , (9.25) \" 与 叼 之 间 的 距 离 为 II\" 一 叼 |[2 = ||a * +〃 •(叼 一 g * ) 一 叼 |12",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 478
    }
  },
  {
    "page_content": "X j , 若 最 近 的 原 型 向 量 与 叼 的 类 别 标 记 相 同 ，则 令 R * 向 X j 的方向靠拢, 如 第 7 行 所 示 ，此 时 新 原 型 向 量 为 ， pf =Pi^ +r)-(叼 - m * ) , (9.25) \" 与 叼 之 间 的 距 离 为 II\" 一 叼 |[2 = ||a * +〃 •(叼 一 g * ) 一 叼 |12 = ( 1 一m T i a * - 叼 112 . (9.26) 令 学 习 率 n e （0 ,1 ）, 则 原 型 向 量 R * 在 更 新 为 之 后 将 更 接 近 Xj. 类 似 的 ，若 Pi*与 叼 的 类 别 标 记 不 同 ，则 更 新 后 的 原 型 向 量 与 Xj之间的 距 离 将 增 大 为 （1 + 小 • |成* - 叼 ||2 , 从而更远离叼. 在 学 得 一 组 原 型 向 量 ｛m ,P 2 ,• • .,% ｝后 ，即 可 实 现 对 样 本 空 间 % 的簇划 206 第 9 章 聚 类 若 将 无 中 样 本 全 用 原 型 向 量 Pi 表 示 ，则 可 实 现 数 据 的 “有 损 压 缩 ” (lossy c o m pressio n),这称 为 “向 量 量 化 ” (vector quantization); LVQ 由立匕而 得名. 分.对任意样本叫它将被划入与其距离最近的原型向量所代表的簇中；换言 之，每个原型向量P i 定义了与之相关的一个区域Ri,该区域中每个样本与Pi 的距离不大于它与其他原型向量P i Y 丰2) 的距离，即 Ri = {x e M \\ \\\\x - pi\\\\2 \\\\x - P0II2, £'丰〉. (9.27) 由 此 形 成 了 对 样 本 空 间 X 的 簇 划 分 {晶 ，必 ，… ，五 该 划 分 通 常 称 为 “Voronoi剖分” (Voronoi tessellation). 下面我们以表9 .1 的西瓜数据集4 .0 为例来演示LVQ的学习过程.令9-21 号样本的类别标记为。2 , 其他样本的类别标记为c i . 假 定 q = 5 , 即学习目 标 是 找 到 5 个原型向量pi, P2, P3, P4, P 5 , 并假定其对应的类别标记分别为 即 希 望 为 “好 瓜 二 是 ” 找 到 3 个簇， “好 瓜 =否 ” 找 到 2 个簇. C1, 算法开始时，根据样本的类别标记和簇的预设类别标记对原型向量进行随 机初始化，假 定 初 始 化 为 样 本 叫 2 , 比1 8 ,出2 3 ,况2 9 . 在第一轮迭代中，假定随",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 479
    }
  },
  {
    "page_content": "即 希 望 为 “好 瓜 二 是 ” 找 到 3 个簇， “好 瓜 =否 ” 找 到 2 个簇. C1, 算法开始时，根据样本的类别标记和簇的预设类别标记对原型向量进行随 机初始化，假 定 初 始 化 为 样 本 叫 2 , 比1 8 ,出2 3 ,况2 9 . 在第一轮迭代中，假定随 机选取的样本为叫，该样本与当前原型向量Pl, P2, P3, P4, P 5 的距离分别为 0.283, 0.506, 0.434, 0.260, 0 .0 3 2 .由于现与叫距离最近且两者具有相同的类 别标记C2,假定学习率刀= 0 .1 ,则 LVQ更新P 5 得到新原型向量 \" = P 5 + 小 ( 叫 一 P5) = (0.725; 0.445) + 0.1- ((0.697; 0.460) — (0.725; 0.445)) = (0.722; 0.442). 将 P 5 更新为“ 后，不断重复上述过程,不同轮数之后的聚类结果如图9.5所示. 9 .4 .3 高斯混合聚类 与 k 均值、LVQ用原型向量来刻画聚类结构不同，高斯混合(Mixture-of- Gaussian)聚类采用概率模型来表达聚类原型. 我们先简单回顾一下(多元)高斯分布的定义.对几维样本空间％ 中的随机 记为 x ~ N * , S ) . 向 量 町 若 。服从高斯分布，其概率密度函数为， 与：对 称 正定矩阵； |S |: W 的行列式； S - 1 : S 的逆矩阵. 以 ⑼ = —— J_ _ r e T ( * 从尸与一1(«一 ⑷ , (9.28) (2TT)2|S|2 其 中 4 是八维均值向量，E 是n x n 的协方差矩阵.由式(9.28)可看出，高斯分 布完全由均值向量M和协方差矩阵2 这两个参数确定.为了明确显示高斯分 9 . 4 原型聚类 207 图 9 . 5 西瓜数据集4 .0 上 L V Q 算法(q = 5)在不同轮数迭代后的聚类结果.。1 , 。2 类样 本 点 与 原 型 向 量 分 别 用 与 表 示 ，红色虚线显示出聚类形成的V oronoi剖分. 布与相应参数的依赖关系，将 概 率 密 度 函 数 记 为 I \" £ ) • 我们可定义高斯混合分布 也 是 概 率 密 度 函 数 ，J PA4(cc)djc = 1. k PA4（⑼ = 〉］& • 0 （% | 也,£〃）， （9.29） 2=1 该 分 布 共 由k 个混合成分组成，每个混合成分对应一个高斯分布.其中也与 凡 是 第 i个高斯混合成分的参数，而 8 > 0 为 相 应 的 “混合系数\" (mixture coefficient), 必 = 1.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 480
    }
  },
  {
    "page_content": "数 ，J PA4(cc)djc = 1. k PA4（⑼ = 〉］& • 0 （% | 也,£〃）， （9.29） 2=1 该 分 布 共 由k 个混合成分组成，每个混合成分对应一个高斯分布.其中也与 凡 是 第 i个高斯混合成分的参数，而 8 > 0 为 相 应 的 “混合系数\" (mixture coefficient), 必 = 1. 假设样本的生成过程由高斯混合分布给出：首先，根 据 。1,。2 , - . ，他 定 义 的先验分布选择高斯混合成分，其 中 作 为 选 择 第 2 个混合成分的概率;然后，根 据被选择的混合成分的概率密度函数进行采样，从而生成相应的样本. 208 第 9 章 聚 类 若 训 练 集 。 = ｛叫 ，宓2,..「亚n｝由上述过程生成，令 随 机 变 量 ^ ｛1， 2, . . . , k ｝表示生成样本 X j 的高斯混合成分，其取值未知.显然，Zj的先验概率 P(zj = i)对 应 于Ui (i = 1,2,..., A;).根据贝叶斯定理，书的后验分布对应于 = 广〃 •双 吃 I也，邑 ) . E a •汉 叼 I应，以) 1=1 (9.30) 换言之,P M ⑶ = i I叼 )给 出 了 样 本 叫 由 第 5 个高斯混合成分生成的后验概 率.为方便叙述,将其简记为8 £ (〃 = L 2,..., k). 当高斯混合分布(9.29)已知时，高斯混合聚类将把样本集D 划 分 为 k 个簇 C = ｛g , 。2,… ，以 ｝,每 个 样 本 叼 的 簇 标 记 ％ 如下确定： Xj = arg m a x 7方 . (9.31) 因此,从原型聚类的角度来看，高斯混合聚类是采用概率模型(高斯分布)对原型 进行刻画，簇划分则由原型对应后验概率确定. 节极大似然估计参见7 . 2 给定样本集0 , 可采用极大似然估计，即最大化(对数)似然 那么，对于式⑼29),模 型 参 数 ｛( q , % , 西 门 W E W 卜｝如何求解呢？显然, LL(D) = In m n P M (叼) J=I m = 5 > £ / k j=l \\i=l a 厂 0(叼 | 也,力£)[ 5 (9.32) E M 算法参见7.6节. 常 采 用 E M 算法进行迭代优化求解.下面我们做一个简单的推导. 若 参 数 ｛( q , 也,2 加 1 W 。W 附 能 使 式 (9.32)最大化，则由 端 罗 = 0 有 £ 丁 .汉 叼 3 , 西 (叼 一 饵 ) = 0 , ' (9.33) j = 1 E a i - P(X J \\ 内Z i) 1=1",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 481
    }
  },
  {
    "page_content": "E M 算法参见7.6节. 常 采 用 E M 算法进行迭代优化求解.下面我们做一个简单的推导. 若 参 数 ｛( q , 也,2 加 1 W 。W 附 能 使 式 (9.32)最大化，则由 端 罗 = 0 有 £ 丁 .汉 叼 3 , 西 (叼 一 饵 ) = 0 , ' (9.33) j = 1 E a i - P(X J \\ 内Z i) 1=1 由式(9.30)以 及 %》= P M ( % = ” 叼)，有 9 . 4 原型聚类 209 (9.34) 乙 % ? 叼 7=1 m Mi = J=1 即各混合成分的均值可通过样本加权平均来估计，样本权重是每个样本属于该 成分的后验概率.类似的，由 嘤 9 = 0 可得 771 £ 力 £(叼 一 %)(叼 一 % ) T — --------- 记-------------------- (9-35) E i j i j= i 对 于 混 合 系 数 除 了 要 最 大 化 LL(D),还 需 满 足 & 2 0 , E t i & = 上考虑 LL(D)的拉格朗日形式 £ £ ( 。) + 入 区 8 - 1 J , \\i= l 其中入为拉格朗日乘子.由式(9.36)对 色 的 导 数 为 0 , 有 £ 卜 0(叼 j = 1 £ on - p ( X j | 凶,2 ) 1=1 — + 入= o , 两边同乘以四,对所有样本求和可知A = - m , 有 ] m & = — , 吗 =i (9.36) (9.37) (9.38) 即每个高斯成分的混合系数由样本属于该成分的平均后验概率确定. 由上述推导即可获得高斯混合模型的E M 算法：在每步迭代中，先根据 当 前 参 数 来 计 算 每 个 样 本 属 于 每 个 高 斯 成 分 的 后 验 概 率 存 但 步 )，再根据 式(9.34)、(9.35)和(9.38)更新模型参数｛四 仙 ,2 ) | 1 J W 舟 (M步). 高斯混合聚类算法描述如图9 .6 所 示 .算 法 第 1 行对高斯混合分布的模型 参数进行初始化.然后，在 第 2 -1 2 行 基 于 E M 算法对模型参数进行迭代更新. 若 E M 算法的停止条件满足(例如已达到最大迭代轮数，或似然函数LL(D)增 210 第 9 章 聚 类 E M 算法 的 E步. E M 算 法的M 步. 例如达到最大迭代轮数. 输入：样本集 D = ｛®l,a?2, . . . , 高斯混合成分个数k.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 482
    }
  },
  {
    "page_content": "210 第 9 章 聚 类 E M 算法 的 E步. E M 算 法的M 步. 例如达到最大迭代轮数. 输入：样本集 D = ｛®l,a?2, . . . , 高斯混合成分个数k. 过程： 1：初始化高斯混合分布的模型参数｛( 色 仙 , 西 I 1 w c W 册 2: repeat 3： 4： 根据式(9.30)计算叼由各混合成分生成的后验概率，即 for J = 1,2,..., m d o 力£ = e n d for for i = 1,2,... ,k d o 1 1 (1 W 〃 W k) 计算新均值向量 必 = 袋 号 叼 ； 5： 6： 7： 8: 计算新协方差矩阵：* = £储力个二?叼也产; 9: 计算新混合系数：M = 再 产 ； e n d for 10： 11： 将模型参数｛(&, M 2 ) 门 W £ W 符 更 新 为 ｛( % 同 * ) 门 4 £ W 阶 12: until满足停止家件 13： Ci = 0 Q 4 i& k) 14： for J = 1,2,... , m d o 15： 根据式(9.31)确 定 X j 的簇标记”; 16： 将叼划入相应的簇：C Xj = C Xj U ｛叼 ｝ 17： e n d for 输出：簇划分C = ｛C L, G , … ，以 ｝___________________________________ 图 9 . 6 高斯混合聚类算法 长很少甚至不再增长)，则 在 第 1 4 - 1 7 行 根 据 高 斯 混 合 分 布 确 定 簇 划 分 ,在 第 18 行返回最终结果. 以 表 9 . 1 的 西 瓜 数 据 集 4 . 0 为 例 ，令 高 斯 混 合 成 分 的 个 数 k = 3 . 算法开始 时，假 定 将 高 斯 混 合 分 布 的 模 型 参 数 初 始 化 为 ： = 迤 = & 3 = M 2 = 宓22, M 3 = 弟27； £ 1 = 2 2 = 2 3 = ( ' j ' ：) . M l = 宓6, 在 第 一 轮 迭 代 中 ，先 计 算 样 本 由 各 混 合 成 分 生 成 的 后 验 概 率 .以 叫 为 例 , 由式(9.30)算 出 后 验 概 率 711 = 0.219, 712 = 0.404, 7 13 = 0 . 3 7 7 . 所有样本的后 验概率算完后，得 到 如 下新的模型参数： % — 0 . 3 6 1 , 跖 = 0.323, M = 0.316",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 483
    }
  },
  {
    "page_content": "由式(9.30)算 出 后 验 概 率 711 = 0.219, 712 = 0.404, 7 13 = 0 . 3 7 7 . 所有样本的后 验概率算完后，得 到 如 下新的模型参数： % — 0 . 3 6 1 , 跖 = 0.323, M = 0.316 M i = (0.491; 0 . 2 5 1 ) ,必 = (0.571; 0 . 2 8 1 ) ,闻 = (0.534; 0.295) , _ (0.025 0.004、 , _ /0.023 0.004、 1 一10.004 0.016) ' 2 — \\0.004 0.017/ ' , _ (0.024 0.005、 3 — 10.005 0.016^ 模 型参数更新后，不 断 重 复 上 述 过 程 ,不 同 轮 数 之 后 的 聚 类 结 果 如 图 9 . 7 所示. 9 . 5 密度聚类 211 密度 (a) 5 轮迭代后 密度 (b) 10轮迭代后 黎 (c) 2 0 轮迭代后 (d) 5 0 轮迭代后 图 9 . 7 高斯混合聚类(k = 3)在不同轮数迭代后的聚类结果.其中样本簇Ci, G 与 。3 中 的 样 本 点 分 别 用 与 “▲”表示，各高斯混合成分的均值向量用“十”表示. 9 . 5 密度聚类 密 度 聚 类 亦 称 “基 于 密 度 的 聚 类 \"(density-based clustering),此类算法假 设聚类结构能通过样本分布的紧密程度确定.通常情形下，密度聚类算法从样 本密度的角度来考察样本之间的可连接性，并基于可连接样本不断扩展聚类簇 以获得最终的聚类结果. 全 称 “ Density-Based S- patial Clustering of Appli­ cations with Noise” . DBSCAN是 一 种 著 名 的 密 度 聚 类 算 法 ，它 基 于 一 组 “邻 域 ” (neigh­ borhood) 参 数 值MinPts)来 刻 画 样 本 分 布 的 紧 密 程 度 . 给 定 数 据 集 D = { % 况2 ,… ，® m ),定义下面这几个概念： 在本章后续内容中，距 离 函 数 dist(一 )在默认情 形下设为欧氏距离. • ♦ 邻域：对 叼 e 其 「邻域包含样本集0 中 与 叼 的 距 离 不 大 于 €的样 本，即 Ne(Xj) = {xiE D \\ dist(£Ci,xj) & e}; 212 第 9 章 聚 类 • 核 心 对 象 (core o b je c t) :若 Xj 的 &■邻域至少包含MinPts个 样 本 ，即",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 484
    }
  },
  {
    "page_content": "• ♦ 邻域：对 叼 e 其 「邻域包含样本集0 中 与 叼 的 距 离 不 大 于 €的样 本，即 Ne(Xj) = {xiE D \\ dist(£Ci,xj) & e}; 212 第 9 章 聚 类 • 核 心 对 象 (core o b je c t) :若 Xj 的 &■邻域至少包含MinPts个 样 本 ，即 |或(叼)|) MinPts,则 Xj是一个核心对象； 密度直达关系通常不满 • 密度直达(directly density-reachable): 若 Xj位 于 Xi的 £-邻域中，且 & 是 足对称性. 核心对象，则 称 Xj 由 Xi密度直达； 密 度 可 达 关 系 满 足 直 递 性 ，但不满足对称性. • 密度可达(density-reachable):对 g 与 叼 ，若存在样本序列pi,p2, • • . ,Pn, 其 中 Pl = Xi, pn = Xj且 Pi+ 1 由Pi密度直达，则 称 Xj 由 Xi密度可达； 密 度 相 连 关 系 满 足 对 称 • 密度相连(density-connected):对 g 与 叼 ，若 存 在xk 使 得 g 与 叼 均 由 性. xk 密度可达，则 称 g 与 xj密度相连. 图 9.8 给出了上述概念的直观显示. 图 9.8 DBSCAN定义的基本概念(加加尸加= 3 ) : 虚 线 显 示 出 e 邻域，叫 是 核 心 对 象，X2 由 XI 密度直达，a?3由 叫 密 度 可 达 ，2 3 与 « 4 密度相连. 基于这些概念,DBSCAN将 “簇 ”定义为:由密度可达关系导出的最大的 太2 7 梵可曾簇飞普 密度相连样本集合.形式化地说,给定邻域参数值MinPts),镀 C J D 是满足 本 被 认 为 ；＜等 尸(noise)或 异 常 (anomaly)样本. 以下性质的非空样本子集： 连接性(connectivity): g € 叼 G C 今 © 与 Xj密度相连 (9.39) 最大性(m axim ality):g G C, Xj 由 X1密度可达 今 Xj £ C (9.40) 那 么 ，如 何 从 数 据 集 。 中 找 出 满 足 以 上 性 质 的 聚 类 簇 呢 ？实 际 上 ，若比 为 核 心 对 象 ，由 x 密 度 可 达 的 所 有 样 本 组 成 的 集 合 记 为 X = {〃 G 。 | 苏 由 \"密 度 可 达 }，则不难证明X 即为满足连接性与最大性的簇. 于是，DBSCAN算 法 先 任 选 数 据 集 中 的 一 个 核 心 对 象 为 “种 子 ” (seed),",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 485
    }
  },
  {
    "page_content": "为 核 心 对 象 ，由 x 密 度 可 达 的 所 有 样 本 组 成 的 集 合 记 为 X = {〃 G 。 | 苏 由 \"密 度 可 达 }，则不难证明X 即为满足连接性与最大性的簇. 于是，DBSCAN算 法 先 任 选 数 据 集 中 的 一 个 核 心 对 象 为 “种 子 ” (seed), 再由此出发确定相应的聚类簇，算 法 描 述 如 图9 .9 所 示 . 在 第 1 ~ 7 行中，算法 先根据给定的邻域参数(g MinPts)找出所有核心对象；然 后 在 第 10~24行中, 以任一核心对象为出发点，找出由其密度可达的样本生成聚类簇，直到所有核 心对象均被访问过为止. 9 . 5 密度聚类 213 输入：样本集。 = ｛叫,⑦2,… ，g n ｝； 邻域参数(a MinPts). e n d if 将样本 X j 加入核心对象集合:Q = Q U ｛叼 ｝ 过程： 1：初始化核心对象集合:。= 0 2 ： fo r j = 1,2,... ,m do 3 : 确定样本Xj的 e-邻域砥(叼)； if \\Ne｛Xj)\\? MinPts th e n 4 ： 5： 6： 7: e n d fo r 8 : 初始化聚类簇数：k = 0 9 ：初始化未访问样本集合：r = 。 10： w h i l e 。壬 0 d o li： 记录当前未访问样本集合：r o l d = r ； 12： 随机选取一个核心对象。e a , 初始化队列Q = ＜ 。〉； 13： 14： w h ile Q 壬 0 d o 15： 取出队列Q 中的首个样本q; 16: 17： 令 △ = N e ( q ) p | r ； 18: 将△中的样本加入队列Q; (q) |) MinPts t h e n r = r \\ ｛。｝； if 19： r = r \\ △； e n d if e n d w h ile 20： 21： 22： k = k + i,生成聚类簇 Ck = r o l d \\ r ； 23: 24： e n d w h ile 输出：簇划分C = ｛G , G , … ，以 ｝ Q = Q \\ Ck 图 9 .9 D B S C A N 算法 以 表 9 .1 的 西 瓜 数 据 集 4 .0 为 例 ，假 定 邻 域 参 数 值 MinPts)设 置 为 e = 0.11, MinPts = 5. DBSCAN算 法 先 找 出 各 样 本 的 &邻 域 并 确 定 核 心 对 象 集",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 486
    }
  },
  {
    "page_content": "Q = Q \\ Ck 图 9 .9 D B S C A N 算法 以 表 9 .1 的 西 瓜 数 据 集 4 .0 为 例 ，假 定 邻 域 参 数 值 MinPts)设 置 为 e = 0.11, MinPts = 5. DBSCAN算 法 先 找 出 各 样 本 的 &邻 域 并 确 定 核 心 对 象 集 合 ：a = ｛® 3 , 比5,北6,宏8,宏9,g 3, ® 1 4 , 叫 8,叫 9 , 宓24,况25,比28,比29卜 然 后 ,从 。 中 随 机 选 取 一 个 核 心 对 象 作 为 种 子 ，找 出 由 它 密 度 可 达 的 所 有 样 本 ，这就构成了 第 一 个 聚 类 簇 .不 失 一 般 性 ，假 定 核 心 对 象 磔 被 选 中 作 为 种 子 ，则 DBSCAN 生成的第一个聚类簇为 GL = ｛宓6,比7,况8,叫 0,比12,叫 8,叫 9,政 0,比2 3 ) • 然 后 ，DBSCAN将 C 1 中 包 含 的 核 心 对 象 从 Q 中 去 除 ：Q = Q \\ C1 - ｛况3 , a 5 , 宏9 , g 3,叫 4,比24,a25,比28,比29卜 再 从 更 新 后 的 集 合 口 中 随 机 选 取 一 个 核 心 对 象 作 为 种 子 来 生 成 下 一 个 聚 类 簇 .上 述 过 程 不 断 重 复 ，直 至 C 为空.图 9.10显 示 出 DBSCAN先 后 生 成 聚 类 簇 的 情 况 .C i 之后生成的聚类簇为 214 第 9 章 聚 类 图 9.10 DBSCAN算法(e = 0 . n , \" 桁 丹 s = 5)生成聚类簇的先后情况.核心对象、 非核心对象、噪 声 样 本 分 别 用 表 示 ，红色虚线显示出簇划分. 。2 = ｛力3 ）宓4 ）冗5 , 上1 3 ,力 14）力 1 6 ,% 17）①21｝ ； 0 3 = ｛叫 , 力 2 , 名2 2 ,% 2 6 ,力29｝ ； 。4 = ｛力2 4 , 力2 5 , % 2 7 ,% 2 8 ,力3。｝ . 9 . 6 层次聚类 层次聚类(hieiarchical clustering)试图在不同层次对数据集进行划分，从而 形成树形的聚类结构.数据集的划分可采用“自底向上”的聚合策略，也可采 用 “自顶向下”的分拆策略. AGNES 是 AGglomera- tive NESting 的简写. AGNES是一种采用自底向上聚合策略的层次聚类算法.它先将数据集中 的每个样本看作一个初始聚类簇，然后在算法运行的每一步中找出距离最近的 9 . 6 层次聚类 215",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 487
    }
  },
  {
    "page_content": "形成树形的聚类结构.数据集的划分可采用“自底向上”的聚合策略，也可采 用 “自顶向下”的分拆策略. AGNES 是 AGglomera- tive NESting 的简写. AGNES是一种采用自底向上聚合策略的层次聚类算法.它先将数据集中 的每个样本看作一个初始聚类簇，然后在算法运行的每一步中找出距离最近的 9 . 6 层次聚类 215 集 合 间 的 距 离 计 算 常 采用豪斯多夫距离(Haus­ dorff distance),参见习题 9.2. 通常使用 dm in, dm ax 或 davg. 初始化单样本聚类簇； 初始化聚类簇距离矩阵. 2* < J * . 两个聚类簇进行合并，该 过 程 不 断 重 复 ,直 至 达到预设的聚类簇个数.这里的关 键 是 如 何 计 算 聚 类 簇 之 间 的 距 离 .实 际 上 ，每 个 簇 是 一 个 样 本 集 合 ，因此，只需 采 用 关 于 集 合 的 某 种 距 离 即 可 .例 如 ，给 定 聚 类 簇 G 与 5 ) 可通过下面的式子 来计算距离： 最小距离：d m i n ( G ，a ) = m i n xeCi,zeCj dist(cc,^) , 最大距离：d m a x ( G ，a ) = m a x dist(cc, z) , xECi,zECj 平均距禺：d a v g ( a ，a ) = । 洲 | V £ xeCizeCj dist(a?,z) . (9.41) (9.42) (9.43) 显 然 ，最 小 距 离 由 两 个 簇 的 最 近 样 本 决 定 ，最大距离由两个簇的最远样本决定, 而 平 均 距 离 则 由 两 个 簇 的 所 有 样 本 共 同 决 定 .当 聚 类 簇 距 离 由 dmin、d m a x 或 输入：样本集 D = {x1,x2 ,..., x m }; 聚类簇距离度量函数d; 聚类簇数k. e n d for Cj = {xj} for j = 1,2,..., m d o = =",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 488
    }
  },
  {
    "page_content": "而 平 均 距 离 则 由 两 个 簇 的 所 有 样 本 共 同 决 定 .当 聚 类 簇 距 离 由 dmin、d m a x 或 输入：样本集 D = {x1,x2 ,..., x m }; 聚类簇距离度量函数d; 聚类簇数k. e n d for Cj = {xj} for j = 1,2,..., m d o = = 过程： 1： for 7 = 1,2,..., m d o 2： 3: e n d for 4： for z = 1,2,..., m d o 5: 6： 7： 8： 9: e n d for 1 0 : 设置当前聚类簇个数：q = m 11： while q > k do 12: 找出距离最近的两个聚类簇g * 和 5 * ； 13： 合并 & * 和 a * ： Ci* = Ci* u 5 * ； 14： is： 将聚类簇5 重编号为a - 16： 17： 删除距离矩阵M 的第歹行与第歹列； 18： 19： 20： 21： 22: 23： e n d while 输出：簇划分c = { a 。 ,… 。 }____________ for j = 1,2,..., — 1 d o = = e n d for q = q — 1 for j = J* + + 2,..., Q d o e n d for 图 9.11 A G N E S 算法 216 第9 章 聚 类 davg计算时，A G N E S 算 法 被 相 应 地 称 为 “单 链 接 ”(single-linkage)、 “全链 接 “(com plete-linkage)或 “均链接 ”(average-linkage)算法. A G N E S 算 法描述如图9 .11所 示 .在 第 1 - 9 行，算法先对仅含一个样本的 初始聚类簇和相应的距离矩阵进行初始化;然后在第1 1 -2 3 行，A G N ES不断合 并距离最近的聚类簇，并对合并得到的聚类簇的距离矩阵进行更新；上述过程 不断重复,直至达到预设的聚类簇数. 西瓜数据集4.。见p.2O2 表9 1 」 以西瓜数据集4 .0 为例，令 A G N E S算法一直执行到所有样本出现在同一 个簇中，即 k = 1 , 则可得到图9.12所 示 的 “树状图” (dendrogram ),其中每层 链接一组聚类簇. 0.7 ▲ [ A M h 门",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 489
    }
  },
  {
    "page_content": "不断重复,直至达到预设的聚类簇数. 西瓜数据集4.。见p.2O2 表9 1 」 以西瓜数据集4 .0 为例，令 A G N E S算法一直执行到所有样本出现在同一 个簇中，即 k = 1 , 则可得到图9.12所 示 的 “树状图” (dendrogram ),其中每层 链接一组聚类簇. 0.7 ▲ [ A M h 门 1 29 26 2 22 21 3 4 23 25 28 24 30 27 5 7 9 17 13 14 16 6 8 18 19 10 20 15 11 12 样本编号 图 9 . 1 2 西 瓜 数 据 集4.0上 AGNES算法生成的树状图(采用dm a x) . 横轴对应于样本 编号，纵轴对应于聚类簇距离. 在树状图的特定层次上进行分割，则可得到相应的簇划分结果.例如，以图 9 .1 2 中所示虚线分割树状图，将得到包含7 个聚类簇的结果： C1 = ｛叫 ，数6 ,数9卜 02 = ｛®2,比3, ®4, 6 1 0 2 2 ｝； 。3 = ｛%23,政4 ,况25,①27,宓28,比3。｝； 04 = ｛a 5,宓7卜 。5 = ｛比9 ,冗13,宏 14,比 16,北17｝；。6 = ｛比6 ,宓8,宏 10,a 15,a 18,比 19,况2。｝； 。7 = ｛宏11,宓12｝・ 9 . 7 阅读材料 217 将分割层逐步提升，则可得到聚类簇逐渐减少的聚类结果.例如图9 .1 3 显 示出了从图9 .1 2 中产生7 至 4 个聚类簇的划分结果. 图 9 . 1 3 西瓜数据集4 .0 上 AGN ES算法（采 用 dmax）在不同聚类簇数依= 7, 6, 5, 4）时 的簇划分结果.样本点用“•”表示，红色虚线显示出簇划分. 9.7 阅读材料 例 如 同 一 堆 水 果 ，既能 按 大 小 ，也 能 按 颜 色 ，甚至 能按产地聚类. 聚类也许是机器学习中“新算法”出现最多、最快的领域.一个重要原因 是聚类不存在客观标准；给定数据集，总能从某个角度找到以往算法未覆盖的 某种标准从而设计出新算法［Estivill-Castro, 2002］. 相对于机器学习其他分支 来说，聚类的知识还不够系统化，因此著名教科书［Mitchell, 1997］中甚至没有 关于聚类的章节.但聚类技术本身在现实任务中非常重要，因此本章勉强采用 了 “列举式”的叙述方式，相较于其他各章给出了更多的算法描述.关于聚类 218 第 9 章 聚 类",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 490
    }
  },
  {
    "page_content": "某种标准从而设计出新算法［Estivill-Castro, 2002］. 相对于机器学习其他分支 来说，聚类的知识还不够系统化，因此著名教科书［Mitchell, 1997］中甚至没有 关于聚类的章节.但聚类技术本身在现实任务中非常重要，因此本章勉强采用 了 “列举式”的叙述方式，相较于其他各章给出了更多的算法描述.关于聚类 218 第 9 章 聚 类 更多的内容，可参阅这方面的专门书籍和综述文章如[Jain and Dubes, 1988; Jain et al., 1999; Xu and Wunsch II, 2005; Jain, 2009]等. 聚 类 性 能 度 量 除 9 .2 节的内容外，常 见 的 还 有 F 值 、互 信 息 (mutual information) > 平 均 廓 宽 (average silhouette width) [Rousseeuw, 1987]等，可 参 阅 [Jain and Dubes, 1988; Halkidi et al., 2001; Maulik and Bandyopadhyay, 2002]. 距离计算是很多学习任务的核心技术.闵可夫斯基距离提供了距离计算的 一般形式.除闵可夫斯基距离之外，内积距离、余弦距离等也很常用，可参阅 [Deza and Deza, 2009]. MinkovDM 在 [Zhou and Yu, 2005]中正式给出.模式 识别、图像检索等涉及复杂语义的应用中常会涉及非度量距离[Jacobs et a l, 2000; Tan et al., 2009].距离度量学习可直接嵌入到聚类学习过程中[Xing et 距离度量学习参见 10.6 节. al., 2003]. 凸 形 簇 结 构 即 形 似 “椭 球”的簇结构. B r e g m a n 距 离 亦 称 Bregman divergence,是一 类不满足对称性和直递性 的距离. 降维参见第1 0 章. k 均值算法可看作高斯混合聚类在混合成分方差相等、且每个样本仅指 派给一个混合成分时的特例.该算法在历史上曾被不同领域的学者多次重",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 491
    }
  },
  {
    "page_content": "节. al., 2003]. 凸 形 簇 结 构 即 形 似 “椭 球”的簇结构. B r e g m a n 距 离 亦 称 Bregman divergence,是一 类不满足对称性和直递性 的距离. 降维参见第1 0 章. k 均值算法可看作高斯混合聚类在混合成分方差相等、且每个样本仅指 派给一个混合成分时的特例.该算法在历史上曾被不同领域的学者多次重 新发明,如 Steinhaus 在 1956 年、Lloyd 在 1957 年 、McQueen 在 1967 年等 [Jain and Dubes, 1988; Jain, 2009]. k 均值算法有大量变体，如 fc-medoids 算 法 [Kaufman and Rousseeuw, 1987]强制原型向量必为训练样本，k-modes算 法 [Huang, 1998]可处理离散属性，Fuzzy C-means (简称 FCM) [Bezdek, 1981] 则 是 “软 聚 类 \"(soft clustering)算法，允许每个样本以不同程度同时属于多个 原型.需注意的是，k 均值类算法仅在凸形簇结构上效果较好.最近研究表明, 若采用某种Bregman距离，则可显著增强此类算法对更多类型簇结构的适用性 [Banerjee et al., 2 0 0 5 ].引入核技巧则可得到核k 均 值 (kernel k-means)算法 [Scholkopf et al., 1998],这与谱聚类(spectral clustering) [von Luxburg, 2007] 有密切联系[Dhillon et al., 2004],后者可看作在拉普拉斯特征映射(Laplacian Eigenm ap)降维后执行k 均值聚类.聚类簇数k 通常需由用户提供，有一些启 发式用于自动确定 k [Pelleg and Moore, 2000; Tibshirani et al., 2001],但常用 的仍是基于不同k 值多次运行后选取最佳结果. LVQ算法在每轮迭代中仅更新与当前样本距离最近的原型向量.同时 更新多个原型向量能显著提高收敛速度，相应的改进算法有LVQ2、LVQ3等 [Kohonen, 2001]. [McLachlan and Peel, 2000]详细介绍了高斯混合聚类，算法 中 E M 迭代优化的推导过程可参阅[Bilmes, 1998; Jain and Dubes, 1988]. 采用不同方式表征样本分布的紧密程度，可设计出不同的密度聚类算 法，除 DBSCAN [Ester et al., 1996]外，较常用的还有 OPTICS [Ankerst et al.,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 492
    }
  },
  {
    "page_content": "采用不同方式表征样本分布的紧密程度，可设计出不同的密度聚类算 法，除 DBSCAN [Ester et al., 1996]外，较常用的还有 OPTICS [Ankerst et al., 9 . 7 阅读材料 219 1999] > DENCLUE [Hinneburg and Keim, 1998]等 . AGNES [Kaufman and Rousseeuw, 1 9 9 0 ]采用了自底向上的聚合策略来产生层次聚类结构，与之相 反，DIANA [Kaufman and Rousseeuw, 1990]则是采用自顶向下的分拆策略. AGNES和 DIANA都不能对已合并或已分拆的聚类簇进行回溯调整，常用的 层次聚类算法如 BIRCH [Zhang et al., 1996]> ROCK [Guha et al., 1999]等对 此进行了改进. 聚类集成(clustering ensemble)通过对多个聚类学习器进行集成，能有效 降低聚类假设与真实聚类结构不符、聚类过程中的随机性等因素带来的不利 影响，可参阅[Zhou, 2012]第 7 章. 亦称 outlier detection. 异 常 检 测 (anomaly detection) [Hodge and Austin, 2004; Chandola et al., 2009]常借助聚类或距离计算进行，如将远离所有簇中心的样本作为 异常点，或将密度极低处的样本作为异常点.最近有研究提出基于“隔离 性”(isolation)可快速检测出异常点[Liu et al., 2012]. 220 第 9 章 聚 类 习题 9.1 试证明：0 》 1 时,闵可夫斯基距离满足距离度量的四条基本性质; 0 W P < 1 时，闵可夫斯基距离不满足直递性，但满足非负性、同一 性、对称性;p 趋向无穷大时，闵可夫斯基距离等于对应分量的最大绝 对距离，即 p雪 晨 ( £ \\xiu - j = max \\xiu - Xju \\ . 9.2 同 一 样 本 空 间 中 的 集 合 X 与 Z 之 间 的 距 离 可 通 过 “豪斯多夫距 离 \" (Hausdorff distance)计算： distH (X, Z) = max (disth (X, Z ),disth (Z, X)) , (9.44) 其中 disth(X,Z) = m ^m in ||a? — z\\\\2 . (9.45) 试证明：豪斯多夫距离满足距离度量的四条基本性质. 9.3 试 析 k 均值算法能否找到最小化式(9.24)的最优解.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 493
    }
  },
  {
    "page_content": "distH (X, Z) = max (disth (X, Z ),disth (Z, X)) , (9.44) 其中 disth(X,Z) = m ^m in ||a? — z\\\\2 . (9.45) 试证明：豪斯多夫距离满足距离度量的四条基本性质. 9.3 试 析 k 均值算法能否找到最小化式(9.24)的最优解. 西 瓜 数 据 集 4 .0 见 p.202 表 9.1. 9.4 试编程实现k 均值算法，设置三组不同的k 值 、三组不同初始中心点, 在西瓜数据集4 .0 上进行实验比较，并讨论什么样的初始中心有利于 取得好结果. 9.5 基 于 DBSCAN的概念定义，若比为核心对象，由 z 密度可达的所有 样本构成的集合为X . 试证明：X 满足连接性(9.39)与最大性(9.40). 9.6 试 析 AGNES算法使用最小距离和最大距离的区别. 即凸形簇结构. 凸包不相交，则称为凸聚类.试析本章介绍的哪些聚类算法只能产生 9.7 聚类结果中若每个簇都有一个凸包(包含簇样本的凸多面体)，且这些 凸聚类，哪些能产生非凸聚类. 9.8 试设计一个聚类性能度量指标，并 与 9 .2 节中的指标比较. 9.9 * 试设计一个能用于混合属性的非度量距离. 9.10 * 试设计一个能自动确定聚类数的改进k 均值算法，编程实现并在西瓜 数 据 集4 .0 上运行. 参考文献 221 参考文献 Aloise, D., A. Deshpande, P. Hansen, and P. Popat. (2009). uNP-hardness of Euclidean sum-o^squares clustering.^^ Machine Learning:75(2):245-248. Anker st, M., M. Breunig, H.-P. Kriegel, and J. Sander. (1999). ^OPTICS: Or­ dering points to identify the clustering structure.\" In Proceedings of the ACM SIGMOD International Conference on Management of Data (SIG- MOD), 49-60, Philadelphia, PA. Banerjee, A., S. Merugu, I. Dhillon, and J. Ghosh. (2005). ^Clustering with",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 494
    }
  },
  {
    "page_content": "ACM SIGMOD International Conference on Management of Data (SIG- MOD), 49-60, Philadelphia, PA. Banerjee, A., S. Merugu, I. Dhillon, and J. Ghosh. (2005). ^Clustering with Bregman divergences.55 Journal of Machine Learning Research1 6:1705-1749. Bezdek, J. C. (1981). Pattern Recognition with Fuzzy Objective Function Algo­ rithms. Plenum Press, New York, NY. Bilmes, J. A. (1998). “A gentle tutorial of the EM algorithm and its appli­ cations to parameter estimation for Gaussian mixture and hidden Markov m odels.Technical Report TR-97-021, Department of Electrical Engineering and Computer Science, University of California at Berkeley, Berkeley, CA. Chandola, V., A. Banerjee, and V. Kumar. (2009). uAnomaly detection: A survey.” ACM Computing Surveys1 41 (3):Article 15. Deza, M. and E. Deza. (2009). Encyclopedia of Distances. Springer,. Berlin. Dhillon, I. S., Y. Guan, and B. Kulis. (2004). ^Kernel A;-means: Spectral clus­ tering and normalized cuts.\" In Proceedings of the 10th ACM SIGKDD In­ ternational Conference on Knowledge Discovery and Data Mining (KDD),",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 495
    }
  },
  {
    "page_content": "tering and normalized cuts.\" In Proceedings of the 10th ACM SIGKDD In­ ternational Conference on Knowledge Discovery and Data Mining (KDD), 551-556, Seattle, WA. Ester, M., H. P. Kriegel, J. Sander, and X. Xu. (1996). “A density-based algo­ rithm for discovering clusters in large spatial databases.\" In Proceedings of the 2nd International Conference on Knowledge Discovery and Data Mining (KDD), 226-231, Portland, OR. Estivill-Castro, V. (2002). “Why so many clustering algorithms - a position paper.” SIGKDD Explorations1(4):65-75. Guha, S., R. Rastogi, and K. Shim. (1999). “ROCK: A robust clustering al­ gorithm for categorical attributes.55 In Proceedings of the 15th International Conference on Data Engineering (ICDE)1 512-521, Sydney, Australia. Halkidi, M., Y. Batistakis, and M. Vazirgiannis. (2001). “On clustering valida- 222 第 9 章 聚 类 tion techniques.,5 Journal of Intelligent Information Systems, 27(2-3):107- 145. Hinneburg, A. and D. A. Keim. (1998). \"An efficient approach to clustering in",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 496
    }
  },
  {
    "page_content": "222 第 9 章 聚 类 tion techniques.,5 Journal of Intelligent Information Systems, 27(2-3):107- 145. Hinneburg, A. and D. A. Keim. (1998). \"An efficient approach to clustering in large multimedia databases with noise25 In Proceedings of the 4th Interna­ tional Conference on Knowledge Discovery and Data Mining (KDD), 58-65, New York, NY. Hodge, V. J. and J. Austin. (2004). “A survey of outlier detection methodolo­ gies27 Artificial Intelligence Review^ 22(2):85-126. Huang, Z. (1998). “Extensions to the k-means algorithm for clustering large data sets with categorical values.5, Data Mining and Knowledge Discovery^ 2(3):283-304. Jacobs, D. W., D. Weinshall, and Y. Gdalyahu. (2000). ^Classification with non-metric distances: Image retrieval and class representation.\" IEEE Transactions on Pattern Analysis and Machine Intelligence^ 6(22):583-600. Jain, A. K. (2009). “Data clustering: 50 years beyond k-means.\" Pattern Recog­ nition Letters, 31(8):651-666. Jain, A. K. and R. C. Dubes. (1988). Algorithms for Clustering Data. Prentice Hall, Upper Saddle River, NJ.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 497
    }
  },
  {
    "page_content": "nition Letters, 31(8):651-666. Jain, A. K. and R. C. Dubes. (1988). Algorithms for Clustering Data. Prentice Hall, Upper Saddle River, NJ. Jain, A. K., M. N. Murty, and P. J. Flynn. (1999). “Data clustering: A review25 ACM Computing Surveys1 3(31):264-323. Kaufman, L. and P. J. Rousseeuw. (1987). ^Clustering by means of medoids.^^ In Statistical Data Analysis Based on the L±-Norm and Related Methods (Y. Dodge, ed.), 405-416, Elsevier, Amsterdam, The Netherlands. Kaufman, L. and P. J. Rousseeuw. (1990). Finding Groups in Data: An Intro­ duction to Cluster Analysis. John Wiley & Sons, New York, NY. Kohonen, T. (2001). Self-Organizing Maps, 3rd edition. Springer, Berlin. Liu, F. T., K. M. Ting, and Z.-H. Zhou. (2012). “Isolation-based anomaly detec- tion.^^ ACM Transactions on Knowledge Discovery from Data, 6(1):Article 3. Maulik, U. and S. Bandyopadhyay. (2002). ^Performance evaluation of some clustering algorithms and validity indices.55 IEEE Transactions on Pattern Analysis and Machine Intelligence^ 24(12):1650-1654. 参考文献 223",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 498
    }
  },
  {
    "page_content": "clustering algorithms and validity indices.55 IEEE Transactions on Pattern Analysis and Machine Intelligence^ 24(12):1650-1654. 参考文献 223 McLachlan, G. and D. Peel. (2000). Finite Mixture Models. John Wiley & Sons, New York, NY. Mitchell, T. (1997). Machine Learning. McGraw Hill, New York, NY. Pelleg, D. and A. Moore. (2000). uX-means: Extending fc-means with efficient estimation of the number of c lu s te rs .In Proceedings of the 17th Interna­ tional Conference on Machine Learning (ICML), 727-734, Stanford, CA. Rousseeuw, P. J. (1987). ^Silhouettes: A graphical aid to the interpretation and validation of cluster analysis.55 Journal of Computational and Applied Mathematics1 20:53-65. Scholkopf, B., A. Smola, and K.-R. Muller. (1998). uNonliear component anal­ ysis as a kernel eigenvalue problem.5, Neural Computation^ 10(5):1299-1319. Stanfill, C. and D. Waltz. (1986). “Toward memory-based reasoning.^^ Commu­ nications of the ACM, 29(12):1213-1228. Tan, X., S. Chen, Z.-H. Zhou, and J. Liu. (2009). “Face recognition under oc­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 499
    }
  },
  {
    "page_content": "nications of the ACM, 29(12):1213-1228. Tan, X., S. Chen, Z.-H. Zhou, and J. Liu. (2009). “Face recognition under oc­ clusions and variant expressions with partial similarity? IEEE Transactions on Information Forensics and S e c u rity2(4):217-230. Tibshirani, R., G. Walther, and T. Hastie. (2001). “Estimating the number of clusters in a data set via the gap statistic.\" Journal of the Royal Statistical Society - Series B, 63(2):411-423. von Luxburg, U. (2007). “A tutorial on spectral clustering.^^ Statistics and Computing, 17(4):395-416. Xing, E. P., A. Y. Ng, M. I. Jordan, and S. Russell. (2003). ^Distance metric learning, with application to clustering with side-information.\" In Advances in Neural Information Processing Systems 15 (NIPS) (S. Becker, S. Thrun, and K. Obermayer, eds.), 505-512, MIT Press, Cambridge, MA. Xu, R. and D. Wunsch II. (2005). “Survey of clustering algorithms.55 IEEE Transactions on Neural Networks, 3(16):645-678. Zhang, T., R. Ramakrishnan, and M. Livny. (1996). “BIRCH: An efficient data",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 500
    }
  },
  {
    "page_content": "Transactions on Neural Networks, 3(16):645-678. Zhang, T., R. Ramakrishnan, and M. Livny. (1996). “BIRCH: An efficient data clustering method for very large databases.55 In Proceedings of the ACM SIG MOD International Conference on Management of Data (SIGMOD), 103-114, Montreal, Canada. Zhou, Z.-H. (2012). Ensemble Methods: Foundations and Algorithms. Chap- 224 第 9 章 聚 类 man & Hall/CRC, Boca Raton, FL. Zhou, Z.-H. and Y. Yu. (2005). “Ensembling local learners through multimodal perturbation.\" IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics, 35(4):725-735. 休息一会儿 小故事：曼哈顿距离与赫尔曼•闵可夫斯基 曼 哈 顿 距 离 (Manhattan distance)亦 称 “出 租 车 几 何 ”(Taxicab geom etry),是 德 国 大 数 学 家 赫 尔 曼 ・闵可 夫 斯 基 (Hermann Minkowski, 1864—1909)所创的词汇，其 得名是由于该距离标明了几何度量空间中两点在标准坐标 系上的绝对轴距总和，这恰是规划为方形区块的城市里两点 之间的最短行程，例如从曼哈顿的第五大道与3 3 街交点前往第三大道与2 3 街 交点，需 走 过 (5 - 3) + (33 - 23) = 1 2 个街区. 今 立 陶 宛 的 考 纳 斯 (K aunas). 哥 尼 斯 堡 是 著 名 的 “七 桥 问 题 ” 发 源 地 ，今俄罗 斯加里宁格勒. 闵可夫斯基出生于俄国亚力克索塔斯(Alexotas)的一个犹太人家庭，由于 当时俄国政府迫害犹太人，他八岁时随全家移居普鲁士哥尼斯堡，与后来成为 大数学家的希尔伯特一河之隔.闵可夫斯基从小就是著名神童，他熟读莎士比 亚、席勒和歌德的作品，几 乎能全文背诵《浮士德》；八岁进入预科学校,仅用",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 501
    }
  },
  {
    "page_content": "哥 尼 斯 堡 是 著 名 的 “七 桥 问 题 ” 发 源 地 ，今俄罗 斯加里宁格勒. 闵可夫斯基出生于俄国亚力克索塔斯(Alexotas)的一个犹太人家庭，由于 当时俄国政府迫害犹太人，他八岁时随全家移居普鲁士哥尼斯堡，与后来成为 大数学家的希尔伯特一河之隔.闵可夫斯基从小就是著名神童，他熟读莎士比 亚、席勒和歌德的作品，几 乎能全文背诵《浮士德》；八岁进入预科学校,仅用 四 维 时 空 亦 称 “闵可夫 斯 基 时 空 ”或 “闵可夫斯 基 空 间 ” . 五年半就完成了八年的学业；十七岁时建立了几元二次型的完整理论体系，解 决了法国科学院公开悬赏的数学难题. 1908年 9 月他在科隆的一次学术会议上 做 了 《空间与时间》的著名演讲，提出了四维时空理论，为广义相对论的建立 开辟了道路.不幸的是，三个月后他死于急性阑尾炎. 1896年闵可夫斯基在苏黎世大学任教期间，是爱因斯坦的数学老师.诺贝 尔物理学奖得主玻恩曾说，在闵可夫斯基的数学工作中找到了 “相对论的整个 武器库”.闵可夫斯基去世后，其生前好友希尔伯特整理了他的遗作，于 1911 年 出 版 了 《闵可夫斯基全集》.闵 可 夫 斯 基 的 哥 哥 奥 斯 卡 是 “胰岛素之父”， 侄子鲁道夫是美国著名天文学家. 第 1 0 章 降 维 与 度 量 学 习 1 0 .1 次近邻学习 k 近邻(^N earest Neighbor,简 称 kNN)学习是一种常用的监督学习方法, 其工作机制非常简单：给定测试样本，基于某种距离度量找出训练集中与其最 . 誓 “近朱者赤，近墨 靠 近 的 k 个训练样本，然后基于这k 个 “邻居”的信息来进行预测.通常，在分 类 任 务 中 可 使 用 “投票法”，即选择这k 个样本中出现最多的类别标记作为预 测结果；在 回 归 任 务 中 可 使 用 “平均法”，即 将 这 k 个样本的实值输出标记的 平均值作为预测结果；还可基于距离远近进行加权平均或加权投票，距离越近 的样本权重越大. 参见8.4节. 与前面介绍的学习方法相比，k 近邻学习有一个明显的不同之处：它似乎 没有显式的训练过程！事实上，它 是 “懒惰学习”(lazy learning)的著名代表, 此类学习技术在训练阶段仅仅是把样本保存起来，训练时间开销为零，待收到 测试样本后再进行处理；相应的，那些在训练阶段就对样本进行学习处理的方 法，称 为 “急切学习”(eager learning). 图 10.1给出了 k 近邻分类器的一个示意图.显然，k 是一个重要参数，当 k 取不同值时，分类结果会有显著不同.另一方面，若采用不同的距离计算方式, 则 找 出 的 “近邻”可能有显著差别，从而也会导致分类结果有显著不同.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 502
    }
  },
  {
    "page_content": "测试样本后再进行处理；相应的，那些在训练阶段就对样本进行学习处理的方 法，称 为 “急切学习”(eager learning). 图 10.1给出了 k 近邻分类器的一个示意图.显然，k 是一个重要参数，当 k 取不同值时，分类结果会有显著不同.另一方面，若采用不同的距离计算方式, 则 找 出 的 “近邻”可能有显著差别，从而也会导致分类结果有显著不同. 暂且假 设 距 离 计 算 是 “恰 当 ”的，即能够恰当地找出k 个近邻，我们来对 “最近邻分类器”(1N N ,即 k = l) 在二分类问题上的性能做一个简单的讨论. 图 10.1 k 近邻分类器示意图.虚线显示出等距线；测 试样本在k = 1 或 k = 5 时被判 别为正例，k = 3 时被判别为反例. 226 第 1 0 章 降维与度量学习 给定测试样本皿若其最近邻样本为苞则最近邻分类器出错的概率就是现 与 N 类别标记不同的概率，即 P(err) = 1 — I ⑼尸(c | z). (10.1) cey 假设样本独立同分布，且对任意比和任意小正数6,在 出 附 近 5 距离范围 内总能找到一个训练样本；换言之,对任意测试样本，总能在任意近的范围内找 到式(10.1)中的训练样本N . 令 c* = argmax c G 3；P( C | ⑼ 表示贝叶斯最优分类 器的结果,有 贝叶斯最优分类器参见 7.1 节. P(err) = 1 — £ P ( c | x)P{c \\ z) cey t l _ £ p 2 ( c ㈤ cey 1 - P 2 (c* I x) = (1 + P ( C * | M ) ( 1 —尸( c * | 0 ) 2 x (1 - P (c* I x)) . (10.2) 为便于初学者理解，本 节仅做了一个简化讨论, 更严 格 的 分 析 参 阅 [Cover and Hart, 1967]. 于是我们得到了有点令人惊讶的结论：最近邻分类器虽简单，但它的泛化错误 率不超过贝叶斯最优分类器的错误率的两倍！ 1 0 . 2 低 维 嵌 入 上一节的讨论是基于一个重要假设：任意测试样本究附近任意小的6 距 离范围内总能找到一个训练样本，即训练样本的采样密度足够大，或 称 为 “密 采 样 ”(dense sample).然而，这个假设在现实任务中通常很难满足，例如若 6 = 0.001,仅考虑单个属性，则 仅 需 1000个样本点平均分布在归一化后的属 性取值范围内，即可使得任意测试样本在其附近0.001距离范围内总能找到一 个训练样本，此时最近邻分类器的错误率不超过贝叶斯最优分类器的错误率",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 503
    }
  },
  {
    "page_content": "采 样 ”(dense sample).然而，这个假设在现实任务中通常很难满足，例如若 6 = 0.001,仅考虑单个属性，则 仅 需 1000个样本点平均分布在归一化后的属 性取值范围内，即可使得任意测试样本在其附近0.001距离范围内总能找到一 个训练样本，此时最近邻分类器的错误率不超过贝叶斯最优分类器的错误率 的 两 倍 .然 而 ，这 仅 是 属 性 维 数 为 1 的情形，若有更多的属性，则情况会发生 显 著 变 化 .例 如 假 定 属 性 维 数 为 20,若要求样本满足密采样条件，则至少需 (103产 = 1 0 60个样本.现实应用中属性维数经常成千上万，要满足密采样条件 所需的样本数目是无法达到的天文数字.此外，许多学习方法都涉及距离计算, 而高维空间会给距离计算带来很大的麻烦，例如当维数很高时甚至连计算内积 作为参照量：宇宙间基 本 粒 子 的 总 数 约 为 1O8 0 (一粒灰尘中含有几十亿 个基本粒子). 1 0 . 2 低维嵌入 227 [Bellman, 1957]最早提 出，亦 称 “维数诅咒” 、 “维数危机”. 另一个重要途径是特征 选择,参见第11章. 都不再容易. 事 实 上 ，在 高 维 情 形 下 出 现 的 数 据 样 本 稀 疏 、距离计算困难等问题, 是 所 有 机 器 学 习 方 法 共 同 面 临 的 严 重 障 碍 ，被 称 为 “维 数 灾 难 ”(curse of dimensionality). 缓解维数灾难的一个重要途径是降维(dimension reduction), 亦 称 “维数 约 简 ”，即 通 过 某 种 数 学 变 换 将 原 始 高 维 属 性 空 间 转 变 为 一 个 低 维 “子空 间”(subspace),在这个子空间中样本密度大幅提高，距离计算也变得更为容 易.为什么能进行降维？这是因为在很多时候，人们观测或收集到的数据样本 虽是高维的，但与学习任务密切相关的也许仅是某个低维分布，即高维空间中 的 一 个 低 维 “嵌 入 ”(em bedding).图 10.2给出了一个直观的例子.原始高维 空间中的样本点，在这个低维嵌入子空间中更容易进行学习. ( a ) 三维空间中观察到的样本点 ( b ) 二维空间中的曲面 图 1 0 . 2 低维嵌入示意图 若要求原始空间中样本之间的距离在低维空间中得以保持，如 图 10.2所 示，即 得 到 “多维缩放\" (Multiple Dimensional Scaling,简称 MDS) [Cox and Cox, 2001]这样一种经典的降维方法.下面做一个简单的介绍.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 504
    }
  },
  {
    "page_content": "( a ) 三维空间中观察到的样本点 ( b ) 二维空间中的曲面 图 1 0 . 2 低维嵌入示意图 若要求原始空间中样本之间的距离在低维空间中得以保持，如 图 10.2所 示，即 得 到 “多维缩放\" (Multiple Dimensional Scaling,简称 MDS) [Cox and Cox, 2001]这样一种经典的降维方法.下面做一个简单的介绍. 假 定 6 个样本在原始空间的距离矩阵为D G 肽M X ? 其第分行j.列的元 素 distij为 样 本 Xi到 X,的距离 .我 们 的 目 标 是 获 得 样 本 在df 维空间的表示 Z e Rd，x m , df < d,且任意两个样本在成维空间中的欧氏距离等于原始空间中 的距离，即 II石 - Zj\\\\ = distij. 令 B = ZTZ 6 股a x ? 其 中 B 为降维后样本的内积矩阵，% = nJn小有 d说 % = |㈤产 + \\\\zjf -2z^Zj = b/i + bjj _ . (10.3) 228 第 1 0 章 降 维 与 度 量 学 习 o e 为全零向量. 为便于讨论,令降维后的样本Z 被中心化，即 £ 隘 备 = 0 . 显然，矩 阵 B 的行与列之和均为零，即 £ 隘 如 = £ % 鲂 = 0 . 易知 m £ dis玲= tr(B ) + m b j j) 2=1 m £ 成 = tr(B) + mba , J=i rrt m £ £ dis焉= 2m tr(B) , 2=1 j = l 其 中 t r ( .) 表示矩阵的迹(trace), tr(B ) = £ 鼠1 |㈤ R 令 1 m distl，= — , J=I 1 m dis玲=—£ distlj , 成 出 = 2=1 1 m m E E dis 玲, i—l j=l (10.4) (10.5) (10.6) (10.7) (10.8) (10.9) 由式(10.3)和式(10.4)〜 (10⑼可得 1 bij = - - { d is tfj — dis场—dis垮 + d is /) , (10.10) 由此即可通过降维前后保持不变的距离矩阵D 求取内积矩阵B. 对矩阵 B 做 特征值分解(eigenvalue decomposition), B = V A V T , 其中",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 505
    }
  },
  {
    "page_content": "(10.9) 由式(10.3)和式(10.4)〜 (10⑼可得 1 bij = - - { d is tfj — dis场—dis垮 + d is /) , (10.10) 由此即可通过降维前后保持不变的距离矩阵D 求取内积矩阵B. 对矩阵 B 做 特征值分解(eigenvalue decomposition), B = V A V T , 其中 A = diag(Ai,A2 , ...,A d ) 为特征值构成的对角矩阵，尢 》 刖 》 为 特 征 向 量 矩 阵 .假 定 其 中 有 d * 个 非 零 特 征 值 ，它 们 构 成 对 角 矩 阵 A* = diag(Ai, A2 , . . . , % * ),令 V * 表示相应的特征向量矩阵，则 Z 可表达为 猫，V z = e R d*x m . (10.11) 在现实应用中为了有效降维，往往仅需降维后的距离与原始空间中的距离 尽可能接近，而 不 必 严 格 相 等 .此 时 可 取 成 《 d 个最大特征值构成对角矩阵 A = diag(Ai,入2,… ，M ) , 令 V 表示相应的特征向量矩阵，则 Z 可表达为 1 0 . 3 主成分分析 Z = AX/2V T e R d ，x m . 图 10.3给出了 M D S 算法的描述. 229 (10.12) 输入：距离矩阵D €即 其 元 素 成 为 样 本 g 到叼的距离; 低维空间维数K 过程： 1：根据式(10.7)~(10.9)计算成s±3 dist2^ dist2.; 2：根据式(10.10)计算矩阵B; 3：对矩阵B 做特征值分解； 4 : 取 A 为成个最大特征值所构成的对角矩阵,V 为相应的特征向量矩阵. 输出：矩阵V A1/2 €及馆xd〔每行是一个样本的低维坐标 图 10.3 M D S 算法 一般来说，欲获得低维子空间，最简单的是对原始高维空间进行线性变换. 通 常 令 力 《 d. 给 定 d 维空间中的样本X = ( 叫 ，①2,… ，Xm ) e R d x m , 变换之后得到力W d 维 空 间 中 的 样 本 . Z = W T X, (10.13) 其 中 w e R dxd，是变换矩阵，z e R d ，x m 是样本在新空间中的表达. 变换矩阵w 可 视 为 力 个 d 维基向量，Zi = W T g 是 第 i个样本与这df 个 基向量分别做内积而得到的成维属性向量.换言之，当 是 原 属 性 向 量 g 在新 坐 标 系 ｛皿,恒2,・一，彷力｝中 的 坐 标 向 量 .若 叫 与 W j (Z* j)正交，则新坐标",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 506
    }
  },
  {
    "page_content": "其 中 w e R dxd，是变换矩阵，z e R d ，x m 是样本在新空间中的表达. 变换矩阵w 可 视 为 力 个 d 维基向量，Zi = W T g 是 第 i个样本与这df 个 基向量分别做内积而得到的成维属性向量.换言之，当 是 原 属 性 向 量 g 在新 坐 标 系 ｛皿,恒2,・一，彷力｝中 的 坐 标 向 量 .若 叫 与 W j (Z* j)正交，则新坐标 系是一个正交坐标系，此 时 W 为正交变换.显然，新空间中的属性是原空间中 属性的线性组合. 基 于 线 性 变 换 来 进 行 降 维 的 方 法 称 为 线 性 降 维 方 法 ，它 们 都 符 合 式(10.13)的 基 本 形 式 ，不 同 之 处 是 对 低 维 子 空 间 的 性 质 有 不 同 的 要 求 ，相 当于对W 施加了不同的约束.在下一节我们将会看到,若要求低维子空间对样 本具有最大可分性，则将得到一种极为常用的线性降维方法. 对降维效果的评估，通常是比较降维前后学习器的性能，若性能有所提高 则认为降维起到了作用.若将维数降至二维或三维，则可通过可视化技术来直 观地判断降维效果. 1 0 .3 主 成 分 分 析 亦 称 “主分量分析”. 主成分分析(Principal C o m p o n e n t Analysis,简 称 P C A ) 是最常用的一种 降 维 方法.在介绍 P C A 之前，不妨先考虑这样一个问题:对于正交属性空间中 230 第 1 0 章 降 维 与 度 量 学 习 的样本点，如何用一个超平面(直线的高维推广)对所有样本进行恰当的表达？ 容易想到，若存在这样的超平面,那么它大概应具有这样的性质： • 最近重构性：样本点到这个超平面的距离都足够近； •最 大 可 分 性 ：样本点在这个超平面上的投影能尽可能分开. 有趣的是，基于最近重构性和最大可分性，能分别得到主成分分析的两种 等价推导.我们先从最近重构性来推导. 假定数据样本进行了中心化，即 g = 0 ；再假定投影变换后得到的新坐 标 系 为 { w i , w 2 ,...,wd } , 其 中 Wi 是标准正交基向量， 皿 \"2 = 1,吟 叼 = 0 (£* J ) . 若丢弃新坐标系中的部分坐标，即将维度降低到d! ＜或 则 样 本 点 g 在低维坐标系中的投影是Zi = (%1； & 2；… ；石力)，其 中 %ij = wjxi是 Xi在低 维坐标系下第j 维的坐标.若基于玄来重构g , 则会得到a 考虑整个训练集，原样本点Xi与基于投影重构的样本点必之间的距离为 const是一个常数. m H d 7 E E i=i |p=i ||2 m m",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 507
    }
  },
  {
    "page_content": "在低维坐标系中的投影是Zi = (%1； & 2；… ；石力)，其 中 %ij = wjxi是 Xi在低 维坐标系下第j 维的坐标.若基于玄来重构g , 则会得到a 考虑整个训练集，原样本点Xi与基于投影重构的样本点必之间的距离为 const是一个常数. m H d 7 E E i=i |p=i ||2 m m - Xi = £ N产玄—2 £ ZirW T Xi + const H2 £=1 £=1 oc —tr ( w ，( ^ 比 £ 哥 ) w ) . (10.14) 根据最近重构性,式(10.14)应被最小化,考虑到吗•是标准正交基,£ . xiXJ 是协方差矩阵，有 min - tr(W T X X T W ). (10.15) s.t. W T W - I . 这就是主成分分析的优化目标. 从最大可分性出发，能得到主成分分析的另一种解释.我们知道，样本点 g 在新空间中超平面上的投影是W T g , 若所有样本点的投影能尽可能分开, 则应该使投影后样本点的方差最大化,如图10.4所示. 投 影 后 样 本 点 的 方 差 是 成 品 于是优化目标可写为 m a x tr(W T X X T W ) (10.16) s.t. W T W = I , 1 0 . 3 主成分分析 231 实践中常通过对x 进行 奇异值分解来代替协方差 矩阵的特征值分解. P C A 也可看作是逐一选 取方差最大方向，即先对 协 方 差 矩 阵 £ 遭 避 : 做 特征值分解，取最大特征 值 对 应 的 特 征 向 量 W 1 ； 再对 S i X iX T - AiwiwJ 1 做特征值分解，取最大特 征值对应的特征 向量W 2 ； .... 由 W 各分量正交及 d i—1 j=l 可知，上述逐一选取方差 最大方向的做法与直接选 取 最 大d!个特征值等价. 图 1 0 . 4 使所有样本的投影尽可能分开(如图中红线所示)，则需最大化投影点的方差 显然，式(10.16)与(10.15)等价. 对式(10.15)或(10.16)使用拉格朗日乘子法可得 X X T W = AW , (10.17) 于 是 ，只 需 对 协 方 差 矩 阵 X X T 进 行 特 征 值 分 解 ，将 求 得 的 特 征 值 排 序 : 人 》 入2 》 ...) ％ , 再 取 前 力 个 特 征 值 对 应 的 特 征 向 量 构 成 W = (W1, w 2 , . . . , w d/ ) . 这就是主成分分析的解.P C A 算法描述如图10.5所示. 输入：样 本 集 0 = {宓1,必2,… ，Xm }]",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 508
    }
  },
  {
    "page_content": "输入：样 本 集 0 = {宓1,必2,… ，Xm }] 低维空间维数力. 过程: 1：对所有样本进行中心化：g - g — * £ 随 叫 2：计算样本的协方差矩阵X X T ； 3：对协方差矩阵X X T 做特征值分解； 4 : 取 最 大 的 1 个特征值所对应的特徒向量亚,叨2,...,叨力. 输出：投影矩阵 W = (叨1,，2, • • •,的力). 图 10.5 P C A 算法 降维后低维空间的维数df 通常是由用户事先指定，或 通 过 在 df 值不同的 低 维 空 间 中 对k 近邻分类器(或其他开销较小的学习器)进行交叉验证来选取 较 好 的 df 值 .对 P C A ,还可从重构的角度设置一个重构阈值,例如t = 95% ,然 后选取使下式成立的最小成值： £3% £3% (10.18) 232 第 1 0 章 降 维 与 度 量 学 习 保存均值向量是为了通 过向量减法对新样本同样 进行中心化. P C A 仅 需 保 留W 与样本的均值向量即可通过简单的向量减法和矩阵-向 量乘法将新样本投影至低维空间中.显然，低维空间与原始高维空间必有不同, 因为对应于最小的d - d f 个特征值的特征向量被舍弃了，这是降维导致的结果. 但舍弃这部分信息往往是必要的：一方面，舍弃这部分信息之后能使样本的采 样密度增大，这正是降维的重要动机；另一方面，当数据受到噪声影响时，最小 的特征值所对应的特征向量往往与噪声有关，将它们舍弃能在一定程度上起到 去噪的效果. 1 0 .4 核化线性降维 线性降维方法假设从高维空间到低维空间的函数映射是线性的，然而，在 不少现实任务中，可能需要非线性映射才能找到恰当的低维嵌入.图10.6给出 了一个例子，样本点从二维空间中的矩形区域采样后以S 形曲面嵌入到三维空 间，若直接使用线性降维方法对三维空间观察到的样本点进行降维，则将丢失 原 本 的 低维结构.为了对“原本采样的”低维空间与降维后的低维空间加以区 别，我 们称前者为“本真”(intrinsic)低维空间. (a)三维空间中的观察 (b)本真二维结构 (c) P C A 降维结果 图 1 0 . 6 三 维 空 间 中 观 察 到 的 30 0 0 个样本点，是从本真二维空间中矩形区域采样后 以 S 形曲面嵌入，此情形下线性降维会丢失低维结构.图中数据点的染色显示出低维 空间的结构. 参 见 6.6 节. 化 \" (kernelized).下 面 我 们 以 核 主 成 分 分 析 (Kemelized P C A ,简 称 KPCA) 非 线 性 降 维 的 一 种 常 用 方 法 ，是 基 于 核 技 巧 对 线 性 降 维 方 法 进 行 “核",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 509
    }
  },
  {
    "page_content": "参 见 6.6 节. 化 \" (kernelized).下 面 我 们 以 核 主 成 分 分 析 (Kemelized P C A ,简 称 KPCA) 非 线 性 降 维 的 一 种 常 用 方 法 ，是 基 于 核 技 巧 对 线 性 降 维 方 法 进 行 “核 [Scholkopf et al., 1998]为例来进行演示. 假 定 我 们 将 在 高 维 特 征 空 间 中 把 数 据 投 影 到 由W 确定的超平面上，即 P C A 欲求解 d 婷 )w = 》w, (10.19) 1 0 . 4 核化线性降维 其 中 入是样本点g 在高维特征空间中的像.易知 w =运用w g 邛 m = ) :NiOii , i=l 233 (10.20) 其 中 必 = & F w . 假 定 x 是由原始属性空间中的样本点修通过映射。产生, 即 凡= 0 ( g ) \" = 1 ,2 ,… ，m . 若 。能被显式表达出来,则通过它将样本映射至 高维特征空间，再在特征空间中实施P C A 即可.式(10.19)变换为 式(10.20)变换为 gO ( g ) ° ( g ) T W = A W , (10.21) m W = £ 0 ( g ) 办 . 2=1 (10.22) 一般情形下，我们不清楚。的具体形式，于是引入核函数 = = 0 (2C/) . (10.23) 将式(10.22)和(10.23)代入式(10.21)后化简可得 K A = A A , 其 中 K 为 K 对应的核矩阵，(K)切 = 长( g , g ♦)，A = (10.24) 显然, 式(10.24)是特征值分解问题,取K 最大的成个特征值对应的特征向量即可. 对新样本宏，其投影后的第j (7 = 1 , 2 , . . . , 成)维坐标为 m Zj = wj(j)(x) = £ * 状Xi^ 蚁 x) i=l m = £ 姆 6(乐 啰 ), i=l (10.25) 其 中 T 已经过规范化，* 是 5 的 第j 个 分 量 .式 (10.25)显示出，为获得投影 后的坐标，K P C A 需对所有样本求和，因此它的计算开销较大. 234 第 1 0 章 降维与度量学习 1 0 .5 流形学习 流 形 学 习 (manifold learning)是 一 类 借 鉴 了 拓 扑 流 形 概 念 的 降 维 方 法 . “流 形 ”是在局部与欧氏空间同胚的空间，换言之，它在局部具有欧氏空间的 性质，能用欧氏距离来进行距离计算.这给降维方法带来了很大的启发：若低",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 510
    }
  },
  {
    "page_content": "234 第 1 0 章 降维与度量学习 1 0 .5 流形学习 流 形 学 习 (manifold learning)是 一 类 借 鉴 了 拓 扑 流 形 概 念 的 降 维 方 法 . “流 形 ”是在局部与欧氏空间同胚的空间，换言之，它在局部具有欧氏空间的 性质，能用欧氏距离来进行距离计算.这给降维方法带来了很大的启发：若低 维流形嵌入到高维空间中，则数据样本在高维空间的分布虽然看上去非常复杂, 但在局部上仍具有欧氏空间的性质，因此，可以容易地在局部建立降维映射关 系，然后再设法将局部映射关系推广到全局.当维数被降至二维或三维时，能对 数据进行可视化展示，因此流形学习也可被用于可视化.本节介绍两种著名的 流形学习方法. 10.5.1 等度量映射 等度量映射(Isometric M apping,简称 Isomap) [Tenenbaum et al., 2000]的 基本出发点，是认为低维流形嵌入到高维空间之后，直接在高维空间中计算直 线距离具有误导性，因为高维空间中的直线距离在低维嵌入流形上是不可达的. 如 图 10.7(a)所示，低维嵌入流形上两点间的距离是“测地线”(geodesic)距离: 想象一只虫子从一点爬到另一点，如果它不能脱离曲面行走，那么图10.7(a)中 的红色曲线是距离最短的路径，即 S 曲面上的测地线，测地线距离是两点之间 的本真距离.显然，直接在高维空间中计算直线距离是不恰当的. (a)测地线距离与高维直线距离 (b)测地线距离与近邻距离 图 1 0 . 7 低维嵌入流形上的测地线距离(红色)不能用高维空间的直线距离计算，但能 用近邻距离来近似 那么，如何计算测地线距离呢？这时我们可利用流形在局部上与欧氏空间 同胚这个性质，对每个点基于欧氏距离找出其近邻点，然后就能建立一个近邻 连接图，图中近邻点之间存在连接，而非近邻点之间不存在连接，于是，计算两 1 0 . 5 流形学习 235 点之间测地线距离的问题，就转变为计算近邻连接图上两点之间的最短路径问 题 .从 图 10.7(b)可看出，基于近邻距离逼近能获得低维流形上测地线距离很好 的近似. 1 9 7 2 年 图 灵 奖 得 主 E. W . Dijkstra 和 1978年图灵 奖 得 主 R. Floyd分别提出 的著名算法，参阅数据结 构教科书. 在近邻连接图上计算两点间的最短路径，可 采 用 著 名 的 Dijkstra算法或 F l o y d 算法,在得到任意两点的距离之后，就 可 通 过 1 0 . 2节介绍的 M D S 方法来 获得样本点在低维空间中的坐标.图1 0 . 8给出了 I s o m a p 算法描述. M D S 参 见 1 0 .2节.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 511
    }
  },
  {
    "page_content": "在近邻连接图上计算两点间的最短路径，可 采 用 著 名 的 Dijkstra算法或 F l o y d 算法,在得到任意两点的距离之后，就 可 通 过 1 0 . 2节介绍的 M D S 方法来 获得样本点在低维空间中的坐标.图1 0 . 8给出了 I s o m a p 算法描述. M D S 参 见 1 0 .2节. 输入：样本集。= {叫，⑦2,… ，空恒}； 近邻参数k; 低维空间维数力. 过程： 1： for « = 1,2,... , m d o 2： 确定g 的 k 近邻； 3： 0与卜近邻点之间的距离设置为欧氏距离，与其他点的距离设置为无穷大； 4： e n d for 5 : 调用最短路径算法计算任意两样本点之间的距离dist(g,叼)； 6：将 dist(g,叼)作为M D S 算法的输入； 7： return M D S 算法的输出 输出：样本集。在低维空间的投影Z = {Z1,Z2,… ，Na}. 图 10.8 I s o m a p 算法 需注意的是,I s o m a p 仅是得到了训练样本在低维空间的坐标,对于新样本, 如何将其映射到低维空间呢？这个问题的常用解决方案,是将训练样本的高维 空间坐标作为输入、低维空间坐标作为输出，训练一个回归学习器来对新样本 的低维空间坐标进行预测.这显然仅是一个权宜之计，但目前似乎并没有更好 的办法. 对近邻图的构建通常有两种做法，一种是指定近邻点个数，例如欧氏距离 最 近 的 k 个点为近邻点，这样得到的近邻图称为k 近邻图；另一种是指定距离 阈 值 c , 距 离 小 于 e 的点被认为是近邻点，这样得到的近邻图称为€近邻图.两 种方式均有不足，例如若近邻范围指定得较大，则距离很远的点可能被误认为 近邻，这 样 就 出 现 “短路”问题;近邻范围指定得较小，则图中有些区域可能与 其他区域不存在连接，这 样 就 出 现 “断路”问题.短路与断路都会给后续的最 短路径计算造成误导. 1 0 . 5 . 2局部线性嵌入 与 I s o m a p 试 图 保 持 近 邻 样 本 之 间 的 距 离 不 同 ，局 部 线 性 嵌 入 (Locally Linear E m b e d d i n g , 简称L L E ) [Roweis a n d Saul, 2 0 0 0 ] 试图保持邻域内样本之 236 第 1 0 章 降维与度量学习 图 1 0 . 9 高维空间中的样本重构关系在低维空间中得以保持 间的线性关系.如图10.9所示,假定样本点g 的坐标能通过它的邻域样本叼, * xi的坐标通过线性组合而重构出来，即 Xi = WijXj + w ikxk + Wuxi , (10.26)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 512
    }
  },
  {
    "page_content": "236 第 1 0 章 降维与度量学习 图 1 0 . 9 高维空间中的样本重构关系在低维空间中得以保持 间的线性关系.如图10.9所示,假定样本点g 的坐标能通过它的邻域样本叼, * xi的坐标通过线性组合而重构出来，即 Xi = WijXj + w ikxk + Wuxi , (10.26) L L E 希望式(10.26)的关系在低维空间中得以保持. L L E 先为每个样本 g 找到其近邻下标集合Q e,然后计算出基于Q e 中的 样本点 对 g 进行线性重构的系数皿： min T 辰 —J ? w ijx j 2=1 || j eQi j^Qi 其 中 Xi和 Xj均为已知，令 Cjk = (Xi - 叼)T (g - xk\\ Wij有闭式解 W = E 审 keQi I jS^,Qi (10.28) L L E 在 低 维 空 间 中 保 持 见 不 变 ，于 是 g 对应的低维空间坐标力可通过 下式求解： mjn Z1/2,…声俏 % - £ 妙 司 . (10.29) 式(10.27)与(10.29)的优化目标同形，唯一的区别是式(10.27)中需确定的是 w b 而式(10.29)中需确定的是g 对应的低维空间坐标% 1 0 . 6 度量学习 237 令 Z = (N1,之2”. . .，Nm ) e 及\"X m , — W2J, M = ( 1 - W ) T (I - W ) , (10.30) 则式(10.29)可重写为 i m n t r ( Z M Z T ), (10.31) s.t. Z Z T = I . 式 (10.31)可通过特征值分解求解：M 最 小 的 d!个特征值对应的特征向量组成 的矩阵即为Z T . L L E 的算法描述如图1 0 . 1 0所 示 .算 法 第 4 行显示出：对于不在样本g 邻 域 区域的样本叼，无论其如何变化都对Xi和 石没有任何影响；这种将变动限 制在局部的思想在许多地方都有用. 输入：样本集 D = ｛x-L,x2,.. ., xm ]; 近邻参数k; 低维空间维数成. 过程： 1： for i = 1,2,... d o 2： 确定Xi^J k 近邻； 3： 从式(10.27)求得 4： 对于j 任QM 令 Wij = 0; 5： e n d for 6：从式(10.30)得到M ; 7：对 M 进行特征值分解； 8： return M 的最小dr个特征值对应的特征向量 输出：样本集。在低维空间的投影2 = ｛力 / 2,….，2仅｝. j € 图 1。.10 L L E 算法 1 0 . 6 度量学习",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 513
    }
  },
  {
    "page_content": "j € 图 1。.10 L L E 算法 1 0 . 6 度量学习 亦 称 “距 离 度 量 学 习 ” (distance metric learning). 在机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低 维空间，在此空间中进行学习能比原始空间性能更好.事实上,每个空间对应了 在样本属性上定义的一个距离度量，而寻找合适的空间，实质上就是在寻找一 个合适的距离度量.那么，为何不直接尝试“学习”出一个合适的距离度量呢? 这就是度量学习(metric learning)的基本动机. 238 第 1 0 章降维与 度 量 学 习 欲对距离度量进行学习,必须有一个便于学习的距离度量表达形式.9.3节 给出了很多种距离度量的表达式，但 它 们 都 是 “固定的”、没有可调节的参数, 因此不能通过对数据样本的学习来加以改善.为此，我们先来做一个推广. 即欧氏距离的平方，这 是为了后面推导的便利. 对 两 个d 维 样 本 X%和 叼 ，它们之间的平方欧氏距离可写为 distgd (x i,Xj) = \\ \\ x i - Xj\\\\l = 成 + 成 + … + dis玲d , (10.32) 其中成s % # 表 示 X i 与 X j 在 第 k 维上的距离.若假定不同属性的重要性不同, 则可引入属性权重犯得到 dis瑜ed(电,Xj) = \\ \\ x i - Xj\\]l = W\\ ・ d i s % + w2 - dist-j 2 + … + 图 •成s % / = (xi - Xj)T W (X i - Xj) , (10.33) 其 中 她 》0, W = diag(w )是一个对角矩阵，(W % = Wi. 式(10.33)中 的 W 可通过学习确定，但我们还能再往前走一步：W 的非对 角元素均为零，这意味着坐标轴是正交的，即属性之间无关;但现实问题中往往 不是这样，例 如 考 虑 西 瓜 的 “重量”和 “体 积 ”这两个属性，它们显然是正相 关的，其对应的坐标轴不再正交.为此,将式(10.33)中 的 W 替换为一个普通的 半正定对称矩阵M , 于是就得到了马氏距离(Mahalanobis distance) dis琮ah(% 叼 ) = 出 一叼)‘M Q e —叼 ) = \\\\xi —叼 隘 , (10.34) 其 中 M 亦 称 “度 量 矩 阵 \"而 度 量 学 习 则 是 对 M 进行学习.注意到为了保持 距离非负且对称，M 必须是(半)正定对称矩阵，即必有正交基P 使 得 M 能写 % M = P P T . 对 M 进行学习当然要设置一个目标.假定我们是希望提高近邻分类器",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 514
    }
  },
  {
    "page_content": "(10.34) 其 中 M 亦 称 “度 量 矩 阵 \"而 度 量 学 习 则 是 对 M 进行学习.注意到为了保持 距离非负且对称，M 必须是(半)正定对称矩阵，即必有正交基P 使 得 M 能写 % M = P P T . 对 M 进行学习当然要设置一个目标.假定我们是希望提高近邻分类器 的性能，则 可 将 M 直接嵌入到近邻分类器的评价指标中去，通过优化该性能 指 标 相 应 地 求 得 M . 下面我们以近邻成分分析(Neighbourhood Component Analysis,简称 NCA) [Goldberger et al., 2005]为例进行讨论. 近邻分类器在进行判别时通常使用多数投票法,邻域中的每个样本投1 票, 邻域外的样本投0 票.不妨将其替换为概率投票法.对于任意样本叼，它 对 g 分类结果影响的概率为 马 氏 距 离 以 印 度 数 学 家 P. C. Mahalanobis 命名. 标 准 马 氏 距 离 中 M 是协 方 差 矩 阵 的 逆 ，即 M = S - 1 ; 在度量学习中M 被 赋予更大的灵活性. 1 0 . 6 度量学习 _ e x p ( - Wxi-XjWl^ J N e x p (—忸 —血 脸 ) ’ 239 (10.35) 留一法参见2 2 2 节. 若 以 留 一 法 ( L 0 0 ) 正确率的最大化为目标，则 可 计 算Xi的留一法正确率，即 当分= 3•时，Pij最大.显然，叼 对 g 的影响随着它们之间距离的增大而减小. 它被自身之外的所有样本正确分类的概率为 Pi — 〉： Pij ) (10.36) 其 中 ％ 表 示 与 XI属于相同类别的样本的下标集合.于是，整个样本集上的留 一法正确率为 m E 2=1 Y m E 2=1 Pij . (10.37) 将式(10.35)代入(10.37),再考虑到 M = P P T , 则 N C A 的优化目标为 m i n 「 玄 £ e x p ( | | P % — 丁 叼 以 . P £= 130% E z ^ x p ( - ] 邛 / _ P T g | 图 可用随机梯度下降法求 解 [Goldberger etal., 2005]. 求解式(10.38)即可得到最大化近邻分类器L 0 0 正确率的距离度量矩阵M . 实际上，我们不仅能把错误率这样的监督学习目标作为度量学习的优化目 标，还能在度量学习中引入领域知识.例如，若已知某些样本相似、某些样本 不相似，则 可 定 义 “必连”(must-link)约束集合 M 与 “勿连”(caimot-link)约",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 515
    }
  },
  {
    "page_content": "求解式(10.38)即可得到最大化近邻分类器L 0 0 正确率的距离度量矩阵M . 实际上，我们不仅能把错误率这样的监督学习目标作为度量学习的优化目 标，还能在度量学习中引入领域知识.例如，若已知某些样本相似、某些样本 不相似，则 可 定 义 “必连”(must-link)约束集合 M 与 “勿连”(caimot-link)约 束 集 合 C , (即 Xj) € M 表 示 Xi与 Xj相似，(g, xk) e C 表 示 Xi与 xk 不相似. 显然，我们希望相似的样本之间距离较小，不相似的样本之间距离较大，于是可 通过求解下面这个凸优化问题获得适当的度量矩阵M [Xing et al, 2003]: (10.39) (ge ) € 人4 s.t. ) ] ||®z — UM 》 1 , (g M 0 , 其中约 束 M 占0 表 明 M 必须是半正定的.式(10.39)要求在不相似样本间的距 离不小 于 1 的前提下，使相似样本间的距离尽可能小. 240 第 1 0 章 降维与度量学习 度量学习自身通常并不 要求学得的M 是低秩的. 不同的度量学习方法针对不同目标获得“好 ”的半正定对称距离度量矩 阵 M , 若 M 是一个低秩矩阵，则通过对M 进行特征值分解，总能找到一组正 交基,其正交基数目为矩阵M 的秩ran k (M ),小于原属性数d . 于是,度量学习 学得的结果可衍生出一个降维矩阵P G 肽dxrank(M),能用于降维之目的. 1 0 .7 阅读材料 懒 惰学习方法主要有\"近邻学习器、懒 惰 决 策 树 [Friedman et al., 1996]; 朴素贝叶斯分类器能以懒惰学习方式使用，也能以急切学习方式使用.关于懒 惰学习的更多内容可参阅[Aha, 1997]. 主成分分析是一种无监督的线性降维方法，监督线性降维方法最著名的 是线性判别分析(LDA) [Fisher, 1936],参 见 3.4节，其核化版本KLDA [Baudat and Anouar, 2000]参 见 6 .6 节.通过最大化两个变量集合之间的相关性，则可 得至IJ “典型相关分析” (Canonical Correlation Analysis,简称 CCA) [Hotelling, 1936]及其核化版本KCCA [Harden et al., 2004],该方法在多视图学习(multi­ view learning) 中 有 广 泛 应 用 .在 模 式 识 别 领 域 人 们 发 现 ，直 接 对 矩 阵 对 象(例如一幅图像)进行降维操作会比将其拉伸为向量(例如把图像逐行拼接",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 516
    }
  },
  {
    "page_content": "1936]及其核化版本KCCA [Harden et al., 2004],该方法在多视图学习(multi­ view learning) 中 有 广 泛 应 用 .在 模 式 识 别 领 域 人 们 发 现 ，直 接 对 矩 阵 对 象(例如一幅图像)进行降维操作会比将其拉伸为向量(例如把图像逐行拼接 成一个向量)再进行降维操作有更好的性能，于是产生了 2DPCA [Yang et al., 2004]> 2DLDA [Ye et al., 2005]> (2D)2PCA [Zhang and Zhou, 2005]等方法, 以及基于张量(tensor)的 方 法 [Kolda and Bader, 2009]. 除了 Isom ap和 L L E ,常见的流形学习方法还有拉普拉斯特征映射(Lapl- cian Eigenmaps,简称 LE) [Belkin and Niyogi, 2003]> 局部切空间对齐(Local Tangent Space Alignment,简称 LTSA) [Zhang and Zha, 2004]等.局部保持投 影(Locality Preserving Projections,简称 LPP) [He and Niyogi, 2004]是基于 L E 的线性降维方法.对监督学习而言,根据类别信息扭曲后的低维空间常比本 真低维空间更有利[Geng et al., 2005].值得注意的是，流形学习欲有效进行邻 域保持则需样本密采样，而这恰是高维情形下面临的重大障碍，因此流形学习 方法在实践中的降维性能往往没有预期的好;但邻域保持的想法对机器学习的 其他分支产生了重要影响，例如半监督学习中有著名的流形假设、流形正则化 参 见 第 1 3 章. [Belkin et al., 2006]. [Yan et al., 2007]从图嵌入的角度给出了降维方法的一个 统一框架. 半监督聚类见13.6节. 究中使用得更早[Wagstaff et al., 2001].在度量学习中，由于这些约束是对所有 将必连关系、勿连关系作为学习任务优化目标的约束，在半监督聚类的研 样本同时发生作用[Xing et al., 2003],因此相应的方法被称为全局度量学习方 1 0 . 7 阅读材料 241 法.人们也尝试利用局部约束（例如邻域内的三元关系），从而产生了局部距离 度量学习方法［Weinberger and Saul, 2009］, 甚至有一些研究试图为每个样本 产生最合适的距离度量［Frome et al., 2007; Zhan et al., 2009］. 在具体的学习",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 517
    }
  },
  {
    "page_content": "1 0 . 7 阅读材料 241 法.人们也尝试利用局部约束（例如邻域内的三元关系），从而产生了局部距离 度量学习方法［Weinberger and Saul, 2009］, 甚至有一些研究试图为每个样本 产生最合适的距离度量［Frome et al., 2007; Zhan et al., 2009］. 在具体的学习 与优化求解方面，不同的度量学习方法往往采用了不同的技术，例 如 ［Yang et al., 2006］将度量学习转化为判别式概率模型框架下基于样本对的二分类问题 求解，［Davis et al., 2007］将度量学习转化为信息论框架下的B regm an优化问 题，能方便地进行在线学习. 242 第 1 0 章降维 与 度 量 学 习 习题 西 瓜 数 据 集 3 .0 a 见 p.89 的 表 4 5 策树分类边界之异同. 10.1 编 程 实 现 k 近邻分类器，在西瓜 数 据 集3.0Q 上比较其分类边界与决 10.2 令 err、err*分别表示最近邻分类器与贝叶斯最优分类器的期望错误 率，试证明 err* W err & err*(2 — x err*) . (10.40) 10.3 在对高维数据降维之前应先进行“中心化”，常见的是将协方差矩阵 X X T 转 化 为 X H H T X T , 其 中 H = 1 —^ 1 1 T ,试析其效果. 10.4 在实践中，协方差矩阵X X T 的特征值分解常由中心化后的样本矩阵 X 的奇异值分解代替,试述其原因. 10.5 降维中涉及的投影矩阵通常要求是正交的.试述正交、非正交投影矩 阵用于降维的优缺点. p rin c o m p 函数调用. ] 0 6 试 使 用 M A T L A B 中 的 P C A 函数对Yale人脸数据集进行降维，并观 Y a l e 人 脸 数 据 集 见 察 前 2 0 个特征向量所对应的图像. http://vision.ucsd.edu/content /yale-face-database. 1 0 7 试述核化线性降维与流形学习之间的联系及优缺点. 10.8* k 近邻图和€近邻图存在的短路和断路问题会给Isomap造成困扰,试 设计一个方法缓解该问题. 10.9* 试设计一个方法为新样本找到L L E 降维后的低维坐标. 参 见 9 . 3 节. 1 0 . 1 0 试述如何确保度量学习产生的距离能满足距离度量的四条基本性质. 参考文献 243 参考文献 Aha, D., ed. (1997). Lazy Learning. Kluwer, Norwell, MA.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 518
    }
  },
  {
    "page_content": "设计一个方法缓解该问题. 10.9* 试设计一个方法为新样本找到L L E 降维后的低维坐标. 参 见 9 . 3 节. 1 0 . 1 0 试述如何确保度量学习产生的距离能满足距离度量的四条基本性质. 参考文献 243 参考文献 Aha, D., ed. (1997). Lazy Learning. Kluwer, Norwell, MA. Baudat, G. and F. Anouar. (2000). ^Generalized discriminant analysis using a kernel approach.” Neural Computation, 12(10):2385-2404. Belkin, M. and P. Niyogi. (2003). “Laplacian eigenmaps for dimensionality re­ duction and data representation.,5 Neural Computation^ 15(6):1373-1396. Belkin, M., P. Niyogi, and V. Sindhwani. (20Q6). “Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.55 Journal of Machine Learning Research, 7:2399-2434. Bellman, R. E. (1957). Dynamic Programming. Princeton University Press, Princeton, NJ. Cover, T. M. and P. E. Hart. (1967). “Nearest neighbor pattern classification.” IEEE Transactions on Information Theory,13(1):21-27. Cox, T. F. and M. A. Cox. (2001). Multidimensional Scaling. Chapman & Hal- 1/CRC, London, UK. Davis, J. V., B. Kulis, P. Jain, S. Sra, and I. S. Dhillon. (2007). “Information-",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 519
    }
  },
  {
    "page_content": "Cox, T. F. and M. A. Cox. (2001). Multidimensional Scaling. Chapman & Hal- 1/CRC, London, UK. Davis, J. V., B. Kulis, P. Jain, S. Sra, and I. S. Dhillon. (2007). “Information- theoretic metric learning.5, In Proceedings of the 24th International Confer­ ence on Machine Learning (ICML), 209-216, Corvalis, OR. Fisher, R. A. (1936). “The use of multiple measurements in taxonomic prob- lems.^^ Annals of Eugenics, 7(2):179-188. Friedman, J. H., R. Kohavi, and Y. Yun. (1996). “Lazy decision trees.\" In Pro­ ceedings of the 13th National Conference on Aritificial Intelligence (AAAI)^ 717-724, Portland, OR. Frome, A., Y. Singer, and J. Malik. (2007). “Image retrieval and classification using local distance functions.,, In Advances in Neural Information Process­ ing Systems 19 (NIPS) (B. Scholkopf, J. C. Platt, and T. Hoffman, eds.), 417-424, MIT Press, Cambridge, MA. Geng, X., D.-C. Zhan, and Z.-H. Zhou. (2005), “Supervised nonlinear dimen­ sionality reduction for visualization and classification.IEEE Transactions",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 520
    }
  },
  {
    "page_content": "Geng, X., D.-C. Zhan, and Z.-H. Zhou. (2005), “Supervised nonlinear dimen­ sionality reduction for visualization and classification.IEEE Transactions on Systems, Man, and Cybernetics - Part B: Cybernetics1 35(6):1098-1107. Goldberger, J., G. E. Hinton, S. T. Roweis, and R. R. Salakhutdinov. (2005). ^Neighbourhood components analysis.5, In Advances in Neural Information 244 第 1 0 章 降维与度量学习 Processing Systems 17 (NIPS) (L. K. Saul, Y. Weiss, and L. Bottou, eds.), 513-520, MIT Press, Cambridge, MA. Harden, D. R., S. Szedmak, and J. Shawe-Taylor. (2004). ^Canonical correla­ tion analysis: An overview with application to learning methods.55 Neural Computation^ 16(12):2639-2664. He, X. and P. Niyogi. (2004). “Locality preserving projections.” In Advances in Neural Information Processing Systems 16 (NIPS) (S. Thrun, L. K. Saul, and B. Scholkopf, eds.), 153-160, MIT Press, Cambridge, MA. Hotelling, H. (1936). “Relations between two sets of variates.55 Biometrika, 28 (3-4):321-377. Kolda, T. G. and B. W. Bader. (2009). “Tensor decompositions and applica­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 521
    }
  },
  {
    "page_content": "Hotelling, H. (1936). “Relations between two sets of variates.55 Biometrika, 28 (3-4):321-377. Kolda, T. G. and B. W. Bader. (2009). “Tensor decompositions and applica­ tions? SIAM Review, 51(3):455-500. Roweis, S. T. and L. K. Saul. (2000), “Locally linear embedding.\" Science1 290 (5500):2323-2316. Scholkopf, B., A. Smola, and K.-R. Muller. (1998). ^Nonlinear component anal­ ysis as a kernel eigenvalue problem.^^ Neural Computation1 10(5):1299-1319. Tenenbaum, J. B., V. de Silva, and J. C. Langford. (2000). “A global geomet­ ric framework for nonlinear dimensionality reduction.” Science,290(5500): 2319-2323. Wagstaff, K., C. Cardie, S. Rogers, and S. Schrddl. (2001). ^Constrained Zu-means clustering with background knowledge.55 In Proceedings of the 18th International Conference on Machine Learning (ICML)^ 577-584, Williamstown, MA. Weinberger, K. Q, and L. K. Saul. (2009), “Distance metric learning for large margin nearest neighbor classification.Journal of Machine Learning Re- search1 10:207-244.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 522
    }
  },
  {
    "page_content": "Weinberger, K. Q, and L. K. Saul. (2009), “Distance metric learning for large margin nearest neighbor classification.Journal of Machine Learning Re- search1 10:207-244. Xing, E. P., A. Y. Ng, M. I. Jordan, and S. Russell. (2003). “Distance metric learning, with application to clustering with side-information.55 In Advances in Neural Information Processing Systems 15 (NIPS) (S. Becker, S. Thrun, and K. Obermayer, eds.), 505-512, MIT Press, Cambridge, MA. Yan, S., D. Xu, B. Zhang, and H.-J. Zhang. (2007). “Graph embedding and ex­ tensions: A general framework for dimensionality reduction.\" IEEE Trans- 参考文献 245 actions on Pattern Analysis and Machine Intelligence1 29(1):40-51. Y ang, J., D. Zhang, A. F. Frangi, and J.-Y. Yang. (2004). “Two-dimensional PCA: A new approach to appearance-based face representation and recog- nition.^^ IEEE Transactions on Pattern Analysis and Machine Intelligence^ 26(1):131-137. Y ang, L., R. Jin, R. Sukthankar, and Y. Liu. (2006). “An efficient algorithm",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 523
    }
  },
  {
    "page_content": "nition.^^ IEEE Transactions on Pattern Analysis and Machine Intelligence^ 26(1):131-137. Y ang, L., R. Jin, R. Sukthankar, and Y. Liu. (2006). “An efficient algorithm for local distance metric learning.\" In Proceedings of the 21st National Con­ ference on Artificial Intelligence (A A A I)r 543-548, Boston, MA. Y e, J., R. Janardan, and Q. Li. (2005). “Two-dimensional linear discriminant analysis.,5 In Advances in Neural Information Processing Systems 17 (NIPS) (L. K. Saul, Y. Weiss, and L. Bottou, eds.), 1569-1576, MIT Press, Cam­ bridge, MA. Zhan, D.-C., Y.-F. Li, and Z.-H. Zhou. (2009), “Learning instance specific distances using metric propagation.^^ In Proceedings of the 26th International Conference on Machine Learning (ICML), 1225-1232, Montreal, Canada. Zhang, D. and Z.-H. Zhou. (2005). U(2D)2PCA: 2-directional 2-dimensional PCA for efficient face representation and recognition? Neurocomputing69 (1-3):224-231. Zhang, Z. and H. Zha. (2004). “Principal manifolds and nonlinear dimension",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 524
    }
  },
  {
    "page_content": "PCA for efficient face representation and recognition? Neurocomputing69 (1-3):224-231. Zhang, Z. and H. Zha. (2004). “Principal manifolds and nonlinear dimension reduction via local tangent space alignment.55 SIAM Journal on Scientific Computingy 26(1):313-338. 246 第 1 0 章 降 维 与 度 量 学 习 休息一会儿 小故事：主成分分析与卡尔•皮尔逊 主 成 分 分 析 （PC A ）是迄今最常用的降维方法，它有许 多名字，例如线性代数中的散度矩阵奇异值分解（SVD）、 统计学中的因子分析（factor analysis）＞信号处理中的离霰 K arhiinen-Loeve变换 、 图 像分析中的H otelling变换、文 本分析中的潜在语义分析（LSA）、机械工程中的本征正交 分 解 （PO D ）、气象学中的经验直交函数（E O F）、结构动力学中的经验模分析 （EMA）、，心理测量学中的Schm idt-M irsky定理等. 卡 尔 •皮 尔 逊 （Karl Pearson, 1857— 1936）在 1901年发明了 P C A .皮尔逊 是一位罕见的百科全书式的学者，他是统计学家、应用数学家、哲学家、历史 学家、民俗学家、宗教学家、人类学家、语言学家，还是社会活动家、教育改 革家、作 家 .1879年他从剑桥大学国王学院数学系毕业，此后到德国海德堡大 学、柏林大学等地游学，涉猎广泛. 1884年他开始在伦敦大学学院（University College L o n d o n ,简 称 UCL）担任应用数学讲席教授，3 9 岁时成为英国皇家学 会 会 士 .他 在 1892年出版的科学哲学经典名著《科学的规范》，为爱因斯坦创 立相对论提供了启发.皮尔逊对统计学作出了极为重要的贡献,例如他提出了 相关系数、标准差、卡方检验、矩估计等，并为假设检验理论、统计决策理论 奠定了基础，被 尊 为 “统计学之父”. 皮尔逊开展统计学研究是因受到了生物学家F. G a lto n 和 W. W e lto n 的影 响，希望使进化论能进行定量描述和分析.1901年他们三人创立了著名的统计 学 期 刊 Biometrika,皮尔逊担任主编直至去世.皮尔逊的独子E g o n 也是著名",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 525
    }
  },
  {
    "page_content": "相关系数、标准差、卡方检验、矩估计等，并为假设检验理论、统计决策理论 奠定了基础，被 尊 为 “统计学之父”. 皮尔逊开展统计学研究是因受到了生物学家F. G a lto n 和 W. W e lto n 的影 响，希望使进化论能进行定量描述和分析.1901年他们三人创立了著名的统计 学 期 刊 Biometrika,皮尔逊担任主编直至去世.皮尔逊的独子E g o n 也是著名 统计学家，是 著 名 的 “奈曼-皮尔逊定理” 中的皮尔逊，他 子 承 父 业 出 任 UCL 的统计学教授以及氏。小况,如i 主编，后来担任了英国皇家统计学会主席. Galton是达尔文的表弟, '优生学”发明人. 第 口 章 特 征 选 择 与 稀 疏 学 习 1 1 .1 子集搜索与评价 我们能用很多属性描述一个西瓜，例如色泽、根 蒂 、敲 声 、纹 理 、触感 等，但有经验的人往往只需看看根蒂、听听敲声就知道是否好瓜.换言之，对 一个学习任务来说，给定属性集，其中有些属性可能很关键、很有用，另一些 属 性 则 可 能 没 什 么 用 .我 们 将 属 性 称 为 “特征”(feature),对当前学习任务有 用 的 属 性 称 为 “相关特征”(relevant feature)、没什么用的属性称为“无关特 征 \" (irrelevant feature).从给定的特征集合中选择出相关特征子集的过程，称 为 “特 征 选 择 \"(feature selection). 特征选择是一个重要的“数据预处理”(data preprocessing)过程，在现实 机器学习任务中，获得数据之后通常先进行特征选择，此后再训练学习器.那 么，为什么要进行特征选择呢？ 有两个很重要的原因：首先，我们在现实任务中经常会遇到维数灾难问题, 这是由于属性过多而造成的，若能从中选择出重要的特征，使得后续学习过程 仅需在一部分特征上构建模型，则维数灾难问题会大为减轻.从这个意义上说, 特征选择与第10章介绍的降维有相似的动机；事实上，它们是处理高维数据的 两大主流技术.第二个原因是，去除不相关特征往往会降低学习任务的难度，这 就像侦探破案一样，若将纷繁复杂的因素抽丝剥茧，只留下关键因素，则真相往 往更易看清. 需注意的是，特征选择过程必须确保不丢失重要特征，否则后续学习过程 会因为重要信息的缺失而无法获得好的性能.给定数据集，若学习任务不同，则 相关特征很可能不同，因此，特 征 选 择 中 所 谓 的 “无关特征”是指与当前学习 任务无关.有一类特征称为“冗 余 特 征 \"(redundant feature),它们所包含的信 息能从其他特征中推演出来.例如，考虑立方体对象，若 已 有 特 征 “底面长”",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 526
    }
  },
  {
    "page_content": "会因为重要信息的缺失而无法获得好的性能.给定数据集，若学习任务不同，则 相关特征很可能不同，因此，特 征 选 择 中 所 谓 的 “无关特征”是指与当前学习 任务无关.有一类特征称为“冗 余 特 征 \"(redundant feature),它们所包含的信 息能从其他特征中推演出来.例如，考虑立方体对象，若 已 有 特 征 “底面长” “底面宽”, 则 “底面积”是冗余特征，因 为 它 能 从 “底面长”与 “底面宽” 得到.冗余特征在很多时候不起作用，去除它们会减轻学习过程的负担.但有 时冗余特征会降低学习任务的难度，例如若学习目标是估算立方体的体积，则 “底面积”这个冗余特征的存在将使得体积的估算更容易；更确切地说，若某 个冗余特征恰好对应了完成学习任务所需的“中间概念”，则该冗余特征是有 248 第 n 章特征选择与稀疏学习 益 的 .为 简 化 讨 论 ,本 章 暂 且 假 定 数 据 中 不 涉 及 冗 余 特 征 ，并 且 假 定 初 始 的 特 征 集 合 包 含 了 所 有 的 重 要 信 息 . 欲 从 初 始 的 特 征 集 合 中 选 取 一 个 包 含 了 所 有 重 要 信 息 的 特 征 子 集 ，若 没 有 任 何 领 域 知 识 作 为 先 验 假 设 ，那 就 只 好 遍 历 所 有 可 能 的 子 集 了 ；然 而 这 在 计 算 上 却 是 不 可 行 的 ，因 为 这 样 做 会 遭 遇 组 合 爆 炸 ,特 征 个 数 稍 多 就 无 法 进 行 .可 行 的 做 法 是 产 生 一 个 “候 选 子 集 ” ，评 价 出 它 的 好 坏 ，基 于 评 价 结 果 产 生 下 一 个 候 选 子 集 ,再 对 其 进 行 评 价 ，… … 这 个 过 程 持 续 进 行 下 去 ，直 至 无 法 找 到 更 好 的 候 选 子 集 为 止 .显 然 ，这 里 涉 及 两 个 关 键 环 节 ：如 何 根 据 评 价 结 果 获 取 下 一 个 候 选 特 征 子 集 ？如 何 评 价 候 选 特 征 子 集 的 好 坏 ？ 第 一 个 环 节 是 “子 集 搜 索 ” (subset search计句 题 . 给 定 特 征 集 合 ｛肉, 。2, • • • , h ｝, 我 们 可 将 每 个 特 征 看 作 一 个 候 选 子 集 ，对 这 d 个 候 选 单 特 征 子 集 进 行 评 价 ，假 定 ｛« 2 ｝最 优 ，于 是 将 ｛念 ｝作 为 第 一 轮 的 选 定 集 ；然 后 ，在 上 一 轮 的 选 定 集 中 加 入 一 个 特 征 ，构 成 包 含 两 个 特 征 的 候 选 子 集 ,假 定 在 这 d - 1 个",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 527
    }
  },
  {
    "page_content": "集 进 行 评 价 ，假 定 ｛« 2 ｝最 优 ，于 是 将 ｛念 ｝作 为 第 一 轮 的 选 定 集 ；然 后 ，在 上 一 轮 的 选 定 集 中 加 入 一 个 特 征 ，构 成 包 含 两 个 特 征 的 候 选 子 集 ,假 定 在 这 d - 1 个 候 选 两 特 征 子 集 中 ｛。2,。4｝最 优 ，且 优 于 ｛。2｝, 于 是 将 ｛。2,的 ｝作 为 本 轮 的 选 定 集 ；… …假 定 在 第 k + 1 轮 时 ，最 优 的 候 选 ( k + 1 ) 特 征 子 集 不 如 上 一 轮 的 选 定 集 ，则 停 止 生 成 候 选 子 集 ，并 将 上 一 轮 选 定 的 用 特 征 集 合 作 为 特 征 选 择 结 果 . 这 样 逐 渐 增 加 相 关 特 征 的 策 略 称 为 “前 向 ” (forward)搜 索 . 类 似 的 ，若 我 们 从 完 整 的 特 征 集 合 开 始 ，每 次 尝 试 去 掉 一 个 无 关 特 征 ，这 样 逐 渐 减 少 特 征 的 策 略 称 为 “后 向 \" (backward)搜 索 .还 可 将 前 向 与 后 向 搜 索 结 合 起 来 ，每 一 轮 逐 渐 增 加 选 定 相 关 特 征 (这 些 特 征 在 后 续 轮 中 将 确 定 不 会 被 去 除 )、 同 时 减 少 无 关 特 征 ，这 样 的 策 略 称 为 “双 向 \" (bidirectional)搜索. 显 然 ，上 述 策 略 都 是 贪 心 的 ，因 为 它 们 仅 考 虑 了 使 本 轮 选 定 集 最 优 ,例 如 在 第 三 轮 假 定 选 择 的 优 于 。6 , 于 是 选 定 集 为 ｛念,。4 , % ｝, 然 而 在 第 四 轮 却 可 能 是 ｛3 , 。4,。6,四 ｝比 所 有 的 ｛仞,。4,。5,电｝都 更 优 . 遗 憾 的 是 ，若 不 进 行 穷 举 搜 索 , 则 这 样 的 问 题 无 法 避 免 . 第 二 个 环 节 是 “子 集 评 价 \" (subset evaluation)问 题 . 给 定 数 据 集 假 定 。 中 第 E 类 样 本 所 占 的 比 例 为 此 ( 分 = 1,2,..., |川 ).为 便 于 讨 论 ，假 定 样 本 属 性 均 为 离 散 型 . 对 属 性 子 集 4 假 定 根 据 其 取 值 将 D 分 成 了 V 个 子 集 ｛。1,。2,...,。卜｝, 每 个 子 集 中 的 样 本 在 4 上 取 值 相 同 ，于 是 我 们 可 计 算 属 性 子 集 4 的 信 息 增 益 G a i n ( A ) = E n t ( B ) - £",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 528
    }
  },
  {
    "page_content": "本 属 性 均 为 离 散 型 . 对 属 性 子 集 4 假 定 根 据 其 取 值 将 D 分 成 了 V 个 子 集 ｛。1,。2,...,。卜｝, 每 个 子 集 中 的 样 本 在 4 上 取 值 相 同 ，于 是 我 们 可 计 算 属 性 子 集 4 的 信 息 增 益 G a i n ( A ) = E n t ( B ) - £ 鲁 E n t ( Z T ) , (11.1) V=1 I ' 亦 称 子 集 “生成与搜 索”. 假设每个属性有v 个可 取值，则U = o⑷，这可能 是一个很大的值，因此实 践中通常是从子集搜索过 程中前一轮属性子集的评 价值出发来进行计算. 1 1 . 2 过滤式选择 249 参 见 4.2.1节. 其中信息嫡定义为 许 多 “多 样 性 度 量 ”， 如不合度量、相关系数等, 稍加调整即可用于特征子 集评价,参见8 5 2 节. 3 E n t ( D ) = log2 P/c , ( U . 2 ) 信 息 增 益 G a i n ( A ) 越大，意味着特征子集A 包含的有助于分类的信息越多.于 是，对每个候选特征子集，我们可基于训练数据集。 来计算其信息增益，以此 作为评价准则. 更一般的，特 征子集A 实际上确定了对数据集D 的一个划分，每个划分区 域对应着A 上的一个取值,而样本标记信息K 则对应着对D 的真实划分,通过 估算这两个划分的差异，就 能 对 A 进 行 评 价 .与 K 对应的划分的差异越小，则 说 明 4 越好.信息嫡仅是判断这个差异的一种途径，其他能判断两个划分差异 的机制都能用于特征子集评价. 将特征子集搜索机制与子集评价机制相结合，即可得到特征选择方法.例 如将前向搜索与信息嫡相结合,这显然与决策树算法非常相似.事实上，决策树 可用于特征选择，树结点的划分属性所组成的集合就是选择出的特征子集.其 他的特征选择方法未必像决策树特征选择这么明显，但它们在本质上都是显式 或隐式地结合了某种(或多种)子集搜索机制和子集评价机制. 常见的特征选择方法大致可分为三类：过滤式(filter)、包裹式( w r a p p e r )和. 嵌入式( e m b e d d i n g ) . 1 1 .2 过滤式选择 过滤式方法先对数据集进行特征选择，然后再训练学习器，特征选择过程 与后续学习器无关.这相当于先用特征选择过程对初始特征进行“过 滤 ”，再 用过滤后的特征来训练模型. Relief (Relevant Features) [Kira a n d Rendell, 1 9 9 2 ] 是一种著名的过滤式",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 529
    }
  },
  {
    "page_content": "1 1 .2 过滤式选择 过滤式方法先对数据集进行特征选择，然后再训练学习器，特征选择过程 与后续学习器无关.这相当于先用特征选择过程对初始特征进行“过 滤 ”，再 用过滤后的特征来训练模型. Relief (Relevant Features) [Kira a n d Rendell, 1 9 9 2 ] 是一种著名的过滤式 特征选择方法，该 方 法 设 计 了 一 个 “相关统计量”来度量特征的重要性.该统 计量是一个向量，其每个分量分别对应于一个初始特征，而特征子集的重要性 则是由子集中每个特征所对应的相关统计量分量之和来决定.于是，最终只需 指定一个阈值T , 然后选择比丁大的相关统计量分量所对应的特征即可;也可指 定欲选取的特征个数h 然后选择相关统计量分量最大的k 个特征. 显 然 ，R e l i e f 的 关 键 是 如 何 确 定 相 关 统 计 量 . 给 定 训 练 集 ｛(叫,阴)， (« 2 ,2 /2 ), . . . , 对 每 个 示 例 叫 R e l i e f先 在 g 的 同 类 样 本 中 寻 找 其 最 近 邻 0 剑 ，称 为 “猜中近邻”(near-hit),再 从 g 的异类样本中寻找其最 250 第 1 1 章 特征选择与稀疏学习 R e lie f中相关统计量的 计算已隐然具有距离度量 学习的意味.距离度量学 习参见10.6节. 近 邻 W n m , 称 为 “猜错近邻”（n e a r - m i s s ）, 然后，相关统计量对应于属性^的 分量为 献 = £ _ 也 任 （婢，戏出产+也任（* % 皿 产 ， （口3 i 其 中 xj a 表 示 样 本 g 在 属 性 3'上的取值,diff（也 , 取 决 于 属 性 ^ 的 类 型 ：若 属 性 ^为 离 散 型 ，则 嫄 = / 时 d i f f H ，4 ）= 0 , 否 则 为 1 ; 若 属 性 3.为连续型， 则 diff（% 域）= \\xl - x{\\,注 意 也,也已规范化到［0 , 1 ］区间. 从式（1 1 . 3 ）可看出，若 Xi与其猜中近邻宓*吐在属性3 上的距离小于g 与 其猜错近邻吃,n m 的距离，则说明属性^对区分同类与异类样本是有益的，于是 增大属性^所对应的统计量分量；反 之 ,若 g 与其猜中近邻g , n h 在属性 3•上的 距 离 大 于 X i 与其猜错近邻 g , n m 的距离，则说明属性^起负面作用，于是减小 属 性 7 所对应的统计量分量.最后，对基于不同样本得到的估计结果进行平均, 就得到各属性的相关统计量分量,分量值越大，则对应属性的分类能力就越强.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 530
    }
  },
  {
    "page_content": "增大属性^所对应的统计量分量；反 之 ,若 g 与其猜中近邻g , n h 在属性 3•上的 距 离 大 于 X i 与其猜错近邻 g , n m 的距离，则说明属性^起负面作用，于是减小 属 性 7 所对应的统计量分量.最后，对基于不同样本得到的估计结果进行平均, 就得到各属性的相关统计量分量,分量值越大，则对应属性的分类能力就越强. 式 （1 1 . 3 ）中的分指出了用于平均的样本下标.实际上R e l i e f 只需在数据集的 采样上而不必在整个数据集上估计相关统计量［K i r a a n d R e n d e l l , 1 9 9 2 ］. 显然, R e l i e f 的时间开销随采样次数以及原始特征数线性增长，因此是一个运行效率 很高的过滤式特征选择算法. R e l i e f 是为二分类问题设计的，其扩 展 变 体 Relief-F ［K o n o n e n k o , 1 9 9 4 ］能 处理多分类问题.假定数据集。 中 的样本来自3 个 类 别 . 对 示 例 若 它 属 于 第 k 类 （k G { 1 , 2 , , 3 } , 则 R e l i e f - F 先 在 第 k 类的样本中寻找g 的最近 邻 示 例 0 触并将其作为猜中近邻，然 后 在 第 k 类之外的每个类中找到一个g 的最近邻示例作为猜错近邻，记为电工n m 。= 1 2 … ，3 ；厅 于 是 ，相关 统计量对应于属性/的分量为 M = diff（您 姆 灿 产 + 工 伍 义 岬 点 或 皿 产 ） ， （1 1 . 4 ） i l^k 其 中 Pl为 第 I类样本在数据集D 中所占的比例. 1 1 .3 包裹式选择 与过滤式特征选择不考虑后续学习器不同，包裹式特征选择直接把最终将 要使用的学习器的性能作为特征子集的评价准则.换言之，包裹式特征选择的 目的就是为给定学习器选择最有利于其性能、 “量身定做”的特征子集. 一般而言，由于包裹式特征选择方法直接针对给定学习器进行优化，因此 1 1 . 3 包裹式选择 251 拉斯维加斯方法和蒙特 卡罗方法是两个以著名赌 城名字命名的随机化方法. 两者的主要区别是：若有 时间限制，则拉斯维加斯 方法或者给出满足要求的 解，或者不给出解，而蒙 特卡罗方法一定会给出解， 虽然给出的解未必满足要 求；若无时间限制，则两者 都能给出满足要求的解. 初始化. 在特征子集H 上通过 交叉验证估计学习器误差. 若连续T 轮未更新则算 法停止. 从 最 终 学 习 器 性 能 来 看 ，包 裹 式 特 征 选 择 比 过 滤 式 特 征 选 择 更 好 ，但 另 一 方 面 ,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 531
    }
  },
  {
    "page_content": "初始化. 在特征子集H 上通过 交叉验证估计学习器误差. 若连续T 轮未更新则算 法停止. 从 最 终 学 习 器 性 能 来 看 ，包 裹 式 特 征 选 择 比 过 滤 式 特 征 选 择 更 好 ，但 另 一 方 面 , 由 于 在 特 征 选 择 过 程 中 需 多 次 训 练 学 习 器 ，因 此 包 裹 式 特 征 选 择 的 计 算 开 销 通 常 比 过 滤 式 特 征 选 择 大 得 多 . L V W (Las V e g a s W r a p p e r ) [Liu a n d Setiono, 1 9 9 6 ] 是 一 个 典 型 的 包 裹 式 特 征 选 择 方 法 . 它 在 拉 斯 维 加 斯 方 法 (Las V e g a s m e t h o d ) 框 架 下 使 用 随 机 策 略 来 进 行 子 集 搜 索 ，并 以 最 终 分 类 器 的 误 差 为 特 征 子 集 评 价 准 则 . 算 法 描 述 如 图 1 1 」 所示. 输 入 ：数 据 集 R 特 征 集 A ； 学 习 算 法 £; 停 止 条 件 控 制 参 数 T. 过 程 ： V. E — oo; 2: d = a ; 3: A* = A; 4: t = 0; 5： w h ile < T d o 6： 随 机产生特征 子集 7: 8： d' = E f = CrossValidation(£(Z)j 4 )); V E ) V ( (E，= E ) 八(成 < d)) t h e n i f 3 t = 0; E = E r- d = d!; 4 * = A f 9： 10： 11： 12： 13: 14： 15: 16： 17： e n d w h ile 输 出 ：特 征 子 集 4 * ,__________________________________________ 七 =力 + 1 e n d i f e ls e 图 1 L 1 L V W 算 法描述 图 1 1 . 1 算 法 第 8 行 是 通 过 在 数 据 集 D 上 ，使 用 交 叉 验 证 法 来 估 计 学 习 器 £ 的 误 差 ，注 意 这 个 误 差 是 在 仅 考 虑 特 征 子 集 A f 时 得 到 的 ，即 特 征 子 集 A r 上 的 误 差 ，若 它 比 当 前 特 征 子 集 4 上 的 误 差 更 小 ，或 误 差 相 当 但 H 中 包 含 的 特 征 数 更 少 ，则 将 4 保 留 下 来 .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 532
    }
  },
  {
    "page_content": "£ 的 误 差 ，注 意 这 个 误 差 是 在 仅 考 虑 特 征 子 集 A f 时 得 到 的 ，即 特 征 子 集 A r 上 的 误 差 ，若 它 比 当 前 特 征 子 集 4 上 的 误 差 更 小 ，或 误 差 相 当 但 H 中 包 含 的 特 征 数 更 少 ，则 将 4 保 留 下 来 . 需 注 意 的 是 ，由 于 L V W 算 法 中 特 征 子 集 搜 索 采 用 了 随 机 策 略 , 而 每 次 特 征 子 集 评 价 都 需 训 练 学 习 器 ，计 算 开 销 很 大 ，因 此 算 法 设 置 了 停 止 条 件 控 制 参 数 T . 然 而 ，整 个 L V W 算 法 是 基 于 拉 斯 维 加 斯 方 法 框 架 ，若 初 始 特 征 数 很 多 ( 即 | A | 很 大 ) 、 T 设 置 较 大 ，则 算 法 可 能 运 行 很 长 时 间 都 达 不 到 停 止 条 件 . 换 言 之 , 252 第 n 章特征选择与稀疏学习 若有运行时间限制，则有可能给不出解. 1 1 .4 嵌入式选择与J 正则化 在过滤式和包裹式特征选择方法中，特征选择过程与学习器训练过程有明 显的分别；与此不同，嵌入式特征选择是将特征选择过程与学习器训练过程融 为一体，两者在同一个优化过程中完成，即在学习器训练过程中自动地进行了 特征选择. 给定数据集。 = {(CC1,7/1),(0:2, 2/2), . . . , (®m, Vm )},其中 « G 们考虑最简单的线性回归模型，以平方误差为损失函数，则优化目标为 7/ E R . 我 m m i n £ (% - w T x i ')2 . 2=1 (11.5) 正则化参见6 .4 节. 缓解过拟合问题,可对式(11.5)引入正则化项.若使用L2 范数正则化，则有 当样本特征很多，而样本数相对较少时，式(11.5)很容易陷入过拟合.为了 m 噌 £ (亚一 w T Xi)2 + A||w||2 . (11.6) i=l 岭 回 归 最 初 由 A. Tikhonov在 1 9 4 3 年发表 于 《苏 联 科 学 院 院 刊 》， 因 此 亦 称 “T ikh o n o v回 归”，而 1_2正则化亦称 “Tikhonov 正则化”. 其 中 正 则 化 参 数1 > 0 . 式(11.6)称 为 “岭回归\" (ridge regression) [Tikhonov and Arsenin, 1977],通过引入L2 范数正则化，确能显著降低过拟合的风险. 那么，能否将正则化项中的L 2 范 数 替 换 为 及 范 数 呢 ？答案是肯定的.若",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 533
    }
  },
  {
    "page_content": "其 中 正 则 化 参 数1 > 0 . 式(11.6)称 为 “岭回归\" (ridge regression) [Tikhonov and Arsenin, 1977],通过引入L2 范数正则化，确能显著降低过拟合的风险. 那么，能否将正则化项中的L 2 范 数 替 换 为 及 范 数 呢 ？答案是肯定的.若 令 p = l , 即采用L 1范数，则有 m 嗯 n £ (% —w T Xi)2 + A||w||i . (11.7) 2=1 直 译 为 “最小绝对收缩 选择算子”，由于比较拗 口，因此一般直接称LAS­ SO. 事实上，对 每 施 加 “稀 疏约束”(即 希 望w 的非 零分量尽可能少)最自然 的 是 使 用 Lo 范数，但 Lo 范数不连续，难以优化求 解，因此常使用L i 范数来 近似. 其中正则化参数 A > 0 . 式(11.7)称为 LASSO (Least Absolute Shrinkage and Selection Operator) [Tibshirani, 1996]). . L i 范 数 和 L2 范数正则化都有助于降低过拟合风险，但前者还会带来一个 额外的好处：它 比 后 者 更 易 于 获 得 “稀 疏 ”(sparse)解，即它求得的馍会有更 少的非零分量. 为了理解这一点，我们来看一个直观的例子：假定况仅有两个属性，于是 无论式(U .6)还是(11.7)解出的叨都只有两个分量，即 w1 , w2 , 我们将其作为两 个坐标轴，然后在图中绘制出式(H.6)与(11.7)的 第 一 项 的 “等 值 线 ”，即在 1 1 . 4 嵌入式选择与L i 正则化 253 (w i,w 2 ) 空间中平方误差项取值相同的点的连线，再分别绘制出 L 1 范 数 与 L 2 范数的等值线，即 在 ® 1 ,\" 2 ) 空 间 中 L I 范数取值相同的点的连线，以 及 L 2 范 数取值相同的点的连线，如 图 H .2 所 示 .式 (1 1 .6 )与(11.7)的解要在平方误差项 与正则化项之间折中，即出现在图中平方误差项等值线与正则化项等值线相交 处 . 由 图 1 1 .2 可看出，采 用 L i 范数时平方误差项等值线与正则化项等值线的 交点常出现在坐标轴上，即 叫 或 \" 2 为 0 , 而 在 采 用 L 2 出现在某个象限中，即 w i 或 w2 得到稀疏解. 均 非 0 ; 换言之，采 用 J 范 数 比 L 2 范数时，两者的交点常 范数更易于",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 534
    }
  },
  {
    "page_content": "处 . 由 图 1 1 .2 可看出，采 用 L i 范数时平方误差项等值线与正则化项等值线的 交点常出现在坐标轴上，即 叫 或 \" 2 为 0 , 而 在 采 用 L 2 出现在某个象限中，即 w i 或 w2 得到稀疏解. 均 非 0 ; 换言之，采 用 J 范 数 比 L 2 范数时，两者的交点常 范数更易于 注 意 到 w 取得稀疏解意味着初始的d 个特征中仅有对应着w 的非零分量 的特征才会出现在最终模型中，于是，求 解 J 范数正则化的结果是得到了仅采 之非 用一部分初始特征的模型；换言之，基 于 J 正则化的学习方法就是一种嵌入式 即选择出对应于 零分量的特征. 特征选择方法，其特征选择过程与学习器训练过程融为一体，同时完成. L i 正则化问题的求解可使用近端梯度下降 (Proximal Gradient Descent, 简 称 PGD) [Boyd and Vandenberghe, 2 0 0 4 ].具体来说，令 ▽表示微分算子，对 优化目标 mXin / Q ) + 础 i , (11.8) 若 于⑷ 可导，且 ▽ /满 足 L-Lipschitz条件，即存在常数L > 0 使得 ■ ■ ) - W Q ) ] < — 司 ； ( V / J (11.9) 254 第 口 章 特征选择与稀疏学习 则 在Xk 附近可将f(x)通过二阶泰勒展式近似为 人 /(«) 1 4 3 ) + (yf(xk\\x- xk) + -\\\\x - xk\\\\2 L = 1 北一 ( 磔 —卷▽ / ( * ) J + const, (11.10) 其 中 co n st是与况无关的常数，《,•)表示内积.显然，式(11.10)的最小值在如下 3 + 1 获得： 宓k+l = L , (11-11) 于是，若通过梯度下降法对/(⑼进行最小化，则每一步梯度下降迭代实际 上等价于最小化二次函数/ Q ) . 将这个思想推广到式( 1 L 8 ) ,则能类似地得到 其每一步迭代应为 xk+1 = arg min | 0 一 ( g - 程▽ / ( * ) 1 + A||o?||i , (11.12) 即在每一步对/ Q ) 进行梯度下降迭代的同时考虑L i 范数最小化. 对于式(11.12),可先计算n = 以 — 然后求解 3 + i = a x g m i n g | a j - N 隙 + 1|罔 L • (11.13) x 幺 习题 11.8.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 535
    }
  },
  {
    "page_content": "(11.12) 即在每一步对/ Q ) 进行梯度下降迭代的同时考虑L i 范数最小化. 对于式(11.12),可先计算n = 以 — 然后求解 3 + i = a x g m i n g | a j - N 隙 + 1|罔 L • (11.13) x 幺 习题 11.8. 令 ^ 表 示 比 的 第 £ 个分量，将式 (11.13)按分量展开可看出，其中不存在 (i* j)这样的项，即 z 的各分量互不影响，于是式(11.13)有闭式解 ' / - A/L, X/L < ; 4 + 1 - 0, ⑻ W X / L ； 、/ + A / L ,d < -X/L , (11.14) 其 中 4 + 1 与 分 别 是 Xk +1 与 N 的第分个分量 因 此 通 过 P G D 能 使 L A S S O 和其他基于J 范数最小化的方法得以快速求解. 1 1 .5 稀疏表示与字典学习 不妨把数据集D 考虑成一个矩阵，其每行对应于一个样本，每列对应于一 个特征.特征选择所考虑的问题是特征具有“稀疏性”，即矩阵中的许多列与 当前学习任务无关，通过特征选择去除这些列，则学习器训练过程仅需在较小 1 1 . 5 稀疏表示与字典学习 255 模型涉及的输入因素减 少了，模 型 所 建 立 的 “输 入-输出”关系会更清晰. 这里为了用汉语来举例 说明，我们回避了分词问 题,仅谈论汉字. 的矩阵上进行，学习任务的难度可能有所降低，涉及的计算和存储开销会减少, 学得模型的可解释性也会提高. 现在我们来考虑另二种稀疏性：。 所对应的矩阵中存在很多零元素，但这 些零元素并不是以整列、整行形式存在的.在不少现实应用中我们会遇到这样 的情形，例如在文档分类任务中，通常将每个文档看作一个样本，每个字（词）作 为一个特征，字（词）在文档中出现的频率或次数作为特征的取值；换言之，D 所对应的矩阵的每行是一个文档，每 列 是 一 个 字 （词），行 、列交汇处就是某 字（词）在某文档中出现的频率或次数.那么，这个矩阵有多少列呢？以汉语为 例， 《康熙字典》中 有47035个汉字，这意味着该矩阵可有4 万多列，即便仅考 虑 《现代汉语常用字表》中的汉字，该矩阵也有3500歹！J . 然而，给定一个文档, 相当多的字是不出现在这个文档中的，于是矩阵的每一行都有大量的零元素; 对不同的文档，零元素出现的列往往很不相同. 当样本具有这样的稀疏表达形式时,对学习任务来说会有不少好处，例如 参 见 6 . 3 节 和 1 2 .4 节. 用上述的字频表示后具有高度的稀疏性，使大多数问题变得线性可分.同时,稀",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 536
    }
  },
  {
    "page_content": "虑 《现代汉语常用字表》中的汉字，该矩阵也有3500歹！J . 然而，给定一个文档, 相当多的字是不出现在这个文档中的，于是矩阵的每一行都有大量的零元素; 对不同的文档，零元素出现的列往往很不相同. 当样本具有这样的稀疏表达形式时,对学习任务来说会有不少好处，例如 参 见 6 . 3 节 和 1 2 .4 节. 用上述的字频表示后具有高度的稀疏性，使大多数问题变得线性可分.同时,稀 线性支持向量机之所以能在文本数据上有很好的性能，恰是由于文本数据在使 字 典 亦 称 “码 书 ” （codebook）. 字 典 学 习 亦 称 “码书学 习” （codebook learning）. 疏样本并不会造成存储上的巨大负担，因为稀疏矩阵已有很多高效的存储方法. 那么，若 给 定 数 据 集 。 是稠密的，即普通非稀疏数据，能否将其转化为 “稀 疏 表 示 \"（sparse representation）形式，从而享有稀疏性所带来的好处呢? 需注意的是,我们所希望的稀疏表示是“恰当稀疏”，而 不 是 “过度稀疏”.仍 以汉语文档为例，基 于 《现代汉语常用字表》得到的可能是恰当稀疏，即其稀 疏性足以让学习任务变得简单可行；而 基 于 《康熙字典》则可能是过度稀疏, 与前者相比，也许并未给学习任务带来更多的好处. 显然，在一般的学习任务中（例如图像分类）并 没 有 《现代汉语常用字表》 可用，我 们 需 学 习 出 这 样 一 个 “字 典 ”.为普通稠密表达的样本找到合适的 字典，将 样 本 转 化为合适的稀疏表示形式，从 而 使 学 习 任务得以简化，模型 复杂度得以降低，通 常 称 为 “字 典 学 习 \"（dictionary learning）, 亦 称 “稀疏编 码 \" （sparse coding）. 这两个称谓稍有差别，“字典学习”更侧重于学得字典的 过程，而 “稀疏编码”则更侧重于对样本进行稀疏表达的过程.由于两者通常 是在同一个优化求解过程中完成的，因此下面我们不做进一步区分，笼统地称 为字典学习. 给定数据集{ x i,g , … ，xm },字典学习最简单的形式为 m m g i i n £ 忸 一B a j 修+ 入 £ | 心 仙 ， （11.15） 256 第 1 1 章 特征选择与稀疏学习 其 中 B € 肽获k 为字典矩阵，k 称为字典的词汇量,通常由用户指定， 是 样 本 X i 6 肽d 的稀疏表示.显然，式(U .15)的第一项是希望由以能很好地重 构 g , 第二项则是希望以尽量稀疏. 则 与 LASSO相比，式(11.15)显然麻烦得多，因为除了类似于式(11.7)中 w 的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 537
    }
  },
  {
    "page_content": "（11.15） 256 第 1 1 章 特征选择与稀疏学习 其 中 B € 肽获k 为字典矩阵，k 称为字典的词汇量,通常由用户指定， 是 样 本 X i 6 肽d 的稀疏表示.显然，式(U .15)的第一项是希望由以能很好地重 构 g , 第二项则是希望以尽量稀疏. 则 与 LASSO相比，式(11.15)显然麻烦得多，因为除了类似于式(11.7)中 w 的 他 还 需 学 习 字 典 矩 阵 B . 不过，受 LASSO的启发，我们可采用变量交替优化 的策略来求解式(11.15). 首先在第一步，我们固定住字典B , 若将式(11.15)按分量展开,可看出其中 不 涉 及 球 球 (〃* 。)这样的交叉项，于 是 可 参 照 LASSO的解法求解下式，从 而为每个样本电找到相应的 min \\\\xi - B a i\\\\l + 入1依 仙 • oti (11.16) 在第二步，我们固定住5 来更新字典B , 此时可将式(U.15)写为 i m n ||X - B A ||^ (11.17) 其中 X = (% 如 … ，而 ) e R d x m , A = ( a i , a 2 , . . . , «m) € Rf c x m , || • ||F 是 矩 阵 的 处 obenius范 数 .式 (11.17)有多种求解方法，常用的有基于逐列更新策 略 的 KSVD [Aharon et al.5 2006].令 仇 表 示 字 典 矩 阵 B 的 第 i 歹U,持 表 示 稀 疏 矩 阵 A 的 第i 行，式(11.17)可重写为 m in ||X - B A ||^ = 叫 X B ? 叫 = min || [ X — = min ||Ei - 仇a 2 H . (11.18) 在更新字典的第i 列时，其他各列都是固定的，因 此 电 = £ 计 也 & 是固定的, 于是最小化式(11.18)原则上只需对&进行奇异值分解以取得最大奇异值所对 应的正交向量.然而，直 接 对 & 进 行 奇 异 值 分 解 会 同 时 修 改 仇 和 从 而 可 能 破 坏 A 的稀疏性.为避免发生这种情况,KSVD对 & 和 5 进行专门处理: M 仅保留非零元素,& 则仅保留& 与 W 的非零元素的乘积项，然后再进行奇 异值分解，这样就保持了第一步所得到的稀疏性. 1 1 . 6 压缩感知 257 初始化字典矩阵B 之后反复迭代上述两步，最终即可求得字典B 和样本 g 的稀疏表示以.在上述字典学习过程中，用户能通过设置词汇量k 的大小来 控制字典的规模,从而影响到稀疏程度. 1 1 .6 压缩感知",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 538
    }
  },
  {
    "page_content": "M 仅保留非零元素,& 则仅保留& 与 W 的非零元素的乘积项，然后再进行奇 异值分解，这样就保持了第一步所得到的稀疏性. 1 1 . 6 压缩感知 257 初始化字典矩阵B 之后反复迭代上述两步，最终即可求得字典B 和样本 g 的稀疏表示以.在上述字典学习过程中，用户能通过设置词汇量k 的大小来 控制字典的规模,从而影响到稀疏程度. 1 1 .6 压缩感知 在现实任务中，我们常希望根据部分信息来恢复全部信息.例如在数据通 奈奎斯特采样定理提供 了信号恢复的充分条件而 非必要条件. 讯中要将模拟信号转换为数字信号，根 据 奈 奎 斯 特 (Nyquist)采样定理，令采 样频率达到模拟信号最高频率的两倍，则采样后的数字信号就保留了模拟信号 的全部信息；换言之，由此获得的数字信号能精确重构原模拟信号.然而，为了 便于传输、存储，在实践中人们通常对采样的数字信号进行压缩，这有可能损 失一些信息，而在信号传输过程中，由于信道出现丢包等问题，又可能损失部 分信息.那么，接收方基于收到的信号，能否精确地重构出原信号呢？压缩感 知(compressed sensing) [Donoho, 2006; Candes et al., 2006]为解决此类问题提 供了新的思路. 亦称 compressive sens­ ing. y 亦 称 “测量值”. 要求的采样率进行采样，得到长度为n 的采样后信号期， 即 假定有长度为m 的离散信号叫不妨假定我们以远小于奈奎斯特采样定理 y = ①比, (11.19) 其 中 ① W R - x - 是对信号* 的测量矩阵，它确定了以什么频率进行采样以及如 何将采样样本组成采样后的信号. 在已知离散信号z 和测量矩阵①时要得到测量值y 很容易，然而，若将测 量值和测量矩阵传输出去，接收方能还原出原始信号x 吗？ 一 般 来 说 ，答 案 是 “ No” ，这 是 由 于 几 《 m , 因 此 y x , ① 组成的 式(1L19)是一个欠定方程，无法轻易求出数值解. 假 定 SD本身不是稀疏的. 现在不妨假设存在某个线性变换9 e Rm x m , 使 得 x 可表示为4 s , 于 是 y 可表示为 y = ①亚s = A.S , (11.20) 其 中 A = m亚 € Rn x m . 于是，若 能根据y 恢 复 出 s , 则可通过x = ^ s 来恢复 出信号X. 粗看起来式(11.20)没有解决任何问题，因为式(11.20)中恢复信号s 这个逆 问题仍是欠定的.然而有趣的是，若 s 具有稀疏性，则这个问题竟能很好地得 258 第 1 1 章 特征选择与稀疏学习",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 539
    }
  },
  {
    "page_content": "(11.20) 其 中 A = m亚 € Rn x m . 于是，若 能根据y 恢 复 出 s , 则可通过x = ^ s 来恢复 出信号X. 粗看起来式(11.20)没有解决任何问题，因为式(11.20)中恢复信号s 这个逆 问题仍是欠定的.然而有趣的是，若 s 具有稀疏性，则这个问题竟能很好地得 258 第 1 1 章 特征选择与稀疏学习 以解决！这是因为稀疏性使得未知因素的影响大为减少.此时式(11.20)中的亚 称为稀疏基，而 A 的作用则类似于字典，能将信号转换为稀疏表示. 事实上,在很多应用中均可获得具有稀疏性的s , 例如图像或声音的数字信 号通常在时域上不具有稀疏性,但经过傅里叶变换、余弦变换、小波变换等处 理后却会转化为频域上的稀疏信号. 显然，与特征选择、稀疏表示不同，压缩感知关注的是如何利用信号本身 所具有的稀疏性,从部分观测样本中恢复原信号.通常认为，压 缩 感 知 分 为 “感 知测量”和 “重构恢复”这 两 个 阶 段 .“感知测量”关注如何对原始信号进行 处理以获得稀疏样本表示，这方面的内容涉及傅里叶变换、小波变换以及11.5 节介绍的字典学习、稀疏编码等，不少技术在压缩感知提出之前就已在信号处 理等领域有很多研究；“重构恢复”关注的是如何基于稀疏性从少量观测中恢 复原信号，这是压缩感知的精髓，当我们谈到压缩感知时,通常是指该部分. 压 缩 感 知 的 相 关 理 论 比 较 复 杂 ，下 面 仅 简 要 介 绍 一 下 “限 定 等 距 性 ” (Restricted Isometry Property,简称 RIP) [Candes, 2008]. 对大小为 n x m (n < m ) 的矩阵A , 若存在常数6k € (0 J ) 使得对于任意 向 量 s 和 A 的所有子矩阵A k e 即 涂 有 ( l - 4 ) | | S | | U | | A ^ | | U ( l + 4 ) | > | | t (11.21) 则 称 A 满 足 A;限定等距性(k-RIP).此时可通过下面的优化问题近乎完美地从 y 中恢复出稀疏信号s , 进而恢复出x ： m i n ||s||o (11.22) s.t. y = A s . 然而,式(11.22)涉 及 L o 范数最小化,这是个N P 难问题.值得庆幸的是,Li 范数最小化在一定条件下与L o 范数最小化问题共解 [Candes et al., 2006],于 是实际上只需关注 m i n ||s||i 8 s.t. y = A s . (11.23) 这样，压缩感知问题就可通过L i 范数最小化问题求解，例如式(11.23)可转化为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 540
    }
  },
  {
    "page_content": "然而,式(11.22)涉 及 L o 范数最小化,这是个N P 难问题.值得庆幸的是,Li 范数最小化在一定条件下与L o 范数最小化问题共解 [Candes et al., 2006],于 是实际上只需关注 m i n ||s||i 8 s.t. y = A s . (11.23) 这样，压缩感知问题就可通过L i 范数最小化问题求解，例如式(11.23)可转化为 1 1 . 6 压缩感知 259 LASSO的等价形式再通过近端梯度下降法求解，即 使 用 “基寻踪去噪”(Basis Pursuit De-Noising) [Chen et al., 1998]. 基于部分信息来恢复全部信息的技术在许多现实任务中有重要应用.例 如网上书店通过收集读者在网上对书的评价，可根据读者的读书偏好来进行新 普 本 「厅 型 的 同 书推荐，从而达到定向广告投放的效果・显然，没有哪位读者读过所有的书，也 过滤” (collaborative filter- 选)任条 没有哪本书被所有读者读过，因此，网上书店所搜集到的仅有部分信息.例如 表 11.1给出了四位读者的网上评价信息，这里评价信息经过处理，形成了 “喜 好程度”评 分 (5 分最高).由于读者仅对读过的书给出评价，因此表中出现了 很 多 未 知 项 . 表 1 L 1 客 户 对 书 的 喜 好 程 度 评 分 《笑 傲 江 湖 》 《万 历 十 五 年 》 《人 间 词 话 》 《云 海 玉 弓 缘 》 《人 类 的 故 事 》 赵大 钱二 孙三 李四 5 ? 5 3 ? 5 3 ? ? 3 ? 5 3 ? ? 4 2 5 ? ? 那么，能 否 将 表 11.1中通过读者评价得到的数据当作部分信号，基于压缩 感知的思想恢复出完整信号呢？ 我们知道，能通过压缩感知技术恢复欠采样信号的前提条件之一是信号 有稀疏表示.读书喜好数据是否存在稀疏表示呢？答案是 肯 定 的 .一 般 情 形 下，读者对书籍的评价取决于题材、作者、装帧等多种因素，为简化讨论,假定 表 11.1中的读者喜好评分仅与题和有关.《笑傲江湖》和 《云海玉弓缘》是武 侠小说， 《万历十五年》和 《人法的故事》是历史读物， 《人间词话》属于诗 词文学.一般来说，相似题材的书籍会有相似的读者，若能将书籍按题材归类, 则题材总数必然远远少于书籍总数，因此从题材的角度来看，表 11.1中反映出 的信号应该是稀疏的.于是,应能通过类似压缩感知的思想加以处理. 亦称\"低秩矩阵恢复”. 矩 阵 补 全 (matrix completion)技 术 [Candes and Recht, 2009]可用于解决 这个问题,其形式为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 541
    }
  },
  {
    "page_content": "词文学.一般来说，相似题材的书籍会有相似的读者，若能将书籍按题材归类, 则题材总数必然远远少于书籍总数，因此从题材的角度来看，表 11.1中反映出 的信号应该是稀疏的.于是,应能通过类似压缩感知的思想加以处理. 亦称\"低秩矩阵恢复”. 矩 阵 补 全 (matrix completion)技 术 [Candes and Recht, 2009]可用于解决 这个问题,其形式为 min rank(X) (11.24) s.t. (X)u = (A)%/, (i, j) W Q, 其中，X 表示需恢复的稀疏信号;ran k (X )表 示 矩 阵 X 的秩;A 是 如 表 11.1的 260 第 1 1 章 特征选择与稀疏学习 读者评分矩阵这样的已观测信号；。是 A 中 非 “？”元 素 (A%・的 下 标( i , j ) 的 集合.式(11.24)的约束项明确指出，恢 复 出 的 矩 阵 中(X )可应当与已观测到的 对应元素相同. 核 范 数 亦 称 “迹 范 数 ” (trace norm). {X e Rm x n : ||X |除 W 1 } 上的凸包是 X 的 “核范数”(nuclear norm): 与式(11.22)相似，式(11.24)也 是 二 个 N P •难问题.注意到ran k (X )在集合 m in {m ,n } ||X ||* = £ 叼(X ), (11.25) 其 中 5 ( X ) 表 示 X 的奇异值，即矩阵的核范数为矩阵的奇异值之和，于是可通 过最小化矩阵核范数来近似求解式(11.24),即 niin ||X||* (11.26) s.t. (X)可= (A)可， (匕)j) w Q S D P 参 见 附 录 B.3. 式(11.26)是一个凸优化问题，可通过半正定规划(Semi-Definite Programming, 简 称 SD P)求解.理论研究表明，在满足一定条件时,若A 的秩为r,n《 m , 则 只需观察到O(mrlog2 m ) 个元素就能完美恢复出A [Recht, 2011]. 1 1 .7 阅读材料 特征选择是机器学习中研究最早的分支领域之一，早期研究主要是按特 征 子 集 “生成与搜索-评价”过程进行.在子集生 成 与 搜 索 方 面 引 入 了 很 多 人工智能搜索技术，如 分支限界法[Narendra and Fukunaga, 1977] ＞浮动搜索 法 [Pudil et a l, 1994]等；在子集评价方面则采用了很多源于信息论的准则,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 542
    }
  },
  {
    "page_content": "特征选择是机器学习中研究最早的分支领域之一，早期研究主要是按特 征 子 集 “生成与搜索-评价”过程进行.在子集生 成 与 搜 索 方 面 引 入 了 很 多 人工智能搜索技术，如 分支限界法[Narendra and Fukunaga, 1977] ＞浮动搜索 法 [Pudil et a l, 1994]等；在子集评价方面则采用了很多源于信息论的准则, 如信息嫡、AIC (Akaike Information Criterion) [Akaike, 1974]等 . [Blum and Langley, 1997]对子集评价准则进行了讨论，[Forman, 2003]则进行了很多实验 比较. . 早期特征选择方法主要是过滤式的，包 裹 式 方 法 出 现 稍 晚 [Kohavi and John, 1997],嵌入式方法事实上更晚[Weston et al., 2003],但由于决策树算法 在构建树的同时也可看作进行了特征选择，因此嵌入式方法也可追溯到ID3 [Quinlan, 1 9 8 6 ].有 很 多 文 献 对 特 征 选 择 方 法 的 性 能 进 行 了 实 验 比 较 [Yang and Pederson, 1997; Jain and Zongker, 1997].更多关于特征选择的内容可参 阅 [Guyon and Elisseeff, 2003; Liu et al., 2010],以及专门关于特征选择的书籍 1 1 . 7 阅读 材 料 261 [Liu and Motoda, 1998, 2007]. 直 译 为 “最小角回归” ， LARS (Least Angle Regression) [Efron et al., 2004]是一种嵌入式特征 通 常 直 接 称 LARS . 仍 以 汉 语 文 档 为 例 ，一 个概念可能由 多 个 字 词 来 表 达 ，这 些 字 词 就 构 成 了 一 个 分 组 ；若 这 个 概 念 在 文 档 中 没 有 出 现 ，则 这整 个分组所 对 应 的 变 量 都 将 为零. 选择方法，它基于线性回归平方误差最小化，每次选择一个与残差相关性最",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 543
    }
  },
  {
    "page_content": "通 常 直 接 称 LARS . 仍 以 汉 语 文 档 为 例 ，一 个概念可能由 多 个 字 词 来 表 达 ，这 些 字 词 就 构 成 了 一 个 分 组 ；若 这 个 概 念 在 文 档 中 没 有 出 现 ，则 这整 个分组所 对 应 的 变 量 都 将 为零. 选择方法，它基于线性回归平方误差最小化，每次选择一个与残差相关性最 大 的 特 征 .LASSO [Tibshirani, 1996]可 通过对LA RS稍加修改而实现.在 LASSO基础上进一步发展出考虑特征分组结构的Group LASSO [Yuan and Lin, 2006]> 考虑特征序结构的 Fused LASSO [Tibshirani et al., 2005]等变体 由于凸性不严格，LASSO类方法可能产生多个解，该问题通过弹性网(Elastic N e t)得以解决[Zou and Hastie, 2005]. 对字典学习与稀疏编码[Aharon et a l, 2006],除了通过控制字典规模从 而影响稀疏性，有时还希望控制字典的“结构”，例如假设字典具有“分组 结构”，即同一个分组内的变量或同为非零，或同为零.这样的性质称为“分 组 稀 疏 性 \"(group sparsity),相应的稀疏编码方法则称为分组稀疏编码(group sparse coding) [Bengio et al., 2009].稀疏编码和分组稀疏编码在图像特征抽取 方面有很多应用，可参阅[Mairal et al., 2008; Wang et al., 2010]. 压 缩 感 知 jDonoho, 2006; Candes et al., 2006]直接催生了人脸识别的 鲁 棒 主 成 分 分 析 [Candes et al., 2011]和 基 于 矩 阵 补 全 的 协 同 过 滤 [Recht [Baraniuk, 2007]是 关 于 压 缩 感 知 的 一 个 简 短 介 绍 .将 L Q 范 et al., 2010]. 数 最 小 化 转 化 为 L i 范数最小化后，常 用 求 解 方 法 除 了 转 化 为 LA SSO 的 基寻踪去噪，还 可 使 用 基 寻 踪 (Basis Pursuit) [Chen et al., 1998]>匹配寻 踪 (Matching Pursuit ) [Mallat and Zhang, 1993]等 . [Liu and Ye, 2009]使",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 544
    }
  },
  {
    "page_content": "用投影法快速 求 解 稀 疏 学 习 问 题 ，并 提 供 了 一 个 稀 疏 学 习 程 序 包 SLEP (http: / / www.yelab.net / software / SLEP/ ) . 262 第 1 1 章特征选择与稀疏学习 习题 西 瓜 数 据 集 3.0见 p.84 I I 1 表 4.3. 试编程实现R elief算法，并考察其在西瓜数据集3 .0 上的运行结果. 11.2 试写 出 R elief-F的算法描述. 11.3 R elief算法是分别考察每个属性的重要性.试设计一个能考虑每一对 属性重要性的改进算法. 11.4 试 为 LV W 设计一个改进算法，即便有运行时间限制，该算法也一定能 给出解. 11.5 结 合 图 11.2,试举例说明L i 正则化在何种情形下不能产生稀疏解. 11.6 试析岭回归与支持向量机的联系. 11.7 试述直接求解Lo 范数正则化会遇到的困难. 11.8 试给出求解L i 范数最小化问题中的闭式解(U .1 4 )的详细推导过程. 11.9 试述字典学习与压缩感知对稀疏性利用的异同. 11.10* 试改进式(11.15),以学习出具有分组稀疏性的字典. 参考文献 263 参考文献 Aharon, M., M. Elad, and A. Bruckstein. (2006). UK-SVD: An algorithm for designing overcomplete dictionaries for sparse representation.55 IEEE Trans­ actions on Image Processing1 54(11):4311-4322. Akaike, H. (1974). “A new look at the statistical model identification.55 IEEE Transactions on Automatic Control, 19(6):716-723. Baraniuk, R. G. (2007). “Compressive sensing75 IEEE Signal Processing Mag­ azine, 24(4):118-121. Bengio, S., F. Pereira, Y. Singer, and D. Strelow. (2009). “Group sparse cod­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 545
    }
  },
  {
    "page_content": "Baraniuk, R. G. (2007). “Compressive sensing75 IEEE Signal Processing Mag­ azine, 24(4):118-121. Bengio, S., F. Pereira, Y. Singer, and D. Strelow. (2009). “Group sparse cod­ ing.5, In Advances in Neural Information Processing Systems 22 (NIPS) (Y. Bengio, D. Schuurmans, J. D. Lafferty, C. K. I. Williams, and A. Culotta, eds.), 82-89, MIT Press, Cambridge, MA. Blum, A. and P. Langley. (1997), “Selection of relevant features and examples in machine learning.55 Artificial Intelligence1 97(1-2):245-271. Boyd, S. and L. Vandenberghe. (2004). Convex Optimization. Cambridge Uni­ versity Press, Cambridge, UK. Candes, E. J. (2008). “The restricted isometry property and its implications for compressed sensing?5 Comptes Rendus Mathematique, 346(9-10) :589-592. Candes, E. J., X. Li, Y. Ma, and J. Wright. (2011). “Robust principal compo­ nent analysis?^^ Journal of the ACM y 58(3):Article 11. Candes, E. J. and B. Recht. (2009). “Exact matrix completion via convex op­ tim iz a tio n .Foundations of Computational Mathematics^ 9(6):717-772.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 546
    }
  },
  {
    "page_content": "Candes, E. J. and B. Recht. (2009). “Exact matrix completion via convex op­ tim iz a tio n .Foundations of Computational Mathematics^ 9(6):717-772. Candes, E. J., J. Romberg, and T. Tao. (2006), “Robust uncertainty principles: Exact signal reconstruction from highly incomplete frequency information.” IEEE Transactions on Information Theory152(2):489-509. Chen, S. S., D. L. Donoho, and M. A. Saunders. (1998). uAtomic decomposition by basis p u r s u i t .SIAM Journal on Scientific Computing, 20(1):33-61. Donoho, D. L. (2006). “Compressed sensing.55 IEEE Transactions on Informa­ tion Theory, 52(4):1289-1306. Efron, B., T. Hastie, I. Johnstone, and R. Tibshirani. (2004). “Least angle regression.^^ Annals of Statistics1 32(2):407-499. 264 第 口 章 特 征 选 择 与 稀 疏 学 习 Forman, G. (2003). uAn extensive empirical study of feature selection metrics for text classification.55 Journal of Machine Learning Research, 3:1289-1305. Guyon, I. and A. Elisseeff. (2003). “An introduction to variable and feature selection.5, Journal of Machine Learning Research1 3:1157-1182.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 547
    }
  },
  {
    "page_content": "Guyon, I. and A. Elisseeff. (2003). “An introduction to variable and feature selection.5, Journal of Machine Learning Research1 3:1157-1182. Jain, A. and D. Zongker. (1997), “Feature selection: Evaluation, application, and small sample performance.5, IEEE Transactions on Pattern Analysis and Machine Intelligence^ 19(2):153-158. Kira, K. and L. A. Rendell. (1992). “The feature selection problem: Tradi­ tional methods and a new algorithm.55 In Proceedings of the 10th National Conference on Artificial Intelligence (AAAI)1 129-134, San Jose, CA. Kohavi, R. and G. H. John. (1997). uWrappers for feature subset selection.^^ Artificial Intelligence1 97(1-2):273-324. Kononenko, I. (1994). “Estimating attributes: Analysis and extensions of RE­ LIEF.,, In Proceedings of the 7th European Conference on Machine Learning (ECML), 171-182, Catania, Italy. Liu, H. and H. Motoda. (1998). Feature Selection for Knowledge Discovery and Data Mining. Kluwer, Boston, MA. Liu, H. and H. Motoda. (2007). Computational Methods of Feature Selection. Chapman & Hall/CRC, Boca Raton, FL.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 548
    }
  },
  {
    "page_content": "Data Mining. Kluwer, Boston, MA. Liu, H. and H. Motoda. (2007). Computational Methods of Feature Selection. Chapman & Hall/CRC, Boca Raton, FL. Liu, H., H. Motoda, R. Setiono, and Z. Zhao. (2010). “Feature selection: An ever evolving frontier in data mining.^^ In Proceedings of the 4th Workshop on Feature Selection in Data Mining (FSDM)^ 4-13, Hyderabad, India. Liu, H. and R. Setiono. (1996). “Feature selection and classification - a prob­ abilistic wrapper approach.5, In Proceedings of the 9th International Con­ ference on Industrial and Engineering Applications of Artificial Intelligence and Expert Systems (IEA/AIE), 419-424, Fukuoka, Japan. Liu, J. and J. Ye. (2009). “Efficient Euclidean projections in linear In Proceedings of the 26th International Conference on Machine Learning (ICML), 657-664, Montreal, Canada. - Mair al, J., M. Elad, and G. Sapiro. (2008). “Sparse representation for color image restoration.\" IEEE Transactions on Image Processing1 17(1):53-69. Mallat, S. G. and Z. F. Zhang. (1993). “Matching pursuits with time-frequency 参考文献",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 549
    }
  },
  {
    "page_content": "image restoration.\" IEEE Transactions on Image Processing1 17(1):53-69. Mallat, S. G. and Z. F. Zhang. (1993). “Matching pursuits with time-frequency 参考文献 265 dictionaries?5 IEEE Transactions on Signal Processing1 41(12):3397-3415. Narendra, P. M, and K. Fukunaga. (1977). “A branch and bound algorithm for feature subset selection.5, IEEE Transactions on Computers, C-26(9): 917-922. Pudil, P., J. Novovicova, and J. Kittier. (1994). “Floating search methods in feature selection? Pattern Recognition Letters1 15(11):1119-1125. Quinlan, J. R. (1986). “Induction of decision trees.\" Machine Learning1 1(1): 81-106. Recht, B. (2011). “A simpler approach to matrix completion.55 Journal of Machine Learning Research^ 12:3413-3430. Recht, B., M. Fazel, and P. Parrilo. (2010). ^Guaranteed minimum-rank so­ lutions of linear matrix equations via nuclear norm minimization.5, SIAM Review, 52(3):471-501. Tibshirani, R. (1996). ^Regression shrinkage and selection via the LASSO.” Journal of the Royal Statistical Society - Series B, 58(1):267-288.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 550
    }
  },
  {
    "page_content": "Review, 52(3):471-501. Tibshirani, R. (1996). ^Regression shrinkage and selection via the LASSO.” Journal of the Royal Statistical Society - Series B, 58(1):267-288. Tibshirani, R., M. Saunders, S. Rosset, J. Zhu, and K. Knight. (2005). uSpar- sity and smoothness via the fused LASSO.\" Journal of the Royal Statistical Society - Series B, 67(1):91-108. Tikhonov, A. N. and V. Y. Arsenin, eds. (1977). Solution of Ill-Posed Problems. Winston, Washington, DC. Wang, J., J. Yang, K. Yu, F. Lv, T. Huang, and Y. Gong. (2010). uLocality- constrained linear coding for image classification.\" In Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recog­ nition (CVPR)13360-3367, San Francisco, CA. Weston, J., A. Elisseff, B. Scholkopf, and M. Tipping. (2003). “Use of the zero norm with linear models and kernel methods.\" Journal of Machine Learning Research1 3:1439-1461. Yang, Y. and J. O. Pederson. (1997). “A comparative study on feature selection in text categorization.\" In Proceedings of the l4th International Conference",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 551
    }
  },
  {
    "page_content": "Research1 3:1439-1461. Yang, Y. and J. O. Pederson. (1997). “A comparative study on feature selection in text categorization.\" In Proceedings of the l4th International Conference on Machine Learning (ICML), 412-420, Nashville, TN. Yuan, M. and Y. Lin. (2006). “Model selection and estimation in regression with grouped variables.,5 Journal of the Royal Statistical Society - Series B, 266 第1 1 章特征选择与稀疏学习 68(1):49-67. Zou, H. and T. Hastie. (2005). “Regularization and variable selection v运 the elastic net.” Journal of the Royal Statistical Society - Series 67(2):301- 320. 休 息 一 会 儿 小故事：蒙特卡罗方法与斯坦尼斯拉夫•乌拉姆 斯 坦 尼 斯 拉 夫 •乌 拉 姆 (Stanislaw Ulam, 1909-1984) 是著名的波兰犹太裔数学家，在遍历论、数论、集合论等方 面都有重要贡献， “乌拉姆数列”就是以他的名字命名的. 乌拉姆出生于奥匈帝国利沃夫，1933年在波兰利沃夫 理工学院获得数学博士学位，然 后 于 1935年 应 冯 • 诺伊曼 的邀请到普林斯顿高等研究院访问，1940年他在威斯康星大学麦迪逊分校获得 教职，翌年加入美国籍. 1943年 起 他 参 与 “曼哈顿计划”并做出重大贡献；当 前世界上绝大部分核武器所使用的设计方案“泰勒-乌拉姆方案”就是以他和 “氢弹之父”爱德 华 ・泰勒的名字命名的. 世界上最早的通用电子计算机之一—— EN IA C在发明后即被用于曼哈 顿计划，乌拉姆敏锐地意识到在计算机的帮助下，可通过重复数百次模拟过程 的方式来对概率变量进行统计估计.冯・诺伊曼立即认识到这个想法的重要 性 并 给 予 支 持 .1947年乌拉姆提出这种统计方法并用于计算核裂变的连锁反 应.由于乌拉姆常说他的叔叔又在蒙特卡罗赌场输钱了，因此他的同事Nicolas",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 552
    }
  },
  {
    "page_content": "世界上最早的通用电子计算机之一—— EN IA C在发明后即被用于曼哈 顿计划，乌拉姆敏锐地意识到在计算机的帮助下，可通过重复数百次模拟过程 的方式来对概率变量进行统计估计.冯・诺伊曼立即认识到这个想法的重要 性 并 给 予 支 持 .1947年乌拉姆提出这种统计方法并用于计算核裂变的连锁反 应.由于乌拉姆常说他的叔叔又在蒙特卡罗赌场输钱了，因此他的同事Nicolas Metropolis戏 称 该 方 法 为 “蒙特卡罗”，不料却流传开去. 利 沃 夫 (Lviv)在 历 史 上 先 属 于 波 兰 ，1867— 1918 年 属 于 奥 匈 帝 国 ，第一 次世界大战后回归波兰, 19 3 9 年划入前苏联的乌克 兰，现为乌克兰利沃夫州 首府. 冯 • 诺 伊 曼 和 爱 德 华 ・泰 勒 都 出 生 在 匈 牙 利. 蒙特卡罗方法的著名代 表 Metropol is-Hasting 算法 是以他的名字命名的. 第 1 2 章 计 算 学 习 理 论 1 2 .1 基础知识 顾名思义，计算学习理论(computational learning theory)研究的是关于通 过 “计算”来 进 行 “学习”的理论，即关于机器学习的理论基础，其目的是分 析学习任务的困难本质，为学习算法提供理论保证，并根据分析结果指导算法 设计. 给定样例集D = {Q 1,阴),(况2,续),… ，(比如Vm)}. Xi e 乜本 章 主 要 讨 论 二分类问题，若无特别说明，y i e y = { - 1 ,+ 1 } .假设彳中的所有样本服从一 个隐含未知的分布3 D 中所有样本都是独立地从这个分布上采样而得，即独 立 同 分 布 (independent and identically distributed,简称 i.i.d.)样本. 令 九 为 从 ％ 到 J 的一个映射,其泛化误差为 石 的 。) : 巴 〜 冲 色 ⑺ 羊 外 ， (12.1) 八在。 上的经验误差为 1 m 取h; D) = - *比 ). (12.2) m i=i 由 于 刀 是 。 的独立同分布采样，因 此 h 的经验误差的期望等于其泛化误 差.在上下文明确时，我 们 将E(h;功 和 自(h;D)分 别 简 记 为 石 ㈤ 和 E(h).令 €为 E(h)的上限，即 E(h) W e ; 我们通常用e 表示预先设定的学得模型所应满 足的误差要求,亦称“误差参数”. 本章后面部分将研究经验误差与泛化误差之间的逼近程度.若h 在数据集",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 553
    }
  },
  {
    "page_content": "由 于 刀 是 。 的独立同分布采样，因 此 h 的经验误差的期望等于其泛化误 差.在上下文明确时，我 们 将E(h;功 和 自(h;D)分 别 简 记 为 石 ㈤ 和 E(h).令 €为 E(h)的上限，即 E(h) W e ; 我们通常用e 表示预先设定的学得模型所应满 足的误差要求,亦称“误差参数”. 本章后面部分将研究经验误差与泛化误差之间的逼近程度.若h 在数据集 D 上的经验误差为0 , 则 称 无 与 。 一致，否则称其与D 不一致.对任意两个映 射 加 ，后 £ £ 1 ， 可 通 过 其 “不合”(disagreement)来度量它们之间的差别： d(历，无2) = 已 ~0 ( 而 ⑸ * 厉 ( ⑼ ) • (12.3) 我们会用到几个常用不等式: 268 第 1 2 章 计 算 学 习 理 论 • Jensen不等式：对任意凸函数/(④)，有 ⑺ ) . (12.4) • Hoeffding不 等 式 [Hoeffding, 1963]:若①i,①2,… ，M 为力个独立随机变 量，且 满 足 0 W g W 1,则对任 意 e 〉0 ,有 1 馆 / £ E ( g ) 》e ) W e x p ( - 2 m c 2 ) , \\ (12.5) \\m i=l 啡久 / i=l m 1 l — ^ E ( ^ ) 》 2=1 e I W 2 exp( - 2nze2 ) . (12.6) • M c D i a r m i d 不 等 式 [McDiarmid, 1989]:若①匕畋,• • •, 为 惟 个独立随 机变量，且对任 意 1 4 E W 函 数 /满 足 SUp ①1，… Mm,吗 I f (2].,•••, — f (^1, • • • , ^i—1,勺,0+1, *^m) I W & , 则对任意e > 0 , 有 xm ) - E ( f ( X i , x m )) > G) exp (12.7) PQf(x 1,...,xm ) - E ( / (rri,...,a;m ))|) e) W 2 exp .(12.8) 12.2 PAC学习 计 算 学 习 理 论 中 最 基 本 的 是 概 率 近 似 正 确 (Probably Approximately Correct,简 称 P A C ) 学 习 理 论 [Valiant, 1984]. “概 率 近 似 正 确 ”这个名字 看起来有点古怪,我们稍后再解释. 令 。表 示 “概 念 \" (concept),这是从样本空间％ 到标记空间J 的映射，它",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 554
    }
  },
  {
    "page_content": "计 算 学 习 理 论 中 最 基 本 的 是 概 率 近 似 正 确 (Probably Approximately Correct,简 称 P A C ) 学 习 理 论 [Valiant, 1984]. “概 率 近 似 正 确 ”这个名字 看起来有点古怪,我们稍后再解释. 令 。表 示 “概 念 \" (concept),这是从样本空间％ 到标记空间J 的映射，它 决定示例况的真实标记y,若 对 任 何 样 例(x,y)有 c(x) = y 成立，则 称 c 为目 标概念；所有我们希望学得的目标概念所构成的集合称为“概念类”(concept class),用符 号 C 表示. 给 定 学 习 算 法 公 它 所 考 虑 的 所 有 可 能 概 念 的 集 合 称 为 “假 设 空 学习算法£的假设空间 不 是 1.3节所讨论的学习 任务本身对应的假设空间. 间”(hypothesis space),用 符 号 H 表 示 .由 于 学 习 算 法 事 先 并 不 知 道 概 念 类的真实存在，因 此 ” 和 。通常是不同的，学习算法会把自认为可能的目标概 12.2 PAC 学习 269 念集中起来构成丸，对 无 e ”，由于并不能确定它是否真是目标概念，因此称为 “假 设 \" (hypothesis).显然，假 设 h 也是从样本空间％ 到标记空间 > 的映射. 若目标概念 c € K 则 H 中存在假设能将所有示例按与真实标记一致的方 式完全分开，我 们 称 该 问 题 对 学 习 算 法 £是 “可 分 的 \" (separable),亦 称 “一 致 的 \" (consistent);若 c g 电 则 我 中 不 存 在 任 何 假 设 能 将 所 有 示 例 完 全 正 确分开，称该问题对学习算法£ 是 “不可分的\" ( m m - s e p arable),亦 称 “不一 致的” (non-consistent). 给定训练集D. 我们希望基于学习算法£ 学得的模型所对应的假设h 尽可 能接近目标概念c 读者可能会问：为什么不是希望精确地学到目标概念。呢? 这是由于机器学习过程受到很多因素的制约，例如我们获得的训练集D 往往仅 参 见 1 .4 节. 包含有限数量的样例，因此，通常会存在一些在。 上 “等 效 ”的假设，学习算 一般来说，训练样例越 少，采样偶然性越大. 法对它们无法区别；再如，从 分 布 。 采 样 得 到 。 的过程有一定偶然性，可以想 象，即便对同样大小的不同训练集，学得结果也可能有所不同.因此，我们是希 望以比较大的把握学得比较好的模型，也就是说，以较大的概率学得误差满足",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 555
    }
  },
  {
    "page_content": "参 见 1 .4 节. 包含有限数量的样例，因此，通常会存在一些在。 上 “等 效 ”的假设，学习算 一般来说，训练样例越 少，采样偶然性越大. 法对它们无法区别；再如，从 分 布 。 采 样 得 到 。 的过程有一定偶然性，可以想 象，即便对同样大小的不同训练集，学得结果也可能有所不同.因此，我们是希 望以比较大的把握学得比较好的模型，也就是说，以较大的概率学得误差满足 预设上限的模型；这 就 是 “概率” “近似正确”的含义.形式化地说，令 6 表示 置信度，可定义： 定 义 12.1 P A C 辨 识 ( P A C Identify):对 0 < a 6 V 1 , 所 有 c e C 和分布 若存在学习算法£ , 其输出假设八e ” 满足 P(E(h) W £ ) 2 1 — 6 , (12.9) 则称学习算法£ 能从假设空间H 中 P A C 辨识概念类C. 这样的 学 习 算 法 £ 能 以 较 大 的 概 率 (至 少 1 - S)学 得 目 标 概 念 c 的近似 (误差最多为c ) .在此基础上可定义： 样 例 数 目m 与 误 差 e、 置 信 度 6 、数据本身的复 杂 度 size(cc)、 目标概念的 复杂度siz e(c)都有关. 定 义 12.2 P A C 可 学 习 ( P A C Learn a b l e ) :令 m 表示从分布V 中独立同 分布采样得到的样例数目，0 < 6 , 5 < 1 , 对所有分布0 , 若存在学习算法£和多 项式函数 poly(-, •,•,•),使得对于任何 m 》 poly(l/e, 1/6, size(a?), size(c)), £ 能 从假设空间H 中 P A C 辨识概念类C , 则称概念类C 对假设空间H 而 言 是 P A C 可学习的，有时也简称概念类C 是 P A C 可学习的. 对计算机算法来说，必然要考虑时间复杂度，于是： 270 第 1 2 章 计 算 学 习 理 论 定 义 12.3 P A C 学 习 算 法 ( P A C Learning A l g o r i t h m ) : 若学习算法£ 使 概 念 类 C 为 P A C 可学习的，且 £ 的 运 行 时 间 也 是 多 项 式 函 数 poly(l/€,l/J, size(jr),size(c)),则称概念类 C 是高效 P A C 可 学 习 (efficiently P A C learnable) 的，称 £ 为概念类 C 的 P A C 学习算法. 假定学习算法£ 处理每个样本的时间为常数，则 £ 的时间复杂度等价于样",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 556
    }
  },
  {
    "page_content": "size(jr),size(c)),则称概念类 C 是高效 P A C 可 学 习 (efficiently P A C learnable) 的，称 £ 为概念类 C 的 P A C 学习算法. 假定学习算法£ 处理每个样本的时间为常数，则 £ 的时间复杂度等价于样 本复杂度.于是,我们对算法时间复杂度的关心就转化为对样本复杂度的关心： 定 义 1 2 . 4 样 本 复 杂 度 ( S a m p l e C o m p l e x i t y ) : 满 足 P A C 学 习 算 法 £ 所 需 的 m 》 poly(l/e, 1/5,size(®),size(c))中 最 小 的 m , 称 为 学 习 算 法 £ 的样本 复杂度. 显然，P A C 学习给出了一个抽象地刻画机器学习能力的框架，基于这个框 架能对很多重要问题进行理论探讨，例如研究某任务在什么样的条件下可学得 较好的模型？某算法在什么样的条件下可进行有效的学习？需多少训练样例才 能获得较好的模型？ P A C 学习中一个关键因素是假设空间H 的复杂度.H 包含了学习算法£ 所有可能输出的假设，若 在 P A C 学习中假设空间与概念类完全相同，即 丸 = C, 这 称 为 “恰 P A C 可学习” (properly P A C learnable);直观地看,这意味着学习 算法的能力与学习任务“恰好匹配”.然 而 ，这种让所有候选假设都来自概念 类的要求看似合理，但却并不实际，因为在现实应用中我们对概念类C 通常一 无所知，更别说获得一个假设空间与概念类恰好相同的学习算法.显然，更重要 的是研究假设空间与概念类不同的情形，即 ^ C 一般而言,H 越大,其包含 任意目标概念的可能性越大，但从中找到某个具体目标概念的难度也越大. |却 有限时，我 们 称 我 为 “有限假设空间”，否 则 称 为 “无限假设空间”. 1 2 . 3 有限假设 空 间 1 2 . 3 . 1 可分情形 可分情形意味着目标概念。属于假设空间丸，即 给 定 包 含 馆 个 样 例的训练集D, 如何找出满足误差参数的假设呢？ 容易想到一种简单的学习策略：既 然 。 中样例标记都是由目标概念c 赋予 的，并 且 c 存在于假设空间我中，那么，任何在训练集。 上出现标记错误的假 设肯定不是目标概念c . 于是，我们只需保留与。 一致的假设，剔 除 与 。 不一 致的假设即可.若训练集D 足够大，则可不断借助D 中的样例剔除不一致的假 1 2 .3 有限假设空间 271 设,直到我中仅剩下一个假设为止,这个假设就是目标概念G 通常情形下，由 于训练集规模有限，假 设 空 间 H 中可能存在不止一个与D 一 致 的 “等效”假",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 557
    }
  },
  {
    "page_content": "设肯定不是目标概念c . 于是，我们只需保留与。 一致的假设，剔 除 与 。 不一 致的假设即可.若训练集D 足够大，则可不断借助D 中的样例剔除不一致的假 1 2 .3 有限假设空间 271 设,直到我中仅剩下一个假设为止,这个假设就是目标概念G 通常情形下，由 于训练集规模有限，假 设 空 间 H 中可能存在不止一个与D 一 致 的 “等效”假 设,对这些等效假设,无法根据D 来对它们的优劣做进一步区分. 到底需多少样例才能学得目标概念C的有效近似呢？对 PA C 学习来说,只 要训练集D 的规模能使学习算法£ 以概率1 - 5 找到目标假设的e 近似即可. 我们先估计泛化误差大于e 但在训练集上仍表现完美的假设出现的概率. 假 定 h 的泛化误差大于g 对 分 布 P 上随机采样而得的任何样例(皿g ) , 有 P (h(x) = y ) = 1 - P (h ( x ) * y) = 1 - 石㈤ < 1 - 6 . (12.10) 由 于 。 包 含 馆 个 从 。 独立同分布采样而得的样例，因此，拉与。 表现一 致的概率为 尸((五(叫)二阴)八… 八(h(x m ) = ym ) ) = (1 - P 仇 (w) # y) ) m < (1 - c)m . (12.11) 我们事先并不知道学习算法£ 会 输 出 H 中的哪个假设，但仅需保证泛化 误差大于€,且在训练集上表现完美的所有假设出现概率之和不大于6 即可： P (h e H ： E(h) > e A E(h) = 0) < |W|(1 - e)m < \\H\\e-m € , (12.12) 令式(12.12)不 大 于 3 , 即 可得 \\H\\e-m e 6 , m - ( i n \\H\\ + In i ) . (12.13) (12.14) 由此可知，有 限 假 设 空 间 笈 都 是 P A C 可 学 习 的 ，所 需 的 样 例 数 目 如 式(12.14)所示，输 出 假 设 h 的泛化误差随样例数目的增多而收敛到0 , 收敛速 率 为 0 ( * ) . 272 第 1 2 章 计 算 学 习 理 论 12.3.2不可分情形 对较为困难的学习问题，目标概念。往往不存在于假设空间巩中.假定对 于 任 何heH, E(K)* 0,也就是说,H 中的任意一个假设都会在训练集上出现 或多或少的错误.由Hoeffding不等式易知： 引 理 1 2 . 1 若 训 练 集。包含m 个 从 分 布 V 上独立同分布采样而得的样 例，0 V e V 1,则对任意八W ”,有",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 558
    }
  },
  {
    "page_content": "12.3.2不可分情形 对较为困难的学习问题，目标概念。往往不存在于假设空间巩中.假定对 于 任 何heH, E(K)* 0,也就是说,H 中的任意一个假设都会在训练集上出现 或多或少的错误.由Hoeffding不等式易知： 引 理 1 2 . 1 若 训 练 集。包含m 个 从 分 布 V 上独立同分布采样而得的样 例，0 V e V 1,则对任意八W ”,有 P(E(h) - E(h)》e) W exp(-2me 2 ) , P(E(h)- 自㈤ 》e) Q exp(-2mc 2 ) , 仇)- E(h)\\》e ) 4 2exp(-2me 2 ) . (12.15) (12.16) (12.17) 推 论 1 2 . 1 若 训 练 集 。 包 含 m 个 从 分 布 T)上独立同分布采样而得的样 例，0 V € < 1,则 对任意h e H , 式(12.18)以至少1 - 6 的概率成立： @ ㈤ - 薯 . 石 ㈤ 《京 ㈤ + 仍 票 • (12.18) V ZiTTb V ZiTTL 推 论 12.1表明，样 例 数 目m 较大时，h 的经验误差是其泛化误差很好的近 似.对于有限假设空间K 我们有 定 理 1 2 . 1 若 H 为有限假设空间，0 < 6 < 1,则对任 意h \" 有 。(旧 ① )—夙 到 W 泮 固 票 瓯 ) 》 1 一鼠 (12.19) 证明 令 加 , 电 … ，hw 表示假设空间H 中的假设，有 P ( 3 h e H : 田 ㈤ 一 百 ㈤ | >€) =P((I 瓦 1 —瓦 11 > 0 V ... V (|瓦因一E 八因| > 0 ) ^ P ( \\ E ( h ) - E W \\ > e ) , heH 由式(12.17)可得 5 2 P(\\E(h)-E(h)\\ > € ) 2|H|exp(-2m6 2 ) , hen 12.4 VC 维 273 于是，令 8 = 2|% exp(—2m€2)即可得式(12.19). 即在我的所有假设中找 出最好的一个. 显然，当 丸 时 ，学习算法£无法学得目标概念。的 e 近似.但是，当 假 设 空 间H 给定时，其中必存在一个泛化误差最小的假设，找出此假设的6 近似也不失为一个较好的目标.H 中泛化误差最小的假设是argm in谀”石仇), 于是，以此为目标可将P A C 学习推广到。任H 的情况，这 称 为 “不可知学 习 \" (agnostic learning).相应的，我们有",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 559
    }
  },
  {
    "page_content": "出最好的一个. 显然，当 丸 时 ，学习算法£无法学得目标概念。的 e 近似.但是，当 假 设 空 间H 给定时，其中必存在一个泛化误差最小的假设，找出此假设的6 近似也不失为一个较好的目标.H 中泛化误差最小的假设是argm in谀”石仇), 于是，以此为目标可将P A C 学习推广到。任H 的情况，这 称 为 “不可知学 习 \" (agnostic learning).相应的，我们有 定义 12.5 不可知 P A C 可 学 习 (agnostic PAC le a rn a b le ):令 m 表 示 从 分 布 。 中 独 立 同 分 布 采 样 得 到 的 样 例 数 目 ，0 V g 3 V 1 , 对所 有 分 布 0 , 若 存 在 学 习 算 法 £ 和 多 项 式 函 数 poly(•一〜)，使得对于任何 m 》poly(l/e, 1/J, size (a?), size (c)), £ 能从假设空间H 中输出满足式(12.20)的 假 设h: P(E(h) - n nnE (/i, ) W。 2 1 一 3 , (12.20) 则称假设空间H 是不可知PA C 可学习的. 与 P A C 可 学 习 类 似 ，若 学 习 算 法 £ 的 运 行 时 间 也 是 多 项 式 函 数 poly(l/€, 1/8, sizeQ ),size(c)),则 称 假设空间H 是高 效 不 可 知 P A C 可学习 的，学习算法£ 则称为假设空间H 的不可知P A C 学习算法,满足上述要求的 最小m 称为学习算法£ 的样本复杂度. 12.4 VC维 现实学习任务所面临的通常是无限假设空间，例如实数域中的所有区 间、好空间中的所有线性超平面.欲对此种情形的可学习性进行研究，需 度量假设空间的复杂度.最常见的办法是考虑假设空间的“VC维” (Vapnik- Chervonenkis dimension) [Vapnik and Chervonenkis, 1971]. 介 绍 V C 维之前，我们先引入几个概念：增长函数(growth function)、对 分 (dichotomy)和打散(shattering). 给定假设空间H 和示例集0 = { g ，g ，… 心m}, H 中每个假设h 都能对 D 中示例赋予标记，标记结果可表示为 h\\D = {仅(叫),九(g ) , . . . , ％ (吃^))}. 2 7 4 例如，对二分类问题,若 D 中 只 有 2 个示例，则赋 予标记的可能结果只有4 种；若 有 3 个示例，则可能 结果有 8 种. N 为自然数域. 第 1 2 章 计 算 学 习 理 论",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 560
    }
  },
  {
    "page_content": "D 中示例赋予标记，标记结果可表示为 h\\D = {仅(叫),九(g ) , . . . , ％ (吃^))}. 2 7 4 例如，对二分类问题,若 D 中 只 有 2 个示例，则赋 予标记的可能结果只有4 种；若 有 3 个示例，则可能 结果有 8 种. N 为自然数域. 第 1 2 章 计 算 学 习 理 论 随 着 m 的增大,H 中所有假设对D 中的示例所能赋予标记的可能结果数 也会增大. 定 义 1 2 . 6 对 所 有 m G N , 假设空间H 的增长函数n H ( m ) 为 口丸(m) = max |{ , . . . , \\heH}\\ . (12.21) 增 长函数n ^ ( m ) 表 示 假 设 空 间 巩 对 m 个示例所能赋予标记的最大可能 结果数.显然，见对示例所能赋予标记的可能结果数越大，H 的表示能力越强, 对学习任务的适应能力也越强.因此，增长函数描述了假设空间H 的表示能力, 由此反映出假设空间的复杂度.我们可利用增长函数来估计经验误差与泛化误 差之间的关系： 定 理 12.2 对 假 设 空 间 m G N, 0 < e < 1 和 任 意 heli有 证 明 过 程 参 阅 [Vapnik and Chervonenkis, 1971]. P{\\E(h) - E(h)\\ > e) 4 n H (2m)exp ( - - ( 1 2 . 2 2 ) o 2 每个假设会把D 中示例 分为两类，因此称为对分. 假 设 空 间H 中不同的假设对于D 中示例赋予标记的结果可能相同，也可 能不同；尽 管 H 可能包含无穷多个假设,但其对D 中示例赋予标记的可能结果 数是有限的：对 馆 个 示 例 ，最 多 有 2m 个可能结果.对二分类问题来说,丸中的 假 设 对 。 中示例赋予标记的每种可能结果称为对。 的 一 种 “对 分 ”.若假设 空 间 H 能实现示例集0 上的所有对分，即 口 丸 ⑺ )= 2 7 则 称 示 例 集D 能被 假设空间” “打散”. 现在我们可以正式定义V C 维了： 定 义 1 2 . 7 假 设 空 间 孔 的 V C 维是能被H 打散的最大示例集的大小，即 V C («) = max{m : n ^ (m ) = 2m } . (12.23) V C (丸)= d 表明存在大小为d 的示例集能被假设空间H 打散.注意：这并 不意味着所有大小为d 的示例集都能被假设空间H 打散.细心的读者可能已发 现,V C 维的定义与数据分布。 无 关 ！因此，在数据分布未知时仍能计算出假设 空 间 月 的 V C 维.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 561
    }
  },
  {
    "page_content": "V C («) = max{m : n ^ (m ) = 2m } . (12.23) V C (丸)= d 表明存在大小为d 的示例集能被假设空间H 打散.注意：这并 不意味着所有大小为d 的示例集都能被假设空间H 打散.细心的读者可能已发 现,V C 维的定义与数据分布。 无 关 ！因此，在数据分布未知时仍能计算出假设 空 间 月 的 V C 维. 通常这样来计算我的V C 维:若存在大小为d 的示例集能被H 打散，但不 存在任何大小为d + 1 的示例集能被H 打散，则 凡 的 V C 维 是 d.下面给出两 个计算V C 维的例子： 12.4 VC 维 275 例 1 2 . 1 实 数 域 中 的 区 间 [a, 6]:令我表示实数域中所有闭区间构成的集 合 ｛h[a,b] ： a, € R, a < 6｝, Af = R . 对① e 匕 若 / e [a,可，则加。,可(C ) = + 1 , 否 则 看QMQ) = - 1 - 令 3 = 0 . 5 / 2 = 1.5,则 假 设 空 间 H 中存在假设 ■ 中 如 ,2],丽 ,2],3 3]｝将 ｛的逆2｝打 散 ,所 以 假 设 空 间 丸 的 V C 维 至 少 为 2 ； 对任意大小为3 的示例集｛力3 « 4 , 6 5 卜 不 妨 设 /3 < ^4 < 6 5 , 则 H 中不存在任 何 假 设 能 实 现 对 分 结 果 ｛( % +),(力4,—),(力5, + ) ｝. 于 是 ,我 的 V C 维 为 2. 例 12・2二维实平面上的线性划分：令我表示二维实平面上所有线性划 分构成的集合，才 = 肽2 . 由 图 12.1可知，存 在 大 小 为 3 的示例集可被H 打散, 但不存在大小为4 的示例集可被H 打散.于是，二维实平面上所有线性划分构 成 的 假 设空间我的 V C 维 为 3. 存在这样的集合，其 2：3 = 8 种对分均可 被线性划分实现 对任何集合，其 24 = 1 6 种对分中 至少有一种不能被线性划分实现 (a)示 例 集 大 小 为 3 (b)示 例 集 大 小 为 4 图 1 2 . 1 二 维 实 平 面 上 所 有 线 性 划 分 构 成 的 假 设 空 间 的 V C 维 为 3 由定 义 12.7可知，V C 维与增长函数有密切联系，引 理 12.2给出了二者之 间的定量关系[Sauer, 1972]: 亦称“Sauer引理] 引 理 12.2 若 假 设 空 间 我 的 V C 维 为 或 则 对 任 意 馆 G N 有 ■ ) ( t ■ 2=0 ' ) (12.24)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 562
    }
  },
  {
    "page_content": "由定 义 12.7可知，V C 维与增长函数有密切联系，引 理 12.2给出了二者之 间的定量关系[Sauer, 1972]: 亦称“Sauer引理] 引 理 12.2 若 假 设 空 间 我 的 V C 维 为 或 则 对 任 意 馆 G N 有 ■ ) ( t ■ 2=0 ' ) (12.24) 证明 由 数 学 归 纳 法 证 明 .当 m = 1, d = 0 或 d = 1 时，定理成立. 假 设 定 理 对 ( 6 — l,d - 1 ) 和(山一 l , d ) 成 立 . 令 。 = ｛«1,^2,...,团馆｝, D = 宏2, • • •,北恒一1｝, H\\D = {(八(叫)，h ( / 2 ) , . .. 1 h (凡馆))| h 6 ? / } , 叫 D 7 = { ( ' (必 1 ) ，h (劣2 ) ，.…，九 1)) | h G \" } . 任 何 假 设 h £ Y 对 Xr n 的 分 类 结 果 或 为 + 1 , 或为一1 , 因此任何出现在 276 第 1 2 章 计 算 学 习 理 论 叫。 中 的 串 都 会 在 我 ⑷ 中 出 现 一 次 或 两 次 . 令 % 表 示 在 中 出 现 两 次 的叫力中串组成的集合，即 丸 = { ( 阴 ，g2, •…，Vm—l) G I 3/l, h G ”, (h(xi) — h (g)= % ) A (h^Xm)* h Q 7n)), 1 W £ W 馆 一 1} • 考 虑 到 中 的 串 在 丸 ⑷ 中 出 现 了 两 次 ，但在凡万中仅出现了一次, 有 出 血 = 冉 别 + 出 力 向 • (12.25) D' 的大小为6 - 1 , 由假设可得 |四力 | & n H ( m — 1) < £ ( m 1 1 ) . (12.26) 令 Q 表 示 能 被汽D''D 打散的集合，由 % \\ D 定 义 可 知 Q u {xm } 必能被 H\\D 打 散 .由 于 我 的 V C 维 为 d , 因此 % \\ D 的 V C 维最大为d - 1,于是有 E = o. 由式(12.25)~(12.27)可得 i=0 ' 7 i=0 V 7 (力 由集合D 的任意性，引 理 12.2得证. ■ 从 引 理 12.2可计算出增长函数的上界： 推 论 1 2 . 2 若 假 设 空 间 我 的 V C 维 为 d,则对任意整数m 2 d 有 e 为自然常数. n?/(m) W ( d )\" . (12.28) 12.4 VC 维 277 证明",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 563
    }
  },
  {
    "page_content": "i=0 ' 7 i=0 V 7 (力 由集合D 的任意性，引 理 12.2得证. ■ 从 引 理 12.2可计算出增长函数的上界： 推 论 1 2 . 2 若 假 设 空 间 我 的 V C 维 为 d,则对任意整数m 2 d 有 e 为自然常数. n?/(m) W ( d )\" . (12.28) 12.4 VC 维 277 证明 根 据 推 论12.2和 定 理 12.2可得基于V C 维的泛化误差界： 定 理 1 2 . 3 若 假 设 空 间 月 的 V C 维 为 d , 则 对 任 意 m 〉 d, 0 V 6 < 1 和 后€” 有 P (E ㈤ - 自㈤ w ^ 8 d l n ^ + ^ i ) 》1 _ 6 . (12.29) 证明 令 4U ” (2m)exp(—嗜 ) W4(笠 ) dexp(—嗜 ) = 6 , 解得 _ 卜 加 口 弩 + 8 1 n . V m ' 代 入 定 理 12.2,于 是定理12.3得证. ■ 由定理12.3可知，式(12.29)的泛化误差界只与样例数目m 有关，收敛速率 为 。(品 )，与数据分布V 和 样 例 集D 无关.因此，基 于 V C 维的泛化误差界是 分 布 无 关 (distribution-free) > 数 据 独 立 (data-independent)的. 278 第 1 2 章 计 算 学 习 理 论 令 h 表示学习算法£ 输出的假设,若％满足 自㈤= 理 技 囱 的 , (12.30) 则 称 £ 为满足经验风险最小化(Empirical Risk M inim ization,简 称 E R M )原 则的算法.我们有下面的定理： 定 理 1 2 . 4 任 何 V C 维有限的假设空间H 都是(不可知)PA C 可学习的. 证明 假 设 £ 为满足经验风险最小化原则的算法，入为学习算法£ 输出的 假 设 .令 g 表示月中具有最小泛化误差的假设，即 E ( g ) = 脾 石 ㈤ • (12.31) 令 5 = 2 (In 2/3，) _ € 2 2m (12.32) 由推论12.1可知 E(g) - 5 W E(g) & E(g) + - 至 少 以 1 - 6 / 2 的概率成立.令 8 d h i竿 + 8 也亳 m e 2 (12.34) 则由定理12.3可知 从而可知 E (九)_ E(g) W E ( h ) 十 * 一 (E ( g ) - = E ( h ) - E ( g ) + e W € 12.5 Rademacher 复杂度",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 564
    }
  },
  {
    "page_content": "至 少 以 1 - 6 / 2 的概率成立.令 8 d h i竿 + 8 也亳 m e 2 (12.34) 则由定理12.3可知 从而可知 E (九)_ E(g) W E ( h ) 十 * 一 (E ( g ) - = E ( h ) - E ( g ) + e W € 12.5 Rademacher 复杂度 279 以 至 少 1 - 6 的概率成立.由式(12.32)和(12.34)可 以解出m , 再 由 H 的任意性 可 知 定 理12.4得证. ■ 12.5 Rademacher复杂度 12.4节提到，基 于 V C 维的泛化误差界是分布无关、数据独立的，也就是 说，对任何数据分布都成立.这使得基于V C 维的可学习性分析结果具有一定 的 “普 适 性 ”；但从另一方面来说，由于没有考虑数据自身，基 于 V C 维得到 的 泛 化 误 差 界 通 常 比 较 “松 ”，对那些与学习问题的典型情况相差甚远的较 “坏 ”分布来说尤其如此. 这 个 名 字 是 为 了 纪 念 德国数学家H. Rademach­ er (1892-1969). Rademacher复 杂 度 (Rademacher complexity)是另一种刻画假设空间复 杂度的途径，与 V C 维不同的是，它在一定程度上考虑了数据分布. 给定训练集D = {(曲，阴),(殴,续),… 加纳H)} , 假 设 h 的经验误差为 1 m 应仇)= £ £ 口 ( 八 ( ^ )丰纳) 2=1 2=1 _ 1 ~ 1 — yjh(xe) 2 m = 5 —石 £ y也仙), 2=1 / ZiTTL (12.36) 其 中 * S X i 亚g i ) 体现了预测值h(Xi)与样例真实标记y i 之间的一致性,若 对 于 所 有 。e {1,2,… ，m } 都 有 h(Xi) = yi,则 £ 黑1 y i ® ) 取 最 大 值 1 . 也 就是说，经验误差最小的假设是 ] m arg max — hen . (12.37) 然而，现实任务中样例的标记有时会受到噪声影响，即对某些样例 物,仇), 其 yi或许已受到随机因素的影响，不 再 是 g 的真实标记.在此情形下，选择假 设 空 间 H 中在训练集上表现最好的假设，有时还不如选择凡中事先已考虑了 随机噪声影响的假设. 考 虑 随 机 变 量 内 ，它 以 0 .5 的 概 率 取 值 - 1 , 0 .5 的 概 率 取 值 + 1 , 称为 280 第 1 2 章 计 算 学 习 理 论 Rademacher随机变量.基于内，可将式(12.37)重写为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 565
    }
  },
  {
    "page_content": "设 空 间 H 中在训练集上表现最好的假设，有时还不如选择凡中事先已考虑了 随机噪声影响的假设. 考 虑 随 机 变 量 内 ，它 以 0 .5 的 概 率 取 值 - 1 , 0 .5 的 概 率 取 值 + 1 , 称为 280 第 1 2 章 计 算 学 习 理 论 Rademacher随机变量.基于内，可将式(12.37)重写为 我是无限假设空间，有 可能取不到最大值，因此 使用上确界代替最大值. ] m sup - T 生力(g) • (12.38) 考虑丸中的所有假设,对式(12.38)取期望可得 电/ sup 石 工 5 h(g)] , (12.39) 其 中 。 = { 九 。2 , - ” 馆 }.式 (12.39)的 取 值 范 围 是 [0,1],它体现了假设空 间 H 的表达能力，例 如 ，当 | % = 1 时，丸 中 仅 有 一 个 假 设 ，这时可计算出 式(12.39)的值为0 ; 当|丸| = 2馆 且 我 能 打 散 D 时，对 任 意 a 总有一个假设使 得 旗 g ) = 5 0 = 1,2,...,m),.这时可计算出式(12.39)的 值 为 1. 考虑实值函数空间尸：2 f 应 令 Z = {zi,z2 , zm },其 中 4 e 2 , 将 式(12.39)中 的 胃 和 我 替 换 为 2 和尸可得 定 义 1 2 . 8 函 数 空 间 尸 关 于 Z 的经验Rademacher复杂度 1 m s u p - 5 2 ^ / ( ^ ) ] . (12.40) 经 验 Rademacher复杂度衡量了函数空间F 与随机噪声在集合Z 中的相 关性.通常我们希望了解函数空间尸在乞上关于分布。 的相关性，因此，对所 有 从 0 独立同分布采样而得的大小为m 的 集 合 Z 求期望可得 定 义 1 2 . 9 函 数 空 间 产 关 于 2 上 分 布V 的 Rademacher复杂度 R m ⑺ = ^ZCZ:\\Z\\=m 匠 ( 刊 . (12.41) 基 于 Rademacher复杂度可得关于函数空间厂的泛化误差界[Mohri et al., 2012]: 定 理 1 2 . 5 对实值函数空间尸：2 1 [0,1],根 据 分 布 。 从 2 中独立同分 布采样得到示例集z = {力,如 . • •, zm }, e z, o < 5 < 1,对 任 意 / e 尸，以 12.5 Rademacher 复杂度 281 至 少 1 - 6 的概率有 叫 八 切 W + 2 品 ( 力 + 仍 罂 , (12.42) 2=1",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 566
    }
  },
  {
    "page_content": "布采样得到示例集z = {力,如 . • •, zm }, e z, o < 5 < 1,对 任 意 / e 尸，以 12.5 Rademacher 复杂度 281 至 少 1 - 6 的概率有 叫 八 切 W + 2 品 ( 力 + 仍 罂 , (12.42) 2=1 叫 八 到 4 = £ > ( 々 ) + 2互2 (尸) + 3仍 票 . (12.43) TTl . 2=1 V ZiTTl 证 明 令 m 1 ①(Z) = sup叫 力 —B z ⑺ ， 氏尸 同 时 ,令 Z ' 为 只 与 Z 有一个示例不同的训练集，不 妨 设 Nm e Z 和 G Z ' 为 不同示例，可得 ①②)—①(Z)= b 普 叫 力 —勇 ，(/))- (;普 叫 力 ― & ⑺ ) « sup包⑴- % ⑴ 氏尸 / 厮 ) 一 / ( % ) m = sup 氏尸 W - - m ①(Z)- ①(z')w , 悭(Z) —①(Z')]忘 ! . 同理可得 根 据 McDiarmid不等式(12.7)可知，对 任 意 S € (0,1), ①(Z) W E z 悭( 0 ] + 侬 1/8) 2m (12.44) 282 第 1 2 章 计 算 学 习 理 论 以至少1 - 6 的概率成立.下面来估计叫悭(Z)]的上界： 弱 国 Z)] = E z [supE[/]- 诙 ( 川 = E z [supE z z 国 / ⑺ _ 星 ( 闻 ] & [涔 & ⑺ - & (7)] 1 m = % z 七 普 五 己 ( / ⑹ 一 \" 以 M = % z , z ，[；售 石 £ 内 ( 〃 公 ) —73))] 1 m 利 用 J e n s e n 不 等 式 (12.4)和上确界函数的凸 性. & [ s u p - E g / 3 ；)] + % z [ j u p - £ - 内 /(司 । m 1 7 n “与 - 6 分布相同. = 2E a ) z [ sup - 1 771 ^/(^)] = 2 6 ( 尸). 至 此 式 (12.42)得 证 .由 定 义 12.9可知，改 变 Z 中的一个示例对我(尸)的值所 造成的改变最多为1/m.由 McDi a r m i d 不等式(12.7)可知， 兄n(尸)W &z⑺ + 仍 罂 (12.45) 以至少1 — 8/2的概率成立.再由式(12.44)可知， ①(Z) W E z 悭(Z)] + / 嘤 生 V ZiTTL",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 567
    }
  },
  {
    "page_content": "至 此 式 (12.42)得 证 .由 定 义 12.9可知，改 变 Z 中的一个示例对我(尸)的值所 造成的改变最多为1/m.由 McDi a r m i d 不等式(12.7)可知， 兄n(尸)W &z⑺ + 仍 罂 (12.45) 以至少1 — 8/2的概率成立.再由式(12.44)可知， ①(Z) W E z 悭(Z)] + / 嘤 生 V ZiTTL 以至少1 - 6 / 2 的概率成立.于是， ①(Z) W 2左z(A) + 3仍 染 (12.46) 以至少1 - 6 的 概 率 成 立 .至 此 式 (12.43)得证. ■ 需注意的是，定 理 12.5中 的 函 数 空 间 尸 是 区 间 [0,. 1]上的实值函数，因此 定 理 12.5只适用于回归问题.对二分类问题，我们有下面的定理： 12.5 Rademacher 复杂度 283 定 理 1 2 . 6 对假设空间隹 X T { - 1 ,+ 1 } ,根据分 布0 从 %中 独 立 同 分 布采样得到示例集D = { % ①2, • • . , xm }, o?i € Af, 0 < 5 < 1 , 对 任 意 h eH, 以 至 少 的 概 率 有 E ㈤ & E(h) + % 坪 + / I B M , V 2m E(h) W E(h) + R D (H) + 3 J 华 也 . V 2m (12.47) (12.48) 证明 对二分类问题的假设空间% 令 2 = % x { - 1 ,+ 1 } ,则 H 中的假设 h 变形为 九( z ) = 九3 y) = 1(九Q ) + y), (12.49) 于 是 就 可 将 值 域 为 { - 1 ,+ 。 的 假 设 空 间 丸 转 化 为 值 域 为 ［0,1］的函数空间 yH = {fh-he H}. 由定义 12.8,有 务 ( % ) = E b [ j 2 石 鼻 内 九 ( 跖 % ) ] . ] m ] m = Ea [sup — 网 (八 但 )* %)] ] 互 i 一 网 ] ] m ] 771 = 卢 (m ! > + 黑 航 £ ( i 帅 ( * ] 一加6 与6 分布相同. z=l 几上\" i=l = 2] E 4 ^ m1 m g (- 班内九(g))] ] 1 m 1 八 = 5 出 ( 却 . (12.50) 对式(12.50)求期望后可得 R m g = % ⑻ . (12.51)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 568
    }
  },
  {
    "page_content": "] ] m ] 771 = 卢 (m ! > + 黑 航 £ ( i 帅 ( * ] 一加6 与6 分布相同. z=l 几上\" i=l = 2] E 4 ^ m1 m g (- 班内九(g))] ] 1 m 1 八 = 5 出 ( 却 . (12.50) 对式(12.50)求期望后可得 R m g = % ⑻ . (12.51) 由定理12.5和 式 (12.50)〜 (12.51),定 理 12.6得证. ■ 284 第 1 2 章 计 算 学 习 理 论 定 理 12.6给出了基于Rademacher复杂度的泛化误差界.与定理12.3对比 可知，基 于 V C 维的泛化误差界是分布无关、数据独立的，而 基 于 Rademacher 复杂度的泛化误差界(12.47)与 分 布 。 有关，式(12.48)与 数 据 。 有关.换言之, 基 于 Rademacher复杂度的泛化误差界依赖于具体学习问题上的数据分布，有 点类似于为该学习问题“量身定制”的，因此它通常比基于V C 维的泛化误差 界更紧一些. 值得一提的是，关 于 Rademacher复杂度与增长函数,有如下定理： 证明过程参阅[Mohri et al., 2012]. 定 理 12.7 假 设 空 间 H 的 Radema c h e r 复 杂 度 & (却 与 增 长 函 数 n ^ ( m ) 满足 户 里 迪 1 . (12.52) V m 由式(12.47), (12.52)和 推 论 12.2可得 E T 嘤 , ( - 3 ) 也就是说，我 们 从 Rademacher复杂度和增长函数能推导出基于V C 维的泛化 误差界. 1 2 . 6 稳 定 性 无论是基于V C 维 还 是 Rademacher复杂度来推导泛化误差界，所得到的 结果均与具体学习算法无关，对所有学习算法都适用.这使得人们能够脱离具 体学习算法的设计来考虑学习问题本身的性质，但在另一方面，若希望获得与 算法有关的分析结果，则 需 另 辟 蹊 径 .稳 定 性 (stabilita 分析是这方面一个值 得关注的方向. 顾名思义，算 法 的 “稳定性”考察的是算法在输入发生变化时，输出是否 会随之发生较大的变化.学习算法的输入是训练集，因此下面我们先定义训练 集的两种变化. 给定 D = = (比 1 ,加)，22 = (宓2 ,沙2), •… ， Vm) }, G AT 是来 自分布。 的独立同分布示例，明 = {-1,4-1}.对 假 设 空 间Y ： X T",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 569
    }
  },
  {
    "page_content": "得关注的方向. 顾名思义，算 法 的 “稳定性”考察的是算法在输入发生变化时，输出是否 会随之发生较大的变化.学习算法的输入是训练集，因此下面我们先定义训练 集的两种变化. 给定 D = = (比 1 ,加)，22 = (宓2 ,沙2), •… ， Vm) }, G AT 是来 自分布。 的独立同分布示例，明 = {-1,4-1}.对 假 设 空 间Y ： X T 和 学 习 算 法 公 令 W 丸表示基于训练集D 从假设空间H 中学得的假设.考 虑 。 的以下变化： 1 2 . 6 稳定性 285 • 表示移除D 中第i个样例得到的集合 = { 力 , • • • , 2 计 1, • …, Zm }, • D i 表示替换D 中第i个样例得到的集合 D' = {Z],, N2, . • • , N j i , N°, N£+I , . . . , Zm }, 其 中 = (宏；,?/.), x[服从分布0 并独立于D. 损失函数2(£。Q ),g) ： J x y 肽+刻画了假设 观 的预测标记 互 ⑺ 与 真实标记y 之间的差别，简记 为 2(£D ,N ) . 下 面 定 义 关 于 假 设 的 几 种 损 失 . • 泛化损失 • 经验损失 2(£,。) = / \" / = ( 硼 )依 £0, n)] . (12.54) 1 m “ £ , 0 = — £ 2 ( £ 0 , % ) . 2=1 (12.55) • 留一 (leave-one-out)损失 ] m & 。。(£,0 = 」 £ 2(£川 0 ) . (12.56) m i=i 下面定义算法的均匀稳定性(uniform stability): 定 义 1 2 . 1 0 对任何比W 工 N = (% ,g),若学习算法£ 满足 M ( £ O ,N ) —以£ ” ,N )| W / , 分= 1 , 2 , . . . , W (12.57) 则 称 £ 关于损失函数Q满足小均匀稳定性. 显然，若 算 法 £ 关于损失函数I满足小均匀稳定性，则有 区 观 ⑶ ― 2(£小,乃| W R ( £ D ,Z ) — 2(£0\\〃,N )| + 伍( £ 0 ,z ) — 2 (£ 0 w z )| 4 2 8 , 286 第 1 2 章 计 算 学 习 理 论 也就是说,移除示例的稳定性包含替换示例的稳定性. 若损失函数2 有 界 即对所有。 和 N = (血 必 有 0 w 2(£D , N) W M , 则有",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 570
    }
  },
  {
    "page_content": "W R ( £ D ,Z ) — 2(£0\\〃,N )| + 伍( £ 0 ,z ) — 2 (£ 0 w z )| 4 2 8 , 286 第 1 2 章 计 算 学 习 理 论 也就是说,移除示例的稳定性包含替换示例的稳定性. 若损失函数2 有 界 即对所有。 和 N = (血 必 有 0 w 2(£D , N) W M , 则有 [Bousquet and Elisseeff, 2002]: 证明 过 程 参 阅 [Bous- quet and Elisseeff, 2002]. 定 理 1 2 . 8 给 定 从 分 布 。上独立同分布 采 样 得 到 的 大 小 为m 的示例集 D , 若学习算法£ 满足关于损失函数0 的 /3-均匀稳定性，且损失 函 数 £ 的上界 为 知 ,0 < 8 V 1 , 则 对 任 意 以 至 少 1 - S 的概率有 2(£,。) 2 (£ ,0 ) W &oo(£,D)+/3 + (12.58) (12.59) 定 理 12.8给出了基于稳定性分析推导出的学习算法£ 学得假设的泛化误 差 界 .从 式(12.58)可看出，经验损失与泛化损失之间差别的收敛率为0 5 欣 若 8 = 。(表)，则可保证收敛率为0 ( 矗 ) . 与 定 理 12.3和 定 理 12 .6 比较可知，这 与基于V C 维 和 Rademacher复杂度得到的收敛率一致. 需注意，学 习 算 法 的 稳 定 性 分 析 所 关 注 的 是 以 而 假 设 空 间复杂度分析所关注的是sup加 丸 恒 ㈤ - E (励 ；也就是说,稳定性分析不必考 虑假设空间中所有可能的假设，只需根据算法自身的特性(稳定性)来讨论输出 假 设 的 泛 化 误 差 界 . 那 么 ，稳定性与可学习性之间有什么关系呢？ 首先，必须假设 g T 0 , 这样才能保证稳定的学习算法£ 具有一定的泛 化能力，即经验损失收敛于泛化损失，否则可学习性无从谈起.为便于计算，我 们 假 定 《 = 总 代 入 式 (12.58)可得 2(£,。) W 及£,。)十卷 + (4 + M) . (12.60) 最小化经验误差和最小 化经验损失有时并不相同, 这是由于存在某些病态的 损 失 函 数 2 使得最小化经 验损失并不是最小化经验 误差.为简化讨论,本章假 定最小化经验损失的同时 会最小化经验误差. 对损失函数0 ,若学习算法£所输出的假设满足经验损失最小化,则称算法 £ 满足经验风险最小化(Empirical Risk M inimization)原则，简称算法是ERM 的.关于学习算法的稳定性和可学习性,有如下定理：",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 571
    }
  },
  {
    "page_content": "对损失函数0 ,若学习算法£所输出的假设满足经验损失最小化,则称算法 £ 满足经验风险最小化(Empirical Risk M inimization)原则，简称算法是ERM 的.关于学习算法的稳定性和可学习性,有如下定理： 定 理 1 2 . 9 若学习算法£ 是 E R M 且稳定的，则假设空间H 可学习. 证明 令 g 表示礼中具有最小泛化损失的假设，即 1 2 . 7 阅读材料 287 再令 他 ,。) = 酬 ( 儿 。). 6 / 6 = 2 , g = 2exp ( - 2 馆 (/产 ), 由 Hoeffding不等式(12.6)可知，当 馆 》 也In ・时， 伍( g ,0 ) — 第 以至少1 - 6 /2 的概率成立.令式(12.60)中 (人 .八 /ln(2/J) 2 - + (4 + M m 7 V ' 2m € = - 2 . , 解 得 馆 = 0 (+ h l 灯 使 F 2 ( £ ,0 ) 々 ( £ , 。) + 5 以至少1 - 6 / 2 的概率成立.从而可得 2(£, 0 ) —如 , 。) W 敢 ⑷ + 厂 ( % , D) - | ) W及£,0 - 制 , 。) + £ W 6 以至少1 - 8 的概率成立.定理12.9得证. ■ 对上面这个定理读者也许会纳闷，为什么学习算法的稳定性能导出假设空 间的可学习性？学习算法和假设空间是两码事呀.事实上，要注意到稳定性与 假设空间并非无关，由稳定性的定义可知两者通过损失函数I 联系起来. 1 2 .7 阅读材料 [Valiant, 1984]提 出 PA C 学习，由此产生了 “计算学习理论”这个机器学 习的分支领域. [Kearns and Vazirani, 1994]是一本很好的入门教材.该领域最 288 第 1 2 章 计 算 学 习 理 论 V C 维的名字就来自两 位作者的姓氏缩写. 重要的学术会议是国际计算学习理论会议(COLT). V C 维 由 ［Vapnik and Chervonenkis, 1971］提出，它的出现使研究无限假 设空间的复杂度成为可能.S au er引 理 由 于 ［Sauer, 1972］而命名，但 ［Vapnik and Chervonenkis, 1971］和 ［Shelah, 1972］也分别独立地推导出了该结果.本 章主要讨论 了 二 分 类 问 题 ，对 多 分 类 问 题 ，可 将 V C 维 扩 展 为 N atarajan 维 ［Natarajan, 1989; Ben-David et al., 1995］.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 572
    }
  },
  {
    "page_content": "章主要讨论 了 二 分 类 问 题 ，对 多 分 类 问 题 ，可 将 V C 维 扩 展 为 N atarajan 维 ［Natarajan, 1989; Ben-David et al., 1995］. Rademacher 复 杂 度 最 早 被 ［Koltchinskii and Panchenko, 2000］引入机器 学习，由 ［Bartlett and Mendelson, 2003］而受到重视. ［Bartlett et al., 2002］提 出了局部Rademacher复杂度，对噪声数据可推导出更紧的泛化误差界. 机器学习算法稳定性分析方面的研究始于［Bousquet and Elisseeff, 2002］ 的工作，此后很多学者对稳定性与可学习性之间的关系进行了讨论，［Mukherjee et al., 2006］和 ［Shalevfhwartz et al., 2010］证明了 ERM 稳定性与 ERM 可学 习性之间的等价关系;但并非所有学习算法都是E R M 的，因 此 ［Shalev-Shwartz et al., 2010］进一步研究了 AERM (Asymptotical Empirical Risk Minimization) 稳定性与可学习性之间的关系. 本章介绍的内容都是关于确定性(deterministic)学习问题，即对于每个示 例比都有一个确定的标记y 与之对应;大多数监督学习都属于确定性学习问题. 但还有 一 种 随 机 性(stochastic)学习问题，其中示例的标记可认为是属性的后 验概率函数，而不再是简单确定地属于某一类.随机性学习问题的泛化误差界 分 析 可参见［Devroye et al., 1996］. 习题 289 习题 12.1 试 证 明 Jensen不等式(12.4). 12.2 试证明引理12.1. 提 示 ：令 B = 2e-2me2 12.3 试证明推论12.1. 12.4 试证明：肽& 空间中线性超平面构成的假设空间的V C 维 是 d + 1. 12.5 试计算决策树桩假设空间的V C 维. 12.6 试证明：决策树分类器的假设空间V C 维可以为无穷大. 12.7 试证明：最近邻分类器的假设空间V C 维为无穷大. 12.8 试证明常数函数。的 Rademacher复杂度为0. 12.9 给定函数空间产1、石 ，试 证 明 Rademacher复 杂 度 & + 石 ) 《 12.10* 考 虑 定 理 12.8,试讨论通过交叉验证法来估计学习算法泛化能力的合 理性. 290 第 1 2 章 计 算 学 习 理 论 参考文献",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 573
    }
  },
  {
    "page_content": "12.7 试证明：最近邻分类器的假设空间V C 维为无穷大. 12.8 试证明常数函数。的 Rademacher复杂度为0. 12.9 给定函数空间产1、石 ，试 证 明 Rademacher复 杂 度 & + 石 ) 《 12.10* 考 虑 定 理 12.8,试讨论通过交叉验证法来估计学习算法泛化能力的合 理性. 290 第 1 2 章 计 算 学 习 理 论 参考文献 Bartlett, P. L., O. Bousquet, and S. Mendelson. (2002). “Localized Rademacher complexities.,5 In Proceedings of the 15th Annual Conference on Learning Theory (COLT), 44-58, Sydney, Australia. Bartlett, P. L, and S. Mendelson. (2003). “Rademacher and Gaussian com­ plexities: Risk bounds and structural results.55 Journal of Machine Learning Research, 3:463-482. Ben-David, S., N. Cesa-Bianchi, D. Haussler, and P. M. Long. (1995). uCharac- terizations of learnability for classes of { 0 , , n}-valued functions.^^ Journal of Computer and System Sciences, 50(1):74-86. Bousquet, O. and A. ElisSeeff. (2002). “Stability and generalization? Journal of Machine Learning Research, 2:499-526. Devroye, L., L. Gyorfi, and G. Lugosi, eds. (1996). A Probabilistic Theory of Pattern Recognition. Springer, New York, NY. Hoeffding, W. (1963). “Probability inequalities for sums of bounded random",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 574
    }
  },
  {
    "page_content": "Pattern Recognition. Springer, New York, NY. Hoeffding, W. (1963). “Probability inequalities for sums of bounded random v a r i a b le s Journal of the American Statistical Association1 58(301):13-30. Kearns, M. J. and U. V. Vazirani. (1994). An Introduction to Computational Learning Theory. MIT Press, Cambridge, MA. Koltchinskii, V. and D. Panchenko. (2000). ^Rademacher processes and bound­ ing the risk of function learning.,5 In High Dimensional Probability II (E. Gine, D. M. Mason, and J. A. Wellner, eds.), 443-457, Birkhauser Boston, Cambridge, MA. McDiarmid, C. (1989). “On the method of bounded differences.55 Surveys in Combinatorics, 141(1):148-188. Mohri, M., A. Rostamizadeh, and A. Talwalkar, eds. (2012). Foundations of Machine Learning. MIT Press, Cambridge, MA. Mukherjee, S., P. Niyogi, T. Poggio, and R. M. Rifkin. (2006). “Learning the­ ory: Stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization.55 Advances in Computational Mathematics^ 25(1-3):161-193.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 575
    }
  },
  {
    "page_content": "ory: Stability is sufficient for generalization and necessary and sufficient for consistency of empirical risk minimization.55 Advances in Computational Mathematics^ 25(1-3):161-193. Natarajan, B. K. (1989). “On learning sets and functions.55 Machine Learning1 4(1):67-97. 参考文献 291 Sauer, N. (1972). “On the density of families of sets.\" Journal of Combinatorial Theory - Series A, 13(1):145-147. Shalev-Shwartz, S., O. Shamir, N. Srebro, and K. Sridhar an. (2010). uLearn- ability, stability and uniform convergence.,5 Journal of Machine Learning Research1 11:2635-2670. Shelah, S. (1972). “A combinatorial problem; stability and order for models and theories in infinitary languages.\" Pacific Journal of Mathematics1 41 (1):247-261. Valiant, L. G. (1984). “A theory of the learnable? Communications of the ACM, 27(11):1134-1142. Vapnik, V. N. and A. Chervonenkis. (1971). “On the uniform convergence of relative frequencies of events to their p ro b a b ilitie s .Theory of Probability and Its Applications, 16(2):264-280. 292 第 1 2 章 计 算 学 习 理 论 休 息 一 会 儿 小故事：计算学习理论之父莱斯利•维利昂特",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 576
    }
  },
  {
    "page_content": "relative frequencies of events to their p ro b a b ilitie s .Theory of Probability and Its Applications, 16(2):264-280. 292 第 1 2 章 计 算 学 习 理 论 休 息 一 会 儿 小故事：计算学习理论之父莱斯利•维利昂特 计算机科学的绝大多数分支领域中都既有理论研究，也 有应用研究，但 当 人 们 说 到 “理论 计 算 机 科 学 ” 时，通常 是指一个特定的研究领域 TCS (Theoretical Computer S cien ce ),它可看作计算机科学与数学的交叉，该领域中最 著 名 的 问 题 是 “P ? = N P ” . 计算学习理论是机器学习的一个分支，它可认为是机器学习与理论计算机 科学的交叉.提起计算学习理论，就必然要谈到英国计算机科学家莱斯利・维 利 昂 特 (Leslie G. Valiant, 1949— ) . 维利昂特先后在剑桥大学国王学院、帝 国理工学院学习，1974年在华威大学获计算机科学博士学位，此后曾在卡耐 基梅隆大学、利兹大学和爱丁堡大学任教，1982年来到哈佛大学任计算机与 应用数学讲席教授. 1984年 他 在 《ACM通讯》发 表 了 论 文 “A theory of the learnable” . 这篇论文首次提出了 P A C 学习，从而开创了计算学习理论的研究. 2010年 A C M 授予维利昂特图灵奖，以表彰他对P A C 学习理论的开创性贡献, 以及他对枚举和计算代数复杂性等其他一些理论计算机科学问题的重要贡献. 颁奖词特别指出，维 利 昂 特 在 1984年发表的论文创立了计算学习理论这个研 究领域，使机器学习有了坚实的数学基础，扫 清 了 学 科 发 展 的 障 碍 .《ACM新 闻》则以 uA C M Turing Award Goes to Innovator in Machine Learning\"为 题对这位机器学习领域首位图灵奖得主的功绩大加褒扬. 第 1 3 章 半 监 督 学 习 1 3 .1 未标记样本 我们在丰收季节来到瓜田，满地都是西瓜，瓜农抱来三四个瓜说这都是好 瓜，然后再指着地里的五六个瓜说这些还不好，还需再生长若干天.基于这些信 息，我们能否构建一个模型，用于判别地里的哪些瓜是已该采摘的好瓜？显然, 可将瓜农告诉我们的好瓜、不好的瓜分别作为正例和反例来训练一个分类器. 然而，只用这不到十个瓜做训练样本，有点太少了吧？能不能把地里的那些瓜 也用上呢？",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 577
    }
  },
  {
    "page_content": "我们在丰收季节来到瓜田，满地都是西瓜，瓜农抱来三四个瓜说这都是好 瓜，然后再指着地里的五六个瓜说这些还不好，还需再生长若干天.基于这些信 息，我们能否构建一个模型，用于判别地里的哪些瓜是已该采摘的好瓜？显然, 可将瓜农告诉我们的好瓜、不好的瓜分别作为正例和反例来训练一个分类器. 然而，只用这不到十个瓜做训练样本，有点太少了吧？能不能把地里的那些瓜 也用上呢？ 形式化地看，我们有训练样本集Di = ｛（如 阴），（殴,统）,...，（皿 加 ｝，这 ％ 个样本的类别标记（即是否好瓜）已知，称 为 “有标记”（匕beled）样本；此外，还 有 。〃 = … 《 跖这〃个样本的类别标记未知（即不知是 否好瓜），称 为 “未标记”（unlabeled）样本.若直接使用传统监督学习技术，则 仅 有 D t 能用于构建模型，D u 所包含的信息被浪费了；另一方面，若 D 较小, 则由于训练样本不足，学得模型的泛化能力往往不佳.那么，能否在构建模型的 过 程 中 将 利 用 起 来 呢 ？ 一个简单的做法,是将中的示例全部标记后用于学习.这就相当于请瓜 农把地里的瓜全都检查一遍，告诉我们哪些是好瓜，哪些不是好瓜，然后再用于 模 型 训 练 .显 然 ，这样做需耗费瓜农大量时间和精力.有没有“便 宜 ” 一点的 办法呢？ 我们可以用Di先训练一个模型，拿这个模型去地里挑一个瓜，询问瓜农好 例 如 基 于 Di 训练一个 S V M ,挑选距离分类超平 面最近的未标记样本来进 行查询. 不好，然后把这个新获得的有标记样本加入R 中重新训练一个模型，再去挑 瓜，……这样，若每次都挑出对改善模型性能帮助大的瓜，则只需询问瓜农比较 少的瓜就能构建出比较强的模型，从而大幅降低标记成本.这样的学习方式称 为 “主 动 学 习 \"（active learning）, 其目标是使用尽量少的“查询”（query）来获 即尽量少向瓜农询问. 得尽量好的性能. 显然，主动学习引入了额外的专家知识，通过与外界的交互来将部分未标 记样本转变为有标记样本.若不与专家交互，没有获得额外信息，还能利用未标 记样本来提高泛化性能吗？ 答 案 是 “ Y es!” ，有点匪夷所思？ 294 第 1 3 章 半 监 督 学 习 事实上，未标记样本虽未直接包含标记信息，但若它们与有标记样本是从 同样的数据源独立同分布采样而来，则它们所包含的关于数据分布的信息对建 立模型将大有裨益.图1 3 .1 给出了一个直观的例示.若仅基于图中的一个正例 和一个反例，则由于待判别样本恰位于两者正中间，大体上只能随机猜测；若能 观察,到图中的未标记样本，则将很有把握地判别为正例. 判 别 样 本 观 察 到 /",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 578
    }
  },
  {
    "page_content": "事实上，未标记样本虽未直接包含标记信息，但若它们与有标记样本是从 同样的数据源独立同分布采样而来，则它们所包含的关于数据分布的信息对建 立模型将大有裨益.图1 3 .1 给出了一个直观的例示.若仅基于图中的一个正例 和一个反例，则由于待判别样本恰位于两者正中间，大体上只能随机猜测；若能 观察,到图中的未标记样本，则将很有把握地判别为正例. 判 别 样 本 观 察 到 / 未 标 记 样 本 、 • + O - I > + o ・ • ・ • • • • 一 • • • • • 图 13.1 未标记样本效用的例示.右边的灰色点表示未标记样本 让学习器不依赖外界交互、 自动地利用未标记样本来提升学习性能，就是 半监督学习(semi-supervised learn in g).半监督学习的现实需求非常强烈，因为 在现实应用中往往能容易地收集到大量未标记样本，而 获 取 “标记”却需耗费 人力、物力.例 如 ，在进行计算机辅助医学影像分析时，可以从医院获得大量医 学影像，但若希望医学专家把影像中的病灶全都标识出来则是不现实的.“有 标记数据少，未标记数据多”这个现象在互联网应用中更明显，例如在进行网 页推荐时需请用户标记出感兴趣的网页，但很少有用户愿花很多时间来提供标 记，因此,有标记网页样本少，但互联网上存在无数网页可作为未标记样本来使 用.半监督学习恰是提供了一条利用“廉价”的未标记样本的途径. 要利用未标记样本，必然要做一些将未标记样本所揭示的数据分布信息与 类 别 标 记 相 联 系 的 假 设 .最 常 见 的 是 “聚类假设”(cluster assum ption),即假 设数据存在簇结构，同一个簇的样本属于同一个类别.图1 3 .1 就是基于聚类假 设来利用未标记样本，由于待预测样本与正例样本通过未标记样本的“撮 合 ” 聚在一起，与相对分离的反例样本相比，待判别样本更可能属于正类.半监督 学习中另一种常见的假设是“流 形 假 设 \"(manifold assum ption),即假设数据 分布在一个流形结构上，邻近的样本拥有相似的输出值.“邻近”程 度 常 用 “相 似 ”程度来刻画，因此,流形假设可看作聚类假设的推广，但流形假设对输出值 没有限制，因此比聚类假设的适用范围更广，可用于更多类型的学习任务.事实 上，无论聚类假设还是流形假设，其 本 质 都 是 “相似的样本拥有相似的输出” 这个基本假设. “流 形 ”概念是 流形学 习的基础，参 见 10.5节. 聚类假设考虑的是类别 标 记 ，通常用于分类任务. 1 3 . 2 生成式方法 295",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 579
    }
  },
  {
    "page_content": "没有限制，因此比聚类假设的适用范围更广，可用于更多类型的学习任务.事实 上，无论聚类假设还是流形假设，其 本 质 都 是 “相似的样本拥有相似的输出” 这个基本假设. “流 形 ”概念是 流形学 习的基础，参 见 10.5节. 聚类假设考虑的是类别 标 记 ，通常用于分类任务. 1 3 . 2 生成式方法 295 半监督学习可进一步划分为纯(pure)半监督学习和直推学习(transductive learning),前者假定训练数据中的未标记样本并非待预测的数据，而后者则假 定学习过程中所考虑的未标记样本恰是待预测数据，学习的目的就是在这些 未标记样本上获得最优泛化性能.换言之，纯半 监 督 学 习 是 基 于 “开放世界” 假设，希望学得模型能适用于训练过程中未观察到的数据；而直推学习是基 于 “封 闭 世 界 ”假设，仅试图对学习过程中观察到的未标记数据进行预测. 图 1 3 .2 直观地显示出主动学习、纯半监督学习、直推学习的区别.需注意的 是，纯半监督学习和直推学习常合称为半监督学习，本书也采取这一态度，在需 专门区分时会特别说明. 图 1 3 . 2 主动学习、(纯)半监督学习、直推学习 1 3 . 2 生成式方法 生成式方法(generative methods)是直接基于生成式模型的方法.此类方法 假设所有数据(无论是否有标记)都是由同一个潜在的模型“生成”的.这个假 设使得我们能通过潜在模型的参数将未标记数据与学习目标联系起来，而未标 E M 算法参见7 .6 节. 记数据的标记则可看作模型的缺失参数，通常可基于E M 算法进行极大似然估 计求解.此类方法的区别主要在于生成式模型的假设，不同的模型假设将产生 不同的方法. 296 第 1 3 章 半 监 督 学 习 这个假设意味着混合成 分与类别之间一一对应. 给定样本叫其真实类别标记为沙e 其 中 y = {1,2,..., N } 为所有可能 的类别.假设样本由高斯混合模型生成，且每个类别对应一个高斯混合成分.换 言之，数据样本是基于如下概率密度生成： N p(”) = £ Q 「夕(宓 I 也 ,此 )， (13.1) 2=1 其中，混 合 系 数 色 》o, & = I； p(x I也，划 是 样 本 比 属于第i个高斯混 高 斯 混 合 模 型 参 见 9.4 节. 合成分的概率;也和此为该高斯混合成分的参数. 令 f(x) e y 表 示 模 型 / 对 z 的预测标记，0 € {1,2, ...,2V}表 示 样 本 X 隶属的高斯混合成分.由最大化后验概率可知 /(«) = arg maxp(7/ = 川 况) jey N = arg m a x",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 580
    }
  },
  {
    "page_content": "高 斯 混 合 模 型 参 见 9.4 节. 合成分的概率;也和此为该高斯混合成分的参数. 令 f(x) e y 表 示 模 型 / 对 z 的预测标记，0 € {1,2, ...,2V}表 示 样 本 X 隶属的高斯混合成分.由最大化后验概率可知 /(«) = arg maxp(7/ = 川 况) jey N = arg m a x = J, 0 = z | a?) i=i N —arg m a x £ 2 (沙= j | 0 = i, ic) - p(0 — i \\ x) , (13.2) 2=1 其中 汉8 = 5 5 ) = : 「P ( W 生，&) (13.3) £ Q 厂2 3 | 也 ，必) i=A. 为 样 本 宓 由 第i个高斯混合成分生成的后验概率,夕仅= 川 9 = E,⑹ 为宓由 第 i 个高斯混合成分生成且其类别为j 的概率.由于假设每个类别对应一个高 斯混合成分，因此p(y = j\\e = i,⑼仅与样本比所属的高斯混合成分e 有关, 可 用 M u = 川 6 = i)代替.不失一般性，假 定 第 i个类别对应于第i个高斯混 合成分，即 p(y = J | 0 = z) = 1 当且仅当i = j,否 则 p(y = j \\ Q = i) = 0. 不难发现，式(13.2)中估计双沙= j | 6 = i㈤ 需知道样本的标记，因此仅 能使用有标记数据；而/ ( 9 = i\\x)不涉及样本标记，因此有标记和未标记数据 均可利用，通过引入大量的未标记数据，对这一项的估计可望由于数据量的增 长而更为准确，于是式(13.2)整体的估计可能会更准确.由此可清楚地看出未标 记 数 据 何 以 能 辅 助 提 高 分 类 模 型 的 性 能 .’ 给 定 有 标 记 样 本 集 。Z = { ( % 勿),(宓2,沙2),… ，(孙功)}和未标记样本集 1 3 .2 生成式方法 半监督学习中通常假设 未标记样本数远大于有标 记样本数，虽然此假设实 际并非必须. 高 斯 混 合 模 型 聚 类 的 E M 算法参见9 .4 节. 可通过有标记数据对模 型参数进行初始化. D u = { 皿 g + 2 , . • . , 都是由同一个高斯混合模型生成的.用极大似然法来估计高斯混合模型的参数 = 假设所有样本独立同分布，且 I《 % { Q , 取 2 扪 1 W £ W N},Di U D u 的对数似然是 297 LL{Di U A ) = In £ (叼，%)eQ + E l n (f (t",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 581
    }
  },
  {
    "page_content": "D u = { 皿 g + 2 , . • . , 都是由同一个高斯混合模型生成的.用极大似然法来估计高斯混合模型的参数 = 假设所有样本独立同分布，且 I《 % { Q , 取 2 扪 1 W £ W N},Di U D u 的对数似然是 297 LL{Di U A ) = In £ (叼，%)eQ + E l n (f (t & • p{xj | 2 ) • p(yj \\e = i,叼) 以 •0(％• | MiAi) . (13.4) 式(13.4)由两项组成：基于有标记数据D t 的有监督项和基于未标记数据D u 的 无监督项.显然，高斯混合模型参数估计可用E M 算法求解，迭代更新式如下： • E 步：根据当前模型参数计算未标记样本叼属于各高斯混合成分的概率 _ 0 • P{Xj | 也,£〃) 力》= ~N E a i - P(x j I Nii 多i) i=l (13.5) • M 步：基 于 更 新 模 型 参 数 ，其中办表示第i类的有标记样本数目 % = 丁 ；一+4 E % » 叼 + E X jE D u ' \\ X j E D u ( x j ,y j)EDi /\\y j —i 叼 (13.6) 兄 = ―y . + Z. I 2 2 8 分(叼 ~ ~ Mi)T X jE D u 3 1 \\ X jE D u + (叼 —也)(叼 —也), ( X j,y j) e D i/\\y j= i a i = m [ £ % + / J j - \\jC jG D u (13.7) (13.8) 以上过程不断迭代直至收敛，即可获得模型参数.然后由式(13.3)和(13.2)就能 对样本进行分类. 将 上 述 过 程 中 的 高 斯 混 合 模 型 换 成 混 合 专 家 模 型 ［Miller and Uyar, 1997］＞朴 素 贝 叶 斯 模 型 ［Nigam et a l, 2000］等即可推导出其他的生成式半 298 第 1 3 章 半 监 督 学 习 监督学习方法.此类方法简单，易于实现,在有标记数据极少的情形下往往比其 他方法性能更好.然而，此类方法有一个关键：模型假设必须准确，即假设的生 成式模型必须与真实数据分布吻合；否则利用未标记数据反倒会降低泛化性能 [Cozman and Cohen, 2002].遗憾的是，在现实任务中往往很难事先做出准确 的模型假设，除非拥有充分可靠的领域知识. 1 3 .3 半监督SVM S V M 参见第6 章.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 582
    }
  },
  {
    "page_content": "他方法性能更好.然而，此类方法有一个关键：模型假设必须准确，即假设的生 成式模型必须与真实数据分布吻合；否则利用未标记数据反倒会降低泛化性能 [Cozman and Cohen, 2002].遗憾的是，在现实任务中往往很难事先做出准确 的模型假设，除非拥有充分可靠的领域知识. 1 3 .3 半监督SVM S V M 参见第6 章. S3VM )是 支 持 向 量 机 在 半 监 督 学 习 上 的 推 广 .在 不 考 虑 未 标 记 样 本 时 ，支 半 监 督 支 持 向 量 机 (Semi-Supervised Support Vector M achine,简称 持向量机试图找到最大间隔划分超平面，而在考虑未标记样本后，S3VM 试 图找到能将两类有标记样本分开，且穿过数据低密度区域的划分超平面，如 图 13.3所示，这 里 的 基 本 假 设 是 “低密度分隔”(low-density separation), 显 然，这是聚类假设在考虑了线性超平面划分后的推广. S3 V M 划分超平面 S V M 划分超平面 图 1 3 . 3 半监督支持向量机与低密度分隔( “十” 灰色点表示未标记样本) ”分别表示有标记的正、反例, 半 监 督 支 持 向 量 机 中 最 著 名 的 是 TSVM (Transductive Support Vector Machine) [Joachims, 1 9 9 9 ].与 标 准 SVM 一样，T SV M 也是针对二分类问题 的 学 习 方 法 .TSV M 试图考虑对未标记样本进行各种可能的标记指派(label assignm ent),即尝试将每个未标记样本分别作为正例或反例，然后在所有这些 结果中，寻求一个在所有样本(包括有标记样本和进行了标记指派的未标记样 本)上间隔最大化的划分超平面.一旦划分超平面得以确定，未标记样本的最终 标记指派就是其预测结果. 1 3 . 3 半监督SVM 299 形 式 化 地 说 ，给定D = { ( % g ),(况2,故),… ，( 孙 知 ) } 和 = {xi+ 1 , g + 2 ,… ，Xi+ u ),其 中 % G { -1 ,+ 1 } , l《 u,l + u = m. TSVM 的学习目标是 为 D u 中的样本给出预测标记y = (如 1,应+2,… ，访+ J Vi e { -1 , + 1 } ,使得 1 求 嗯 成 ㈤ 隙 + ，，， I i=l m £ & S.t. yi(wT Xi + b ) 2 1 - 〃= 1 2 ・•・ 4 (13.9)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 583
    }
  },
  {
    "page_content": "1 求 嗯 成 ㈤ 隙 + ，，， I i=l m £ & S.t. yi(wT Xi + b ) 2 1 - 〃= 1 2 ・•・ 4 (13.9) Vi(3 Xj + b ) 》l - 〃 = / + l )2 + 2 ) ..・, m) E = TTI) 其中，(叫 b)确定了一个划分超平面;£ 为松弛向量,& (6= 1 , 2 , ... N )对应于有 标记样本，& (分= Z + 1N + 2 ,. . . ,馆)对应于未标记样本；Cl与 Cu 是由用户指 定的用于平衡模型复杂度、有标记样本与未标记样本重要程度的折中参数. 显然，尝试未标记样本的各种标记指派是一个穷举过程，仅当未标记样本 很少时才有可能直接求解.在一般情形下，必须考虑更高效的优化策略. TSV M 采用局部搜索来迭代地寻找式(13.9)的近似解.具体来说，它先利 用有标记样本学得一个S V M ,即忽略式(13.9)中 关 于 。〃与自的项及约束.然 后，利 用 这 个 SVM 对未标记数据进行标记指派(label assignm ent),即 将 SVM 预 测 的 结 果 作 为 “伪标记”(pseudo-label)赋予未标记样本.此时不成为已知, 将其代入式(13.9)即得到一个标准SV M 问题，于是可求解出新的划分超平面和 松弛向量；注意到此时未标记样本的伪标记很可能不准确，因 此 要 设 置 为 比 Ci小的值，使有标记样本所起作用更大.接下来，TSV M 找出两个标记指派为 异类且很可能发生错误的未标记样本，交换它们的标记，再重新基于式(13.9)求 解出更新后的划分超平面和松弛向量，然后再找出两个标记指派为异类且很可 能发生错误的未标记样本，……标记指派调整完成后，逐渐增大a 以提高未标 记样本对优化目标的影响，进行下一轮标记指派调整，直 至 Cu = Ci为止.此时 求解 得 到 的SVM 不仅给未标记样本提供了标记，还能对训练过程中未见的示 例进行预测.TSV M 的算法描述如图13.4所示. 在对未标记样本进行标记指派及调整的过程中，有可能出现类别不平衡问 题，即某类的样本远多于另一类，这 将 对 SV M 的训练造成困扰.为了减轻类别 不平衡性所造成的不利影响，可 对 图 13.4的算法稍加改进：将优化目标中的 项 拆 分 为 C + 与 c - 两项，分别对应基于伪标记而当作正、反例使用的未标记 样本，并在初始化时令 类 别 不 平 衡 问 题 及 式(13.10)的 缘 由 见 3 .6 节. 300 第1 3 章半监督学习",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 584
    }
  },
  {
    "page_content": "题，即某类的样本远多于另一类，这 将 对 SV M 的训练造成困扰.为了减轻类别 不平衡性所造成的不利影响，可 对 图 13.4的算法稍加改进：将优化目标中的 项 拆 分 为 C + 与 c - 两项，分别对应基于伪标记而当作正、反例使用的未标记 样本，并在初始化时令 类 别 不 平 衡 问 题 及 式(13.10)的 缘 由 见 3 .6 节. 300 第1 3 章半监督学习 输 入 ：有好记样本集Q = {(%阴 )，3 2 , 沙2),… ，(皿，讥)}； 未^5记样本集 Du = {冗z+i, g + 2 , • • • 5 血+〃}; 折中参数G , a . 此 时 y 为已知. yi与 yj进行调整. 提高未标记样本的影响. while 3{i,j \\ ^yj < 0) A & > 0) A 过 程 ： 1：用 R 训练一个S V M z ； 2：用 S V M z 对 D u 中样本进行预测，得到y = (或+i,或+2,… ，或+〃)； 3：初始化a 《 a ； 4： while Cu < Ci do 5： 基于 Di,Du1 y,Ch Cu 求解式(13.9),得至！J (叫 &), & 6： 7： 8： 9： 基于D h D u, y, Ci.Cu重新求解式(13.9),得到(叫b), £ 10： e n d while 11： Cu = mm{2Cu,Ci} 12： e n d while 输 出 ：未标记样本的预测结果：& = (负+1,而+2, •••,«+〃) Vi = -y^ yj = —%; > 0) A (a + & > 2)} d o 图 13.4 T S V M 算法 ^ = — C , (13.10) 其 中 〃 +与 为 基 于 伪 标 记 而 当 作 正 、反例使用的未标记样本数. 在 图 13.4算 法 的 第 6 -1 0 行中，若 存 在 一 对 未 标 记 样 本 X i 与 叼 ，其标记 指 派 yi与 yj不同，且对应的松弛变量满足& + &• > 2 , 则 意 味 着yi与 病 很可 能是错误的，需对二者进行交换后重新求解式(13.9),这样每轮迭代后均可使 收 . 敛 性 证 明 参 阅 [Joachims, 1999]. 式(13⑼的目标函数值下降. 、 显 然 ，搜寻标记指派可能出错的每一对未标记样本进行调整，是一个涉 及 巨 大 计 算 开 销 的 大 规 模 优 化 问 题 .因 此 ，半 监 督 SVM 研究的一个重点是 如何设 计 出 高 效 的 优 化 求 解 策 略 ，由此发展出很多方法，如 基 于图核(graph",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 585
    }
  },
  {
    "page_content": "收 . 敛 性 证 明 参 阅 [Joachims, 1999]. 式(13⑼的目标函数值下降. 、 显 然 ，搜寻标记指派可能出错的每一对未标记样本进行调整，是一个涉 及 巨 大 计 算 开 销 的 大 规 模 优 化 问 题 .因 此 ，半 监 督 SVM 研究的一个重点是 如何设 计 出 高 效 的 优 化 求 解 策 略 ，由此发展出很多方法，如 基 于图核(graph kernel)函数梯度下降的LDS [Chapelle and Zien, 2005]> 基于标记均值估计的 meanS3VM [Li et al., 2009]等. 1 3 .4 图半监督学习 给定一个数据集，我们可将其映射为一个图，数据集中每个样本对应于图 中一个结点，若两个样本之间的相似度很高(或相关性很强)，则对应的结点之间 存在一条边，边 的 “强度” (strength)正比于样本之间的相似度(或相关性).我 们可将有标记样本所对应的结点想象为染过色，而未标记样本所对应的结点尚 1 3 . 4 图半监督学习 301 未染色.于是，半监督学习就对应于“颜色”在图上扩散或传播的过程.由于一 个图对应了一个矩阵，这就使得我们能基于矩阵运算来进行半监督学习算法的 推导与分析. 给定 Di = {(叫，见)，(比2,沙2),… 和 D u = { g + i , g + 2 , . . . , g + “}, L《u,l + u = m . 我 们 先 基 于 Q U O ”构 建 一 个 图 G = (匕石)，其中结点 E 可 表 示 为 一 个 亲 和 矩 阵 (affinity 集 V = { g , … ，叫 集 边 matrix),常基于高斯函数定义为 exp ( 当 声 ) ， if仔 九 ( W ) L ' ) (13.11) 、0 , otherwise , 其 中 z,j€ {l,2,...,m},<7>0是用户指定的高斯函数带宽参数. 假 定 从 图G = (V,石)将学得一个实值函数/ ：卜 T 见其对应的分类规则 为：% = sign(/(g)), yi E { - 1 , + 1 ) . 直观上看,相似的样本应具有相似的标记, 于是可定义关于f 的 “能 量 函 数 \"(energy function) [Zhu et al., 2003]: 能量函 数 最 小 化 时 即 得 到最优结果. 、 m m E(f) = / (叼)『 i—1 j=l / m m m m \\ £ d \" 2 ( g ) + £ 力 产 ( 叼 ) - 2 E £ ( W % / ( g ) / (叼) 1 = 2",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 586
    }
  },
  {
    "page_content": "能量函 数 最 小 化 时 即 得 到最优结果. 、 m m E(f) = / (叼)『 i—1 j=l / m m m m \\ £ d \" 2 ( g ) + £ 力 产 ( 叼 ) - 2 E £ ( W % / ( g ) / (叼) 1 = 2 y 2=1 m j=l m m = E &尸 (g ) _ £ i=l i=l j=l = / T ( D - W ) f , i=l j=l J . (叼) (13.12) W 为 对 称 矩 阵 ，因此否 亦 为 W 第 。列元素之和. 其 中 f = (力丁疗尸，fi = (/(附);/(政);… \"(g)), fu = (/(@ +i); 〃电钻)；… ；/ Q z + G ) 分别为函数f 在有标记样本与未标记样本上的预测结果, D = diag(di,加 … ，dl+u)是 一 个 对 角 矩 阵 ,其 对 角 元 素 = £ 署 ( W ) 〃・为矩 阵 W 的 第 5 行元素之和. 具有 最 小 能 量 的 函 数f 在 有 标 记 样 本 上 满 足f(xi) = % (E = 1,2,...,力 在未标记样本上满足△/ = (),其 中 4 = D - W 为拉普拉斯矩阵 (Laplacian -W77 W 7 - matrix).以 第l行 与 第 l列为界，采用分块矩阵表示方式：W = 11 也 ， W 加 W w 302 第1 3 章半监督学习 D = Du Oiu 。加 D M” ,则式(13.12)可重写为 成 /) = (力T为 吃 Wzz w® w 加 Ww fl fu (13.13) = 力T (D 〃 - W 加力—2打 W 加力 + 片 ( D u u - W u u )fu (13.14) 由 等 Q = o 可得 。丁 u 令 fu = ( D 1 m - W q T W 加力. . (13.15) P = D - 1 W = P U % ] * W ® _ °加 ^uu_ ul = D / W ® ] 一 D熟W加 D-JWUJ ) (13.16) 即 P u u = D - J W „ , P u l = D ^ W 加，则式(13.15)可重写为 fu = ( D ^ ( I - D / W M ))T W 加力 = u - D ^ W W )T D 烹 w 加力 = ( I - P u u ) - 1P u lf l . (13.17)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 587
    }
  },
  {
    "page_content": "一 D熟W加 D-JWUJ ) (13.16) 即 P u u = D - J W „ , P u l = D ^ W 加，则式(13.15)可重写为 fu = ( D ^ ( I - D / W M ))T W 加力 = u - D ^ W W )T D 烹 w 加力 = ( I - P u u ) - 1P u lf l . (13.17) 于是，将 D l 上的标记信息作为fi = (7/i； 7/2；… ；明)代入式(13.17),即可利用求 得 的 f u 对未标记样本进行预测. 上面描述的是一个针对二分类问题的标记传播(label propagation)方法,下 面来看一个适用于多分类问题的标记传播方法[Zhou et al., 2004]. 假 定 yi e ， 仍 基 于 Di U D u 构 建 一 个 图 G = \" E ) , 其 中 结 点 集 卜 = { % . . . ，如 … ，皿+〃},边 集 石 所 对 应 的 W 仍 使 用 式 (13.11),对 角矩阵 D = diag(di,d2,...,dz+”) 的 对 角 元 素 & = 定义一 个 Q + M 义 3 的 非 负 标 记 矩 阵 F = ( 瑁 , 吗 ，… ，F a J T , 其 第 E 行元素 玛 = ((F)〃,(F)% ...，便 )心 |)为 示 例 X i 的 标 记 向 量 ，相应的分类规则为: Vi = a r g m a x i * w » | ( F ) 切. 对〃 = 1,2,..., = 1,2,..., I” , 将 F 初始化为 1 3 . 4 图半监督学习 F(0) = (丫后= 1, if (1 W W %)八 ( % = 力 ； 0, otherwise. 303 (13.18) 显然，Y 的 前 I行 就 是I个有标记样本的标记向量. 基 于 W 构 造 一 个 标 记 传 播 矩 阵 S = D i W D - i , 其 中 D i = 也 能 ( 含 ，矗 ，… ，扁 ：) ，于是有迭代计算式 F(t + 1) = a S F ⑴ 4 - ( 1 - a ) Y / (13.19) 其 中 a G (0,1)为用户指定的参数，用于对标记传播项S F ( t ) 与初始化项Y 的 重要性进行折中.基于式(13.19)迭代至收敛可得 F * = lim F ⑴ = ( 1 - a)(I - ⑹ 一 丫 tt-yoo (13.20) 由 F * 可 获 得D u 中样本的标记你+1,应+2,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 588
    }
  },
  {
    "page_content": "(13.19) 其 中 a G (0,1)为用户指定的参数，用于对标记传播项S F ( t ) 与初始化项Y 的 重要性进行折中.基于式(13.19)迭代至收敛可得 F * = lim F ⑴ = ( 1 - a)(I - ⑹ 一 丫 tt-yoo (13.20) 由 F * 可 获 得D u 中样本的标记你+1,应+2, 算法描述如图13.5所示. 输入：有好用样本集 R = {(®i, 2/1), (a?2 ,2/2), • • •, (xi, yi)}; 未标记样本集 Du = {血+i,血+ 2 , ,血+〃}； 构 图 参 数 。； 折 中 参 数 a. 过程： 1：套 于 式 (13.11)和 参 数 。得 到 W ; F(% + 1) = aSF(t) + ( 1 - a)Y; t = t + 1 2：基 于 W 构造标记传播矩阵S = D - 4 W D - I ; 3：根据式(13.18)初 始 化 F(0); 4 : 力= 0 ; 5： r e p e a t 6： 7： 8： u n t i l 迭 代 收 敛 至 F * 9： fo r 〃 = % + 10： 11： e n d for 输 出 ：未标记样本的预测结果:欧= ( % +1,仇+2, • • •,我+〃) yi = a r g m a x i w ^ | ，| ( F * % + 2 , , Z + a d o 图 1 3 . 5 迭代式标记传播算法 事实上，图 13.5的算法对应于正则化框架[Zhou et al., 2004] / 2=1 (13.21) 304 第 1 3 章 半 监 督 学 习 其 中 4 > 0 为正则化参数.当〃= 噤 时 ，式(13.21)的最优解恰为图13.5算法 的迭代收敛解F , 式(13.21)右边第二项是迫使学得结果在有标记样本上的预测与真实标记 尽可能相同，而第一项则迫使相近样本具有相似的标记，显然,它与式(13.12)都 是基于半监督学习的基本假设，不 同 的是式(13.21)考虑离散的类别标记，而 式(13.12)则是考虑输出连续值. 图半监督学习方法在概念上相当清晰，且易于通过对所涉矩阵运算的分析 来探索算法性质.但此类算法的缺陷也相当明显.首先是在存储开销上，若样 本 数 为 O (m ),则算法中所涉及的矩阵规模为。(馆2 ) ,这使得此类算法很难直接 处理大规模数据；另一方面，由于构图过程仅能考虑训练样本集,难以判知新样",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 589
    }
  },
  {
    "page_content": "式(13.12)则是考虑输出连续值. 图半监督学习方法在概念上相当清晰，且易于通过对所涉矩阵运算的分析 来探索算法性质.但此类算法的缺陷也相当明显.首先是在存储开销上，若样 本 数 为 O (m ),则算法中所涉及的矩阵规模为。(馆2 ) ,这使得此类算法很难直接 处理大规模数据；另一方面，由于构图过程仅能考虑训练样本集,难以判知新样 本在图中的位置，因此，在接收到新样本时，或是将其加入原数据集对图进行重 构并重新进行标记传播，或是需引入额外的预测机制，例 如 将DL 和经标记传播 后得到标记的D u 合并作为训练集，另外训练一个学习器例如支持向量机来对 新样本进行预测. 1 3 .5 基于分歧的方法 与生成式方法、半 监 督 SVM、图半监督学习等基于单学习器利用未标记 数据不同，基于分歧的方法(disagreement-based m ethods)使用多学习器，而学 习 器 之 间 的 “分歧”(disagreement)对未标记数据的利用至关重要. “协 同 训 练 \"(co-training) [Blum and Mitchell, 1998]是此类方法的重要 代 表 ,它 最 初 是 针 对 “多视图”(multi-view)数据设计的，因 此 也 被 看 作 “多视 图学习\" (multi-view learning)的代表.在介绍协同训练之前，我们先看看什么 是多视图数据. 在不少现实应用中，一个数据对象往往同时拥有多个“属 性 集 \"(attribute s e t) ,每个属性集就构成了一个“视图”(v ie w ).例如对一部电影来说，它拥有 多个属性集：图像画面信息所对应的属性集、声音信息所对应的属性集、字幕 信息所对应的属性集、甚至网上的宣传讨论所对应的属性集等.每个属性集都 .可看作一个视图.为简化讨论，暂且仅考虑图像画面属性集所构成的视图和声 音属性集所构成的视图.于是，一个电影片段可表示为样本(3 \\ a 2 ) , g ), 其中 是样本在视图。中的示例，即基于该视图属性描述而得的属性向量，不妨假 定比1 为图像视图中的属性向量，比2 为声音视图中的属性向量；y 是标记，假定 是电影的类型，例 如 “动作片”、 “爱情片”等. (3 \\ 宠2〉用)这样的数据就是 多视图数据. disagreement 亦称 diver­ sity. 1 3 . 5 基于分歧的方法 305 假 设 不 同 视 图 具 有 “相 容 性 ”(com patibility),即其所包含的关于输出空 间 ， 的信息是一致的：令 「 表示从图像画面信息判别的标记空间，然 表 示 从",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 590
    }
  },
  {
    "page_content": "多视图数据. disagreement 亦称 diver­ sity. 1 3 . 5 基于分歧的方法 305 假 设 不 同 视 图 具 有 “相 容 性 ”(com patibility),即其所包含的关于输出空 间 ， 的信息是一致的：令 「 表示从图像画面信息判别的标记空间，然 表 示 从 声音信息判别的标记空间，则 有 J 而不能是” = ｛爱情片,动作片｝而 然 = ｛文艺片，惊悚片｝.在此假设下，显式 例如两者都是｛爱情片，动作片｝, \" 地考虑多视图有很多好处.仍以电影为例，某个片段上有两人对视,仅凭图像画 面信息难以分辨其类型，但此时若从声音信息听到“我爱你”，则可判断出该 片 段 很 可 能 属 于 “爱情片”；另一方面，若仅凭图像画面信息认为“可能是动 作 片 ”，仅 凭 声 音 信 息 也 认 为 “可能是动作片”，则当两者一起考虑时就有很 大的把握判别为“动作片”.显 然 ，在 “相容性”基础上，不同视图信息的“互 补性，，会给学习器的构建带来很多便利. 协同训练正是很好地利用了多视图的“相容互补性”.假设数据拥有两个 充分(sufficient)且条件独立视图，“充 分 ”是指每个视图都包含足以产生最优 学习器的信息，“条件独立”则是指在给定类别标记条件下两个视图独立.在 此情形下，可用一个简单的办法来利用未标记数据：首先在每个视图上基于有 标记样本分别训练出一个分类器，然后让每个分类器分别去挑选自己“最有把 握 的 ”未标记样本赋予伪标记，并将伪标记样本提供给另一个分类器作为新 增的有标记样本用于训练更新……这 个 \"互 相 学 习 、共同进步”的过程不断 迭代进行，直到两个分类器都不再发生变化，或达到预先设定的迭代轮数为止. 算 法 描 述 如 图 13.6所示.若在每轮学习中都考察分类器在所有未标记样本上 的分类置信度，会有很大的计算开销，因此在算法中使用了未标记样本缓冲池 [Blum and Mitchell, 1998].分类置信度的估计则因基学习算法£ 而异，例如若 使用朴素贝叶斯分类器，则可将后验概率转化为分类置信度；若使用支持向量 机,则可将间隔大小转化为分类置信度. 弱分类器参见第8 章. 且条件独立，则可利用未标记样本通过协同训练将弱分类器的泛化性能提升到 协同训练过程虽简单，但令人惊讶的是，理论证明显示出，若两个视图充分 例如电影画面与声音显 然不会是条件独立的. 单视图数据即仅有一个 属性集合的常见数据. 任意高[Blum and Mitchell, 1998].不过，视图的条件独立性在现实任务中通常 很难满足，因此性能提升幅度不会那么大，但研究表明，即便在更弱的条件下,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 591
    }
  },
  {
    "page_content": "协同训练过程虽简单，但令人惊讶的是，理论证明显示出，若两个视图充分 例如电影画面与声音显 然不会是条件独立的. 单视图数据即仅有一个 属性集合的常见数据. 任意高[Blum and Mitchell, 1998].不过，视图的条件独立性在现实任务中通常 很难满足，因此性能提升幅度不会那么大，但研究表明，即便在更弱的条件下, 协同训练仍可有效地提升弱分类器的性能[周志华,2013]. 协同训练算法本身是为多视图数据而设计的，但此后出现了一些能在单视 图数据上使用的变体算法,它们或是使用不同的学习算法[Goldman and Zhou, 2000],或使用不同的数据采样[Zhou and Li, 2005b],甚至使用不同的参数设置 [Zhou and Li, 2005a]来产生不同的学习器，也能有效地利用未标记数据来提升 性能.后续理论研究发现,此类算法事实上无需数据拥有多视图，仅需弱学习器 306 四 的 上 标 仅 用 于 指 代 两 个 视 图 ，不 表 示 序 关 系 ，即 〈吟 ，吟 〉与 〈吟 ，吟 〉袤 示 的 是 同 一 个 样 采 . 令 0,72《 S. 初 始 化 每 个 视 图 上 的 有 标 记 训练集. 在 视 图 彳 上 用 有 标 记 样 本 训 练 编 . 扩 充 有 标 记 数 据 集 . 第 1 3 章半监督学习 _ 输入：有标记样本集Di = ｛（〈W , 就 〉,也），… ，（〈W ，/ 〉,勿）｝; 未标记样本集D u = ｛（吗+1，时+ 1 〉,… ，（研+口,若+口）｝; 缓冲池大小s ; 每轮挑选的正例数R ； 每轮挑选的反例数几； 基学习算法£; 学习轮数T . 过程： 1：从 D u 中随机抽取s个样本构成缓冲池 2： D u — Du \\ Ds； 3： for j = 1,2 do 4： D ： = ｛㈤ 加 | （〈必 ，琮 加 G Di｝- 5： end for 6: for = 1,2,... , T do for J = 1,2 do 7： 8: hj — £ （瓦 ）； 考 察hj在 D g = ｛* | 〈* , 姆P ） e D s y上的分类置信度,挑选p 个正例 置信度最高的样本Dp U Ds、n 个反例置信度最高的样本D n C 由以 生成伪标记正例比\" = ｛Q 尸 ,+ i ）| * G 修 ｝; 由D 需生成伪标记反例比7 = ｛Q 尸 , [ * e 以 ｝; D s = D s \\ （Dp U 。九）； end for if hi, h?均未发生改变then break else for J = 1,2 do",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 592
    }
  },
  {
    "page_content": "end for if hi, h?均未发生改变then break else for J = 1,2 do R = E u （见 U 您 ）； \" 9 ： 10： 11： 12： 13： 14： 15： 16： 17： 18： end for 19： 20: 从 。”中随机抽取2p + 2 n 个样本加入D s end if 21： 22: end for 输出：分类器比，殳 图 1 3 . 6 协同训练算法 因 此 ，该 类 方 法 被 称 为 “基 于 分 歧 的 方 法 ” . 之 间 具 有 显 著 的 分 歧 （或 差 异 ），即 可 通 过 相 互 提 供 伪 标 记 样 本 的 方 式 来 提 升 泛 化 性 能 [周 志 华 ，2 0 1 3 ] ; 不 同 视 图 、不 同 算 法 、不 同 数 据 采 样 、不同参 数 设 置 等 ，都仅是产生差异的渠道，而非必备条件. 基 于 分 歧 的 方 法 只 需 采 用 合 适 的 基 学 习 器 ，就 能 较 少 受 到 模 型 假 设 、损失 函数非凸性 和 数 据 规 模 问 题 的 影 响 ，学 习 方 法 简 单 有 效 、理 论 基 础 相 对 坚 实 、 适 用 范 围 较 为 广 泛 .为 了 使 用 此 类 方 法 ，需 能 生 成 具 有 显 著 分 歧 、性能尚可的 多个学习器，但 当 有 标 记 样 本 很 少 ，尤其是数据 不 具 有 多 视 图 时 ，要做到这一点 并不容易，需有巧妙的设计. 1 3 . 6 半监督聚类 307 1 3 .6 半监督聚类 聚类是一种典型的无监督学习任务，然而在现实聚类任务中我们往往能获 得一些额外的监督信息，于是可通过半监督聚类(semi-supervised clustering)来 利用监督信息以获得更好的聚类效果. 聚 类 任 务 中 获 得 的 监 督 信 息 大 致 有 两 种 类 型 .第 一 种 类 型 是 “必 连 ” (must-link)与 “勿连” (cannot-link)约束，前者是指样本必属于同一个簇，后 者是指样本必不属于同一个簇;第二种类型的监督信息则是少量的有标记样本. 约束 k 均 值 (Constrained k - m e a n s ) 算 法 ［Wagstaff et al., 2001］是利用第 一 类 监 督 信 息 的 代 表 .给 定 样 本 集 。 = 以 及 “必 连 ”关系 输 入 ：样 本 集 。 = {叫,比2,… ,Xm ］- 必连约束集合M ; 勿连约束集合C; 聚 类 簇 数k .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 593
    }
  },
  {
    "page_content": "约束 k 均 值 (Constrained k - m e a n s ) 算 法 ［Wagstaff et al., 2001］是利用第 一 类 监 督 信 息 的 代 表 .给 定 样 本 集 。 = 以 及 “必 连 ”关系 输 入 ：样 本 集 。 = {叫,比2,… ,Xm ］- 必连约束集合M ; 勿连约束集合C; 聚 类 簇 数k . 过程： L 从 。 中随机选取k 个样本作为初始均值向量{41,M2, ..,麻}; 2: r e p e a t 初 始 化k 个空簇. 更新均值向量. 3: 4: 5: 6: 7: 8: 9: 0:L 1 1 12： 13： 14： 15： 16： 17： 18： 19： 20： 21： 22: 23： g = 0 Q W j 4 吩; fo r z = 1 , 2 , . . . , m d o 计 算 样 本Xi与各均值向量% Q & j 4 k)的距离：dij = | ㈤ - p,j\\\\2 ; R = { 1 , 2 , … is_merged=false; w h ile -i is_merged d o 基 于 JC找 出与样本Xi距离最近的簇：r = a r g m i % 6 d刃； 检 测 将 g 划 入 聚 类 簇 C T 是否会 违 背 M 与 C 中的约束； if -i is.voilated t h e n C r = C r U { g } ; is_merged=true else /C = /C \\ {r}; if JC = 0 t h e n b r e a k 并返回错误提示 e n d if e n d if e n d w h ile e n d fo r fo r j = 1,2,... % = 信 j d o 产 ； en d fo r 24： 25: u n t i l 均值向量均未更新 输出：簇 划 分 … ，以 } 图 1 3 . 7 约 束 k 均值算法 308 第 1 3 章 半监督学习 集 合 M 和 “勿 连 ”关 系 集 合 C , （即 叼 ）e M 表 示 g 与 叼 必 属 于 同 簇 , 卜均值算法见9 4 1 节 ・ （叫，叼 ）e C 表 示 g 与 叼 必 不 属 于 同 簇 .该 算 法 是 k 均值算法的扩展，它在聚 类 过 程 中 要 确 保 从 与 。中的约束得以满足，否则将返回错误提示，算法如图 1 3 . 7 所示. 见P.202表9.1.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 594
    }
  },
  {
    "page_content": "卜均值算法见9 4 1 节 ・ （叫，叼 ）e C 表 示 g 与 叼 必 不 属 于 同 簇 .该 算 法 是 k 均值算法的扩展，它在聚 类 过 程 中 要 确 保 从 与 。中的约束得以满足，否则将返回错误提示，算法如图 1 3 . 7 所示. 见P.202表9.1. 以西瓜数据集4 . 0 为例，令 样 本X4与 / 2 5 , 叫 2 与劣2 0 , 比1 4 与 叫 7 之间存在 必连约束，X2 与力2 1 , 叫 3 与宓2 3 , / 1 9 与劣2 3 之间存在勿连约束，即 M = ｛（叫,妆5 ）, （g 5 , / 4 ）, （北⑵救0 ）,（重20,冗 12）, （叫4, ^ 1 7 ）, （« 1 7 , 叫4 ）｝, C = ｛（力2 ,力21）, （力21,力2 ）,（① 13, ^ 2 3 ）, （宽2 3 , / 1 3 ）, （/ 1 9 , 冗23）, （北23,重19）｝. 设聚类簇数 k = 3 , 随机选取样木碗，叫 2, Z 2 7 作为初始均值向量，图 13.8 图 1 3 . 8 西 瓜 数 据 集 4 .0 上 约 束 k 均 值 算 法 （k = 3）在各轮迭代后的结果.样本点与 均 值 向 量 分 别 用 一 与 “十”表 示 ，必连约束和勿连约束分别用实线段与虚线段表示，红 色虚线显示出簇划分. 1 3 . 6 半监督聚类 309 显示出约束k 均值算法在不同迭代轮数后的聚类结果.经5 轮迭代后均值向量 不再发生变化(与第4 轮迭代相同)，于是得到最终聚类结果 G . = ｛Z 3 , ①5 ,北7, W 9,g 3 ,比 14,叫 6 ,比 1 7 ,宓21｝； 0 2 = ｛冗6 ,宓8 ,叫0 ,叫 1 ,叫2 ,叫5 ,叫8 ,叫9, ®20) ； 0 3 = ｛叫 ，g , g 4, « 2 2 ,比2 3 ,比2 4 ,2 2 5 ,况2 6 ,2 2 7 ,①2 8 ,g 9, ®3o｝- 此 处 样 本 标 记 指 簇 标 记 (cluster label),不是类别 标 记 (class label). 第 二 种 监 督 信 息 是 少 量 有 标 记 样 本 .给 定 样 本 集 。 假定少量的有标记样本为S = U 限1 Sj U D , 其 中 Sj* 0 为隶属于第j 个聚 类簇的样本.这样的监督信息利用起来很容易：直 接 将 它 们 作 为 “种 子 ”，用 它 们 初 始 化 k 均 值 算 法 的 k 个聚类中心，并且在聚类簇迭代更新过程中不改",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 595
    }
  },
  {
    "page_content": "第 二 种 监 督 信 息 是 少 量 有 标 记 样 本 .给 定 样 本 集 。 假定少量的有标记样本为S = U 限1 Sj U D , 其 中 Sj* 0 为隶属于第j 个聚 类簇的样本.这样的监督信息利用起来很容易：直 接 将 它 们 作 为 “种 子 ”，用 它 们 初 始 化 k 均 值 算 法 的 k 个聚类中心，并且在聚类簇迭代更新过程中不改 变种子样本的簇隶属关系.这样就得到了约束种子k 均 值 ( C o n s tr a in e d S e e d /u - m e a n s )算 法 [B asu e t a l., 2 0 0 2 ] ,其算法描述如图1 3 .9 所示. S G D , | 5 |《 \\D\\. 输入：样本集D = ｛史1, g 2, • • • , 宓m ｝； 少量有标记样本5 = 1 ^ 曰 $5 ； 聚类簇数k . 用 有 标 记 样 本 初 始 化 簇 中心. 用 有 标 记 样 本 初 始 化 k 个簇. 更新均值向量. j 过程： 1： f o r j = 1 ,2 ,. . . , A; d o % = 赢 EceWS产 2： 3： e n d f o r 4 ： r e p e a t 5 ： 6: 7： 8： 9： 10： 11： 12： 13： Cj = 0 (1 f o r / = 1 , 2 , . . . , k d o f o r a l l x e Sj d o Cj = a UK} e n d f o r f o r a]l Xi e D \\ S d o e n d f o r k); e n d f o r f o r J = 1 , 2 , . . . , A: d o 14： 15： 16： 17： 18： 19: u n t i l 均值向量均未更新 输出：簇 划 分 … ，以 ｝ 世j = |^7| YlxeCj \" ； e n d f o r 计算样本Xi后各均值向量% (1 W j 4 k ) 的距离：dij = 忸 一 Mj||2 ； 找出与样本Xi距离最近的窥” = a rg m i〜 e{i,2,...,a}小 ； 将样本g 划入相应的簇：Cr = Cr |J { g } 图 1 3 . 9 约束种子k 均值算法 310 第 1 3 章 半 监 督 学 习 仍以西瓜数据集4.0为例，假定作为种子的有标记样本为 S1 = { 1 4 速 2 5 卜 $ 2 = {«12,«2O} 5",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 596
    }
  },
  {
    "page_content": "图 1 3 . 9 约束种子k 均值算法 310 第 1 3 章 半 监 督 学 习 仍以西瓜数据集4.0为例，假定作为种子的有标记样本为 S1 = { 1 4 速 2 5 卜 $ 2 = {«12,«2O} 5 S 3 = {«14, 以这三组种子样本的平均向量作为初始均值向量，图 13.10显示出约束种子 k 均值算法在不同迭代 轮数后的聚类结果.经 4 轮迭代后均值向量不再发生变 化(与第3 轮迭代相同)，于是得到最终聚类结果 C1 = { 宓 1, 冗 2 , 力 4, 4 2 2 , 多 23, 北 24, 名 2 5 , % 26,% 2 7 , % 2 8 , 重 29, ^ 3 0 } ； C2 — { 冗 6 , 必 7 , 多 8 , 多 10, 冗 1 1 , 必 15, 力 18, 劣 19, 多 2。} ； 。 3 = { 力 3, 必 9 , 劣 13, 必 1 4 , 1 1 6 , 力 17)/ 2 1 }• .1 0.2 0.3 0.4 0.5 密度 0.6 0.7 0.8 0.9 0.3 0.4 0.6 0.7 0.8 0.9 0.5 密度 (a)第 1 轮迭代后 (b)第 2 轮迭代后 0.2 0.3 0.4 0.5 密度 0.6 0.7 0.8 0.9 0.3 0.4 0.5 密度 0.6 0.7 0.8 0.9 (c)第 3 轮迭代后 (d)第 4 轮迭代后 图 1 3 . 1 0 西瓜数 据 集4.0上 约 束 种 子k 均 值 算 法 (k = 3)在各轮迭代后的结果.样本 点与均值向量分别用“/ 与 表 示 ，种子样本点为红色，红色虚线显示出簇划分. 1 3 . 7 阅读材料 311 1 3 .7 阅读材料 半监督学习的研究一般认为始于［Shahshahani and Landgrebe, 1994］, 该 领域在二十世纪末、二十一世纪初随着现实应用中利用未标记数据的巨大需 求涌现而蓬勃发展.国际机器学习大会(ICML)从 2008年 开 始 评 选 “十年最佳 论 文 \" 在 短 短 6 年中，半监督学习四大范型(paradigm)中基于分歧的方法、 半 监 督 SVM、图半监督学习的代表性工作先后于2008年 ［Blum and Mitchell, 1998］ > 2009 年 ［Joachims, 1999］> 2013 年 ［Zhu et al., 2003］获奖.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 597
    }
  },
  {
    "page_content": "论 文 \" 在 短 短 6 年中，半监督学习四大范型(paradigm)中基于分歧的方法、 半 监 督 SVM、图半监督学习的代表性工作先后于2008年 ［Blum and Mitchell, 1998］ > 2009 年 ［Joachims, 1999］> 2013 年 ［Zhu et al., 2003］获奖. 生成式半监督学习方法出现最早［Shahshahani and Landgrebe, 1994］. 由 于需有充分可靠的领域知识才能确保模型假设不至于太坏，因此该范型后来主 要是在具体的应用领域加以研究. 半 监 督 SV M 的目标函数非凸，有不少工作致力于减轻非凸性造成的不 利影响，例如使用连续统(continuation)方法，从优化一个简单的凸目标函数开 始，逐步变形为非凸的S3V M 目标函数［Chapelle et a l, 2006a］; 使用确定性退 火(deterministic annealing)过程，将非凸问题转化为一系列凸优化问题，然后 由易到难地顺序求解［Sindhwani et a l, 2006］; 利 用 C C C P 方法优化非凸函数 ［Collobert et al., 2006］等. 最 早 的 图 半 监 督 学 习 方 法 ［Blum and Chawla, 2001］直接基于聚类假设, 将学习目标看作找出图的最小割(m in cu t).对此类方法来说，图的质量极为重 要，13.4节的高斯距离图以及k 近邻图、e 近邻图都较为常用，此外已有一些 关于构图的研究［Wang and Zhang, 2006; Jebara et al., 2009］, 基于图核(graph kernel)的方法也与此有密切联系［Chapelle et al., 2003］. 基于分歧的方法起源于协同训练，最初设计是仅选取一个学习器用于预测 ［Blum and Mitchell, 1998］. 三体训练(tri-training)使用三个学习器，通 过 “少 数服从多数”来产生伪标记样本，并将学习器进行集成［Zhou and Li, 2005b］. 后续研究进一步显示出将学习器集成起来更有助于性能提升，并出现了使用更 多学习器的方法.更为重要的是，这将集成学习与半监督学习这两个长期独立 发展的领域联系起来［Zhou, 2009］. 此外，这些方法能容易地用于多视图数据, 并可自然地与主动学习进行结合［周志华,2013］. ［Belkin et al., 2006］在半监督学习中提出了流形正则化(manifold regular- ization)框架，直接基于局部光滑性假设对定义在有标记样本上的损失函数进行",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 598
    }
  },
  {
    "page_content": "发展的领域联系起来［Zhou, 2009］. 此外，这些方法能容易地用于多视图数据, 并可自然地与主动学习进行结合［周志华,2013］. ［Belkin et al., 2006］在半监督学习中提出了流形正则化(manifold regular- ization)框架，直接基于局部光滑性假设对定义在有标记样本上的损失函数进行 正则化，使学得的预测函数具有局部光滑性. 半监督学习在利用未标记样本后并非必然提升泛化性能，在有些情形下甚 k 近 邻 图 和 e 近邻图参 见 10.5.1 节. 许多集成学习研究者认 为：只要能使用多个学习 器即可将弱学习器性能提 升到极高，无须使用未标 记样本；许多半监督学习 研究者 认 为 ：只要能使用 未标记样本即可将弱学习 器性能提升到极高，无须 使用多学习器.但这两种 看法都有其局限. 312 第 1 3 章 半 监 督 学 习 这 里 的 “安全”是指利 用未标记样本后，能确保 泛化性能至少不差于仅利 用有标记样本. 至会导致性能下降.对生成式方法，其成因被认为是模型假设不准确［Cozman and Cohen, 2002］, 因此需依赖充分可靠的领域知识来设计模型.对半监督 S V M ,其成因被认为是训练数据中存在多个“低密度划分”，而学习算法有可 能做出不利的选择；S4VM ［Li and Zhou, 2015］通过优化最坏情形性能来综合 利用多个低密度划分，提升了此类技术的安全性.更一般的“安全”（safe）半监 督学习仍是一个未决问题. 本章主要介绍了半监督分类和聚类，但半监督学习已普遍用于各类机器学 习任务，例如在半监督回归［Zhou and Li, 2005a］, 降 维 ［Zhang et al., 2007］等 方面都有相关研究.更多关于半监督学习的内容可参见［Chapelle et a l, 2006b; Zhu, 2006］, ［Zhou and Li, 2 0 1 0 ;周志华，2013］专门介绍了基于分歧的方法. ［Settles, 2009］是一个关于主动学习的介绍. 习题 313 习题 13.1 试推导出式(13.5)~(13.8). 13.2 试基于朴素贝叶斯模型推导出生成式半监督学习算法. 13.3 假设数据由混合专家(mixture of experts)模型生成，即数据是基于k 个成分混合而得的概率密度生成： k | 6) = £ & . 仇 )， (13.22) i=l",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 599
    }
  },
  {
    "page_content": "习题 313 习题 13.1 试推导出式(13.5)~(13.8). 13.2 试基于朴素贝叶斯模型推导出生成式半监督学习算法. 13.3 假设数据由混合专家(mixture of experts)模型生成，即数据是基于k 个成分混合而得的概率密度生成： k | 6) = £ & . 仇 )， (13.22) i=l 其 中 o = { % ,3 , … ，ek} 是模型参数,P (x |仇 )是 第 z 个混合成分的 概率密度，混 合 系 数 色 2 o, E t i ^ = 上假设每个混合成分对应一 个类别，但每个类别可包含多个混合成分.试推导相应的生成式半监 督学习算法. uci数据集见 13.4 从网上下载或自己编程实现TSVM 算法，选 择 两 个 U C I数据集,将其 http://archive.ics.uci.edu/ml/. 中 30% 的样例用作测试样本，10% 的样例用作有标记样本，60% 的样 例用作无标记样本，分别训练出利用无标记样本的T S V M 以及仅利 用有标记样本的SV M ,并比较其性能. 13.5 对未标记样本进行标记指派与调整的过程中有可能出现类别不平衡 问题,试给出考虑该问题后的改进TSVM 算法. 13.6* TSV M 对未标记样本进行标记指派与调整的过程涉及很大的计算开 销，试设计一个高效的改进算法. 13.7* 试设计一个能对新样本进行分类的图半监督学习方法. 13.8 自训练(self-training)是一种比较原始的半监督学习方法 它先在有标 记样本上学习，然后用学得分类器对未标记样本进行判别以获得其伪 标记，再在有标记与伪标记样本的合集上重新训练，如此反复.试析该 方法有何缺陷. 13.9* 给定一个数据集，假设其属性集包含两个视图，但事先并不知道哪些 属性属于哪个视图，试设计一个算法将这两个视图分离出来. 13.10 试 为 图 13.7算 法 的 第 1 0 行写出违约检测算法(用于检测是否有约束 未被满足). 314 第 1 3 章 半 监 督 学 习 参考文献 周志华. (2013). “基 于 分 歧 的 半 监 督 学 习 自 动 化 学 报 ,39(11):1871-1878. Basu, S., A. Banerjee, and R. J. Mooney. (2002). “Semi-supervised clustering by seeding.55 In Proceedings of the 19th International Conference on Machine",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 600
    }
  },
  {
    "page_content": "Basu, S., A. Banerjee, and R. J. Mooney. (2002). “Semi-supervised clustering by seeding.55 In Proceedings of the 19th International Conference on Machine Learning (ICML), 19-26, Sydney, Australia. Belkin, M., P. Niyogi, and V. Sindhwani. (2006). “Manifold regularization: A geometric framework for learning from labeled and unlabeled examples.75 Journal of Machine Learning Research^ 7:2399-2434. Blum, A. and S. Chawla. (2001). “Learning from labeled and unlabeled data using graph mmcuts.^^ In Proceedings of the 18th International Conference on Machine Learning (ICML), 19-26, Williamston, MA. Blum, A. and T. Mitchell. (1998). “Combining labeled and unlabeled data with co-trainmg.^^ In Proceedings of the 11th Annual Conference on Computation­ al Learning Theory (COLT), 92-100, Madison, WL Chapelle, O., M. Chi, and A. Zien. (2006a). “A continuation method for semi- supervised SVMs.\" In Proceedings of the 23rd International Conference on Machine Learning (ICML), 185-192, Pittsburgh, PA. Chapelle, O., B. Scholkopf, and A. Zien, eds. (2006b). Semi-Supervised Learn­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 601
    }
  },
  {
    "page_content": "Machine Learning (ICML), 185-192, Pittsburgh, PA. Chapelle, O., B. Scholkopf, and A. Zien, eds. (2006b). Semi-Supervised Learn­ ing. MIT Press, Cambridge, MA. Chapelle, O., J. Weston, and B. Scholkopf. (2003). “Cluster kernels for semi­ supervised learning.5, In Advances in Neural Information Processing Systems 15 (NIPS) (S. Becker, S. Thrun, and K. Obermayer, eds.), 585-592, MIT Press, Cambridge, MA. Chapelle, O. and A. Zien. (2005). “Semi-supervised learning by low density separation.^^ In Proceedings of the 10th International Workshop on Artificial Intelligence and Statistics (AISTATS), 57-64, Savannah Hotel, Barbados. Collobert, R., F. Sinz, J. Weston, and L. Bottou. (2006). “Trading convexity for scalability.55 In Proceedings of the 23rd International Conference on Machine Learning (ICML), 201-208, Pittsburgh, PA. Cozman, F. G. and I. Cohen. (2002). uUnlabeled data can degrade classifica­ tion performance of generative classifiers.55 In Proceedings of the 15th Inter­ national Conference of the Florida Artificial Intelligence Research Society 参考文献 315",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 602
    }
  },
  {
    "page_content": "tion performance of generative classifiers.55 In Proceedings of the 15th Inter­ national Conference of the Florida Artificial Intelligence Research Society 参考文献 315 (FLAIRS), 327-331, Pensacola, FL. Goldman, S. and Y. Zhou. (2000). “Enhancing supervised learning with unla­ beled data.\" In Proceedings of the 17th International Conference on Machine Learning (ICML)1327-334, San Francisco, CA. Jebara, T., J. Wang, and S. F. Chang. (2009). “Graph construction and b- matching for semi-supervised le a rn in g .In Proceedings of the 26th Interna­ tional Conference on Machine Learning (ICML), 441-448, Montreal, Cana­ da. Joachims, T. (1999). aTransductive inference for text classification using sup­ port vector machines.5, In Proceedings of the 16th International Conference on Machine Learning (ICML)^ 200-209, Bled, Slovenia. Li, Y.-F., J. T. Kwok, and Z.-H. Zhou. (2009). “Semi-supervised learning using label mean.^^ In Proceedings of the 26th International Conference on Machine Learning (ICML))633-640, Montreal, Canada.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 603
    }
  },
  {
    "page_content": "label mean.^^ In Proceedings of the 26th International Conference on Machine Learning (ICML))633-640, Montreal, Canada. Li, Y.-F. and Z.-H. Zhou. (2015). ^Towards making unlabeled data never hurt.^^ IEEE Transactions on Pattern Analysis and Machine Intelligence1 37(1): 175-188. Miller, D. J. and H. S. Uyar. (1997). “A mixture of experts classifier with learning based on both labelled and unlabelled data.\" In Advances in Neural Information Processing Systems 9 (NIPS) (M. Mozer, M. I. Jordan, and T. Petsche, eds.), 571-577, MIT Press, Cambridge, MA. Nigam, K., A. McCallum, S. Thrun, and T. Mitchell. (2000). “Text classifica­ tion from labeled and unlabeled documents using EM.\" Machine Learning, 39(2-3):103-134. Settles, B. (2009). uActive learning literature survey.,5 Technical Re­ port 1648, Department of Computer Sciences, University of Wis­ consin at Madison, Wisconsin, WL http://pages.cs.wisc.edu/~bsettles/ pub/settles. activelearning.pdf. Shahshahani, B. and D. Landgrebe. (1994). “The effect of unlabeled samples",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 604
    }
  },
  {
    "page_content": "consin at Madison, Wisconsin, WL http://pages.cs.wisc.edu/~bsettles/ pub/settles. activelearning.pdf. Shahshahani, B. and D. Landgrebe. (1994). “The effect of unlabeled samples in reducing the small sample size problem and mitigating the Hughes phe­ nomenon.5, IEEE Transactions on Geoscience and Remote Sensing^ 32(5): 1087-1095. 316 第 1 3 章 半 监 督 学 习 Sindhwani, V., S. S. Keerthi, and O. Chapelle. (2006). ^Deterministic annealing for semi-supervised kernel machines.,5 In Proceedings of the 23rd Internation­ al Conference on Machine Learning (ICML), 123-130, Pittsburgh, PA. Wagstaff, K., C. Cardie, S. Rogers, and S. Schrddl. (2001). ^Constrained fc-means clustering with background knowledge.5, In Proceedings of the 18th International Conference on Machine Learning (ICML), 577-584, Williamstown, MA. Wang, F. and C. Zhang. (2006). “Label propagation through linear neighbor- hoods.^^ In Proceedings of the 23rd International Conference on Machine Learning (ICML), 985-992, Pittsburgh, PA. Zhang, D., Z.-H. Zhou, and S. Chen. (2007). “Semi-supervised dimensionality",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 605
    }
  },
  {
    "page_content": "Learning (ICML), 985-992, Pittsburgh, PA. Zhang, D., Z.-H. Zhou, and S. Chen. (2007). “Semi-supervised dimensionality reduction? In Proceedings of the 7th SIAM International Conference on Data Mining (SDM), 629-634, Minneapolis, MN. Zhou, D., O. Bousquet, T. N. Lal, J. Weston, and B. Scholkopf. (2004). aLearn- ing with local and global consistency.55 In Advances in Neural Information Processing Systems 16 (NIPS) (S. Thrun, L. Saul, and B. Scholkopf, eds.), 284-291, MIT Press, Cambridge, MA. Zhou, Z.-H. (2009). “When semi-supervised learning meets ensemble learning/5 In Proceedings of the 8th International Workshop on Multiple Classifier Sys­ tems, 529-538, Reykjavik, Iceland. Zhou, Z.-H. and M. Li. (2005a). “Semi-supervised regression with co-training.55 In Proceedings of the 19th International Joint Conference on Artificial In­ telligence (IJCAI), 908-913, Edinburgh, Scotland. Zhou, Z.-H. and M. Li. (2005b). uTri-training: Exploiting unlabeled data using three classifiers.\" IEEE Transactions on Knowledge and Data Engineering^ 17(11):1529-1541.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 606
    }
  },
  {
    "page_content": "Zhou, Z.-H. and M. Li. (2005b). uTri-training: Exploiting unlabeled data using three classifiers.\" IEEE Transactions on Knowledge and Data Engineering^ 17(11):1529-1541. Zhou, Z.-H. and M. Li. (2010). “Semi-supervised learning by disagreement.5, Knowledge and Information Systems, 24(3):415-439. Zhu, X. (2006). “Semi-supervised learning literature survey?5 Technical Report 1530, Department of Computer Sciences, University of Wisconsin at Madi­ son, Madison, WI. http://www.cs.wisc.edu/~jerryzhu/ pub/ssl_survey.pdf. Zhu, X., Z. Ghahramani, and J. Lafferty. (2003). “Semi-supervised learning 休息一会儿 317 using Gaussian fields and harmonic functions?5 In Proceedings of the 20th International Conference on Machine Learning (ICML), 912-919, Washing­ ton, DC. 休 息 一 会 儿 小故事：流形与伯恩哈德•黎曼 “流 形 \" (m a n ifo ld )这 个 名 字 源 于 德 语 Mannig- fa ltig k eit,是 伟 大 的 德 国 数 学 家 伯 恩 哈 德 •黎 曼 (Bernhard Riemann, 1826— 1866)提出的，其译名则是我国拓扑学奠 基人江泽涵先生借鉴文天祥《正气歌》 “天地有正气，杂然 赋流形”而来，可 能 是 由于光滑流形恰与“气”相似，整体 上看可流动、变形. 黎曼出生于德国汉诺威的布列斯伦茨(B reselenz),幼年时就展现出惊人的 数学天赋.1846年父亲送他到哥廷根大学攻读神学，在旁听了高斯关于最小二 乘法的讲座后，他决定转攻数学，并在高斯指导下于1851年获博士学位.期间",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 607
    }
  },
  {
    "page_content": "基人江泽涵先生借鉴文天祥《正气歌》 “天地有正气，杂然 赋流形”而来，可 能 是 由于光滑流形恰与“气”相似，整体 上看可流动、变形. 黎曼出生于德国汉诺威的布列斯伦茨(B reselenz),幼年时就展现出惊人的 数学天赋.1846年父亲送他到哥廷根大学攻读神学，在旁听了高斯关于最小二 乘法的讲座后，他决定转攻数学，并在高斯指导下于1851年获博士学位.期间 有两年他在柏林大学学习，受到了雅可比、狄利克雷等大数学家的影响. 1853 年，高斯让黎曼在几何学基础方面准备一个报告，以便取得哥廷根大学的教职; 1854年，黎曼做了 “论作为几何基础的假设” 的著名演讲，这个报告开创了黎 曼几何，提出了黎曼积分，并首次使用了 M annigfaltigkeit这个词.此后黎曼一 直在哥廷根大学任教，并 在 1859年接替去世的狄利克雷担任数学教授. 黎曼是黎曼几何的创立者、复变函数论的奠基人，并对微积分、解析数 论 、组合拓扑、代数几何、数学物理方法均做出了开创性贡献，他的工作直接 影响了近百年数学的发展，许多杰出的数学家前赴后继地努力论证黎曼断言过 的定理. 1900年希尔伯特列出的2 3 个世纪数学问题与2000年美国克雷数学研 究所列出的7 个千禧年数学难题中，有一个问题是相同的，这 就是黎曼1859年 因当选院士而提交给柏林科学院的文章中提出的“黎曼猜想”.这是关于黎曼 C 函数非平凡零点的猜想.目前已有不同数学分支的千余个数学命题以黎曼猜 想为前提，若黎曼猜想正确，它们将全部升格为定理.一个猜想联系了如此多不 同数学分支、如此多命题，在数学史上是极为罕见的，因此它被公认为当前最 重要的数学难题. 传统的德国大学中一个 系 只 有 一 位 “教授 ”，相 当于系主任.高斯长期担 任哥廷根大学数学教授, 1855年他去世后由狄利克 雷接任. 7 个千禧年数学难题中, 已 被 证 明 的 “庞 加 莱 猜 想”直接与流形有关：任 何一个单连通、闭的三维 流形一定同胚于一个三维 球面. 第 1 4 章 概 率 图 模 型 1 4 .1 隐马尔可夫模型 机器学习最重要的任务，是根据一些已观察到的证据(例如训练样本)来 对感兴趣的未知变量(.例如类别标记)进行估计和推测..概率模型(probabilistic 基于学习器进行预测, 例如根据纹理、颜 色 、根 蒂等信息判断一个瓜是否 为好瓜就是在做推断；但 推断远超出预测范畴，例 如在吃到一个不见根蒂的 好 瓜时， “由果溯因”逆 推其根蒂的状态也是推断.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 608
    }
  },
  {
    "page_content": "1 4 .1 隐马尔可夫模型 机器学习最重要的任务，是根据一些已观察到的证据(例如训练样本)来 对感兴趣的未知变量(.例如类别标记)进行估计和推测..概率模型(probabilistic 基于学习器进行预测, 例如根据纹理、颜 色 、根 蒂等信息判断一个瓜是否 为好瓜就是在做推断；但 推断远超出预测范畴，例 如在吃到一个不见根蒂的 好 瓜时， “由果溯因”逆 推其根蒂的状态也是推断. model)提供了一种描述框架，将学习任务归结于计算变量的概率分布.在概 率 模 型 中 ，利 用 已 知 变 量 推 测 未 知 变 量 的 分 布 称 为 “推 断 \" (inference),其 核心是如何基于可观测变量推测出未知变量的条件分布.具体来说，假定所 关 心 的 变 量 集 合 为 V , 可观测变量集合为' 3 其 他 变 量 的 集 合 为 凡 “生成 式 “(generative)模 型 考 虑 联 合 分 布 “判别式\" (discriminative)模 型考虑条件分布P (K A | 0 ) . 给定一组观测变量值，推断就是要由P ( K 此 O) 或 P(Y, R | O)得到条件概率分布P(Y\\ 0 ). 直接利用概率求和规则消去变量R 显然不可行，因为即便每个变量仅有两 种取值的简单问题,其复杂度已至少是0 (2 凶+闽).另一方面,属性变量之间往 往存在复杂的联系，因此概率模型的学习，即基于训练样本来估计变量分布的 参数往往相当困难.为了便于研究高效的推断和学习算法，需有一套能简洁紧 凑地表达变量间关系的工具. 概率图模型(probabilistic graphical model)是一类用图来表达变量相关关 系 的 概 率 模 型 .它 以 图 为 表 示 工 具 ，最常见的是用一个结点表示一个或一组 随机变量，结点之间的边表示变量间的概率相关关系，即 “变量关系图”.根 据边的性质不同，概率图模型可大致分为两类：第一类是使用有向无环图表 示变量间的依赖关系，称为有向图模型或贝叶斯网(Bayesian netw ork);第二类 是使用无向图表示变量间的相关关系，称为无向图模型或马尔可夫网(Markov network). 若变量间存在显式的因 果关系，则常使用贝叶斯 网；若变量间存在相关性, 但难以获得显式的因果关 系，则常使用马尔可夫网. 静 态 贝 叶 斯 网 参 见 7.5 节. 隐马尔可夫模型(Hidden Markov M odel,简 称 HMM)是结构最简单的动态 贝叶斯网(dynamic Bayesian netw ork),这是一种著名的有向图模型，主要用于 时序数据建模,在语音识别、 自然语言处理等领域有广泛应用.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 609
    }
  },
  {
    "page_content": "静 态 贝 叶 斯 网 参 见 7.5 节. 隐马尔可夫模型(Hidden Markov M odel,简 称 HMM)是结构最简单的动态 贝叶斯网(dynamic Bayesian netw ork),这是一种著名的有向图模型，主要用于 时序数据建模,在语音识别、 自然语言处理等领域有广泛应用. 如 图 14.1所示，隐马尔可夫模型中的变量可分为两组.第一组是状态变量 ｛组用2 , - •，阴 其 中 Vi W J 表示第,分时刻的系统状态.通常假定状态变量是隐 藏的、不可被观测的，因此状态变量亦称隐变量(hidden variable).第二组是观 320 第 1 4 章 概率图模型 测 变 量 ｛知 如 … ，斯 ｝,其 中 g e % 表示第成时刻的观测值.在隐马尔可夫模 型中，系统通常在多个状态｛si, 52,..., S N ｝之间转换，因此状态变量yi的取值 范 围 J (称为状态空间)通常是有N 个可能取值的离散空间.观测变量◎ 可以 是离散型也可以是连续型，为便于讨论，我们仅考虑离散型观测变量,并假定其 取 值 范 围 % 为 • • • , 图 14.1中的箭头表示了变量间的依赖关系.在任一时刻，观测变量的取值 仅依赖于状态变量，即 色 由 yt 确定，与其他状态变量及观测变量的取值无关. 同 时 \"时 刻 的 状 态 yt仅 依 赖 于t - 1 时刻的状态yt-i,与 其 余n - 2 个状态无 关 .这 就 是 所 谓 的 “马尔可夫链”(Markov chain),即：系统下一时刻的状态仅 所谓“现在决定未来”.由当前状态决定,不依赖于以往的任何状态.基于这种依赖关系，所有变量的联 合概率分布为 , n P(x1,y1,...,xn ,yn y= | 即 ) ( 班 | 统 | 仍). (14.1) 。= 2 除了结构信息，欲确定一个隐马尔可夫模型还需以下三组参数： • 状 态 转 移 概 率 ：模 型 在 各 个 状 态 间 转 换 的 概 率 ，通 常 记 为 矩 阵 A = laij]NxN,其中 — P(yt+i = sj I yt - si) , \\ 4 3 j 4 N, 表示在任意时刻t,若 状 态 为 密 则 在 下 一 时 刻 状 态 为 S j 的概率. • 输出观测概率：模型根据当前状态获得各个观测值的概率,通常记为矩阵 B = [bij]NxM,其中 bij = P (岔 t = Oj | yt — Si) , J W j W M 表 示 在 任 意 时 刻 若 状 态 为 S强则观测值Oj被获取的概率.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 610
    }
  },
  {
    "page_content": "\\ 4 3 j 4 N, 表示在任意时刻t,若 状 态 为 密 则 在 下 一 时 刻 状 态 为 S j 的概率. • 输出观测概率：模型根据当前状态获得各个观测值的概率,通常记为矩阵 B = [bij]NxM,其中 bij = P (岔 t = Oj | yt — Si) , J W j W M 表 示 在 任 意 时 刻 若 状 态 为 S强则观测值Oj被获取的概率. • 初 始 状 态 概 率 ：模 型 在 初 始 时 刻 各 状 态 出 现 的 概 率 ，通 常 记 为 7T = 1 4 . 1 隐马尔可夫模型 321 (7T1,7T2,… / N ), 其中 穴i = P(yi = Si), \\ & i & N 表示模型的初始状态为%的概率. 通过指定状态空间y 、观测空间＜¥和上述三组参数,就能确定一个隐马尔 可夫模型,通常用其参数A = [A,B,7r]来指代.给定隐马尔可夫模型A , 它按如 下过程产生观测序列｛叼，①2 , … ，x n ｝: ( 1 ) 设置力= 1 , 并根据初始状态概率7T选择初始状态7/1； ( 2 ) 根据状态比和输出观测概率 B 选择观测变量取值g; ( 3 ) 根据状态仇和状态转移矩阵 A 转移模型状态，即 确 定 %+ i ； ( 4 ) 若力V % 设置力= 力+ 1 , 并 转到第 ( 2 ) 步，否 则 停 止 . . 其 中 yt w ｛s i , s 2 , … ，$N ｝和 g e ｛。1 ,。2 , . . . , 。时｝分 别为第t 时刻的状态和观 测值. 在实际应用中，人们常关注隐马尔可夫模型的三个基本问题： • 给 定 模 型 入 = [ A , B , 7 T ] , 如 何 有 效 计 算 其 产 生 观 测 序 列 X = ｛的,①2 , … ，厮 ｝的 概 率 P (X I A) ? 换言之，如何评估模型与观测序列 之间的匹配程度？ • 给 定 模 型 A = [A , B , 7T ]和 观 测 序 列 X = ｛3 / 2 , … ，厮 ｝,如何找到与此 观测序列最匹配的状态序列y = ｛% 用 2, • • • ? 换言之，如何根据观测 序列推断出隐藏的模型状态？ • 给定观测序列 X = ｛叫《2 , … ，如 ｝,如 何调整模型参数 A = [A,B,7r]使 得该序列出现的概率P ( x I A ) 最大？换言之，如何训练模型使其能最好地 描述观测数据？ 上述问题在现实应用中非常重要.例如许多任务需根据以往的观测序列 ｛叼《2 , - . 《吁 1｝来推测当前时刻最有可能的观测值厮，这显然可转化为求取",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 611
    }
  },
  {
    "page_content": "• 给定观测序列 X = ｛叫《2 , … ，如 ｝,如 何调整模型参数 A = [A,B,7r]使 得该序列出现的概率P ( x I A ) 最大？换言之，如何训练模型使其能最好地 描述观测数据？ 上述问题在现实应用中非常重要.例如许多任务需根据以往的观测序列 ｛叼《2 , - . 《吁 1｝来推测当前时刻最有可能的观测值厮，这显然可转化为求取 概率尸 ( x I A ) , 即上述第一个问题；在语音识别等任务中，观测值为语音信号, 隐藏状态为文字，目标就是根据观测信号来推断最有可能的状态序列(即对应 的文字)，即上述第二个问题；在大多数现实应用中，人工指定模型参数已变得 322 第 1 4 章 概 率 图 模 型 越来越不可行，如何根据训练样本学得最优的模型参数，恰是上述第三个问题. 值得庆幸的是，基于式(14.1)的条件独立性，隐马尔可夫模型的这三个问题均能 被高效求解. 1 4 .2 马尔可夫随机场 马尔可夫随机场( Markov R a n d o m Field,简 称 M R F ) 是典型的马尔可夫网, 这是一种著名的无向图模型.图中每个结点表示一个或一组变量，结点之间 的边表示两个变量之间的依赖关系.马尔可夫随机场有一组势函数(potential functions),亦 称 “因子”(factor),这是定义在变量子集上的非负实函数，主要 用于定义概率分布函数. 图 14.2显示出一个简单的马尔可夫随机场.对于图中结点的一个子集，若 其中任意两结点间都有边连接，则称该结点子集为一个“团”(clique).若在一 个团中加入另外任何一个结点都不再形成团，则 称 该 团 为 “极大团”(maximal clique);换言之，极 大 团 就 是 不 能 被 其 他 团 所 包 含 的 团 .例 如 ，在 图 1 4 . 2 中, ｛力匕数｝, ①3八 ｛62,力4卜 ｛力2,①5卜 ｛①2 , % ｝, ｛磔 5卜 ｛①5,6 6｝和 ｛初，65,①6｝ 都是团，并且除了 ｛①2,磔｝, ｛%2,①6｝和 ｛3 , 比 ｝之外都是极大团；但是，因 为 N2 和力3 之间缺乏连接，｛的厘2,力3｝并不构成团.显然，每个结点至少出现在一个 极大团中. 在 马 尔 可 夫 随 机 场 中 ，多 个 变 量 之 间 的 联 合 概 率 分 布 能 基 于 团 分 解 为 多 个 因 子 的 乘 积 ，每 个 因 子 仅 与 一 个 团 相 关 .具 体 来 说 ，对 于 几 个 变 量 x = ｛% % … 《九｝,所有团构成的集合为C , 与 团 Q e C 对应的变量集合记为 X Q , 则联合概率P ( X ) 定义为",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 612
    }
  },
  {
    "page_content": "在 马 尔 可 夫 随 机 场 中 ，多 个 变 量 之 间 的 联 合 概 率 分 布 能 基 于 团 分 解 为 多 个 因 子 的 乘 积 ，每 个 因 子 仅 与 一 个 团 相 关 .具 体 来 说 ，对 于 几 个 变 量 x = ｛% % … 《九｝,所有团构成的集合为C , 与 团 Q e C 对应的变量集合记为 X Q , 则联合概率P ( X ) 定义为 P ( x ) = 看 I I 协Q ( X Q ) ， (14⑵ 其中砂Q 为 与 团 Q 对应的势函数，用 于 对 团 Q 中的变量关系进行建模，z = 1 4 . 2 马尔可夫随机场 323 E X H Q G @Q （X Q ）为规范化因子，以确 保 p （x ）是被正确定义的概率• 在实际 应用中，精 确 计 算 Z 通常很困难,但许多任务往往并不需获得Z 的精确值. 显然，若变量个数较多，则团的数目将会很多（例如，所有相互连接的两个 变量都会构成团），这就意味着式（14.2）会有很多乘积项，显然会给计算带来负 担 .注 意 到 若 团Q 不是极大团，则它必被一个极大团Q* 所包含，即 XQ C XQ*; 这意味着变量 X Q 之间的关系不仅体现在势函数协Q 中，还体现在欧Q* 中.于 是，联合概率尸（x ）可基于极大团来定义.假定所有极大团构成的集合为C * , 则 有 尸（x ） = U H 4 Q （X Q ）， （14.3） ZJ — — Qec* 其 中 Z* = I I QGC* @Q（X Q）为规范化因子.例如图14.2中 x = ｛/ 1/ 2,… , 力6｝, 联合概率分布P （x ）定义为 P （x）= 下之2（6 1 / 2 ）耽3（/1,①3）924（力2逆4）砂35（/3,①5）@256（①2,①5逆6）, 1 ZJ 其中，势 函 数 4256（为2,①5避6）定 义 在 极 大 团 ｛劣2,为5避6｝上，由于它的存在，使 我们不再需为团｛© 逆 5｝, ｛①2,劣6｝和 ｛3 遂6｝构建势函数. 参见7 5 1 节. 念 ,如 图 14.3所示,若从结点集A 中的结点到B 中的结点都必须经过结点集C 在马尔可夫随机场中如何得到“条件独立性”呢？同 样 借 助 “分离”的概 中的结点，则称结点集A 和 B 被结点集C 分离，C 称 为 “分 离 集 \"（separating set）. 对马尔可夫随机场，有 • “全局马尔可夫性\" （global Markov property）: 给定两个变量子集的分 离集，则这两个变量子集条件独立.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 613
    }
  },
  {
    "page_content": "在马尔可夫随机场中如何得到“条件独立性”呢？同 样 借 助 “分离”的概 中的结点，则称结点集A 和 B 被结点集C 分离，C 称 为 “分 离 集 \"（separating set）. 对马尔可夫随机场，有 • “全局马尔可夫性\" （global Markov property）: 给定两个变量子集的分 离集，则这两个变量子集条件独立. 也就是说，图 14.3中若令4 6 和 。对应的变量集分别为X A , X B 和 X C , 则 X A 和 X B 在给定X 。的条件下独立，记为2 4 ± X B I xC. 图 1 4 . 3 结点集4 和 B 被结点集C 分离 324 第 1 4 章 概 率 图 模 型 下面我们做一个简单的验证.为便于讨论，我 们 令 图 14.3中 的 4 B 和 。 分别对应单变量以，X B 和冗c , 于 是 图 14.3简 化 为 图 14.4. 图 1 4 . 4 图 14.3的简化版 对 于 图 14.4,由式（14.2）可得联合概率 P Q A S B , ①C ) = 万协A C (① 4/0)协8 c (25,力。) . (14.4) 基于条件概率的定义可得 、 I 约 ） 产（6 4 / 8 I = — P （X A,X 耳 C） 说B ,X \" ~ £ 吟 £ 吆p（办 脸 m ） _ + @ a c Q a , 叱 ）@ B C Q B ,叼 ） £ 或 £ 吆 与WA C G A , GC）帆 c（x 'B）岔C） = 矽力0 （6 4 / 。）______ 帆 C（*B,3C） ~ £ 吟协幺。3 3 2 。） £ 吆 帆 c l % n。） (14.5) pz I x _ P(xA ,xc) _ £ 吆 的 I s ) - P ( w ) - £ 崂 £ 吆 尸 得 ，蝠 ，力。) _ ____ b £ 吟 号也4。(6 4 ①。)也B C (吃，力。) i^AC^ A , XC ^BC(Xf __________ B , XC ) = 似 C ( © 1 , S ) - ^ A C ^ J X C Y /1 4 f i x ； 1 ' 由式(14.5)和(14.6)可知 P (X A , X B I xc) - P(xA | xc )P(xB | ①。) , . (14.7) 即 X A 和 X B 在 给 定X c 时条件独立. 由全局马尔可夫性可得到两个很有用的推论： • 局部马尔可夫性（local M a r k o v property）: 给定某变量的邻接变量，则该 1 4 . 3 条件随机场",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 614
    }
  },
  {
    "page_content": "P (X A , X B I xc) - P(xA | xc )P(xB | ①。) , . (14.7) 即 X A 和 X B 在 给 定X c 时条件独立. 由全局马尔可夫性可得到两个很有用的推论： • 局部马尔可夫性（local M a r k o v property）: 给定某变量的邻接变量，则该 1 4 . 3 条件随机场 某变量的所有邻接变量 组成的集合称为该变量的 “马 尔 可 夫 毯 ”(Markov blanket). 325 变 量 条 件 独 立 于 其 他 变 量 .形 式 化 地 说 ，令 『 为图的结点集,九(。)为结点 V 在图上的邻接结点，71*®) = n(v) U ｛。｝,有 X。± Xu\\九*⑺I X九⑻. • 成 对 马 尔可夫性(pairwise Markov property):给定所有其他变量，两个非 邻 接 变 量 条 件 独 立 .形 式 化 地 说 ，令 图 的 结 点 集 和 边 集 分 别 为 V 和 区 对 图中的两个结点〃和v , 若 (生 v ) 任E )则 _L X。| ⑼. 现 在 我 们 来 考 察 马 尔 可 夫 随 机 场 中 的 势 函 数 .显 然 ，势函数矽Q(XQ) 的作 用 是 定 量 刻 画 变 量 集 X Q 中变量之间的相关关系，它应该是非负函数,且在所偏 好 的 变 量 取 值 上 有 较 大 函 数 值 .例 如 ，假 定 图 14.4中 的 变 量 均 为 二 值 变 量 ，若 势函数为 ^A C(XA,XC)= < [ 1 .5 , if x A = 6。； [ 0 .1 , otherwise , [ 0 .2 , if x B = x c \\ I 1.3, otherwise , 则说明该模型偏好变量力力与XC 拥 有 相 同 的 取 值 ，XB 与力。拥有不同的取值; 换 言 之 ，在 该 模 型 中 X A 与 X C 正 相 关 ,X B 与 X C 负 相 关 .结 合 式 (14.2)易知，令 力 /与 NC相 同 且 与 岔C 不同的变量值指派将取得较高的联合概率. 为了满足非负性,指数函数常被用于定义势函数，即 协Q(XQ) = C—\"Q(XQ) . (14.8) H Q(XQ) 是 一 个 定 义 在 变 量 X Q 上的实值函数，常见形式为 HQ(XQ)= 〉］ Oiu v Xu Xv + ) u,veQ,u^v veQ : Pvx v , (14.9) 其 中 和 pv 是 参 数 .上 式 中 的 第 二 项 仅 考 虑 单 结 点 ，第一项则考虑每一对结 点的关系. 1 4 .3 条件随机场",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 615
    }
  },
  {
    "page_content": "(14.8) H Q(XQ) 是 一 个 定 义 在 变 量 X Q 上的实值函数，常见形式为 HQ(XQ)= 〉］ Oiu v Xu Xv + ) u,veQ,u^v veQ : Pvx v , (14.9) 其 中 和 pv 是 参 数 .上 式 中 的 第 二 项 仅 考 虑 单 结 点 ，第一项则考虑每一对结 点的关系. 1 4 .3 条件随机场 条件随机场可看作给定 观测值的马尔可夫随机场, 也可看作对率回归的扩展; 对率回归参见3 .3 节. 条 件 随 机 场 (Conditional Random F ield ,简 称 C R F )是一种判别式无向图 模 型 .14.1节提到 过 ，生成式模型是直接对联合分布进行建模，而判别式模型则 是对条件分布进行建 模 .前 面 介 绍 的 隐 马 尔 可 夫 模 型 和 马 尔 可 夫 随 机 场 都 是 生 成式模 型 ，而条件随机场则是判别式模型. 326 第 1 4 章 概 率 图 模 型 条件随机场试图对多个变量在给定观测值后的条件概率进行建模.具体来 说，若 令 X = {61,力2 , … ，Xn } 为观测序列，y = {?/1, 7/2, yn } 为与之相应 的标记序列，则条件随机场的目标是构建条件概率模型P ( y I x ) . 需注意的是, 标记变 量 y 可以是结构型变量，即其分量之间具有某种相关性.例如在自然语 言处理的词性标注任务中，观测数据为语句(即单词序列)，标记为相应的词性序 歹U,具有线性序列结构，如 图 14.5(a)所示；在语法分析任务中，输出标记则是语 法树，具有树形结构，如 图 14.5(b)所示. {yi V2 | 回 [N] g 勿 / 比} [V] [P] [D] [N] { . 为 13 74/5 打} The boy knocked at the watermelon. y x ( a ) 词性标注 ( b ) 语法分 析 图 1 4 . 5 自 然 语 言 处 理 中 的 词 性 标 注 和 语 法 分 析 任 务 令 6 = (V.E)表示结点与标记变量y 中元素一一对应的无向图，yv 表示 与结点。对应的标记变量，n(i;)表 示结点。的邻接结点，若 图 G 的每个变量yv 都满足马尔可夫性，即 P(yv I x, yv \\{v}) = P (物 I x , y 九⑻), (14.10) 则 (y,x)构成一个条件随机场. 理论上来说，图 G 可具有任意结构，只要能表示标记变量之间的条件独立 性关系即可.但在现实应用中，尤其是对标记序列建模时，最常用的仍是图14.6",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 616
    }
  },
  {
    "page_content": "P(yv I x, yv \\{v}) = P (物 I x , y 九⑻), (14.10) 则 (y,x)构成一个条件随机场. 理论上来说，图 G 可具有任意结构，只要能表示标记变量之间的条件独立 性关系即可.但在现实应用中，尤其是对标记序列建模时，最常用的仍是图14.6 所示的链式结构，即 “链 式 条 件 随 机 场 \"(chain-structured C R F ) . 下面我们主 要讨论这种条件随机场. X = {xi 22 ...力打} 图 14.6 链 式 条 件 随 机 场 的 图 结 构 1 4 . 3 条件随机场 327 与马尔可夫随机场定义联合概率的方式类似，条件随机场使用势函数和图 结构上的团来定义条件概率P (y | x ) . 给定观测序列x , 图 14.6所示的链式条 件随机场主要包含两种关于标记变量的团，即单个标记变量｛仍｝以及相邻的标 记 变 量 步 ｝.选择合适的势函数，即可得到形如式(14.2)的条件概率定义 在条件随机场中，通过选用指数势函数并引入特征函数(feature function),条件 概率被定义为 n—1 ] 尸(y I X) = ^ e x p £ £ \\ j 2=1 / n \\ yi, X, i) + £ £ NkSk(yi)X, i ) , k 2=1 J (14.11) 其 中 方2•(%+ i,如 x \" ) 是定义在观测序列的两个相邻标记位置上的转移特征函 数(transition feature function),用于刻画相邻标记交量之间的相关关系以及观 测序列对它们的影响，Sk(yi,x,i)是定义在观测序列的标记位置i 上的状态特征 函数(status feature function),用于刻画观测序列对标记变量的影响，% 和 取 为参数,Z 为规范化因子,用于确保式(14.11)是正确定义的概率. 显然，要使用条件随机场，还需定义合适的特征函数.特征函数通常是实值 函数，以刻画数据的一些很可能成立或期望成立的经验特性.以图14.5(a)的词 性标注任务为例，若采用转移特征函数 方式仇+L 统，x ,z ) = < . I 0, otherwise, f 1, if yi+1 = [P], yi = [V] and Xi = uknock,5; 则表示第i个观测值g 为单词“knock” 时，相应的标记比和 % + i 很可能分别为 [V]和 [ P ] .若采用状态特征函数 [ 1, if yi = [V] and g = \"knock”； S M % , X , 2 ) = < .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 617
    }
  },
  {
    "page_content": "f 1, if yi+1 = [P], yi = [V] and Xi = uknock,5; 则表示第i个观测值g 为单词“knock” 时，相应的标记比和 % + i 很可能分别为 [V]和 [ P ] .若采用状态特征函数 [ 1, if yi = [V] and g = \"knock”； S M % , X , 2 ) = < . [ 0 , otherwise, 则表示观测值0 为单词“knock” 时，它所对应的标记很可能为[V]. 对比式(14.11)和(14.2)可看出，条件随机场和马尔可夫随机场均使用团上 的势函数定义概率，两者在形式上没有显著区别；但条件随机场处理的是条件 概率,而马尔可夫随机场处理的是联合概率. 328 第 1 4 章 概 率 图 模 型 贝叶斯学派认为未知参 数与其他变量一样，都是 随机变量，因此参数估计 和变量推断能统一在推断 框架下进行.但频率主义 学派对此并不认同. 1 4 . 4 学 习 与 推 断 基 于 概 率 图 模 型 定 义 的 联 合 概 率 分 布 ，我 们 能 对 目 标 变 量 的 边 际 分 布 (marginal distribution)或以某些可观测变量为条件的条件分布进行推断.条 件分布我们已经接触过很多，例如在隐马尔可夫模型中要估算观测序列x 在给 定 参 数 A 下的条件概率分布.边际分布则是指对无关变量求和或积分后得到结 果，例如在马尔可夫网中，变量的联合分布被表示成极大团的势函数乘积，于 是，给 定 参 数 0 求解某个变量 x 的分布，就变成对联合分布中其他无关变量进 行积分的过程，这 称 为 “边际化”(marginalization). 对概率图模型，还需确定具体分布的参数，这称为参数估计或参数学习问 题，通常使用极大似然估计或最大后验概率估计求解.但若将参数视为待推测 的变量，则参数估计过程和推断十分相似，可 以 “吸收”到推断问题中.因此, 下面我们只讨论概率图模型的推断方法. 具体来说，假设图模型所对应的变量集x = ｛的,,2, • • ., xN ｝能分为 X E 和 x F 两个不相交的变量集，推断问题的目标就是计算边际概率P ( x F ) 或条件概 率 P(xF I X E ) . 由条件概率定义有 尸(XE) E x 尸P ( x 处 X 尸) 其中联合 概 率 P ( X 石,X p ) 可基于概率图模型获得，因此，推断问题的关键就是 如何高效地计算边际分布，即 • P ( X E ) = £ P (X E , X F ) . . (14.13) X ?",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 618
    }
  },
  {
    "page_content": "尸(XE) E x 尸P ( x 处 X 尸) 其中联合 概 率 P ( X 石,X p ) 可基于概率图模型获得，因此，推断问题的关键就是 如何高效地计算边际分布，即 • P ( X E ) = £ P (X E , X F ) . . (14.13) X ? 概率图模型的推断方法大致可分为两类.第一类是精确推断方法，希望能 计算出目标变量的边际分布或条件分布的精确值;遗憾的是，一般情形下，此类 算法的计算复杂度随着极大团规模的增长呈指数增长，适用范围有限.第二类 是近似推断方法，希望在较低的时间复杂度下获得原问题的近似解；此类方法 在现实任务中更常用.本节介绍两种代表性的精确推断方法，下一节介绍近似 推断方法. 1 4 . 4 . 1 变量消去 精确推断的实质是一类动态规划算法，它利用图模型所描述的条件独立性 来削减计算目标概率值所需的计算量.变量消去法是最直观的精确推断算法, 1 4 . 4 学习与推断 329 也是构建其他精确推断算法的基础. ， 我们先以图14.7（a）中的有向图模型为例来介绍其工作流程. （a ）贝叶斯网络结构 （b ）消息传递过程 图 1 4 . 7 变量消去法及其对应的消息传递过程 假定推断目标是计算边际概率P （g ）. 显然，为了完成此目标，只需通过加 法消去变量｛的,冗2 , 6 3 , / 4 ｝, 即 口 3 ）= 2 , 力3 , 力4 , ①5 ） X4 63 力2 6 1 基于有向图模型所描述 的条件独立性. = £ £ £ X4 6 3 6 2 6 1 £ 「3 ）。（力2 | 力1）尸（力3 | 力2 ）「（力4 | 力3 * （力5 | 力3 ）. （14.14） 不难发现，若 采 用 ｛的,6 2 , 6 4 « 3 ｝ 的顺序计算加法，则有 P （6 5 ）= £ 。（力5 | 6 3 ）£ 。（力4 | 力3 ）£ 尸（力3 | 力2 ）£ P （X1）P （X2 | 的） X3 / 4 /2 力1 = £ P （①5 | 的）£ 「（6 4 | ①3）£ P （*3 I 6 2）m i 2 （/ 2 ）, （14.15） 23 x4 X2 其中恒切（叼）是求加过程的中间结果，下 标 i表 示 此项是对Xi求加的结果，下 标 3•表示此项中剩下的其他变量.显然,皿引（叼）是关于叼的函数.不断执行此 过程可得 P （g ） = £ p （＞5 I 力3 ）£ ? （①4 | 6 3 ）m 2 3 （/ 3 ） 2 3 6 4",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 619
    }
  },
  {
    "page_content": "（14.15） 23 x4 X2 其中恒切（叼）是求加过程的中间结果，下 标 i表 示 此项是对Xi求加的结果，下 标 3•表示此项中剩下的其他变量.显然,皿引（叼）是关于叼的函数.不断执行此 过程可得 P （g ） = £ p （＞5 I 力3 ）£ ? （①4 | 6 3 ）m 2 3 （/ 3 ） 2 3 6 4 = £ P （g | 力3 ）加2 3（2 3 ）£ 「（力4 | 力3 ） 力3 %4 = £ P （力5 | 啰3 ）馆2 3 （/ 3 ）壮4 3 （6 3 ） 力3 = 恤 5 （窃）• (14.16) 330 第 1 4 章 概 率 图 模 型 ・显然，最 后 的 m 3 5 （^ 5 ）是 关 于 3 的函数，仅与变量方的取值有关. 事实上，上述方法对无向图模型同样适用.不妨忽略图 14.7（a ）中的箭头, 将其看作一个无向图模型,有 产（如屹 2 , 6 3 , 6 4 , 6 5 ）= 共 12侬1 , 6 2 ）矽23（% 6 3 ）矽34（/ 3 , 6 4 ）@ 3 5 （23,±5）, 其 中 Z 为规范化因子.边际分布。（磔）可这样计算： （14.17） 尸（① 5）= ｝ £ 矽 3 5 3 3 收5 ）£ 协34（6 3 , 6 4 ）£ 矽23（政,％3）£ 我2 （叫厘2） a?3 x4 = : £ g 3 5 （力3,力5 ）£ 62 矽34（6 3 , 立4 ）£ 的23（6 2,力3）馆12（/ 2 ） X3 X4 X2 = 万恒35（3 ）. 1 ZJ （14.18） 显然，通过利用乘法对加法的分配律，变量消去法把多个变量的积的求和 问题，转化为对部分变量交替进行求积与求和的问题.这种转化使得每次的求 和与求积运算限制在局部,仅与部分变量有关，从而简化了计算. 变量消去法有一个明显的缺点：若需计算多个边际分布，重复使用变量 消去法将会造成大量 的冗余计算.例如在图 14.7（a ）的贝叶斯网上，假定在计 算 P （x 5 ）之外还希望计算尸（力4）, 若 采 用 ｛叫 % 磔 , 磔 ｝的顺序，则 m i 2 （rr2 ）和 m 2 3 （^ 3 ）的计算是重复的. 1 4 . 4 . 2 信念传播 亦 称 Sum-Product算法. 信念传播（Belief P r o p a g a t i o n ）算法将变量消去法中的求和操作看作一个消 息传递过程,较好地解决了求解多个边际分布时的重复计算问题.具体来说,变 量消去法通过求和操作 恒力（叼）壬£ 矽（如 叼 ） Xi k£n（i）\\j 恒演（g ） （14.19）",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 620
    }
  },
  {
    "page_content": "1 4 . 4 . 2 信念传播 亦 称 Sum-Product算法. 信念传播（Belief P r o p a g a t i o n ）算法将变量消去法中的求和操作看作一个消 息传递过程,较好地解决了求解多个边际分布时的重复计算问题.具体来说,变 量消去法通过求和操作 恒力（叼）壬£ 矽（如 叼 ） Xi k£n（i）\\j 恒演（g ） （14.19） 消 去变量g , 其中 确 表 示 结 点g 的邻接结点.在信念传播算法中，这个操作 被 看 作 从 3 向 Xj传递了一个消息mij（Xj）.这样，式（14.15）和 （14.16）所描述的 变量消去过程就能描述为图14.7（b ）所示的消息传递过程.不难发现，每次消息 传递操作仅与变量电及其邻接结点直接相关，换言之，消息传递相关的计算被 1 4 . 5 近似推断 331 限制在图的局部进行. i 在信念传播算法中，一个结点仅在接收到来自其他所有结点的消息后才能 向另一个结点发送消息，且结点的边际分布正比于它所接收的消息的乘积，即 P(Xi)(X [ J . (14.20) fcGn(z) 例 如 在 图 14.7(b)中，结 点 /3 要向①5 发送消息，必须事先收到来自结点力2 和 出4 的消息，且传递到出 的 消 息 皿 35(05)恰为概率 P ( 3 ) . 若图结构中没有环，则信念传播算法经过两个步骤即可完成所有消息传递, 进而能计算所有变量上的边际分布： • 指定一个根结点，从所有叶结点开始向根结点传递消息，直到根结点收到 所有邻接结点的消息； • 从根结点开始向叶结点传递消息，直到所有叶结点均收到消息. 例 如 在 图 14.7(a)中，令 g 为根结点，则 窈 和 磔 为 叶 结 点 .以 上 两 步 消 息 传递的过程如图 1 4 . 8所示.此时图的每条边上都有方向不同的两条消息，基于 这些消息和式(14.20)即可获得所有变量的边际概率. ( a ) 消息传向根结点 ( b ) 消息从根结点传出 图 1 4 . 8 信念传播算法图示 1 4 . 5 近 似 推 断 精确推断方法通常需要很大的计算开销，因此在现实应用中近似推断方法 更为常用.近似推断方法大致可分为两大类：第一类是采样(sampling),通过使 用随机化方法完成近似；第二类是使用确定性近似完成近似推断，典型代表为 变分推断(variational inference). 14.5.1 MCMC 采样 在很多任务中，我们关心某些概率分布并非因为对这些概率分布本身感兴 332 第 1 4 章 概 率 图 模 型 趣，而是要基于它们计算某些期望，并且还可能进一步基于这些期望做出决策.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 621
    }
  },
  {
    "page_content": "用随机化方法完成近似；第二类是使用确定性近似完成近似推断，典型代表为 变分推断(variational inference). 14.5.1 MCMC 采样 在很多任务中，我们关心某些概率分布并非因为对这些概率分布本身感兴 332 第 1 4 章 概 率 图 模 型 趣，而是要基于它们计算某些期望，并且还可能进一步基于这些期望做出决策. 例 如 对 图 14.7(a)的贝叶斯网，进行推断的目的可能是为了计算变量出5 的期望. 若直接计算或逼近这个期望比推断概率分布更容易，则直接操作无疑将使推断 问题的求解更为高效. 采样法正是基于这个思路.具体来说,假定我们的目标是计算函数/(力)在 概率密度函数2 侬)下的期望 若 x 是 离 散 变 量 ，则把 积分换做求和即可. 1M 力 = / /(力)0(力川力, (14.21) 或 0 3 ) 的相关分布. 则可根据p⑺ 抽 取 一 组 样 本 … ，C N },然后计算了(乃在这些样本上的 均值 1 N 『= 耳 5 > 3 ) ， 2=1 M W 以此来近似目标期望E [7 ].若样本{的心2, • •.也N } 独立，基于大数定律，这种 通过大量采样的办法就能获得较高的近似精度.问题的关键是如何采样.对概 率图模型来说,就是如何高效地基于图模型所描述的概率分布来获取样本. 概率图模型中最常用的采样技术是马尔可夫链蒙特卡罗(Markov Chain Monte C a rlo ,简 称 MCMC)方 法 .给 定 连 续 变 量 c G X 的概率密度函数汉乃, n 在 区 间 A 中的概率可计算为 P(A) = / p[x}dx . (14.23) 若 有 函 数 了 : X 1 风则可计算/(力)的期望 夕( / ) = 电目[/(X)] = / f{x}p(x)dx . (14.24) 若力不是单变量而是一个高维多元变量X ,且服从一个非常复杂的分布，则对 式(14.24)求积分通常很困难.为此，M CM C先构造出服从P 分布的独立同分布 随机变量x i ,x 2 , … ，X N ,再得到式(14.24)的无偏估计 双 / ) = 河 £ / ( 〜 > (1425) 然而，若概率密度函数p ( x ) 很复杂，则构造服从p 分布的独立同分布样本 1 4 . 5 近似推断 333 也很困难.MCM C方法的关键就在于通过构造“平稳分布为p 的马尔可夫链” 来产生样本：若马尔可夫链运行时间足够长(即收敛到平稳状态)，则此时产出",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 622
    }
  },
  {
    "page_content": "双 / ) = 河 £ / ( 〜 > (1425) 然而，若概率密度函数p ( x ) 很复杂，则构造服从p 分布的独立同分布样本 1 4 . 5 近似推断 333 也很困难.MCM C方法的关键就在于通过构造“平稳分布为p 的马尔可夫链” 来产生样本：若马尔可夫链运行时间足够长(即收敛到平稳状态)，则此时产出 的样本x 近似服从于分布p . 如何判断马尔可夫链到达平稳状态呢？假定平稳 马尔可夫链T 的状态转移概率(即从状态x 转移到状态中的概率)为T (x，| x), t 时刻状态的分布为0(犬)，则若在某个时刻马尔可夫链满足平稳条件 p(xt )T(x f - 1 | x*) = p(x t ~1)T (x t | x 'T ) , (14.26) 则 p ( x ) 是该马尔可夫链的平稳分布，且马尔可夫链在满足该条件时已收敛到平 稳状态. 也就是说,M CM C方法先设法构造一条马尔可夫链，使其收敛至平稳分布 恰为待估计参数的后验分布，然后通过这条马尔可夫链来产生符合后验分布的 样本，并基于这些样本来进行估计.这里马尔可夫链转移概率的构造至关重要, 不同的构造方法将产生不同的M CM C算法. Metropolis-Hastings 算 法 是 由 N. Metropolis等人 1953 年 提 出 [Metropolis et aL, 1 9 5 3 ],此后 W. K. Hastings将其推广到一般 形 式 [Hastings, 1 9 7 0 ] ,因 此而得名. Metropolis-Hastings (简称M H )算 法 是 M CM C 的 重 要 代 表 .它 基 于 “拒 绝 采 样 ”(嘀ect sam pling)来 逼 近 平 稳 分 布 p . 如 图 14.9所示，算法每次根 据 上 一 轮 采 样 结 果 婷 T 来 采 样 获 得 候 选 状 态 样 本 x * ,但这个候选样本会以 一 定 的 概 率 被 “拒 绝 ”掉 .假 定 从 状 态 X%T 到 状 态 x * 的 转 移 概 率 为 Q(x* | X E T )4 ( X* | $ T ) , 其 中 Q(x* |婷-1 ) 是用户给定的先验概率，A(x* | X%T ) 是 x * 被接受的概率.若x * 最终收敛到平稳状态，则根据式(14.26)有 p(x£T)Q(x* I x±T)Z(x* I x%T) = p (x*)Q (xJi I x * )4 x * T I X*) , (14.27) 重复足够多次以达到平 稳分布. 根据式(14.28).",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 623
    }
  },
  {
    "page_content": "x * 被接受的概率.若x * 最终收敛到平稳状态，则根据式(14.26)有 p(x£T)Q(x* I x±T)Z(x* I x%T) = p (x*)Q (xJi I x * )4 x * T I X*) , (14.27) 重复足够多次以达到平 稳分布. 根据式(14.28). 实践中常会丢弃前面若 干个样本，因为达到平稳 分布后产生的才是希望得 到的样本. 输入：先验概率Q ( x * 过程： 1：初始化X 。； 2 ： for t = 1,2,... do 3 ： 4: 5: 6: 7: 8: X 方= X* else X£ = x f - 1 根 据 Q ( x * I x / T ) 采样出候选样本X*; 根据均匀分布从( 0 , 1 )范围内采样出阈值 if u A(x* | x i - 1 ) then end if 9: 10: end for 11: return x ' x 2 … . 输出：采 样 出 的 一 个 样 本 序 列 ____________________ 图 14.9 Metropolis-Hastings 算法 334 第 1 4 章概率图模型 于是，为了达到平稳状态,只需将接受率设置为 A ( x * I X - ) = m i n ( 1,点？ 照)) (14.28) 参 见 7 5 3 节. 吉布斯采样(Gibbs sampling)有 时 被 视 为 M H 算法的特例，它也使用马尔 可夫链获取样本，而该马尔可夫链的平稳分布也是采样的目标分布p ( x ) . 具体 来 说 ,假 定 X = 独 ｝,目标分布为P(x),在 初始化 X 的取值后，通过 循环执行以下步骤来完成采样： ( 1 ) 随机或以某个次序选取某变量g; ( 2 ) 根 据 x 中 除 g 外 的 变 量 的 现 有 取 值 ，计 算 条 件 概 率 p Q e | x ) 其中 X, — ｛① 1, *2, ♦… , 1,3 + 1, •… , 出N ｝； ( 3 ) 根 据 p(Xi | x - ) 对 变 量Xi采样,用采样值代替原值. 14.5.2变分推断 变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近 似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布. 在学习变分推断之前，我们先介绍概率图模型一种简洁的表示方法—— 盘 式 记 法 (plate notation) [Buntine, 1 9 9 4 ] . 图 14.10 给出 了一个简单的例子.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 624
    }
  },
  {
    "page_content": "14.5.2变分推断 变分推断通过使用已知简单分布来逼近需推断的复杂分布，并通过限制近 似分布的类型，从而得到一种局部最优、但具有确定解的近似后验分布. 在学习变分推断之前，我们先介绍概率图模型一种简洁的表示方法—— 盘 式 记 法 (plate notation) [Buntine, 1 9 9 4 ] . 图 14.10 给出 了一个简单的例子. 图 14.10(a)表 示 N 个 变 量 ｛如 ％ … 避N ｝均 依 赖 于 其 他 变 量 z . 在图 14.10(b)中，相互独立的、 由相同机制生成的多个变量被放在一个方框(盘)内, 并在方框中标出类似变量重复出现的个数N ; 方框可以嵌套.通常用阴影标注 出已知的、能观察到的变量，如 图 14.10中的变量力.在很多学习任务中，对属 性变量使用盘式记法将使得图表示非常简洁. (a)普通变量关系图 (b)盘式记法 图 1 4 . 1 0 盘式记法的例示 1 4 . 5 近似推断 变分推断使用的近似分 布需具有良好的数值性质， 通常是基于连续型变量的 概率密度函数来刻画的. 335 在 图 14.10(b)中，所有能观察到的变量”的联合分布的概率密度函数是 注 「 P(X | © ) = ] ] 上 仪 电 ⑶ ⑼ ， i=l z (14.29) 所对应的对数似然函数为 lnp(x | 0) = | 0 ) 1 , (14.30) i=l I z ) 其 中 X = {的,优2,… ，①N }, 9 是 X 与 Z 服从的分布参数. 一般来说，图 14.10所对应的推断和学习任务主要是由观察到的变量X 来 估计隐变量Z 和分布参数变量0 , 即求解p(z I X, 9 ) 和 O. 概率模型的参数估计通常以最大化对数似然函数为手段.对式(14.30)可使 E M 算法参见7.6节. 用 E M 算 法 在 E 步，根据方时刻的参数日对p(z I X, V ) 进行推断，并计算联 合似然函数p(x, z | 9 );在 M 步，基 于 E 步的结果进行最大化寻优，即对关于变 量 e 的 函 数 Q(9; 9±)进行最大化从而求取 = arg m a x Q(©; 0^) 0 二号咚 M E W ) . (14.3D 式(14.31)中 的 Q ( @ U ) 实际上是对数联合似然函数lnp(x,z | 9 ) 在分布 p(z | x , 6 ^ 下的期望，当 分 布 p(z | x , U ) 与 变 量 z 的真实后验分布相等时, Q(0; 近似于对数似然函数.于是,E M 算法最终可获得稳定的参数0 , 而隐 变 量 z 的分布也能通过该参数获得.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 625
    }
  },
  {
    "page_content": "E W ) . (14.3D 式(14.31)中 的 Q ( @ U ) 实际上是对数联合似然函数lnp(x,z | 9 ) 在分布 p(z | x , 6 ^ 下的期望，当 分 布 p(z | x , U ) 与 变 量 z 的真实后验分布相等时, Q(0; 近似于对数似然函数.于是,E M 算法最终可获得稳定的参数0 , 而隐 变 量 z 的分布也能通过该参数获得. 需注意的是,p(z | x , 9 力)未必是隐变量z 服从的真实分布，而只是一个近 似分布.若将这个近似分布用Q(Z) 表示,则不难验证 lnp(x) = £(q) + KL(Q || p), (14.32) 其中 £(q) = / q ( z ) l n { ^ ^ d z , (14.33) K L 散度，参见附录 C 3 KL(Q \\\\p) = - [ q(z) In。(空)dz . J 式z) (14.34) 336 第 1 4 章 概 率 图 模 型 然而在现实任务中，E 步 对 p(z | x ,6%)的推断很可能因z 模型复杂而难以 进行,此时可借助变分推断.通常假设z 服从分布 M q(z)= n % ( Z £ ) ， (14.35) 即 假 设 复 杂 的 多 变 量 Z 可 拆 解 为 一 系 列 相 互 独 立 的 多 变 量 卯 更重要的是, 为 简 化 表 述 ，这 里 将 可 以 令 qi分布相对简单或有很好的结构，例 如 假 设 Qi为指数族(exponential Q i( z i) 简写为生. family)分布，此时有 £(q) = / n 型{lnp(x，z) — £ l n % } dz co n st是一个常数. = [ lnp(x,z) d% — J qj In qjdzj + const - 梃7 qj Ingjdzj + const , (14.36) 其中 lnp(x, zj) = [lnp(x, z)] + const , E i74j [lnp(x, z)]= 型dz° . (14.37) (14.38) 我 们 关 心 的 是 幼 因 此 可 固 定 出 海 再 对 £( q ) 进 行 最 大 化 ，可 发 现 式(14.36)等 于 - K L ⑨ ||/(x,z/, 即 当 qj = p(x, zj)时 £ ( q ) 最 大 .于 是 可 知变量子集z; 所服从的最优分布Q*应满足 IIIQJ(ZJ) = [lnp(x, z)] + const , (14.39) 即 exp.(叫羚[In2 (x,z)]) % Zj",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 626
    }
  },
  {
    "page_content": "式(14.36)等 于 - K L ⑨ ||/(x,z/, 即 当 qj = p(x, zj)时 £ ( q ) 最 大 .于 是 可 知变量子集z; 所服从的最优分布Q*应满足 IIIQJ(ZJ) = [lnp(x, z)] + const , (14.39) 即 exp.(叫羚[In2 (x,z)]) % Zj f exp (叫却[ln0 (x, z)])dzj > (14.40) 换 言 之 ，在 式 (14.35)这 个 假 设 下 ，变 量 子 集 盯 最 接 近 真 实 情 形 的 分 布 由 式(14.40)给出. 显然，基于式(14.35)的假设，通过恰当地分割独立变量子集4 并选择 q i 服 从的分布,E^[ln^(x,z)]往往有闭式解,这使得基于式(14.40)能高效地对隐变 量 z 进行推断.事实上，由式(14.38)可看出，对 变 量 4 •分 布 q；进行估计时融合 1 4 . 6 话题模型 337 m ean指期望，fie ld 贝U是 指分布. 了町之外的其他々用的信息，这是通过联合似然函数ln p (x ,z )在 4 之外的隐 变量分布上求期望得到的，因 此 亦 称 “平均场”(mean field)方法. 在实践中使用变分法时，最重要的是考虑如何对隐变量进行拆解，以及假 设各变量子集服从何种分布，在此基础上套用式(14.40)的结论再结合E M 算法 即可进行概率图模型的推断和参数估计.显然，若隐变量的拆解或变量子集的 分布假设不当,将会导致变分法效率低、效果差. 1 4 .6 话题模型 话题模型(topic model)是一族生成式有向图模型，主要用于处理离散型的 数据(如文本集合)，在信息检索、 自然语言处理等领域有广泛应用.隐狄利克 雷分配模型(Latent Dirichlet Allocation,简 称 LDA)是话题模型的典型代表. 我们先来了解一下话题模型中的几个概念：词(word)、文档(document)和 话题(to p ic ).具体来说，“词 ”是待处理数据的基本离散单元，例如在文本处理 任务中，一个词就是一个英文单词或有独立意义的中文词.“文档”是待处理 的数据对象，它由一组词组成，这些词在文档中是不计顺序的，例如一篇论文、 一个网页都可看作一个文档；这样的表示方式称为“词袋”(bag-of-words).数 据对象只要能用词袋描述,就可使用话题模型.“话题”表示一个概念，具体表 示为一系列相关的词，以及它们在该概念下出现的概率.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 627
    }
  },
  {
    "page_content": "的数据对象，它由一组词组成，这些词在文档中是不计顺序的，例如一篇论文、 一个网页都可看作一个文档；这样的表示方式称为“词袋”(bag-of-words).数 据对象只要能用词袋描述,就可使用话题模型.“话题”表示一个概念，具体表 示为一系列相关的词，以及它们在该概念下出现的概率. 形 象 地 说 ，如 图 1 4 .H 所示，一 个 话 题 就 像 是 一 个 箱 子 ，里面装着在这 个 概 念 下 出 现 概 率 较 高 的 那 些 词 .不 妨 假 定 数 据 集 中 一 共 包 含 K 个话题 和 T 篇文 档 ，文 档 中 的 词 来 自 一 个 包 含 N 个 词 的 词 典 .我 们 用 T 个N 维 向 量 w = {wi, W2,.. . , WT } 表示数据集(即文档集合)，K 个 N 维 向 量 Bk (k = 1 ,2 ,… ，K ) 表示话题，其 中 皿 G 陂 的 第 n 个分量 % 表 示 文 档t 中词 n 的词频，(3k £ 的第八个分量 / 表 示 话 题k 中 词n 的词频. 在 现 实 任 务 中 可 通 过 统 计 文 档 中 出 现 的 词 来 获 得 词 频 向 量 皿 (z = 1 ,2 ,... , T ) , 但通常并不知道这组文档谈论了哪些话题,也不知道每篇文档与哪 些话题有关. LD A 从生成式模型的角度来看待文档和话题.具体来说,LDA认 为每篇文档包含多个话题，不 妨 用 向 量 仇 €肽长表示文档t 中所包含的每个话 题的比例，Q t,k 即表示文档t 中包含话题k 的比例，进而通过下面的步骤由话 题 “生成”文档九 例如若把图像中的小块 看 作 “词 ”，则可将图像 表示为词袋，于是话题模 型也可用于图像数据. 通 常 需 对 词 频 做 一 些 处理，例 如 去 除 “停用词 表 ”中的词等. 狄利克雷分布参见附录 C .I.6. ( 1 ) 根据参数为a 的狄利克雷分布随机采样一个话题分布e t ； ( 2 ) 按如下步骤生成文档中的N 个词： 338 第 1 4 章 概 率 图 模 型 桨声灯影里的秦淮河 一 九 二 三 年 八 月 的 一 晚 ，我 和 平 伯 同 游 秦 淮 河 ； 平 伯 是 初 泛 ，我 是 重 来 了 。 我 们 庵 了 一 只 \" 七 板 子 \" ，在 夕 阳 已 去 ，皎 月 方 来 的 时 候 ，便 下 了 船 。 于 是 桨 声汨一 汩 ， 我 们 开 始 领 略 那 见 荡 才 蔷 蔽 色 的 历 包 的 粪 淮 河 行 窗 格 雕 镂 颇 细 ，使 人 起 柔 腻 之 感 。 窗 格 里 映 着 红 色 蓝 色 的 玻 璃 玻 璃 上 有 精 致 的 花",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 628
    }
  },
  {
    "page_content": "夕 阳 已 去 ，皎 月 方 来 的 时 候 ，便 下 了 船 。 于 是 桨 声汨一 汩 ， 我 们 开 始 领 略 那 见 荡 才 蔷 蔽 色 的 历 包 的 粪 淮 河 行 窗 格 雕 镂 颇 细 ，使 人 起 柔 腻 之 感 。 窗 格 里 映 着 红 色 蓝 色 的 玻 璃 玻 璃 上 有 精 致 的 花 规 模 虽 不 及 大 邂 _0但 平 次 ，足 系 人 情 思 , 部 。 上 面 有 弧 形 的 顶 丁 彘 面 疏 疏 时 秦 淮 河 里 的 船 ， 比 北 京 万 姓 园 ， 心 干 支 着 。 里 面 通 常 放 着 两 张 藤 的 躺 颐 和 园 的 船 好 ， 比 西 湖 的 那 好 ， 比扬 州 瘦 西 湖 珀 般 也 生 _ 这 儿 处 的 船 不 是 觉 着 笨 ， 就 获 丁 而 k 以 迷 。 躺 下 ， 可 以 谈 天 ， 可 以 望 远 , 以 顾 盼 两 岸 的 河 房 。 大 船 上 也 有 j 便 在 小 船 上 更 觉 清 先 罢 了 。 舱 露 能 引 超 乘 客 们 的 情 韵 ，如 秦 淮 河 的 船 一 样 。 莽 淮 河 的 相 约 略 可 分 为 两 种 ： 一 是 大 船 ； 一 是 小 那 ， 就 是 所 谓 “七 板 子 ” 。 大 船 的 闷 大 ， 可 容 二 三 十 人 。 里 面 陈 设 卷 字 曲 布 先 涉 型 7 具 ， 桌 上 一 律 嵌 着 冰 凉 的 大 理 看 而 。 # 方 的 罗 少 ， 彩 苏 的 精 粗 歹 总 还 你 一 个 灯 彩 , 这 灯 彩 实 在 是 放 能 钩 人 的 东 西 。 夜 幕 垂 垂 地 下 来 时 ， 卜船） 小卜占起灯火r、 话题分布 图 14.11 L D A 的文档生成过程示意图 话题指派 （a）根 据 5 进行话题指派，得到文 档t中 词n 的话题zt,£ （b）根据指派的话题所对应的词频分布为随机采样生成词. 图 14.11演示出根据以上步骤生成文档的过程.显然，这样生成的文档自 然地以不同比例包含多个话题（步 骤 1）, 文档中的每个词来自一个话题（步骤 2b）, 而这个话题是依据话题比例产生的（步 骤 2a）. 图 14.12描述了 L D A 的变量关系，其中文档中的词频仪加是唯一的已观 测变量，它依赖于对这个词进行的话题指派就加以及话题所对应的词频力解同 时，话 题 指 派%打依赖于话题分布0 , 6 依赖于狄利克雷分布的参数期而话 题词频则依赖于参数小 图 1 4.12 L D A 的盘式记法图 于是,LD A模型对应的概率分布为 339 \\ / 1 4 . 7 阅读材料",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 629
    }
  },
  {
    "page_content": "图 14.12描述了 L D A 的变量关系，其中文档中的词频仪加是唯一的已观 测变量，它依赖于对这个词进行的话题指派就加以及话题所对应的词频力解同 时，话 题 指 派%打依赖于话题分布0 , 6 依赖于狄利克雷分布的参数期而话 题词频则依赖于参数小 图 1 4.12 L D A 的盘式记法图 于是,LD A模型对应的概率分布为 339 \\ / 1 4 . 7 阅读材料 p ( W , z , ^ , 0 | a , \" ) =. T K J J p © | a )Y ［p ^ k |r?) t=l i=l / N \\n= l J J P (w t ,n I zt ^ ( 3 k )P (z t ,n I ©t) I , (14.41) 其 中 p (e t I a ) 和 p ( 仇 I 77) 通常分别设置为以a 和 ”为参数的K 维 和 N 维狄 利克雷分布,例如 0 (仇 ⑷ = 殁 ： (W 42) 参见附录C.1.5, 其 中 r ( - ) 是 G a m m a函数.显然，a 和 7 /是模型式(1 4 .4 1 )中待确定的参数. 训练文档集对应的词频. 给定训练数据W = { w i,w 2 , . . . , w T }, L D A 的模型参数可通过极大似然 法估计，即寻找a 和 17以最大化对数似然 T L L ( a ,峪 = £ In p (皿 | 4 ⑺ . (14.43) t=i 但由于以比力|以用不易计算，式(14.43)难以直接求解，因此实践中常采用变分 法来求取近似解. 若模型已知，即参数a 和 ”已确定，则根据词频 飞 来推断文档集所对应 的话题结构(即推断© t ,队 和鬼九)可通过求解 彘 £ 9 M 5 ) = 叱解：产1 . (14.44) 然而由于分母上的0 (W I a m ) 难以获取，式(14.44)难以直接求解，因此在实践 中常采用吉布斯采样或变分法进行近似推断. 1 4 .7 阅读材料 概率图模型方面已经有专门的书籍如［Koller and Friedman, 2009］. ［Pearl, 1982］倡导了贝叶斯网的研究，［Pearl, 1988］对这方面的早期研究工 作进行了总结.马尔可夫随机场由［Geman and Geman, 1984］提出.现实应用 中使用的模型经常是贝叶斯网与马尔可夫随机场的结合.隐马尔可夫模型及 其在语音识别中的应用可参阅［Rabiner, 1989］. 条 件 随 机 场 由 ［Lafferty et al.,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 630
    }
  },
  {
    "page_content": "［Pearl, 1982］倡导了贝叶斯网的研究，［Pearl, 1988］对这方面的早期研究工 作进行了总结.马尔可夫随机场由［Geman and Geman, 1984］提出.现实应用 中使用的模型经常是贝叶斯网与马尔可夫随机场的结合.隐马尔可夫模型及 其在语音识别中的应用可参阅［Rabiner, 1989］. 条 件 随 机 场 由 ［Lafferty et al., 2001］提出，更多的内容可参阅［Sutton and McCallum, 2012］. 340 第 1 4 章 概 率 图 模 型 信 念 传 播 算 法 最 早 由 ［Pearl, 1986］作为精确推断技术提出，后来衍生出 多 种 近 似 推 断 算 法.对一般的带环图，信念传播算法需在初始化、消息传递 等环节进行调整，由此形成了迭代信念传播算法(Loopy Belief Propagation) ［M urphy et al., 1999］, 但 其 理 论性质尚不清楚，这 方 面 的 进 展 可 参 阅 ［Mooij and Kappen, 2007; Weiss, 2000］. 有些带环图可先用“因子图 \" (factor graph) ［Kschischang et al., 2001］描述，再转化为因子树(factor tr e e ) 进行信念传播.对 任意图结构的信念传播已有一些研究［Lauritzen and Spiegelhalter, 1988］. 近来 随着并行计算技术的发展，信念传播的并行加速实现受到关注，例 如 ［Gonzalez et a l, 2009］提 出 r e 近似推断的概念并设计出多核并行信念传播算法，其时间 开销随内核数的增加而线性降低. 概率图模型的建模和推断，尤其是变分推断在2 0 世 纪 9 0 年代中期逐步发 展成熟\" Jo rd a n , 1998］对这个阶段的主要成果进行了总结.关于变分推断的更 多内容可参阅［Wainwright and Jordan, 2008］. 图模型带来的一大好处是使得人们能直观、快速地针对具体任务定义模 型. LDA ［Biei et al., 2003］是这方面的重要代表，由它产生了很多变体，关于这 方面的内容可参阅［Biei, 2012］. 概率图模型的一个发展方向是使得模型的结构 “非 参 数 化 ”指参数的 数 目 无 须 事 先 指 定 ，是贝 叶斯学习方法的重要发展. 能对数据有一定的自适应能力，即 “非参数化\" (non-param etric)方法，例如层 次化狄利克雷过程模型［Teh et al., 2006］＞无限隐特征模型 ［Ghahramani and",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 631
    }
  },
  {
    "page_content": "方面的内容可参阅［Biei, 2012］. 概率图模型的一个发展方向是使得模型的结构 “非 参 数 化 ”指参数的 数 目 无 须 事 先 指 定 ，是贝 叶斯学习方法的重要发展. 能对数据有一定的自适应能力，即 “非参数化\" (non-param etric)方法，例如层 次化狄利克雷过程模型［Teh et al., 2006］＞无限隐特征模型 ［Ghahramani and 贝 叶 斯 学 习 参 见 p.164. Griffiths, 2006］等. LS A 是 S V D 在文本数据 上的变体. 参 见 p.266. 话题模型包含了多种模型,其中有些并不采用贝叶斯学习方法,例如PLSA (概率隐语义分析)［Hofmarm, 2001］, 它 是 LSA (隐语义分析)的概率扩展. 蒙特卡罗方法是二十世纪四十年代产生的一类基于概率统计理论、使用 随机数来解决问题的数值计算方法，M C M C 是马尔可夫链与蒙特卡罗方法的 结 合 ,最 早 由 ［Pearl, 1987］引入贝叶斯网推断.关于M C M C 在概率推断中的应 用 可 参 阅 ［Neal, 1993］, 更 多 关 于 M C M C 的 内 容 可 参 阅 ［Andrieu et al., 2003; Gilks et al., 1996］. 习题 341 习题 14.1 试用盘式记法表示条件随机场和朴素贝叶斯分类器. 14.2 试证明图模型中的局部马尔可夫性：给定某变量的邻接变量，则该变 量条件独立于其他变量. 14.3 试证明图模型中的成对马尔可夫性：给定其他所有变量，则两个非邻 接变量条件独立. 14.4 试述在马尔可夫随机场中为何仅需对极大团定义势函数. 14.5 比较条件随机场和对率回归，试析其异同. 14.6 试证明变量消去法的计算复杂度随图模型中极大团规模的增长而呈 指数增长，但随结点数的增长未必呈指数增长. 14.7 吉布斯采样可看作M H 算法的特例，但吉布斯采样中未使用“拒绝采 样 ”策略,试述这样做的好处. 14.8 平均场是一种近似推断方法.考虑式(1432),试析平均场方法求解的 近似问题与原问题的差异，以及实践中如何选择变量服从的先验分布. 14.9 * 从网上下载或自己编程实现L D A ,试 分 析 金 庸 作 品 《天龙八部》中 每十回的话题演变情况. 14.10 * 试设计一个无须事先指定话题数目的L D A 改进算法. 342 第 1 4 章 概 率 图 模 型 参考文献",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 632
    }
  },
  {
    "page_content": "近似问题与原问题的差异，以及实践中如何选择变量服从的先验分布. 14.9 * 从网上下载或自己编程实现L D A ,试 分 析 金 庸 作 品 《天龙八部》中 每十回的话题演变情况. 14.10 * 试设计一个无须事先指定话题数目的L D A 改进算法. 342 第 1 4 章 概 率 图 模 型 参考文献 Andrieu, C., N. De Freitas, A. Doucet, and M. I. Jordan. (2003). “An intro­ duction to MCMC for machine learning.55 Machine Learning^ 50(1-2):5-43. Biei, D. M. (2012). uProbabilisitic topic models.” Communications of the ACM, 55(4):77-84. Biei, D. M., A. Ng, and M. I. Jordan. (2003). ^Latent Dirichlet allocation.^^ Journal of Machine Learning Research^ 3:993-1022. Buntine, W. (1994). ^Operations for learning with graphical m o d e ls .Journal of Artificial Intelligence Research1 2:159-225. Geman, S. and D. Geman. (1984). “Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images.5, IEEE Transactions on Pattern Analysis and Machine Intelligence1 6(6):721-741. Ghahramani, Z. and T. L. Griffiths. (2006). ^Infinite latent feature models and the Indian buffet process?5 In Advances in Neural Information Processing Systems 18 (NIPS) (Y. Weiss, B. Scholkopf, and J. C. Platt, eds.), 475-482,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 633
    }
  },
  {
    "page_content": "the Indian buffet process?5 In Advances in Neural Information Processing Systems 18 (NIPS) (Y. Weiss, B. Scholkopf, and J. C. Platt, eds.), 475-482, MIT Press, Cambridge, MA. Gilks, W. R., S. Richardson, and D. J. Spiegelhalter. (1996). Markov Chain Monte Carlo in Practice. Chapman & Hall/CRC, Boca Raton, FL. Gonzalez, J. E., Y. Low, and C. Guestrin. (2009). “Residual splash for optimally parallelizing belief propagation.\" In Proceedings of the 12th International Conference on Artificial Intelligence and Statistics (AISTATS), 177-184, Clearwater Beach, FL. Hastings, W. K. (1970). “Monte Carlo sampling methods using Markov chains and their applications.\" Biometrica, 57(1):97-109. Hofmann, T. (2001). uUnsupervised learning by probabilistic latent semantic analysis.55 Machine Learning, 42(1):177-196. Jordan, M. L, ed. (1998). Learning in Graphical Models. Kluwer, Dordrecht, The Netherlands. Koller, D. and N. Friedman. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press, Cambridge, MA.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 634
    }
  },
  {
    "page_content": "The Netherlands. Koller, D. and N. Friedman. (2009). Probabilistic Graphical Models: Principles and Techniques. MIT Press, Cambridge, MA. Kschischang, F. R., B. J. Frey, and H.-A. Loeliger. (2001). “Factor graphs and the sum-product a lg o rith m .IEEE Transactions on Information Theory,47 参考文献 343 (2):498-519. Lafferty, J. D., A. McCallum, and F. C. N. Pereira. (2001). ^Conditional ran­ dom fields: Probabilistic models for segmenting and labeling sequence data.” In Proceedings of the 18th International Conference on Machine Learning (ICML), 282-289, Williamstown, MA. Lauritzen, S. L. and D. J. Spiegelhalter. (1988). “Local computations with prob­ abilities on graphical structures and their application to expert systems.55 Journal of the Royal Statistical Society - Series B, 50(2):157-224. Metropolis, N., A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller. (1953). “Equations of state calculations by fast computing machines.55 Journal of Chemical Physics, 21(6):1087-1092. Mooij, J. M, and H. J. Kappen. (2007). ^Sufficient conditions for convergence",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 635
    }
  },
  {
    "page_content": "Journal of Chemical Physics, 21(6):1087-1092. Mooij, J. M, and H. J. Kappen. (2007). ^Sufficient conditions for convergence of the sum-product algorithm.\" IEEE Transactions on Information Theory, 53(12):4422-4437. Murphy, K. P., Y. Weiss, and M. I. Jordan. (1999). “Loopy belief propaga­ tion for approximate inference: An empirical study25 In Proceedings of the 15th Conference on Uncertainty in Artificial Intelligence (UAI), 467-475, Stockholm, Sweden. Neal, R. M. (1993). ^Probabilistic inference using Markov chain Monte Carlo methods? Technical Report CRG-TR-93-1, Department of Computer Sci­ ence, University of Toronto. Pearl, J. (1982). uAsymptotic properties of minimax trees and game-searching procedures? In Proceedings of the 2nd National Conference on Artificial Intelligence (AAAI)^ Pittsburgh, PA. Pearl, J. (1986). “Fusion, propagation and structuring in belief networks.55 Artificial Intelligence^ 29(3):241-288. Pearl, J. (1987). “Evidential reasoning using stochastic simulation of causal models.” Artificial Intelligence, 32(2):245-258.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 636
    }
  },
  {
    "page_content": "Artificial Intelligence^ 29(3):241-288. Pearl, J. (1987). “Evidential reasoning using stochastic simulation of causal models.” Artificial Intelligence, 32(2):245-258. Pearl, J. (1988). Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference. Morgan Kaufmann, San Francisco, CA. Rabiner, L. R. (1989). “A tutorial on hidden Markov model and selected ap­ plications in speech recognition.,, Proceedings of the IEEE, 77(2):257-286. 344 第 1 4 章 概 率 图 模 型 Sutton, C. and A. McCallum. (2012), “An introduction to conditional random f ie ld s .Foundations and Trends in Machine Learning, 4(4):267-373. Teh, Y. W., M. I. Jordan, M. J. Beal, and D. M. Biei. (2006). ^Hierarchical Dirichlet processes? Journal of the American Statistical Association1 101 (476):1566-1581. Wainwright, M. J. and M. I. Jordan. (2008). “Graphical models, exponential families, and variational inference? Foundations and Trends in Machine Learning1 1(1-2):1-305. Weiss, Y. (2000), ^Correctness of local probability propagation in graphical",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 637
    }
  },
  {
    "page_content": "families, and variational inference? Foundations and Trends in Machine Learning1 1(1-2):1-305. Weiss, Y. (2000), ^Correctness of local probability propagation in graphical models with loops.” Neural Computation1 12(1):1-41. 休息一会儿 345 休息一会儿 小故事：概率图模型奠基人朱迪亚•珀尔 说起概率图模型，就必然要谈到犹太裔美国计算机科学 家 朱 迪 亚 -珀 尔 (Judea Pearl, 1936— ) . 珀尔出生于特拉 维夫，1960年他在以色列理工学院电子工程本科毕业后来 到美国，在 R u tg e rs大学和布鲁克林理工学院分别获得物理 学硕士和电子工程博士学位.1965年博士毕业后进入RCA 研 究 实 验 室 从 事 超 导 存 储 方 面 的 工 作 ，1970年到加州大学洛杉矶分校任教 至今. 参 阅 1 .5 节. 早期的主流人工智能研究专注于以逻辑为基础来进行形式化和推理，但这 样很难定量地对不确定性事件进行表达和处理.珀尔在二十世纪七十年代将概 率方法引入人工智能，开创了贝叶斯网的研究，提出了信念传播算法，催生了概 率图模型这一大类技术，他还以贝叶斯网为工具开创了因果推理方面的研究. 由于对人工智能中概率与因果推理的重大贡献,他获得2011年图灵奖，此前他 已获A C M 与 A A A I联合颁发的2003年 艾 伦 •纽 厄 尔 奖 .A C M 评价珀尔在人 工智能领域的贡献已扩展到诸多学科领域， “使统计学、心理学、医学以及社 会科学中因果性的理解产生了革命性的变化”. 2011年珀尔还获得科学哲学领 域最高奖拉卡托斯奖. 珀 尔 之 子 丹 尼 尔 是 《华尔街日报》驻南亚记者， 事件后他在巴 基斯坦追踪报道激进武装组织时被绑架审讯并残忍地斩首，此事震惊世界.珀 尔此后筹办了丹尼尔・珀尔基金会，并参与了很多致力于促进世界民族和平共 处的活动. 艾 伦 ・纽 厄 尔 奖 是 奖 励那些拓宽了计算机科学, 或架设了计算机科学与其 他 学 科 桥 梁 的 卓 越 科 学 家，该奖以图灵奖得主、 人工智能先驱Allen Newell (1 9 2 7 -1 9 9 2 )命 名 . 机 器 学习界的另一位著名学者 Michael Jordan 在 2009 年 获该奖. 第 1 5 章 规 则 学 习 1 5 .1 基本概念",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 638
    }
  },
  {
    "page_content": "艾 伦 ・纽 厄 尔 奖 是 奖 励那些拓宽了计算机科学, 或架设了计算机科学与其 他 学 科 桥 梁 的 卓 越 科 学 家，该奖以图灵奖得主、 人工智能先驱Allen Newell (1 9 2 7 -1 9 9 2 )命 名 . 机 器 学习界的另一位著名学者 Michael Jordan 在 2009 年 获该奖. 第 1 5 章 规 则 学 习 1 5 .1 基本概念 所 有 预 测 模 型 在 广 义 上 都 可 称 为 一 个 或 一 组 “规 则 ” ，但 规 则 学 习 中 的 “规 则 ” 是 狭 义 的 ，事 实 上 约 定 俗 成 地 省 略 了 “逻 辑 ”二字. 机 器 学 习 中 的 “规 则 ”（rule）通 常 是 指 语 义 明 确 、能 描 述 数 据 分 布 所 隐 含 的 客 观 规 律 或 领 域 概 念 、可 写 成 “若 … …，则 … … ”形式的逻辑规则 [Fiirnkranz et al., 2012]. “规则学习\" （rule learning）是从训练数据中学习出 一组能用于对未见示例进行判别的规则. 形式化地看，一条规则形如. 在 数 理 逻 辑 中 “文 字 ” 专 指 原 子 公 式 （atom）及其 否定. ㊉— 八… 八 伉 ， （15.1） 其 中 逻 辑 蕴 含 符 号 右 边 部 分 称 为 “规 则 体 \" （b o d y ）, 表示该条规则的前 提，左 边 部 分 称 为 “规 则 头 ”（h e a d ）, 表示该条规则的结果.规则体是由逻辑 文字（literal）泉组成的合取式（conjunction）, 其 中 合 取 符 号 \"八 \"用 来 表 示 “并 且 ”.每 个 文 字 也 都 是 对 示 例属性进行检验的布尔表达式，例 如 “（色泽=乌 黑）”或 “「（根 蒂 =硬 挺 ）” . 乙是规则体中逻辑文字的个数，称为规则的长度. 规 则 头 的 “㊉”同样是逻辑文字，一般用来表示规则所判定的目标类别或概念, 例 如 “好瓜”.这样的逻辑规则也被称为 “if-then规则”. 与神经网络、支 持 向 量机这样的“黑箱模型”相比，规则学习具有更好的 口J 解释性，能使用户更直观地对判别过程有所了解.另一方面，数理逻辑具有 极强的表达能力，绝大多数人类知识都能通过数理逻辑进行简洁的刻画和表达. 例 如 “父亲的父亲是爷爷”这样的知识不易用函数式描述，而用一阶逻辑则可 方 便 地 写 为 “爷爷（X , y ）一 父 亲 （x , z ）A 父亲（Z , y ）” ，因 此 规则学习能更 自然地在学习过程中引入领域知识.此外，逻辑规则的抽象描述能力在处理一",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 639
    }
  },
  {
    "page_content": "极强的表达能力，绝大多数人类知识都能通过数理逻辑进行简洁的刻画和表达. 例 如 “父亲的父亲是爷爷”这样的知识不易用函数式描述，而用一阶逻辑则可 方 便 地 写 为 “爷爷（X , y ）一 父 亲 （x , z ）A 父亲（Z , y ）” ，因 此 规则学习能更 自然地在学习过程中引入领域知识.此外，逻辑规则的抽象描述能力在处理一 些高度复杂的 A I 任务时具有显著的优势，例如在问答系统中有时可能遇到非 常多、甚至无穷种可能的答案,此时若能基于逻辑规则进行抽象表述或者推理, 则将带来极大的便利. 假定我们从西瓜数据集学得规则集合用： 规则1 :好 瓜 一 （根蒂= 蜷缩）A （脐部= 凹陷）； 348 第 1 5 章 规 则 学 习 规则2 : 「好 瓜 ― (纹 理 = 模 糊 ). . 规 则 1 的 长 度 为 2 , 它通过判断两个逻辑文字的赋值(valuation)来对示例进行 西瓜数据集2.0见 p . 7 6 判别.符合该规则的样本(例如西瓜数据集 2 . 0 中 的 样 本 1)称 为 被 该 规 则 “覆 麦4 1 盖 \" ( c o v e r ) .需注意的是,被规则 1 覆盖的样本是好瓜，但没被规则 1 覆盖的未 必不是好瓜；只有被规则 2 这 样 以 好 瓜 ”为头的规则覆盖的才不是好瓜. 显然，规则集合中的每条规则都可看作一个子模型，规则集合是这些子模 集成学习参见第8 章. 型的一个集成.当同一个示例被判别结果不同的多条规则覆盖时，称发生了 “冲突”(conflict),解决冲突的办法称为“冲 突 消 解 \" (conflict resolution).常 用的冲突消解策略有投票法、排序法、元规则法等.投票法是将判别相同的规 则数最多的结果作为最终结果.排序法是在规则集合上定义一个顺序，在发生 冲突时使用排序最前的规则；相应的规则学习过程称为“带序规则”(ordered rule)学 习 或 “优先级规则”(priority r u l e )学习.元规则法是根据领域知识事先 设 定 一 些 “元规则”( m e t a r u l e ) , 即关于规则的规则，例 如 “发生冲突时使用 长度最小的规则”，然后根据元规则的指导来使用规则集. 此外，从训练集学得的规则集合也许不能覆盖所有可能的未见示例，例如 前 述 规 则 集 合 冗 无 法 对 “根 蒂 = 蜷 缩 \" 、 “脐部= 稍凹”且 “纹理= 清晰”的 示例进行判别；这种情况在属性数目很多时常出现.因此,规则学习算法通常会",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 640
    }
  },
  {
    "page_content": "长度最小的规则”，然后根据元规则的指导来使用规则集. 此外，从训练集学得的规则集合也许不能覆盖所有可能的未见示例，例如 前 述 规 则 集 合 冗 无 法 对 “根 蒂 = 蜷 缩 \" 、 “脐部= 稍凹”且 “纹理= 清晰”的 示例进行判别；这种情况在属性数目很多时常出现.因此,规则学习算法通常会 、亦f \"缺省规则：，可 设 置 一 条 “默 认 规 贝 (default r u l e ) ,由它来处理规则集合未覆盖的样本；例如 认为是一种特殊的元规则.为冗增加一条默认规则：“未被规 则 1, 2 覆盖的都不是好瓜” . 从形式语言表达能力而言，规则可分为两类： “命题规则”(propositional rule)和 “一 阶 规 则 ”(first-order r u l e ) . 前 者 是 由 “原子命题”(propositional a t o m ) 和 逻 辑 连 接 词 “与\"(人)、 “或 ”( V )、 “非 ”㈠ 和 “蕴含”(一)构成的 简单陈述句；例如规则集冗就是一个命题规则集，“根 蒂 =蜷 缩 ” “脐部=凹 陷”都是原子命题.后者的基本成分是能描述事物的属性或关系的“原子公 式 \" (ato m i c f o r m u l a ) , 例如表达父子关系的谓词(predicate) “父亲( X , V ) ” 就 是原子公式，再 如 表 示 加 一 操 作 “° (X) = X + 1 ” 的 函 数 也 是 原 子 公式.如果进一步用谓词“自然数( X ) ” 表 示 X 是自然数，“V X ” 表 示 “对于 任 意 x 成 立 “，y y ” 表 示 “存 在 y 使 之 成 立 \"，那 么 “所有自然数加 1 都 是自然数”就 可 写 作 “v x » (自然数(丫)一自然数( X ) 八( y = a ( x ) ) ) ” ，或 更 简 洁 的 “v x (自然数。( X ) ) — 自然数( X ) ) ” . 这样的规则就是一阶规则，其 中 x 和 y 称为逻辑变量，\" v ” \"才’分 别 表 示 “任意”和 “存在”，用于限定 变量的取值范围，称 为 “量 词 ”(quantifier).显然，一阶规则能表达复杂的关 1 5 . 2 序贯覆盖 349 系，因此也被称为“关系型规则”(relational rule).以西瓜数据为例，若我们简 单地把属性当作谓词来定义示例与属性值之间的关系，则命题规则集冗可改写 为 一 阶 规 则 集 比 ： 规 则 1 :好瓜( X ) 一 根 蒂 ( X , 蜷缩)八脐部( X , 凹 陷 )； 规 则 2 : 「好瓜( X ) 一 纹 理 ( X , 模糊).",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 641
    }
  },
  {
    "page_content": "349 系，因此也被称为“关系型规则”(relational rule).以西瓜数据为例，若我们简 单地把属性当作谓词来定义示例与属性值之间的关系，则命题规则集冗可改写 为 一 阶 规 则 集 比 ： 规 则 1 :好瓜( X ) 一 根 蒂 ( X , 蜷缩)八脐部( X , 凹 陷 )； 规 则 2 : 「好瓜( X ) 一 纹 理 ( X , 模糊). 显然，从形式语言系统的角度来看,命题规则是一阶规则的特例，因此一阶规则 的学习比命题规则要复杂得多. 1 5 . 2 序贯覆盖 规 则 学 习 的 目 标 是 产 生 一 个 能 覆 盖 尽 可 能 多 的 样 例 的 规 则 集 .最 直 接 的 做 法 是 “序 贯 覆 盖 \" (sequential covering),即逐条归纳：在训练集上每学 到 一 条 规 则 ，就 将 该 规 则 覆 盖 的 训 练 样 例 去 除 ，然 后 以 剩 下 的 训 练 样 例 组 成 训 练 集 重 复 上 述 过 程 .由 于 每 次 只 处 理 一 部 分 数 据 ，因 此 也 被 称 为 “分 治” (separate-and-conquer) . 我们以命题规则学习为例来考察序贯覆盖法.命题规则的规则体是对样 例属性值进行评估的布尔函数，如 “色泽= 青 绿 ” “含 糖 率 W 0 . 2 \" 等,.规则 头是样例类别.序贯覆盖法的关键是如何从训练集学出单条规则.显然，对规 则 学习目标㊉，产生一条规则就是寻找最优的一组逻辑文字来构成规则体, 这是一个搜索问题.形式化地说，给定正例集合与反例集合，学习任务是基于 候 选 文 字 集 合 乃 = { 1 } 来 生 成 最 优 规 则 r . 在命题规则学习中，候选文字是 形 如 “私属性〃，属 性 值 的 布 尔 表 达 式 ，其中属性〃表示样例第 z 个属性, 属性值切表示属性£ 的 第3 个候选值，R E y ) 则是判断力、y 是否满足关系R 的二元布尔函数. 最简单的做法是从空规则“㊉ 一 ”开始，将正例类别作为规则头，再逐个 遍历训练集中的每个属性及取值，尝试将其作为逻辑文字增加到规则体中，若 能使当前规则体仅覆盖正例，则由此产生一条规则，然后去除已被覆盖的正例 并基于剩余样本尝试生成下一条规则. p.80表 4.2上半部分. 以西瓜数据集2 . 0 训练集为例，首 先 根 据 第 1 个 样 例 生 成 文 字 “好 瓜 ”和 “色泽= 青绿”加入规贝％得到 好瓜―(色泽=青绿). 350 第 1 5 章 规 则 学 习 为 简 便 起 见 ，本 章 后 续 部 分 不 考 虑 否 定 形 式 的 逻 辑 文 字 ，即 仅 以 f 为 候选 文字，不考虑",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 642
    }
  },
  {
    "page_content": "p.80表 4.2上半部分. 以西瓜数据集2 . 0 训练集为例，首 先 根 据 第 1 个 样 例 生 成 文 字 “好 瓜 ”和 “色泽= 青绿”加入规贝％得到 好瓜―(色泽=青绿). 350 第 1 5 章 规 则 学 习 为 简 便 起 见 ，本 章 后 续 部 分 不 考 虑 否 定 形 式 的 逻 辑 文 字 ，即 仅 以 f 为 候选 文字，不考虑 这条规则覆盖样例 1, 6, 1 0 和 1 7 , 其中有两个正例和两个反例，不 符 合 “当前 规则仅覆盖正例”的条件.于是，我们尝试将该命题替换为基于属性“色 泽 ” 形成的其他原子命题，例 如 “色泽= 乌黑” 然而在这个数据集上，这样的操作 不能产生符合条件的规则.于是我们回到“色 泽 =青 绿 ”，尝试增加一个基于其 他属性的原子命题,例如“根蒂= 蜷 缩 ”： 好 瓜 ― （色泽= 青绿）A （根蒂=蜷缩）. 该规则仍覆盖了反例1 7 . 于是我们将第二个命题替换为基于该属性形成的其他 原 子 命 题 ,例 如 “根蒂= 稍蜷”： 好 瓜 ― （色泽= 青绿）A （根蒂=稍蜷）. 这条规则不覆盖任何反例，虽然它仅覆盖一个正例，但 已 满 足 “当前规则仅覆 盖正例”的条件.因此我们保留这条规则并去除它覆盖的样例6 , 然后将剩下的 9 个样例用作训练集.如此继续,我们将得到： 规 则 1 :好 瓜 一 （色泽= 青绿）A （根蒂二稍蜷）； 规 则 2 : 好 瓜 一 （色泽= 青绿）A （敲声=浊响）； 规 则 3 : 好 瓜 — （色泽= 乌黑）A （根蒂=蜷缩）； 规 则 4 : 好 瓜 什 （色泽= 乌黑）A （纹理=稍糊）. 例 如 不 含 任 何 属 性 的 空 规 则 ，它覆盖所有样例，就 是一条比较一般的规则. 例 如 直 接 以 某 样 例 的 属 性 取 值 形 成 规 则 ，该规则 仅 覆 盖 此 样 例 ，就 是 一 条 比较特殊的规则. 这个规则集覆盖了所有正例，未覆盖任何反例，这就是序贯覆盖法学得的结果. 上 面 这 种 基 于 穷 尽 搜 索 的 做 法 在 属 性 和 候 选 值 较 多 时 会 由 于 组 合 爆 炸 而 不 可 行 .现 实 任 务 中 一 般 有 两 种 策 略 来 产 生 规 则 ：第 一 种 是 “自顶 向 下 \" （t o p - d o w n ）, 即 从 比 较 一 般 的 规 则 开 始 ，逐 渐 添 加 新 文 字 以 缩 小 规 则覆盖范围，直 到 满 足 预 定 条 件 为 止 ；亦 称 为 “生 成 -测 试 \"（generate-then-",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 643
    }
  },
  {
    "page_content": "炸 而 不 可 行 .现 实 任 务 中 一 般 有 两 种 策 略 来 产 生 规 则 ：第 一 种 是 “自顶 向 下 \" （t o p - d o w n ）, 即 从 比 较 一 般 的 规 则 开 始 ，逐 渐 添 加 新 文 字 以 缩 小 规 则覆盖范围，直 到 满 足 预 定 条 件 为 止 ；亦 称 为 “生 成 -测 试 \"（generate-then- test）法，是 规 则 逐 渐 “特 化 ”（specialization）的 过 程 .第 二 种 策 略 是 “自底向 （b o t t o m - u p ）, 即从比较特殊的规则开始，逐渐删除文字以扩大规则覆盖范 围，直到满足条件为止；亦 称 为 “数 据 驱 动 \" （data-driven）法，是 规 则 逐 渐 “泛 化 \" （generalization）的过程.第一种策略是覆盖范围从大往小搜索规则，第二 种策略则相反；前者通常更容易产生泛化性能较好的规则，而后者则更适合于 训练样本较少的情形，此外，前者对噪声的鲁棒性比后者要强得多.因此，在命 题规则学习中通常使用第一种策略，而第二种策略在一阶规则学习这类假设空 1 5 . 2 序贯覆盖 351 间非常复杂的任务上使用较多. 下面以西瓜数据集2 .0 训练集为例来展示自顶向下的规则生成方法.首先 从 空 规 则 “好 瓜 一 ”开始，逐 一 将 “属性= 取值”作为原子命题加入空规则进 行考察.假定基于训练集准确率来评估规则的优劣，n /馆表示加入某命题后新 规则在训练集上的准确率，其 中 m 为覆盖的样例总数，n 为覆盖的正例数.如 图 15.1所示,经过第一轮评估，“色 泽 = 乌 黑 \" 和 “脐部= 凹陷”都达到了最高 脐触 部感 == 硬凹滑陷 ((33//64)) 准 确 率 3/4. 纹 理 = 清 晰 (4/6) 第一轮候选集 第二轮候选集 西 瓜 数 据 集 2 .0 训练集 见 p.80表 4 .2 上半部分. 图 1 5 . 1 在西瓜数据集2 .0 训 练 集 上 “自顶向下”生成单条规则 - 根 蒂 = 蜷 缩 (2/2) J … A 八 敲 声 =沉 闷 (1/1) 纹 理 = 稍 糊 。/1) 脐 部 = 凹 陷 (2/2) 触 感 = 硬 滑 (2/2) 两轮之后产生单条规则： 好瓜―(色泽= 乌黑)人(根蒂= 蜷缩) 色泽= 青 绿 (2/4) 敲 声 = 浊 响 (4/6) 色泽= 乌 黑 (3/4) 根 蒂 = 蜷 缩 (3/5) i 将属性次序最靠前的逻辑文字“色泽= 乌黑”加入空规则，得到 好 瓜 — (色泽二乌黑).",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 644
    }
  },
  {
    "page_content": "纹 理 = 稍 糊 。/1) 脐 部 = 凹 陷 (2/2) 触 感 = 硬 滑 (2/2) 两轮之后产生单条规则： 好瓜―(色泽= 乌黑)人(根蒂= 蜷缩) 色泽= 青 绿 (2/4) 敲 声 = 浊 响 (4/6) 色泽= 乌 黑 (3/4) 根 蒂 = 蜷 缩 (3/5) i 将属性次序最靠前的逻辑文字“色泽= 乌黑”加入空规则，得到 好 瓜 — (色泽二乌黑). 然后，对上面这条规则覆盖的样例，通过第二轮评估可发现，将 图 1 5 .1 中的五 个逻辑文字加入规则后都能达到100%准确率，我们将覆盖样例最多、且属性 次序最靠前的逻辑文字“根蒂= 蜷缩”加入规则，于是得到结果 好 瓜 一 (色 泽 = 乌黑)八(根蒂=蜷缩). 规则生成过程中涉及一个评估规则优劣的标准,在上面的例子中使用的标 准是：先考虑规则准确率,准确率相同时考虑覆盖样例数，再相同时考虑属性次 序.现实应用中可根据具体任务情况设计适当的标准. 352 第 1 5 章 规 则 学 习 此外，在上面的例子中每次仅考虑一个“最优”文字,这通常过于贪心，易 陷入局部最优.为缓解这个问题,可采用一些相对温和的做法,例如采用“集束 搜 索 ”（b e a m search）, 即每轮保留最优的b 个逻辑文字，在下一轮均用于构建 候选集，再把候选集中最优的b 个 留 待 再 下 一 轮 使 用 .图 1 5 . 1 中 若 采 用 b = 2 的集束搜索，则第一轮将保留准确率为3 / 4 的两个逻辑文字，在第二轮评估后 就能获得下面这条规则，其准确率仍为 1 0 0 % , 但是覆盖了 3 个正例： 好 瓜 — （脐部= 凹陷）A （根蒂=蜷缩）. 由于序贯覆盖法简单有效，几乎所有规则学习算法都以它为基本框架.它 能方便地推广到多分类问题上，只需将每类分别处理即可：当学习关于第 c 类 的规则时,将所有属于类别c 的样本作为正例，其他类别的样本作为反例. 1 5 .3 剪枝优化 决策树剪枝参见4.3节. 险，最常见的做法是剪枝（p r u ning）. 与决策树相似，剪枝可发生在规则生长过 规则生成本质上是一个贪心搜索过程，需有一定的机制来缓解过拟合的风 程中，即 “预剪枝”，也可发生在规则产生后，即 “后剪枝”：通常是基于某种 性能度量指标来评估增/删逻辑文字前后的规则性能，或增/删规则前后的规则 集性能，从而判断是否要进行剪枝. 统 计 显 著 性 检 验 参 见 剪枝还可借助统计显著性检验来进行.例如C N 2 算 法 ［Clark a n d Niblett, 2.4 节. 1989］在预剪枝时，假设用.规则集进行预测必须显著优于直接基于训练样例集",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 645
    }
  },
  {
    "page_content": "性能度量指标来评估增/删逻辑文字前后的规则性能，或增/删规则前后的规则 集性能，从而判断是否要进行剪枝. 统 计 显 著 性 检 验 参 见 剪枝还可借助统计显著性检验来进行.例如C N 2 算 法 ［Clark a n d Niblett, 2.4 节. 1989］在预剪枝时，假设用.规则集进行预测必须显著优于直接基于训练样例集 后 验 概 率 分 布 进 行 预 测 .为 便 于 计 算 ，C N 2 使用了似然率统计量（Likelihood Ratio Statistics,简 称 L R S ）. 令 m + , m _ 分别表示训练样例集中的正、反例数 目，病+, 分别表示规则（集）覆盖的正、反例数目，则有 ( 病一 [m + +m- Lrvb = 2 T TTl-i- logo -------- \\-- 1- TYl— logo -------- ( m + ] ( J y m + + m _ / [人 \\ \\ ( 病+ ) J 人 1 。5 ⑵ 这实际上是一种信息量指标，衡量了规则（集）覆盖样例的分布与训练集经验分 布的差别：L R S 越大，说明采用规则（集）进行预测与直接使用训练集正、反例 比率进行猜测的差别越大；L R S 越小，说明规贝！1（集）的效果越可能仅是偶然现 象.在数据量比较大的现实任务中，通常设置为在 L R S 很大（例 如 0.99）时 C N 2 算法才停止规则（集）生长. 1 5 . 3 剪枝优化 353 后剪枝最常用的策略是“减 错 剪 枝 \"(Reduced Error Pruning,简 称 R E P ) 规 则 学 习 中 常 称 为 “生 长 集 ” (growing s e t )和 \"剪 枝 集 \" (pruning set). [Brunk and Pazzani, 1991],其基本做法是：将样例集划分为训练集和验证集, 从训练集上学得规则集冗后进行多轮剪枝，在每一轮穷举所有可能的剪枝操 作，包括删除规则中某个文字、删除规则结尾文字、删除规则尾部多个文字、 删除整条规则等，然后用验证集对剪枝产生的所有候选规则集进行评估，保留 最好的那个规则集进行下一轮剪枝，如此继续，直到无法通过剪枝提高验证集 上的性能为止. R E P 剪 枝 通 常 很 有 效 [Brunk and Pazzani, 1991],但 其 复 杂 度 是 0 m 4 ), m 为训练样例数目. I R E P (Incremental R E P ) [Fiirnkranz and Widmer, 1994] 将 复 杂 度 降 到 O ( M log2rn),其做法是：在生成每条规则前，先将当前样例集",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 646
    }
  },
  {
    "page_content": "上的性能为止. R E P 剪 枝 通 常 很 有 效 [Brunk and Pazzani, 1991],但 其 复 杂 度 是 0 m 4 ), m 为训练样例数目. I R E P (Incremental R E P ) [Fiirnkranz and Widmer, 1994] 将 复 杂 度 降 到 O ( M log2rn),其做法是：在生成每条规则前，先将当前样例集 划分为训练集和验证集，在训练集上生成一条规则r , 立即在验证集上对其进 行R E P 剪枝，得 到 规 则 M 将 rz 覆盖的样例去除，在更新后的样例集上重复上 述过程.显然，R E P 是针对规则集进行剪枝，而 I R E P 仅对单条规则进行剪枝, 因此后者比前者更高效. RIPPER 全 称 Repeat­ ed Incremental Pruning to Produce Error Reduction, W E K A 中 的 实 现 称 为 J RIP. 图 1 5 .2 中重复次数取值 K 时 亦 称 RIPPER fc,例如 RIPPER5 意味着 k = 5. 若将剪枝机制与其他一些后处理手段结合起来对规则集进行优化，则往往 能获得更好的效果.以著名的规则学习算法R I P P E R [Cohen, 1995]为例，其泛 化性能超过很多决策树算法，而且学习速度也比大多数决策树算法更快，奥妙 就在于将剪枝与后处理优化相结合. R I P P E R 算 法 描 述 如 图 15.2所 示 .它 先 使 用 I R E P * 剪枝机制生成规则 2M 取代了 I R E P 使用的准确率作为规则性能度量指标，在剪枝时删除规则尾部的多个文 集 11. I R E P * [Cohen, 1995]是 I R E P 的改进，主要是以 字，并在最终得到规则集之后再进行一次I R E P 剪 枝 .R I P P E R 中的后处理机 基 于 IR E P *生成规则集. 后处理. 去除已被覆盖的样例. 输入：训练样例集。 重复次数k. 过程： 1： n = I R E P *(P )； 2： z = 0; 3： repeat 4: 1V = Post Opt (7?.); 5： Di = Not Covered^ 7, Z)); 6： Q = I R E P * ( A ) ； 7： R = R U R%; 8： i = z + 1; 9: until i = k 输出：规则集火 图 15.2 R IP P E R 算法 354 第 1 5 章 规 则 学 习",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 647
    }
  },
  {
    "page_content": "6： Q = I R E P * ( A ) ； 7： R = R U R%; 8： i = z + 1; 9: until i = k 输出：规则集火 图 15.2 R IP P E R 算法 354 第 1 5 章 规 则 学 习 制是为了在剪枝的基础上进一步提升性能.对R 中的每条规则将, R IP P E R 为 它产生两个变体： • 此 ：基于总覆盖的样例，用 IR E P * 重新生成一条规则% 该规则称为替 换规则(replacement rule); • < ：对 将增加文字进行特化，然 后 再 用IR E P *剪枝生成一条规则 该 规则称为修订规则(revised rule). 接下来，把 匕 和 < 分别与冗中除此之外的规则放在一起，组成规则集R!和 冗〃，将它们与冗一起进行比较,选择最优的规则集保留下柒.这就是图15.2中 算 法 第4 行所做的操作. 为 什 么 R IP P E R 的优化策略会有效呢？原因很简单：最初生成冗的时候, 规则是按序生成的，每条规则都没有对其后产生的规则加以考虑，这样的贪心 算法本质常导致算法陷入局部最优；R IP P E R 的后处理优化过程将改中的所 有规则放在一起重新加以优化,恰是通过全局的考虑来缓解贪心算法的局部性, 从而往往能得到更好的效果[Fiirnkranz et al., 2012]. 15.4 一阶规则学习 受 限 于 命 题 逻 辑 表 达 能 力 ,命 题 规 则 学 习 难 以 处 理 对 象 之 间 的 “关 系 \" (relation),而关系信息在很多任务中非常重要.例如，我们在现实世界挑 选西瓜时，通常很难把水果摊上所有西瓜的特征用属性值描述出来，因为我们 很难判断：色泽看起来多深才叫“色泽青绿”？敲起来声音多低才叫“敲声沉 闷”？ 比较现实的做法是将西瓜进行相互比较，例如，“瓜 1 的颜色比瓜2 更 深，并 且 瓜 1 的根蒂比瓜2 更蜷”，因 此 “瓜 1 比 瓜 2 更好”. 然而，这已超越 了命题逻辑的表达能力，需用一阶逻辑表示，并且要使用一阶规则学习. 对西瓜数据，我们不妨定义： • 色泽深度：乌 黑 〉青 绿 〉浅白； • 根蒂蜷度：蜷 缩 〉稍蜷 > 硬挺； • 敲声沉度:沉闷 > 浊响 > 清脆； • 纹理清晰度：清 晰 〉稍糊 > 模糊； • 脐部凹陷度：凹 陷 〉稍 凹 〉平坦； • 触感硬度:硬滑 > 软粘. 15.4 一阶规则学习 括号内数字对应于p.80 表 4 . 2 中 的 样 例 编 号 . 表 1 5 . 1 西瓜数据集5.0 355 色泽更 深 ⑵ 1) 色泽 更 深 ⑵ 16)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 648
    }
  },
  {
    "page_content": "• 敲声沉度:沉闷 > 浊响 > 清脆； • 纹理清晰度：清 晰 〉稍糊 > 模糊； • 脐部凹陷度：凹 陷 〉稍 凹 〉平坦； • 触感硬度:硬滑 > 软粘. 15.4 一阶规则学习 括号内数字对应于p.80 表 4 . 2 中 的 样 例 编 号 . 表 1 5 . 1 西瓜数据集5.0 355 色泽更 深 ⑵ 1) 色泽 更 深 ⑵ 16) 色泽更深⑵ 6) 色 泽更深⑵ 17) 色泽更 深 ⑵ 10) 色泽更深(3, 1) 色 泽更深⑵ 14) 色泽更深(3, 6) 色泽更深(15, 16) 色泽更深(15, 17) 色泽更深(17, 14) 色泽更深(17, 16) 根蒂更蜷(1, 6) 根蒂更蜷(1, 14) 根蒂更蜷(1, 10) 根蒂更蜷(1, 7) 根蒂更蜷(17, 7) 敲声更沉(2, 1) 根蒂更蜷(17, 10) 根蒂更蜷(17, 14) 根蒂更蜷(17, 15) 敲声更沉(2, 3) 敲声更沉(2, 6) 敲声更沉⑵ 7) 敲声更沉(17, 7) 纹理更清(1, 7) 敲声更沉(17, 10) 敲声更沉(17, 15) 敲声更沉(17, 16) 纹理更清(1, 16) 纹理更清(1, 14) 纹理更清(1, 17) 纹理更清(15, 14) 纹理更清(15, 16) 纹理更清(15, 17) 纹理更清(17, 16) 脐部更凹(1, 6) 脐部更凹(1, 15) 脐部更凹(1, 10) 脐部更凹(1, 7) 脐部更凹(15, 10) 脐部更凹(15, 16) 脐部更凹(17, 10) 脐部更凹(17, 16) 触感更硬(1, 15) 触感更硬(1, 6) 触感更硬& 10) 触感更硬(1, 7) 分隔线上半部分为背景 知识，下半部分为样例. 触感更硬(17, 6) 触感更硬(17, 7) 触感更硬(17, 10) 触感更硬(17, 15) 更好(1, 10) 更好(1, 14) 更好(1, 15) 更好(1, 16) 更好(7, 14) 「更好(10, 1) 更好(7, 15) 「更好(10, 2) 更好(7, 16) 「更好(10, 3) 更好(7, 17) 「更好(10, 6) 「更好(17, 2) 「更好(17, 3) 「更好(17, 6) 「更好(17, 7) 于 是 ，西 瓜 数 据 集 2.0训 练 集 就 转 化 为 表 15.1的 西 瓜 数 据 集 5.0.这样的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 649
    }
  },
  {
    "page_content": "更好(7, 15) 「更好(10, 2) 更好(7, 16) 「更好(10, 3) 更好(7, 17) 「更好(10, 6) 「更好(17, 2) 「更好(17, 3) 「更好(17, 6) 「更好(17, 7) 于 是 ，西 瓜 数 据 集 2.0训 练 集 就 转 化 为 表 15.1的 西 瓜 数 据 集 5.0.这样的 数 据 直 接 描 述 了 样 例 间 的 关 系 ，称 为 “关 系 数 据 \" (relational data),其中由 原 样 本 属 性 转 化 而 来 的 “色 泽 更 深 ” “根 蒂 更 蜷 ”等 原 子 公 式 称 为 “背景知 识 ”(background knowledge),而 由 样 本 类 别 转 化 而 来 的 关 于 “更 好 ” “「更 好 ” 的 原 子 公 式 称 为 关 系 数 据 样 例 (examples).从 西 瓜 数 据 集 5.0可学出这样 这样的规则亦称为一阶 逻辑子句(clause). 的一阶规则： (VX, V V ) (更好(X, y ) 一 根 蒂 更 蜷 (X, y) A 脐 部 更 凹(X , y ) ) . 显 然 ，一阶规则 仍 是 式 (15.1)的形式，但 其 规 则 头 、规则体都是一阶逻辑表 达 式 ，“更 好 (•,•)”、 “根蒂 更 蜷 (•,•)”、 “脐 部 更 凹 (•,•)”是关系描述所对应 的谓词，个 体 对 象 “瓜 I”、 “瓜 2 ”被 逻 辑 变 量 “x ”、 \" y ”替 换 .全 称 量 词 “V ”表 示 该 规 则 对 所 有 个 体 对 象 都 成 立 ;通 常 ，在一阶规则中所有出现的变 量 都 被 全 称 量 词 限 定 ，因 此 下 面 我 们 在 不 影 响 理 解 的 情 况 下 将 省 略 量 词 部 分 . 356 第 1 5 章 规 则 学 习 统 计 学 习 一 般 是 基 于 “属性-值”表 示 ，这与命 题 逻 辑 表 示 等 价 ；此类学 习 可 统 称 为 “基 于 命 题 表 示的学习”. 一阶规则有强大的表达能力，例如它能简洁地表达递归概念,如 更好（X, y ）一 更 好 （X, Z ） A 更好（Z, y ）. 一阶规则学习能容易地引入领域知识，这是它相对于命题规则学习的另一 大优势.在命题规则学习乃至一般的统计学习中，若欲引入领域知识，通常有两 种做法：在现有属性的基础上基于领域知识构造出新属性，或基于领域知识设 计某种函数机制（例如正则化）来对假设空间加以约束.然而，现实任务中并非 所有的领域知识都能容易地通过属性重构和函数约束来表达.例如，假定获得",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 650
    }
  },
  {
    "page_content": "一阶规则学习能容易地引入领域知识，这是它相对于命题规则学习的另一 大优势.在命题规则学习乃至一般的统计学习中，若欲引入领域知识，通常有两 种做法：在现有属性的基础上基于领域知识构造出新属性，或基于领域知识设 计某种函数机制（例如正则化）来对假设空间加以约束.然而，现实任务中并非 所有的领域知识都能容易地通过属性重构和函数约束来表达.例如，假定获得 了包含某未知元素的化合物x , 欲通过试验来发现它与已知化合物y 的反应 方程式.我们可多次重复试验，测出每次结果中化合物的组分含量.虽然我们 对反应中的未知元素性质一无所知，但知道一些普遍成立的化学原理，例如金 属原子一般产生离子键、氢原子之间一般都是共价键等，并且也了解已知元素 间可能发生的反应.有了这些领域知识，重复几次试验后就不难学出x 和 y 的 反应方程式，还可能推测出x 的性质、甚至发现新的分子和元素.类似这样的 领域知识充斥在日常生活与各类任务中，但在基于命题表示的学习中加以利用 却非常困难. FOIL （First-Order Inductive Learner） [Quinlan, 1990]是著名的一阶规则 学习算法，它遵循序贯覆盖框架且采用自顶向下的规则归纳策略，与 15.2节中 的命题规则学习过程很相似.但由于逻辑变量的存在,FO IL 在规则生成时需考 虑不同的变量组合.例如在西瓜数据集5 .0 上，对 “更好（X ,Y ）” 这个概念，最 初的空规则是 更好（X , y ）一 . 接下来要考虑数据中所有其他谓词以及各种变量搭配作为候选文字.新加 入的文字应包含至少一个已出现的变量，否则没有任何实质意义.在这个例子 中考虑下列候选文字： 色泽更深（X , y ）, 色泽更深（K X ）, 色泽更深（x , z ）, 色泽更深（z , x ）, 色泽更深（y , z ）, 色泽更深（z , y ）, 色泽更深（x , x ）, 色泽更深（y , y ）, 根蒂更蜷（x , y ）, 敲声更沉（x , y ）, … … … … … … 1 5 . 5 归纳逻辑程序设计 357 F O I L 使 用 “F O I L 增 益 \" (FOIL gain)来选择文字: F - G a m = 抗+ x (log2 一 ， (场3) 决策树的信息增益参见 4.2.1 节. 这实质上与类别不平衡 性有关，参 见 3.6 节. 其中，仇+, m _ 分别为增加候选文字后新规则所覆盖的正、反例数;m + , m _ 为 原规则覆盖的正、反例数.F O I L 增益与决策树使用的信息增益不同，它仅考虑 正例的信息量，并且用新规则覆盖的正例数作为权重.这是由于关系数据中正",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 651
    }
  },
  {
    "page_content": "一 ， (场3) 决策树的信息增益参见 4.2.1 节. 这实质上与类别不平衡 性有关，参 见 3.6 节. 其中，仇+, m _ 分别为增加候选文字后新规则所覆盖的正、反例数;m + , m _ 为 原规则覆盖的正、反例数.F O I L 增益与决策树使用的信息增益不同，它仅考虑 正例的信息量，并且用新规则覆盖的正例数作为权重.这是由于关系数据中正 例数往往远少于反例数，因此通常对正例应赋予更多的关注. 在 西 瓜 数 据 集 5 . 0 的 例 子 中 ， 只 需 给 初 始 的 空 规 则 体 加 入 “色泽更深(x , y ) ”或 “脐部更凹(x, y ) ”，新 规 则 就 能 覆 盖 1 6 个 正 例 和 2 个反例，所对应的F O I L 增益为候选最大值16 x (log2 || -log 2 磊 )= 13.28.假 定前者被选中，则得到 更好(X, K ) — 色泽更深(X, Y). 该 规则仍覆盖2 个反例： “更好(15, 1)”与 “更好(15, 6)” . 于是，F O I L 像命 题规则学习那样继续增加规则体长度，最终生成合适的单条规则加入规则集. 此后，F O I L 使用后剪枝对规则集进行优化. 若允许将目标谓词作为候选文字加入规则体，则 F O I L 能学出递归规则; 若允许将否定形式的文字「f 作为候选，则往往能得到更简洁的规则集. F O I L 可大致看作命题规则学习与归纳逻辑程序设计之间的过渡，其自顶 向下的规则生成过程不能支持函数和逻辑表达式嵌套，因此规则表达能力仍有 不足;但它是把命题规则学习过程通过变量替换等操作直接转化为一阶规则学 习，因此比一般归纳逻辑程序设计技术更高效. 1 5 .5 归纳逻辑程序设计 归纳逻辑程序设计(Inductive Logic Programming,简 称 ILP ) 在一阶规则 学习中引入了函数和逻辑表达式嵌套.一方面，这使得机器学习系统具备了更 为强大的表达能力；另一方面，I L P 可看作用机器学习技术来解决基于背景知 识的逻辑程序 (logic program)归纳，其 学 得 的 “规则”可 被 P R O L O G 等逻辑 程序设计语言直接使用. 然 而 ，函 数 和 逻 辑 表 达 式 嵌 套 的 引 入 也 带 来 了 计 算 上 的 巨 大 挑 战 .例 如，给 定 一 元 谓 词 尸 和 一 元 函 数 为 它 们 能 组 成 的 文 字 有 P(X), P(/(X)), 358 第 1 5 章 规 则 学 习 P(/(/(X)))等无穷多个，这就使得规则学习过程中可能的候选原子公式有无 ・ 穷多个.若仍采用命题逻辑规则或F O I L 学习那样自顶向下的规则生成过程,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 652
    }
  },
  {
    "page_content": "如，给 定 一 元 谓 词 尸 和 一 元 函 数 为 它 们 能 组 成 的 文 字 有 P(X), P(/(X)), 358 第 1 5 章 规 则 学 习 P(/(/(X)))等无穷多个，这就使得规则学习过程中可能的候选原子公式有无 ・ 穷多个.若仍采用命题逻辑规则或F O I L 学习那样自顶向下的规则生成过程, 则在增加规则长度时将因无法列举所有候选文字而失败.实际困难还不止这 些，例 如 计 算 F O I L 增益需对规则覆盖的全部正反例计数，而在引入函数和逻 辑表达式嵌套之后这也变得不可行. 15.5.1最小一般泛化 归纳逻辑程序设计采用自底向上的规则生成策略,直接将一个或多个正例 所对应的具体事实(grounded fact)作为初始规则，再对规则逐步进行泛化以增 加其对样例的覆盖率.泛化操作可以是将规则中的常量替换为逻辑变量，也可 以是删除规则体中的某个文字. 以西瓜数据集5.0为例，为简便起见，暂 且 假 定 “更好( x , y ) ”仅决定于 ( X , V ) 取值相同的关系，正 例 “更好(1,10)”和 “更好(1,15)”所对应的初始 这里的数字K 的编号.规则分别为 更好(1,10)一根 蒂更蜷(1,10)八声音更沉(1,10) A 脐部更凹(1,10) 八触感更硬(1,10); 更好(1,15)一根蒂更蜷(1,15) A 脐部更凹(1,15)八触感更硬(1,15). 显然，这两条规则只对应了特殊的关系数据样例，难以具有泛化能力.因 此，我 们 希 望 把 这 样 的 “特 殊 ”规 则 转 变 为 更 “一 般 ”的规则.为达到这个 目的，最 基 础 的 技 术 是 “最 小 一 般 泛 化 \"(Least General Generalization,简称 L G G ) [Plotkin, 1970]. 给 定 一 阶 公 式 门 和 r2 , L G G 先找出涉及相同谓词的文字，然后对文字 中每个位置的常量逐一进行考察，若常量在两个文字中相同则保持不变，记 为 LGG(t,t) = t;否则将它们替换为同一个新变量，并将该替换应用于公式 的所有其他位置：假 定 这 两 个 不 同 的 常 量 分 别 为 s \" , 新 变 量 为 V , 则记为 LGG(s,£)=匕 并 在 以 后 所 有 出 现 L G G ( s \" ) 的位置用V 来代替.例如对上面 ' 例子中的两条规则,先比较“更好(1,10)”和 “更好(1,15)”，由于文字中常量 “10”* “15”，因此将它们都替换为F , 并 在 门 和 r2 中将其余位置上成对出 现 的 “10”和 “15”都 替 换 为 工 得 到",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 653
    }
  },
  {
    "page_content": "LGG(s,£)=匕 并 在 以 后 所 有 出 现 L G G ( s \" ) 的位置用V 来代替.例如对上面 ' 例子中的两条规则,先比较“更好(1,10)”和 “更好(1,15)”，由于文字中常量 “10”* “15”，因此将它们都替换为F , 并 在 门 和 r2 中将其余位置上成对出 现 的 “10”和 “15”都 替 换 为 工 得 到 更好( I , y ) J 根蒂更蜷(I,y)八声音更沉(1,10)八脐部更凹(I,y) 八触感更硬(i,y)； 1 5 . 5 归纳逻辑程序设计 359 更好(I,y)一根蒂更蜷(1,Y)八脐部更凹(I,y)八触感更硬(i,y). 然后，L G G 忽 略 r i 和 r2 中不含共同谓词的文字，因 为 若 L G G 包含某条 公式所没有的谓词，则 L G G 无法特化为那条公式.容易看出，在这个例子中需 忽 略 “声音更沉(1,10)”这个文字，于是得到的L G G 为 更好(1, Y ) 一根蒂更蜷(1, y ) A 脐部更凹(1, y) A 触感更硬(1, Y). (15.4) 式(15.4)仅 能 判断瓜1 是否比其他瓜更好.为了提升其泛化能力，假定另有 一条关于瓜2 的初始规则 更好(2,10)一颜色更深(2 JO) A 根蒂更蜷(2 JO) A 敲声更沉(2,10) A 脐部更凹(2 JO) A 触感更硬(2 JO) , (15.5) 于 是 可 求 取 式 (15.4)与(15.5)的 L G G . 注 意 到 文 字 “更好(2,10)” 和 “更 好 的 对 应 位 置 同 时 出 现 了 常 量 “10”与 变 量 “V ”，于是可令 L G G ( i o , y ) = 并 将 所 有 “10”与 “y ”成 对 出 现 的 位 置 均 替 换 为 妁 .最 后，令 L G G ⑵ 1) = X 并删去谓词不同的文字，就得到如下这条不包含常量的 一般规则： 更好(X, K ) 什根蒂更蜷(X, K ) A 脐部更凹(X, 12)A 触感更硬(X, K). 上面的例子中仅考虑了肯定文字，未 使 用 符 号 . 实 际 上 L G G 还能进 行更复杂的泛化操作.此外，上 面 还 假 定 “更好(X , Y ) ”的初始规则仅包含变 量 同 为 ( X , y ) 的关系，而背景知识中往往包含其他一些有用的关系，因此许多 I L P 系统采用了不同的初始规则选择方法.最常用的是R L G G (Relative Least General Generalization) [Plotkin, 1971],它在计算 L G G 时考虑所有的背景知",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 654
    }
  },
  {
    "page_content": "量 同 为 ( X , y ) 的关系，而背景知识中往往包含其他一些有用的关系，因此许多 I L P 系统采用了不同的初始规则选择方法.最常用的是R L G G (Relative Least General Generalization) [Plotkin, 1971],它在计算 L G G 时考虑所有的背景知 识 ,将 样 例 e 的初始规则定义为e ― K , 其 中 K 是背景知识中所有原子的合取. 容易证明，L G G 是能特化为n 和 r2 的所有一阶公式中最特殊的一个：不 存 在 既 能 特 化 为 门 和 r2 , 也能泛化为它们的L G G 的 一 阶 公 式 X 在归纳逻辑程序设计中，获 得 L G G 之后，可将其看作单条规则加入规则 集,最后再用前几节介绍的技术进一步优化,例如对规则集进行后剪枝等. 15.5.2逆归结 在逻辑学中，“演绎”(deduction)与 “归 纳 \" (induction)是人类认识世界 的两种基本方式.大致来说,演绎是从一般性规律出发来探讨具体事物,而归纳 参 阅 ［Lavra亡and roski, 1993］第 3 章. 360 第 1 5 章 规 则 学 习 十 九 世 纪 英 国 政 治 经 济 学 家 和 哲 学 家 W . S. Jevons通过数理方法论证, 最 早 明 确 指 出 归 纳 是 演 绎 的逆过程. 则是从个别事物出发概括出一般性规律.一般数学定理证明是演绎实践的代表, 而机器学习显然是属于归纳的范畴. 1 9 6 5 年，逻 辑 学 家 J. A. R o b i n s o n 提出, 一阶谓词演算中的演绎推理能用一条十分简洁的规则描述，这就是数理逻辑 中著名的归结原理(resolution principle) [Robinson, 19 6 5 ] .二十多年后，计算机 科 学 家 S. M u g g l e t o n 和 W . B u n t i n e 针对归纳推理提出了 “逆 归 结 ”(inverse resolution) [Muggleton a n d Buntine, 1988],这对归纳逻辑程序设计的发展起到 了重要作用. 基于归结原理，我们可将貌似复杂的逻辑规则与背景知识联系起来化繁为 简；而基于逆归结，我们可基于背景知识来发明新的概念和关系.下面我们先以 较为简单的命题演算为例，来看看归结、逆归结是怎么回事. 假 定 两 个 逻 辑 表 达 式 和 Q 成立，且分别包含了互补项L 1 与上2；不失 一般性，令 E = £ 1 = 乜 2 , = 4 V E , 。2 = 归结原理告诉我们，通过 演绎推理能消去上而得到“归 结 项 \"。 =",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 655
    }
  },
  {
    "page_content": "简；而基于逆归结，我们可基于背景知识来发明新的概念和关系.下面我们先以 较为简单的命题演算为例，来看看归结、逆归结是怎么回事. 假 定 两 个 逻 辑 表 达 式 和 Q 成立，且分别包含了互补项L 1 与上2；不失 一般性，令 E = £ 1 = 乜 2 , = 4 V E , 。2 = 归结原理告诉我们，通过 演绎推理能消去上而得到“归 结 项 \"。 = 若定义析合范式的删除操作 ( A V B ) - { ^ } = A , (15.6) 则归结过程可表述为 简记为 。二 (。1 — {£}) V ( G — { [ £ } ) , (15.7) 。 = G • G . (15.8) 图 1 5 . 3给出了归结原理的一个直观例示. 图 1 5 . 3 归结原理例示 与上面的过程相反，逆归结研究的是在已知C 和 某 个 G 的情况下如何得 到 g ( 冷 力 假 定 已 知 。和 G 求 。2 , 则由式(15.7),该过程可表述为 G = (。— © —⑷ ) ) V { - L } . (15.9) 1 5 . 5 归纳逻辑程序设计 361 在逻辑推理实践中如何实现逆归结呢？ [Muggleton, 1 9 9 5 ]定义了四种完备 的逆归结操作.若以规则形式p - q 等价地表达p V 「％ 并假定用小写字母表 示逻辑文字、大写字母表示合取式组成的逻辑子句，则这四种操作是： 吸 收 触 初 … ) ： 辨识(identification) : 仁 然 ：二:⑻ 。) 「二 二觉:；支 C1 5 -1 1 ) 内构(mtra-constructioii) : — §- 八----一 0 5 W(mter-construction) ' 、 : ------ p -- A — - - - - A 《— B \\ / - - --- -- - - r A Q <- r A C C \\ / -- - - - q --- --- -- —• (15.12) , 15.13)x ( 这 里 我 们 用 等 表 示 X 蕴 含 Y,在数理逻辑里写作X 卜Y . 上述规则中，X 的子 句 或 是 y 的归结项,或是y 的某个子句的等价项；而 v 中出现的新逻辑文字则 可看作通过归纳学到的新命题. 归结、逆归结都能容易地扩展为一阶逻辑形式；与命题逻辑的主要不同之 处是，一阶逻辑的归结、逆归结通常需进行合一置换操作. “置 换 ”(substitution)是 用 某 些 项 来 替 换 逻 辑 表 达 式 中 的 变 量 .例 如",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 656
    }
  },
  {
    "page_content": "句 或 是 y 的归结项,或是y 的某个子句的等价项；而 v 中出现的新逻辑文字则 可看作通过归纳学到的新命题. 归结、逆归结都能容易地扩展为一阶逻辑形式；与命题逻辑的主要不同之 处是，一阶逻辑的归结、逆归结通常需进行合一置换操作. “置 换 ”(substitution)是 用 某 些 项 来 替 换 逻 辑 表 达 式 中 的 变 量 .例 如 用 o = {1/X.2/Y}置 换 “c = 色泽更深( X , y ) A 敲声更沉( X , y ) ” 可得到 = ce = 色泽更深(1,2) A 敲声更沉( 1 , 2 ) \" ，其 中 {X.Y}称 为 0 的作用 域( d o m a i n ) . 与代数中的置换类似，一 阶 逻 辑 中 也 有 “复 合 置 换 ”和 “逆置 换 ”.例 如 先 用o = {Y/X}将 x 替 换 为 y , 再用入= {1/Y}将 y 替 换 为 1 , 这 样的复合操作记为eox;o的逆置换则记为0-1 = {X/Y}. “合 一 ”(unification)是 用 一 种 变 量 置 换 令 两 个 或 多 个 逻 辑 表 达 式 相 等 . 例 如 对 ((A = 色泽更深( 1 , X ) ” 和 “B = 色泽更深(工2)” ，可 用 夕 = [2/X,1/Y}使 “A 。= = 色泽更深(1,2)\" ；此 时 称 4 和 8 是 “可合一 的“(unifable),称 。为 4 和 B 的 “合 一化子 \" (unifier).若 6 是一组一阶逻 辑 表 达 式 W 的合一化子，且 对 W 的任意合一化子0 均 存 在 相 应 的 置 换 A 使 J = 6 。入 则 称 8 为 W 的 “最一般合一置换”或 “最 一 般 合 一 化 子 \"(most general unifier,简 记 为 M G U ) , 这是归纳逻辑程序中最重要的概念之一.例如 “色泽更深( i , y ) ”和 “色泽更深( x , y ) \" 能 被 & = { i / x } , 心= { i / x , 2 / y } , & = {i/z, Z/X}合 一 ,但 仅 有 出 是 它 们 的 M G U . 一阶逻辑进行归结时，需利用合一操作来搜索互补项5 和 L2. 对两个一 阶逻辑表达式g = a v 上1 和 。2 = 8 v r 2 , 若存在合一化子o 使 L xe = 也仇 362 第 1 5 章 规 则 学 习 则可对其进行归结: 。 = ( G — {£1}用 V (。2 - { L 2 })61 . (15.14)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 657
    }
  },
  {
    "page_content": "一阶逻辑进行归结时，需利用合一操作来搜索互补项5 和 L2. 对两个一 阶逻辑表达式g = a v 上1 和 。2 = 8 v r 2 , 若存在合一化子o 使 L xe = 也仇 362 第 1 5 章 规 则 学 习 则可对其进行归结: 。 = ( G — {£1}用 V (。2 - { L 2 })61 . (15.14) 类似的，可利用合一化子对式(15.9)进行扩展得到一阶逻辑的逆归结.基 于式(15.8),定义 Ci = C/C2 和 0 = 。/。1 为 “归结商”(resolution quotient), 于是,逆归结的目标就是在已知C 和 Q 时 求 出 归 结 商 对 某 个 e C i , 假 定 0 1 是一个置换，它能使 对 C = 4 V 8 , 有 4 卜C 与三8 （。= 4 V 8 ）等价. ( G — { % } ) 如卜 C , (15.15) 这 里 0 1 的 作 用域是 C i 中所有变量，记 为 vars(Ci),其 作 用 是 使 G - { % } 与 C 中 的 对 应 文 字 能 合 一 .令 如 为 作 用 域 是 vars(Li) - v a r s © - { % } ) 的置 换，工2 为 归 结 商 。2 中将被消去的文字，e2 是 以 vars(L2 ) 为作用域的置换，弧 与 共 同 作 用 于 Z / L 使 得 。。2 = 七262,于 是 。。2 。夕2 为 「5 与 L2 的 M G U . 将前两步的复合置换0i o 的 记 为 0 , 用 表 示 02 的逆置换，则有 (乜 1 & ) % 1 = L 2 . 于是,类似于式(15.9), 一阶逆归结是 C 2 = (C- (Ci - {Li})0i V ^ L i ^ i } ) ^ 1 . (15.16) 在一阶情形下E i 、工2、& 和 。2 的选择通常都不唯一，这时需通过一些其他的 判断标准来取舍,例如覆盖率、准确率、信息焙等. 以西瓜数据集5.0为例，假定我们通过一些步骤已得到规则 Ci = 更好(1, X ) 一根蒂更蜷 (1, X ) 八纹理更清(1, X ) ； a = 更好a, Y ) 一根蒂更蜷 (i,y)八敲声更沉(I,Y ). 容易看出它们是“0 - 和 “0 什 A 八。”的形式，于是可使用内构操作 式(15.12)来 进 行 逆 归 结 .由 于 Ci, G 中的谓词都是二元的，为保持新规则描 述信息的完整性，我们创造一个新的二元谓词q ( M N ) , 并根据式(15.12)得到",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 658
    }
  },
  {
    "page_content": "a = 更好a, Y ) 一根蒂更蜷 (i,y)八敲声更沉(I,Y ). 容易看出它们是“0 - 和 “0 什 A 八。”的形式，于是可使用内构操作 式(15.12)来 进 行 逆 归 结 .由 于 Ci, G 中的谓词都是二元的，为保持新规则描 述信息的完整性，我们创造一个新的二元谓词q ( M N ) , 并根据式(15.12)得到 °，= 更好(1, Z ) 一 根蒂更蜷(1, Z) A q ( M N ) , 式 (15.12)中 横 线下方的另两项分别是 5 / 0 和 G / C ，的 归 结 商 .对 容 易 发 现 C , 中 通 过 归 结 消 去 L i 的 选 择 可 以 有 “「根蒂更蜷(1,Z)” 和 1 5 . 6 阅读材料 363 奥 卡 姆 剃 刀 原 则 参 见 来 定 义 它 ；根 据 奥 卡 姆 剃 刀 原 则 ，同 等 描 述 能 力 下 学 得 的 规 则 越 少 越 . q 是新发明的谓词，迟早需学习一条新规则 1.4 节. AQ 是 Algorithm Quasi- optim al的缩写. 决策树的每个叶结点对 应一个等价类. W E K A 中 有 P R IS M 的 ' 实现. RIPPER 达到 了 比 C4.5 决策树既快又好的效果. 好，因 此 我 们 将 作 为 L i . 由式(15.16),存 在 解 ：L2 = q (l,S ), 弧 = {X/Z}, 02 = {l/M,X/N}, 02 = {X/S}.通 过 简 单 的 演 算 即 可 求 出 归 结 商 为 Q ( 1 , S ) 一 纹 理 更 清 (1,S )” . 类 似 地 可 求 出 的 归 结 商 “ q(l,T ) 一 敲声更沉(1,T )” . 逆归结的一大特点是能自动发明新谓词，这些新谓词可能对应于样例属性 和背景知识中不存在的新知识，对知识发现与精化有重要意义.但自动发明的 新谓词究竟对应于什么语义,例如“q”意 味 着 “更新鲜”？ “更甜”？ “更多 日晒”？……这只能通过使用者对任务领域的进一步理解才能明确. 上面的例子中我们只介绍了如何基于两条规则进行逆归结.在现实任务 中，I L P 系统通常先自底向上生成一组规则，然后再结合最小一般泛化与逆归 结做进一步学习. 1 5 .6 阅读材料 规 则 学 习 是 “符 号 主 义 学 习 \"(symbolism learning)的主要代表，是最早开 始研究的机器学习技术之一 [Michalski, 1983]. [Fiirnkranz et al., 2012]对规则 学习做了比较全面的总结.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 659
    }
  },
  {
    "page_content": "中，I L P 系统通常先自底向上生成一组规则，然后再结合最小一般泛化与逆归 结做进一步学习. 1 5 .6 阅读材料 规 则 学 习 是 “符 号 主 义 学 习 \"(symbolism learning)的主要代表，是最早开 始研究的机器学习技术之一 [Michalski, 1983]. [Fiirnkranz et al., 2012]对规则 学习做了比较全面的总结. 序 贯 覆 盖 是 规 则学习的基本框架，最 早 在 [Michalski, 1969]的 A Q 中被 提出，A Q 后来发展成一个算法族，其中比较著名的有AQ15 [Michalski et a l, 1986]> AQ17-HCI [Wnek and Michalski, 1994]等 .受 计 算 能 力 的 制 约 ，早期 A Q 在学习时只能随机挑选一对正反例作为种子开始训练，样例选择的随机性 导 致 A Q 学习效果不稳定.PRISM [Cendrowska, 1987]解决了这个问题，该算 法最早采用自顶向下搜索，并显示出规则学习与决策树学习相比的优点：决策 树试图将样本空间划分为不重叠的等价类，而规则学习并不强求这一点，因此 后者学得的模型能有更低的复杂度.虽然PR ISM 的性能不如A Q ,因此在当时 反响不大,但今天来看，它是规则学习领域发展的重要一步. CN2 [Clark and Niblett, 1989]采用集束搜索，是最早考虑过拟合问题的规 则学习算法. [Fiirnkranz, 1994]显示出后剪枝在缓解规则学习过拟合中的优势. RIPPER [Cohen, 1995]是命题规则学习技术的高峰，它融合了该领域的许多技 巧，使规则学习在与决策树学习的长期竞争中首次占据上风，作 者 主 页 上 的C 语 言 R IP P E R 版本至今仍代表着命题规则学习的最高水平. 关系学习的研究一般认为始于[Winston, 1970];由于命题规则学习很难完 364 第 1 5 章 规 则 学 习 知 识 工 程 与 专 家 系 统 参 见 1 .5 节. 成此类任务,一阶规则学习开始得以发展.FO IL 通过变量替换等操作把命题规 则学习转化为一阶规则学习，该技术至今仍有使用，例 如 2010年卡耐基梅隆大 学 开 展 的 “永动语言学习\" (Never-Ending Language Learning,简 称 NELL)计 划即采用FO IL 来学习自然语言中的语义关系[Carlson et al., 2010].很多文献 将所有的一阶规则学习方法都划入归纳逻辑程序设计的范畴,本书则是作了更 为严格的限定.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 660
    }
  },
  {
    "page_content": "则学习转化为一阶规则学习，该技术至今仍有使用，例 如 2010年卡耐基梅隆大 学 开 展 的 “永动语言学习\" (Never-Ending Language Learning,简 称 NELL)计 划即采用FO IL 来学习自然语言中的语义关系[Carlson et al., 2010].很多文献 将所有的一阶规则学习方法都划入归纳逻辑程序设计的范畴,本书则是作了更 为严格的限定. [Muggleton, 1991]提出了 “归 纳 逻 辑 程 序 设 计 ”(I L P ) 这 个 术 语 ，在 GOLEM [Muggleton and Feng, 1990]中克服了许多从命题逻辑过渡到一阶 逻辑学习的困难，并确立了自底向上归纳的IL P 框 架 .最 小 一 般 泛 化 (LGG) 最 早 由 [Plotkin, 1970]提出，GOLEM 则使用了 RLGG. PROGOL [Muggleton, 1995]将逆归结改进为逆蕴含(inverse entailme明 并 取 得 了 更好效果.新谓词 发 明 方 面 近 年 有 一 些 新 进 展 [Muggleton and Lin, 2 0 1 3 ].由 于 I L P 学得的规 则几乎能直接被PR O LO G 等逻辑程序解释器调用，而 PRO LO G 在专家系统 中常被使用，因 此 I L P 成为连接机器学习与知识工程的重要桥梁.PROGOL [Muggleton, 1995]和 ALEPH [Srinivasan, 1999]是应用广泛的 ILP 系统，其基 本思想已在本章关于I L P 的部分有所体现.Datalog [Ceri et al., 1989]则对数 据库领域产生了很大影响，例如甚至影响了 SQL 1999标 准 和 IBM DB2. ILP 方面的重要读物有 p\\iuggleton, 1992; Lavrac and Dzeroski, 1993],并且有专门 的国际归纳逻辑程序设计会议(ILP). I L P 复杂度很高，虽在生物数据挖掘和自然语言处理等任务中取得一些 成 功 [Bratko and Muggleton, 1995],但问题规模稍大就难以处理，因此，这方 面的研究在统计学习兴起后受到一定抑制.近年来随着机器学习技术进入更 多应用领域，在富含结构信息和领域知识的任务中，逻辑表达的重要性逐渐凸 显出来，因此出现了一些将规则学习与统计学习相结合的努力，例如试图在归",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 661
    }
  },
  {
    "page_content": "I L P 复杂度很高，虽在生物数据挖掘和自然语言处理等任务中取得一些 成 功 [Bratko and Muggleton, 1995],但问题规模稍大就难以处理，因此，这方 面的研究在统计学习兴起后受到一定抑制.近年来随着机器学习技术进入更 多应用领域，在富含结构信息和领域知识的任务中，逻辑表达的重要性逐渐凸 显出来，因此出现了一些将规则学习与统计学习相结合的努力，例如试图在归 纳逻 辑 程 序 设 计 中 引 入 概 率 模 型 的 “概 率 归 纳 逻 辑 程 序 设 计 \"(probabilistic ILP) [De Raedt et al., 2008]＞给贝叶斯网中的结点赋予逻辑意义的“关系贝 叶斯网 \" (relational Bayesian network)」Jaeger, 2002]等.事实上，将关系学习 与统计学习相结合是机器学习发展的一大趋势，而概率归纳逻辑程序设计是 其中的重要代表，其他重要代表还有概率关系模型[FYiedman et al., 1999]＞贝 叶斯逻辑程序(Bayesian Logic Program) [Kersting et al., 2000]＞ 马尔可夫逻辑 网(Markov logic network) [Richardson and Domingos, 2006]等，统 称 为 “统计 关系学习 \" (statistical relational learning) [Getoor and Taskar, 2007]. 习题 365 习题 西 瓜 数 据 集 2 .0 见 p.76 表 4.1. 15.1 对西瓜数据集2 .0 ,允许使用否定形式的文字,试基于自顶向下的策略 学出命题规则集. 15.2 对 西 瓜 数 据 集2 .0 ,在学习过程中可通过删去文字、将常量替换为变 量来进行规则泛化,试基于自底向上的策略学出命题规则集. 15.3 从网上下载或自己编程实现R IP P E R 算法，并在西瓜数据集2.0 上学 出规则集. 15.4 规则学习也能对缺失数据进行学习.试模仿决策树的缺失值处理方法, 西 瓜 数 据 集 2 .0 a 见 p.86 表 4.4. 基于序贯覆盖在西瓜数据集2 .0 a 上学出命题规则集. 15.5 从网上下载或自己编程实现R IP P E R 算法，允许使用否定形式的文 字,在西瓜数据集5 .0 上学出一阶规则集. 15.6 对西瓜数据集5 .0 ,试利用归纳逻辑程序学习概念“更坏(x , y )” . 15.7 试证明：对于一阶公式n 和 r 2 , 不 存 在 既 能 特 化 为 门 和 驾 、也能泛 化为它们的L G G 的一阶公式M",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 662
    }
  },
  {
    "page_content": "15.5 从网上下载或自己编程实现R IP P E R 算法，允许使用否定形式的文 字,在西瓜数据集5 .0 上学出一阶规则集. 15.6 对西瓜数据集5 .0 ,试利用归纳逻辑程序学习概念“更坏(x , y )” . 15.7 试证明：对于一阶公式n 和 r 2 , 不 存 在 既 能 特 化 为 门 和 驾 、也能泛 化为它们的L G G 的一阶公式M 15.8 试生成一个西瓜数据集5 .0 的 L G G 集合. 15.9* 一阶原子公式是一种递归定义的公式，形 如 P (力1\"2, • • • ,% ) ,其 中 P 是谓词或函数符号，^ 称 为 “项 ”，可以是逻辑常量、变量或者其他 原子公式.对一阶原子公式Ei的 集 合 S = {石1,石2,… ，& } , 试设计 在 S 无 法 合 一 时 输 出 “无解” . 一个算法求解其MGU. 15.10* 基于序贯覆盖的规则学习算法在学习下一条规则前,会将已被当前规 则集所覆盖的样例从训练集中删去.这种贪心策略使得后续学习过程 仅需关心以往未覆盖的样例,在判定规则覆盖率时不需考虑前后规则 间的相关性；但该策略使得后续学习过程所能参考的样例越来越少. 试设计一种不删除样例的规则学习算法. 366 第 1 5 章 规 则 学 习 参考文献 Bratko, I. and S. Muggleton. (1995). uApplications of inductive logic program­ ming?5 Communicantions of the ACM1 38(11):65-70. Brunk, C. A. and M. J. Pazzani. (1991). “An investigation of noise-tolerant re­ lational concept learning algorithms.^^ In Proceedings of the 8th International Workshop on Machine Learning (IWML), 389-393, Evanston, IL. Carlson, A., J. Bett eridge, B. Kisiel, B. Settles, E. R. Hruschka, and T. M. Mitchell. (2010), “Toward an architecture for never-ending language learn­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 663
    }
  },
  {
    "page_content": "Carlson, A., J. Bett eridge, B. Kisiel, B. Settles, E. R. Hruschka, and T. M. Mitchell. (2010), “Toward an architecture for never-ending language learn­ i n g .I n Proceedings of the 24th A A A I Conference on Artificial Intelligence (AAAI), 1306-1313, Atlanta, GA. Cendrowska, J. (1987). “PRISM: An algorithm for inducing modular rules.” International Journal of Man-Machine Studies, 27(4):349-370. Ceri, S., G. Gottlob, and L. Tanca. (1989). uW hat you always wanted to know about Datalog (and never dared to ask).\" IEEE Transactions on Knowledge and Data Engineering^ 1(1):146-166. Clark, P. and T. Niblett. (1989). “The CN2 induction algorithm.5, Machine Learning,3(4):261-283. Cohen, W. W. (1995). “Fast effective rule induction.” In Proceedings of the 12th International Conference on Machine Learning (ICML), 115-123, Tahoe, CA. De Raedt, L., P. Frasconi, K. Kersting, and S. Muggleton, eds. (2008). Prob­ abilistic Inductive Logic Programming: Theory and Applications. Springer, Berlin. Friedman, N., L. Getoor, D. Koller, and A Pfeffer. (1999). “Learning prob­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 664
    }
  },
  {
    "page_content": "abilistic Inductive Logic Programming: Theory and Applications. Springer, Berlin. Friedman, N., L. Getoor, D. Koller, and A Pfeffer. (1999). “Learning prob­ abilistic relational models.55 In Proceedings of the 16th International Joint Conference on Artificial Intelligence (IJCAI)^ 1300-1307, Stockholm, Swe­ den. Fiirnkranz, J. (1994). “Top-down pruning in relational learning.,5 In Proceed­ ings of the 11th European Conference on Artificial Intelligence (ECAI), 453- 457, Amsterdam, The Netherlands. Fiirnkranz, J., D. Gamberger, and N. Lavrac. (2012). Foundations of Rule Learning. Springer, Berlin. 参考文献 367 Fiirnkranz, J. and G. Widmer. (1994). ^Incremental reduced error pruning?5 In Proceedings of the 11th International Conference on Machine Learning (ICML), 70-77, New Brunswick, NJ. Getoor, L. and B. Taskar. (2007). Introduction to Statistical Relational Learn­ ing. MIT Press, Cambridge, MA. Jaeger, M. (2002). ^Relational Bayesian networks: A survey.\" Electronic Trans­ actions on Artificial Intelligence^ 6:Article 15.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 665
    }
  },
  {
    "page_content": "ing. MIT Press, Cambridge, MA. Jaeger, M. (2002). ^Relational Bayesian networks: A survey.\" Electronic Trans­ actions on Artificial Intelligence^ 6:Article 15. Kersting, K., L. De Raedt, and S. Kramer. (2000). ^Interpreting Bayesian logic programs.55 In Proceedings of the AAAF2000 Workshop on Learning Statis­ tical Models from Relational Data, 29-35, Austin, TX. Lavrac, N. and S. Dzeroski. (1993). Inductive Logic Programming: Techniques and Applications. Ellis Horwood, New York, NY. Michalski, R. S. (1969). “On the quasi-minimal solution of the general covering problem.^^ In Proceedings of the 5th International Symposium on Information Processing (FCIP), volume A3, 125-128, Bled, Yugoslavia. Michalski, R. S. (1983). “A theory and methodology of inductive leaming.\" In Machine Learning: An Artificial Intelligence Approach (R. S. Michalski, J. Carbonell, and T. Mitchell, eds.), 111-161, Tioga, Palo Alto, CA. Michalski, R. S., I. Mozetic, J. Hong, and N. Lavrac. (1986). “The multi-purpose incremental learning system AQ15 and its testing application to three med­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 666
    }
  },
  {
    "page_content": "Michalski, R. S., I. Mozetic, J. Hong, and N. Lavrac. (1986). “The multi-purpose incremental learning system AQ15 and its testing application to three med­ ical domains.55 In Proceedings of the 5th National Conference on Artificial Intelligence (AAAI)1 1041-1045, Philadelphia, PA. Muggleton, S. (1991). “Inductive logic programming.5, New Generation Com­ puting^ 8(4):295-318. Muggleton, S., ed. (1992). Inductive Logic Programming. Academic Press, Lon­ don, UK. Muggleton, S. (1995). “Inverse entailment and Progol.55 New Generation Com- puling, 13(3-4):245-286. Muggleton, S. and W. Buntine. (1988). “Machine invention of first order predi­ cates by inverting resolution.5, In Proceedings of the 5th International Work­ shop on Machine Learning (IWML)1 339-352, Ann Arbor, ML Muggleton, S. and C. Feng. (1990). “Efficient induction of logic programs.” 368 第 1 5 章 规 则 学 习 In Proceedings of the 1st International Workshop on Algorithmic Learning Theory (ALT)1368-381, Tokyo, Japan. Muggleton, S. and D. Lin. (2013). “Meta-interpretive learning of higher-order",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 667
    }
  },
  {
    "page_content": "Theory (ALT)1368-381, Tokyo, Japan. Muggleton, S. and D. Lin. (2013). “Meta-interpretive learning of higher-order dyadic datalog: Predicate invention revisited.55 In Proceedings of the 23rd In­ ternational Joint Conference on Artificial Intelligence (IJ CAI) 1551-1557, Beijing, China. Plotkin, G. D. (1970). “A note on inductive generalization.\" In Machine Intel­ ligence 5 (B. Meltzer and D. Mitchie, eds.), 153-165, Edinburgh University Press, Edinburgh, Scotland. Plotkin, G. D. (1971). “A further note on inductive generalization.55 In Ma­ chine Intelligence 6 (B. Meltzer and D. Mitchie, eds.), 107-124, Edinburgh University Press, Edinburgh, Scotland. Quinlan, J. R. (1990). “Learning logical definitions from relations.55 Machine Learning^ 5(3):239-266. Richardson, M. and P. Domingos. (2006). “Markov logic networks.^^ Machine Learning, 62(1-2):107-136. Robinson, J. A. (1965). UA machine-oriented logic based on the resolution prin- ciple.55 Journal of the ACM1 12(1):23-41. Srinivasan,A.(1999).uThe Aleph manual25 http:/ /www.cs.ox.ac.uk/activities/ machlearn / Aleph / aleph.html.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 668
    }
  },
  {
    "page_content": "ciple.55 Journal of the ACM1 12(1):23-41. Srinivasan,A.(1999).uThe Aleph manual25 http:/ /www.cs.ox.ac.uk/activities/ machlearn / Aleph / aleph.html. Winston, P. H. (1970). Learning structural descriptions from examples. Ph.D. thesis, Department of Electrical Engineering, MIT, Cambridge, MA. Wnek, J. and R. S. Michalski. (1994). “Hypothesis-driven constructive induc­ tion in AQ17-HCI: A method and experiments.\" Machine Learning^ 2(14): 139-168. 休息一会儿 369 休 息 一 会 儿 小故事：机器学习先驱雷萨德•迈克尔斯基 A Q 系列算法是规则学习研究早期的重要成果，主要发 明人是机器学习先驱、美籍波兰裔科学家雷萨德•迈克尔 斯 基 (Ryszard S. Michalski, 1937—2007). 卡 鲁 兹 (Kalusz)在 历 史 上 先 后 属 于 波 兰 、俄罗 斯 、德国、乌克兰等国. 迈克尔斯基出生在波兰卡鲁兹，1969年在波兰获得计 算机科学博士学位，同年在南斯拉夫布莱德(B le d ,现属斯 洛文尼亚)举行的F C I P 会议上发表了 AQ. 1970年他前往美国U IU C 任教，此 后在美国进一步发展了 A Q 系列算法.迈克尔斯基是机器学习领域的主要奠基 人之一. 1980年 他 与 J. G. Carbonell. T. Mitchell 一起在卡耐基梅隆大学组织 了第一次机器学习研讨会，1983、1985年又组织了第二、三次，这个系列研讨 会后来发展成国际机器学习会议(ICML); 1983年，迈克尔斯基作为第一主编 出 版 了 《机器学习：一种人工智能途径》这本机器学习史上里程碑性质的著作; 参 见 1 .5 节. 1986年 Machine Learning创刊，迈克尔斯基是最初的三位编辑之一.1988年 他将研究组迁到乔治梅森大学，使该校成为机器学习早期发展的一个重镇. 第 1 6 章 强 化 学 习 1 6 .1 任务与奖赏 我们考虑一下如何种西瓜.种瓜有许多步骤，从一开始的选种，到定期浇",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 669
    }
  },
  {
    "page_content": "参 见 1 .5 节. 1986年 Machine Learning创刊，迈克尔斯基是最初的三位编辑之一.1988年 他将研究组迁到乔治梅森大学，使该校成为机器学习早期发展的一个重镇. 第 1 6 章 强 化 学 习 1 6 .1 任务与奖赏 我们考虑一下如何种西瓜.种瓜有许多步骤，从一开始的选种，到定期浇 水、施肥、除草、杀虫，经过一段时间才能收获西瓜.通常要等到收获后，我们 才知道种出的瓜好不好.若将得到好瓜作为辛勤种瓜劳动的奖赏，则在种瓜过 程中当我们执行某个操作（例如，施肥）时，并不能立即获得这个最终奖赏，甚至 难以判断当前操作对最终奖赏的影响，仅能得到一个当前反馈（例如，瓜苗看起 来更健壮了）.我们需多次种瓜,在种瓜过程中不断摸索，然后才能总结出较好 亦 称 “再励学习 的种瓜策略.这个过程抽象出来，就 是 “强化学习\" （reinforcement learning）. 奖赏厂 图 1 6 . 1 强 化 学 习 图 示 图 16.1给出了强化学习的一个简单图示.强化学习任务通常用马尔可夫决 策 过 程 （Markov Decision Process,简 称 MDP）来描述：机器处于环境石中，状 态空间 为X , 其中每个状态比e x 是机器感知到的环境的描述，如在种瓜任务 上这就是当前瓜苗长势的描述；机器能采取的动作构成了动作空间4 如种瓜 过程中有浇水、施不同的肥、使用不同的农药等多种可供选择的动作；若某个 动 作 。e 4 作用在当前状态化上，则潜在的转移函数p 将使得环境从当前状态 按某种概率转移到另一个状态，如瓜苗状态为缺水，若选择动作浇水，则瓜苗长 势会发生变化,瓜苗有一定的概率恢复健康，也有一定的概率无法恢复;在转移 到另一个状态的同时，环境会根据潜在的“奖赏”（reward）函数兄反馈给机器 一个奖赏，如保持瓜苗健康对应奖赏+ 1 , 瓜苗凋零对应奖赏- 1 0 , 最终种出了 好瓜对应奖赏+ 1 0 0 .综合起来，强化学习任务对应了四元组E = 其 中 尸 ：X x 4 x X i 肽指定了状态转移概率，兄 ：X x 4 x X i 肽指定了奖 赏；在有的应用中，奖赏函数可能仅与状态转移有关，即 K : X x X 1 肽. 图 16.2给出了一个简单例子：给西瓜浇水的马尔可夫决策过程.该任务中 372 第 1 6 章 强 化 学 习 。二浇水/不浇水 片 1 r=-100 图 1 6 . 2 给西瓜浇水问题的马尔可夫决策过程 只有四个状态（健康、缺水、溢水 、凋亡）和两个动作（浇 水 、不浇水），在每一 步转移后,若状态是保持瓜苗健康则获得奖赏1 ,瓜苗缺水或溢水奖赏为- 1 , 这",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 670
    }
  },
  {
    "page_content": "图 16.2给出了一个简单例子：给西瓜浇水的马尔可夫决策过程.该任务中 372 第 1 6 章 强 化 学 习 。二浇水/不浇水 片 1 r=-100 图 1 6 . 2 给西瓜浇水问题的马尔可夫决策过程 只有四个状态（健康、缺水、溢水 、凋亡）和两个动作（浇 水 、不浇水），在每一 步转移后,若状态是保持瓜苗健康则获得奖赏1 ,瓜苗缺水或溢水奖赏为- 1 , 这 时通过浇水或不浇水可以恢复健康状态，当瓜苗凋亡时奖赏是最小值- 1 0 0 且 无法恢复.图中箭头表示状态转移，箭 头 旁 的 a , 3 7•分别表示导致状态转移的 动作、转移概率以及返回的奖赏.容易看出，最 优 策 略 在 “健 康 ”状态选择动 作 “浇 水 ”、在 “溢 水 ”状 态 选 择 动 作 “不浇水”、在 “缺 水 ”状态选择动 作 “浇水”、在 “凋亡”状态可选择任意动作. 需 注 意 “机器”与 “环 境 ”的界限，例如在种西瓜任务中，环境是西瓜生 长的自然世界；在下棋对弈中，环境是棋盘与对手；在机器人控制中，环境是机 器人的躯体与物理世界.总之，在环境中状态的转移、奖赏的返回是不受机器 控制的，机器只能通过选择要执行的动作来影响环境，也只能通过观察转移后 的状态和返回的奖赏来感知环境. 机器要做的是通过在环境中不断地尝试而学得一个“策略”（policy）明 根 据这个策略，在状态力下就能得知要执行的动作a = 7r（c ）, 例如看到瓜苗状态 是缺水时，能 返 回 动 作 “浇 水 ”.策略有两种表示方法：一种是将策略表示为 函数7T: X 1 4 确定性策略常用这种表示；另一种是概率表示7T: X x 4 1 见 随机性策略常用这种表示，不（伤。）为状态力下选择动作a 的概率，这里必须有 E a 7 r（力，。）= 1・ 策略的优劣取决于长期执行这一策略后得到的累积奖赏，例如某个策略使 得瓜苗枯死,它的累积奖赏会很小，另一个策略种出了好瓜，它的累积奖赏会很 16.2 K -摇臂赌博机 373 大.在强化学习任务中，学习的目的就是要找到能使长期累积奖赏最大化的策 略.长期累积奖赏有多种计算方式，常 用 的 有 “ T 步累积奖赏” M惇 £ 3 叫 和 “ 7 折扣累积奖赏” 叫 £ 篙 y ^ + i ] , 其 中 rt 表 示 第t步获得的奖赏值,E 表 示对所有随机变量求期望. 读者也许已经感觉到强化学习与监督学习的差别.若将这里的“状态”对 应 为 监 督 学 习 中 的 “示例”、 “动作”对 应 为 “标 记 ”，则可看出，强化学习 中 的 “策 略 ”实际上 就 相 当 于 监 督 学 习 中 的 “分类 器 ”（当动作是离散的）或",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 671
    }
  },
  {
    "page_content": "读者也许已经感觉到强化学习与监督学习的差别.若将这里的“状态”对 应 为 监 督 学 习 中 的 “示例”、 “动作”对 应 为 “标 记 ”，则可看出，强化学习 中 的 “策 略 ”实际上 就 相 当 于 监 督 学 习 中 的 “分类 器 ”（当动作是离散的）或 “回归器”（当动作是连续的），模型的形式并无差别.但不同的是，在强化学 习中并没有监督学习中的有标记样本（即 “示例-标记”对），换言之，没有人直 接告诉机器在什么状态下应该做什么动作，只有等到最终结果揭晓，才能通过 “反思”之前的动作是否正确来进行学习.因此，强化学习在某种意义上可看 作 具 有 “延迟标记信息”的监督学习问题. 16.2 K -摇臂赌博机 16.2.1 探索与利用 与一般监督学习不同，强化学习任务的最终奖赏是在多步动作之后才能观 察到，这里我们不妨先考虑比较简单的情形：最大化单步奖赏，即仅考虑一步 操作.需注意的是，即便在这样的简化情形下，强化学习仍与监督学习有显著不 同，因为机器需通过尝试来发现各个动作产生的结果，而没有训练数据告诉机 器应当做哪个动作. 欲最大化单步奖赏需考虑两个方面：一是需知道每个动作带来的奖赏，二 是要执行奖赏最大的动作.若每个动作对应的奖赏是一个确定值,那么尝试一 遍所有的动作便能找出奖赏最大的动作.然而，更一般的情形是,一个动作的奖 赏值是来自于一个概率分布,仅通过一次尝试并不能确切地获得平均奖赏值. 实际上,单步强化学习任务对应了一个理论模型，即 摇 臂 赌 博 机 ”（K- 亦 称 “K-摇 臂 老 虎 机”. armed bandit）. 如 图 16.3所示，K -摇臂赌博 机 有K 个摇臂，赌徒在投入一个 硬币后可选择按下其中一个摇臂，每个摇臂以一定的概率吐出硬币，但这个概 率赌徒并不知道.赌徒的目标是通过一定的策略最大化自己的奖赏，即获得最 多的硬币. 若 仅 为 获 知 每 个 摇 臂 的 期 望 奖 赏 ，则 可 采 用 “仅 探 索 ”（exploration- only） 法： 将所有的尝试机会平均分配给每个摇臂（即轮流按下每个摇臂），最后 以每个摇臂各自的平均吐币概率作为其奖赏期望的近似估计.若仅为执行奖赏 最大的动作，则 可 采 用 “仅 利 用 \"（exploitation-only）法：按下目前最优的（即到 374 第 1 6 章 强 化 学 习 图 16.3 K-摇臂赌博机图示 目前为止平均奖赏最大的)摇臂，若有多个摇臂同为最优，则从中随机选取一个. 显然，“仅探索”法能很好地估计每个摇臂的奖赏，却会失去很多选择最优摇 臂的机会；“仅利用”法则相反，它没有很好地估计摇臂期望奖赏，很可能经常",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 672
    }
  },
  {
    "page_content": "374 第 1 6 章 强 化 学 习 图 16.3 K-摇臂赌博机图示 目前为止平均奖赏最大的)摇臂，若有多个摇臂同为最优，则从中随机选取一个. 显然，“仅探索”法能很好地估计每个摇臂的奖赏，却会失去很多选择最优摇 臂的机会；“仅利用”法则相反，它没有很好地估计摇臂期望奖赏，很可能经常 选不到最优摇臂.因此,这两种方法都难以使最终的累积奖赏最大化. 事 实 上 ， “探 索 ”(即 估 计 摇 臂 的 优 劣 )和 “利 用 ”(即选择当前最优摇 臂)这两者是矛盾的，因为尝试次数(即总投币数)有限，加 强了一方则会自 然 削 弱 另 一 方 ，这 就 是 强 化 学 习 所 面 临 的 “探索■利用窘境\"(Exploration- Exploitation dilem m a).显然，欲累积奖赏最大，则必须在探索与利用之间达成 较好的折中. 16.2.2 6 贪心 ，贪心法基于一个概率来对探索和利用进行折中：每次尝试时，以 €的概率 进行探索，即以均匀概率随机选取一个摇臂；以 1 - € 的概率进行利用，即选择 当前平均奖赏最高的摇臂(若有多个，则随机选取一个). 令 Q ⑹ 记 录 摇 臂k 的 平 均 奖 赏 .若 摇 臂k 被尝试了 n 次，得到的奖赏为 … ，。如则平均奖赏为 1 Q(k) = —£ % . n (16.1) 若直接根据式(16.1)计算平均奖赏，则需记录几个奖赏值.显然，更高效的 做法是对均值进行增量式计算，即每尝试一次就立即更新Q ( k ) .不妨用下标来 表示尝试的次数,初始时QoW = 0 . 对于任意的九? 1，若第九- 1 次尝试后的 平均奖赏为Q吁 i ( k ) ,则在经过第n 次尝试获得奖赏诙后，平均奖赏应更新为 Q式k) = x Q n-1(k) + vn ) (16.2) 16.2 K - 摇臂赌博机 式(16.3)会 在 16.4.2节 中用到. — Q n - 1 ( ^ ) ~ {yn ~ Q n - 1(^)) • (16.3) 375 这样,无论摇臂被尝试多少次都仅需记录两个值：已尝试次数几 - 1 和最近平均 奖 赏 孰 ・贪心算法描述如图1 6 . 4所示. 输入：摇臂数K ; 奖赏函数R; 尝试次数T ； 探索概率€. Q(i)和 count(z)分别记 录 摇 臂 。的平均奖赏和选 中次数. 在 ［0,1］中生成随机数. 本次尝试的奖赏值. 式(16.2)更新平均奖赏. k = 从 1,2,..., K 中以均匀分布随机选取 else",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 673
    }
  },
  {
    "page_content": "- 1 和最近平均 奖 赏 孰 ・贪心算法描述如图1 6 . 4所示. 输入：摇臂数K ; 奖赏函数R; 尝试次数T ； 探索概率€. Q(i)和 count(z)分别记 录 摇 臂 。的平均奖赏和选 中次数. 在 ［0,1］中生成随机数. 本次尝试的奖赏值. 式(16.2)更新平均奖赏. k = 从 1,2,..., K 中以均匀分布随机选取 else 过程： 1： r = 0; 2： V 分= 1 , 2 , … K : Q ⑶ = 0 , count(z) = 0; 3： fo r — 1 , 2 , . . . , T d o 4： if rand()< e t h e n 5： 6： 7: 8： 9： 10: 11. — Q(k) xcount(k)+。. 口. 12： 13： e n d fo r 输出：累积奖赏r e n d if v = R(k); r = r + v ; 3 旧 — count (fc)+l ， count (/c) — count (A;) + 1; k = argrnaxi Q(%) 图 1 6 .4 6 贪心算法 若摇臂奖赏的不确定性较大，例如概率分布较宽时，则需更多的探索，此时 需要较大的€值;若摇臂的不确定性较小，例如概率分布较集中时，则少量的尝 试就能很好地近似真实奖赏，此时需要的 6 较 小 .通 常 令 6 取一个较小的常数, 如 0 . 1 或 0 . 0 1 . 然而，若尝试次数非常大，那么在一段时间后，摇臂的奖赏都能 很好地近似出来，不再需要探索，这种情形下可让€随着尝试次数的增加而逐 渐减小，例 如 令 € = 1/Vt. 16.2.3 Softmax S o f t m a x 算法龛于当前已知的摇臂平均奖赏来对探索和利用进行折中.若 各摇臂的平均奖赏相当，则选取各摇臂的概率也相当；若某些摇臂的平均奖赏 明显高于其他摇臂，则它们被选取的概率也明显更高. 376 第16章强化学习 Softmax算法中摇臂概率的分配是基于B o l t z m a n n 分布 Q(fc) P T P⑻ = 工— ， g 2(1) (16.4) 第 4 行 中式(16.4)的参 数. Q(i)和 count(z)分别记 录 摇 臂 £ 的平均奖赏和选 中次数. 本次尝试的奖赏值. 式(16.2)更新平均奖赏. 分=1 其中，Q(i)记录当前摇臂的平均奖赏；丁 > 0 称 为 “温度”，r 越小则平均奖赏 高的摇臂被选取的概率越高. T 趋 于 。时 Softmax将 趋 于 “仅利用”，丁趋于无",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 674
    }
  },
  {
    "page_content": "(16.4) 第 4 行 中式(16.4)的参 数. Q(i)和 count(z)分别记 录 摇 臂 £ 的平均奖赏和选 中次数. 本次尝试的奖赏值. 式(16.2)更新平均奖赏. 分=1 其中，Q(i)记录当前摇臂的平均奖赏；丁 > 0 称 为 “温度”，r 越小则平均奖赏 高的摇臂被选取的概率越高. T 趋 于 。时 Softmax将 趋 于 “仅利用”，丁趋于无 穷 大 时 Softmax则 将 趋 于 “仅探索”. Soft m a x算法描述如图16.5所示. 输入：摇臂数段 奖赏函数此 尝试次数T; 温度参数r. for t = 1 ,2 ,... ,T do 过程： 1: r = 0; 2: Vi = 1,2,... : Q0) = 0, count(i) = 0; 3: 4： a = 从1 , 2 , , K 中根据式(16.4)随机选取 5: o = R⑹; 6： r = r + v; 7 . / . 8： 9: end for 输出：累积奖赏r W S J — — co u n t(a)+ l - ， count (A;) = count (A;) + 1; — Q (k )x c o u n t(/g )+ o . 图 16.5 Softmax 算法 e 贪 心 算 法 与 Sof t m a x算法孰优孰劣，主要取决于具体应用.为了更直观 地观察它们的差别，考虑一个简单的例子：假 定 2-摇臂赌博机的摇臂［以 0.4 的概率返回奖赏1 , 以 0.6的概率返回奖赏0 ; 摇 臂 2 以 0.2的概率返回奖赏1, 以 0.8的概 率 返 回 奖 赏 0 . 图 16.6显示了不同算法在不同参数下的平均累积 奖赏，其中每条曲线对 应于重复 1 0 0 0 次实验的平均结果.可以看出，Softmax (r = 0.01)的 曲 线 与 “仅利用”的曲线几乎重合. 对于离散状态空间、离散动作空间上的多步强化学习任务，一种直接的办 法是将每个状态上动作的选择看作一个K - 摇臂赌博机问题，用强化学习任务 的累积奖赏来代替K - 摇臂赌博机算法中的奖赏函数，即可将赌博机算法用于 每个状态：对每个状态分别记录各动作的尝试次数、当前平均累积奖赏等信 息，基于赌博机算法选择要尝试的动作.然而这样的做法有很多局限，因为它没 1 6 . 3 有模型学习 377 O. OS. .40 ,35 ,30 0.25 0 500 1000 1500 尝试次数 2000 2500 3000 图 1 6 . 6 不同算法在 2-摇臂赌博机上的性能比较",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 675
    }
  },
  {
    "page_content": "每个状态：对每个状态分别记录各动作的尝试次数、当前平均累积奖赏等信 息，基于赌博机算法选择要尝试的动作.然而这样的做法有很多局限，因为它没 1 6 . 3 有模型学习 377 O. OS. .40 ,35 ,30 0.25 0 500 1000 1500 尝试次数 2000 2500 3000 图 1 6 . 6 不同算法在 2-摇臂赌博机上的性能比较 有考虑强化学习任务马尔可夫决策过程的结构.在1 6 . 3节将会看到，若能有效 考虑马尔可夫决策过程的特性，则可有更聪明的办法. 1 6 . 3 有模型学习 考虑多步强化学习任务，暂且先假定任务对应的马尔可夫决策过程四元组 普4 节将讨论模型未知 后= (X.A, P.R)均为已知，这 样 的 情形称为“模型已知”，即机器已对环境进 行了建模，能在机器内部模拟出与环境相同或近似的状况.在已知模型的环境 中 学 习 称 为 “有模型学习\" (model-based learning).此时，对于任意状态为,力， 和 动 作 见 在力状态下执行动作a 转 移 到 “ 状态的概率P % 是已知的，该转 移 所 带 来 的 奖 赏 %也 是 已 知 的 .为 便 于 讨 论 ，不妨假设状态空间X 和动作 空 间 4 均为有限. 1 6 . 3 . 1 策略评估 在模型已知时，对任意策略乃能估计出该策略带来的期望累积奖赏.令 函数/式 /)表 示 从 状 态 力 出 发 ，使 用 策 略 7F所带来的累积奖赏；函 数 Q \" ( C , 。) 表 示 从 状 态 力 出 发 ，执 行 动 作 Q 后 再 使 用 策 略 7T带 来 的 累 积 奖 赏 .这 里 的 V ( - ) 称 为 “状 态 值 函 数 \" (state value function), Q ( ・)称 为 “状态-动作值函 数”(state-action value function), 分 别 表 示 指 定 “状 态 ”上 以 及 指 定 “状 态-动作”上的累积奖赏. 378 第 1 6 章 强 化 学 习 . 由 累 积 奖 赏 的 定 义 ,有 状 态 值 函 数 呼 (力 )= 吗 ［宗 £ 篙 勺 | g = H , T 步 累 积 奖 赏 ； q ⑺ = 吗 ［£ 嵩 也 讦 1 | 加 = 司 ， 7 折扣累积奖赏. (16.5) 为 叙 述 简 洁 ,后 面 在 涉 及 上 述 两 种 累 积 奖 赏 时 ，.就 不 再 说 明 奖 赏 类 别 ，读者 从 上 下 文 应 能 容 易 地 判 知 .令 3 表 示 起 始 状 态 ,刖 蓑 示 起 始 状 态 上 采 取 的 第 一",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 676
    }
  },
  {
    "page_content": "T 步 累 积 奖 赏 ； q ⑺ = 吗 ［£ 嵩 也 讦 1 | 加 = 司 ， 7 折扣累积奖赏. (16.5) 为 叙 述 简 洁 ,后 面 在 涉 及 上 述 两 种 累 积 奖 赏 时 ，.就 不 再 说 明 奖 赏 类 别 ，读者 从 上 下 文 应 能 容 易 地 判 知 .令 3 表 示 起 始 状 态 ,刖 蓑 示 起 始 状 态 上 采 取 的 第 一 个 动 作 ；对 于 T 步 累 积 奖 赏 ，用 下 标 t 表 示 后 续 执 行 的 步 数 .我 们 有 状 态 -动 作 值 函 数 ✓ a ) = 叫 停 £力 =1々|力0 = 力 , = 砧 a ) = \\ xo = x, a()= a］. (16.6) 这样的递归等式称为 Bellman 等式. 由 于 M D P 具 有 马 尔 可 夫 性 质 ，即 系 统 下 一 时 刻 的 状 态 仅 由 当 前 时 刻 的 状 态 决 定 ，不 依 赖 于 以 往 任 何 状 态 ，于 是 值 函 数 有 很 简 单 的 递 归 形 式 . 对 于 T 步 累 积 奖 赏 有 I 「1 7 可 ⑺ = ! £ 7 r 亍 £ 勺 | g = 力 . t=1 , = % 1 1 - r 1 + - ^ - ^ — ^ 2 ^ r t \\ x Q = x T — 1 . 动作-状态全概率展开. = £ 7r(0 。) £ a ^ A \\ = £ 开 出 。) E P建日G 鸾 母 ，+ 筝 呼 —1 3 ) ) . x 'E X L t= l 々 | 初 = / ' \\ ) (16.7) a e A x K X ' ) 类 似 的 ，对 于 ) 折 扣 累 积 奖 赏 有 可 ⑺ = E 7 r(e a) £ P J (成 TW + 7 号 3 ) ) . (16.8) a e A x f e X 需 注 意 的 是 ，正 是 由 于 F 和 兄 已 知 ，才 可 以 进 行 全 概 率 展 开 . 读 者 可 能 已 发 现 ，用 上 面 的 递 归 等 式 来 计 算 值 函 数 ，实 际 上 就 是 一 种 动 态 规 划 算 法 . 对 于 库 ，可 设 想 递 归 一 直 进 行 下 去 ，直 到 最 初 的 起 点 ；换 言 之 ，从 值 函 数 的 初 始 值 踏 出 发 ，通 过 一 次 迭 代 能 计 算 出 每 个 状 态 的 单 步 奖 赏 可 ，进 而 1 6 . 3 有模型学习 379",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 677
    }
  },
  {
    "page_content": "规 划 算 法 . 对 于 库 ，可 设 想 递 归 一 直 进 行 下 去 ，直 到 最 初 的 起 点 ；换 言 之 ，从 值 函 数 的 初 始 值 踏 出 发 ，通 过 一 次 迭 代 能 计 算 出 每 个 状 态 的 单 步 奖 赏 可 ，进 而 1 6 . 3 有模型学习 379 输入：M D P 四元组 E = (X , A ,P , R ); 被评估的策略7T； 累积奖赏参数工 V Q ) 为二的累积奖赏. 式(16.7)更新值函数. 这个写法是为了便于在 同样的算法框架下考虑T 步累积奖赏和7 折扣累积 奖赏. V ” £ X : 『(①)= if t = T + 1 then 过程： 1： V% G X : 卜 ⑺ = 0； 2： for t = 1,2,... d o 3: 4： 5： 6： 7： 8： e n d if 9: e n d for 输出：状态值函数U V = V f break else 7r(①，°) E o / w x 图 1 6 . 7 基于T 步累积奖赏的策略评估算法 从单步奖赏出发,通过一次迭代计算出两步累积奖赏吟，……图 16.7中算法遵 循了上述流程,对于T 步累积奖赏，只需迭代T 轮就能精确地求出值函数. 参见习题16.2. 16.7算 法 的 第 3 行根据式(16.8)进行替换.此外，由于算法可能会迭代很多次, 对于忆7 , 由于旷在方很大时趋于0 , 因此也能使用类似的算法，只需将图 因此需设置一个停止准则.常见的是设置一个阈值4 若在执行一次迭代后值函 数的改变小于 6 则算法停止；相应的，图 16.7算 法 第 4 行中的力= 7 + 1 需替 换为 m a x \\V(x) — V f(x)\\ < 0 . xEX (16.9) 有了状态值函数匕就能直接计算出状态-动作值函数 % 纵力, a ) = E 有 + 争 呼 —1 3 ) ) ； < W W X (16.10) 际 但 a ) = £ 「黑 品 或 1 引 + 7 寸 3 ) ) . 1 w e x 16.3.2策 略 改 进 . 对某个策略的累积奖赏进行评估后，若发现它并非最优策略，则当然希望 对其进行改进.理想的策略应能最大化累积奖赏 7r* = arg m a x £ V 7r(力). (16.11) 380 第 1 6 章 强 化 学 习 一个强化学习任务可能有多个最优策略,最优策略所对应的值函数V * 称 为最优值函数，即 V/ € X : V * ⑺ = V 7r*3). (16.12)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 678
    }
  },
  {
    "page_content": "对其进行改进.理想的策略应能最大化累积奖赏 7r* = arg m a x £ V 7r(力). (16.11) 380 第 1 6 章 强 化 学 习 一个强化学习任务可能有多个最优策略,最优策略所对应的值函数V * 称 为最优值函数，即 V/ € X : V * ⑺ = V 7r*3). (16.12) 注意,当策略空间无约束时式(16.12)的 V * 才是最优策略对应的值函数,例如对 离散状态空间和离散动作空间，策略空间是所有状态上所有动作的组合，共有 |用因种不同的策略.若策略空间有约束，则 违 背 约 束 的 策 略 是 “不合法”的, 即便其值函数所取得的累积奖赏值最大,也不能作为最优值函数. 由 于 最 优 值 函 数 的 累 积 奖 赏 值 已 达 最 大 ，因 此 可 对 前 面 的 Bellman等 式(16.7)和(16.8)做一个改动，即将对动作的求和改为取最优： W 3 ) = 麒 耳 耳 t h 停 五 \" + ? 说 —1 3 ) ) ； 吟 ⑸ = 瞟 ”2 溢 * (成~^x, 十 )吟 3)). 换言之， V*(x) = m a x Q 7r*Q, a). aeA 代入式(16.10)可得最优状态-动作值函数 Q 乳6,a) = £ P * T X 人今璞C T X，+ < w ex 察 a E A - 。'))； Q ：Q , a ) = £ 耳 ，，ex 网 + ) n ^ Q K * a ，)). a E A (16.13) (16.14) (16.15) 上述关于最优值函数的等式，称为最优 Bellman等式，其唯一解是最优值函数. 最 优 Bellman等式揭示了非最优策略的改进方式：将策略选择的动作改变 为当前最优的动作.显然，这样的改变能使策略更好.不妨令动作改变后对应的 策 略 为 (改 变 动 作 的 条 件 为 Q 以对〃(彷)) V 万Q ) , 以 7 折扣累积奖赏为例, 由式(16.10)可计算出递推不等式 P 7r(①)W Q 7r(应穴’(力)) = fe x X ( 成 竺 + M 3 ) ) ・ £ 。% ( 成 竺 + 曾 3 时 3))) xfe x 1 6 . 3 有模型学习 381 (16.16) 值函数对于策略的每一点改进都是单调递增的，因此对于当前策略7T,可 放心地将其改进为 〃(①)= arg max Q7r(% a), aeA (16.17) 直到不，与 7T 一致、不再发生变化，此时就满足了最优Bellman等式，即找到了 最优策略. 16.3.3策略迭代与值迭代",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 679
    }
  },
  {
    "page_content": "xfe x 1 6 . 3 有模型学习 381 (16.16) 值函数对于策略的每一点改进都是单调递增的，因此对于当前策略7T,可 放心地将其改进为 〃(①)= arg max Q7r(% a), aeA (16.17) 直到不，与 7T 一致、不再发生变化，此时就满足了最优Bellman等式，即找到了 最优策略. 16.3.3策略迭代与值迭代 由前两小节我们知道了如何评估一个策略的值函数，以及在策略评估后如 何改进至获得最优策略.显然，将这两者结合起来即可得到求解最优解的方法: 从一个初始策略(通常是随机策略)出发，先进行策略评估，然后改进策略，评估 改进的策略，再进一步改进策略，……不断迭代进行策略评估和改进,直到策略 收敛、不再改变为止.这样的做法称为“策略迭代”(policy iteration). 图 16.8给出的算法描述,就是在基于T 步累积奖赏策略评估的基础上，加 输入：MDP 四元组 E = (X, 4, 累积奖赏参数T. 过程： 1： yx E X : V ⑺ = 0 , 7r(x,a) = 7r( % °)E a / W X 耳一修(手用 —廿 + 1 ^ 3 ) ) ； 2: loop 3: for t = 1,2,... do 4 ： \\/x £ X ： V r(x) = if t = T + 1 then 5： 6： 7： 8： 9： 10： 11： break else V = end if else break 12： 13： 14： 15： 16： end if 17: end loop 输出 ：最 优 策 略 7T 7T = 7T' end for Yx G X : TT/ Q ) = a r g m a x a € A Q(x,a); if Vrr : TT'Q ) = 7r3 ) then 图 1 6 . 8 基 于 T 步累积奖赏的策略迭代算法 |4 (乃 |是 2 状态下所有 可选动作数. 式(16.7)更新值函数. 式(16.10)计 算 Q 值. 382 参见习题1 6 3 式(16.18)更新值函数. 式(16.10)计 算 Q 值. 第 1 6 章 强 化 学 习 入策略改进而形成的策略迭代算法.类似的，可 得 到 基 于 7 折扣累积奖赏的策 略迭代算法.策略迭代算法在每次改进策略后都需重新进行策略评估，这通常 比较耗时. 由式(16.16)可知，策略改进与值函数的改进是一致的，因此可将策略改进 视为值函数的改善，即由式(16.13)可得",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 680
    }
  },
  {
    "page_content": "式(16.18)更新值函数. 式(16.10)计 算 Q 值. 第 1 6 章 强 化 学 习 入策略改进而形成的策略迭代算法.类似的，可 得 到 基 于 7 折扣累积奖赏的策 略迭代算法.策略迭代算法在每次改进策略后都需重新进行策略评估，这通常 比较耗时. 由式(16.16)可知，策略改进与值函数的改进是一致的，因此可将策略改进 视为值函数的改善，即由式(16.13)可得 % 力 ) = m a x a F E w c x 岑 T W G E - W + ? 攻 - 1 3 ) ) ； < 门人［只、 (16.18) ⑺ = m a x a e A £ w e x 有 - w (段- w + 7 匕 3 ) ) - 于是可得到值迭代(value iteration)算法，如 图 16.9所示. 输入：M D P 四元组E = (X, A, P ® ; 累积奖赏参数T ； 收敛阈值0 . Vrre.X: U ⑺ = m a x a€ A ^ , e X P ^ x.(淄 葭 ,，+ 『 V 侬))； if max°ex M Q ) — V f(x)\\ < 0 then 过程： 1： Vc e X ： V{x} = o； 2： for t = 1,2,... do 3： 4： 5： 6： 7： 8： end if 9： end for 输出：策略 7TQ ) = a r g m a X a w ^ Q Q , 。) V = V f break else 图 1 6 . 9 基于T 步累积奖赏的值迭代算法 若采 用 7 折扣累积奖赏，只 需 将 图 16.9算法中第 3 行替换为 V / G X : V ，⑺ = 噌 £ P \" (段 仔 ，+ 7 V 3 ) ) . (16.19) a Xyx 从上面的算法可看出，在模型已知时强化学习任务能归结为基于动态规划 的寻优问题.与监督学习不同，这里并未涉及到泛化能力，而是为每一个状态找 到最好的动作. 1 6 . 4 免模型学习 在现实的强化学习任务中，环境的转移概率、奖赏函数往往很难得知，甚 1 6 . 4 免模型学习 383 至很难知道环境中一共有多少状态.若学习算法不依赖于环境建模，则称为 亦 称 “无模型学习”. “免模型学习”(model-free learning),这比有模型学习要困难得多. 蒙特卡罗方法参见14.7 节；1 4 5 1 节中使用过马尔 可夫链蒙特卡罗方法. 16.4.1蒙特卡罗强化学习 在免模型情形下，策略迭代算法首先遇到的问题是策略无法评估，这是由 于模型未知而导致无法做全概率展开.止匕时，只能通过在环境中执行选择的动",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 681
    }
  },
  {
    "page_content": "亦 称 “无模型学习”. “免模型学习”(model-free learning),这比有模型学习要困难得多. 蒙特卡罗方法参见14.7 节；1 4 5 1 节中使用过马尔 可夫链蒙特卡罗方法. 16.4.1蒙特卡罗强化学习 在免模型情形下，策略迭代算法首先遇到的问题是策略无法评估，这是由 于模型未知而导致无法做全概率展开.止匕时，只能通过在环境中执行选择的动 作，来观察转移的状态和得到的奖赏.受K 摇臂赌博机的启发，一种直接的策 略评估替代方法是多次“采样”，然后求取平均累积奖赏来作为期望累积奖赏 的近似，这称为蒙特卡罗强化学习.由于采样必须为有限次数，因此该方法更适 合于使用T 步累积奖赏的强化学习任务. 另一方面，策略迭代算法估计的是状态值函数匕而最终的策略是通过状 态-动作值函数Q 来获得.当模型已知时，从 卜 到 Q 有很简单的转换方法，而 当模型未知时，这也会出现困难.于是，我们将估计对象从V 转 变 为 Q , 即估计 每 一 对 “状态-动作”的值函数. 此外，在模型未知的情形下，机器只能是从一个起始状态(或起始状态集 合)开始探索环境，而策略迭代算法由于需对每个状态分别进行估计，因此在这 种情形下无法实现.例如探索种瓜的过程只能从播下种子开始，而不能任意选 择种植过程中的一个状态开始.因此，我们只能在探索的过程中逐渐发现各个 状态并估计各状态-动作对的值函数. 综合起来,在模型未知的情形下，我们从起始状态出发，使用某种策略进行 采样,执行该策略T 步并获得轨迹 < g « 0 , n , ^ 1 , a 1 , 7,2, • . . , X T -l,C L T -l,rT , XT >, 然后，对轨迹中出现的每一对状态-动作，记录其后的奖赏之和，作为该状态-动 作对的一次累积奖赏采样值.多次采样得到多条轨迹后，将每个状态-动作对的 累积奖赏采样值进行平均，即得到状态-动作值函数的估计. 可以看出，欲较好地获得值函数的估计，就需要多条不同的采样轨迹.然 而，我们的策略有可能是确定性的，即对于某个状态只会输出一个动作，若使用 这样的策略进行采样，则只能得到多条相同的轨迹.这与K 摇 臂 赌 博 机 的 “仅 利 用 ”法面临相同的问题，因此可借鉴探索与利用折中的办法，例 如 使 用 e 贪 心法，以 €的概率从所有动作中均匀随机选取一个，以 1 - €的概率选取当前最 优动作.我们将确定性的策略7T称 为 “原始策略”，在原始策略上使用e 贪心 法的策略记为 384 第 1 6 章 强化学习 ，/ 、 7T ⑺ = ( 》(力)， 以 概 率 1 —a (16.20) \\a 中以均匀概率选取的动作， 以概率巳",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 682
    }
  },
  {
    "page_content": "心法，以 €的概率从所有动作中均匀随机选取一个，以 1 - €的概率选取当前最 优动作.我们将确定性的策略7T称 为 “原始策略”，在原始策略上使用e 贪心 法的策略记为 384 第 1 6 章 强化学习 ，/ 、 7T ⑺ = ( 》(力)， 以 概 率 1 —a (16.20) \\a 中以均匀概率选取的动作， 以概率巳 对 于 最 大 化 值 函 数 的 原 始 策 略a = a r g m a X a Q (6,a),其 e 贪 心 策 略 六 中 ，当前 假定只有一个最优动作・最 优 动 作 被 选 中 的 概 率 是 1 - 1 鬲 而 每 个 非 最 优 动 作 被 选 中 的 概 率 是 鬲 于是,每个动作都有可能被选取,而多次采样将会产生不同的采样轨迹. 与 策 略 迭 代 算 法 类 似 ，使 用 蒙 特 卡 罗 方 法 进 行 策 略 评 估 后 ，同 样 要 对 策 略 进 行 改 进 .前 面 在 讨 论 策 略 改 进 时 利 用 了 式 (16.16)揭 示 的 单 调 性 ，通过换 入 当 前 最 优 动 作 来 改 进 策 略 .对 于 任 意 原 始 策 略 7T,其 ■ 贪 心 策 略 7T€仅是将 €的 概 率 均 匀 分 配 给 所 有 动 作 ，因 此 对 于 最 大 化 值 函 数 的 原 始 策 略 7T；同样有 Q 万(力/，(力))2 V 万3 ) , 于 是 式 (16.16)仍 成 立 ，即可以使用同样方法来进行策略 改进. 图 16.10给 出 了 上 述 过 程 的 算 法 描 述 ，这 里 被 评 估 与 被 改 进 的 是 同 一 个 策 略，因 此 称 为 “同 策 略 ”(ompolicy)蒙 特 卡 罗 强 化 学 习 算 法 .算 法 中 奖 赏 均 值 采 用 增 量 式 计 算 ，每 采 样 出 一 条 轨 迹 ，就 根 据 该 轨 迹 涉 及 的 所 有 “状态■■动作” 对来对值函数进行更新. 输 入 ：环 境 E ; 动 作 空 间 A; 起 始 状 态 g ; 策略执行步数T . 过程： 1: Q & a ) = 0, c o u n te r, a) = 0, TT(X , a) = 高 ； 默认均匀概率选取动作. 采样第S 条轨迹. 对每一个状态-动作对. 计算轨迹中的累积奖赏. 式(16.2)更新平均奖赏. 4: 5: 6: 2: for s = 1 , 2 , … d o 3: 在 石 中 执 行 策 略 7T产生轨迹 7 1, < XQ : for t = 0 , 1 , . . . — 1 d o",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 683
    }
  },
  {
    "page_content": "默认均匀概率选取动作. 采样第S 条轨迹. 对每一个状态-动作对. 计算轨迹中的累积奖赏. 式(16.2)更新平均奖赏. 4: 5: 6: 2: for s = 1 , 2 , … d o 3: 在 石 中 执 行 策 略 7T产生轨迹 7 1, < XQ : for t = 0 , 1 , . . . — 1 d o 丁2) • • ・)力T—b ^ T —l ) ? 岔T > ； r t ； R = C/% c 、— Q M a t)X c o u n t(* a ± )+ R . W W 力 a ” 一 ， count ( g , at) = count ( g , 俐) + 1 c o u n t y ,a t )+ l 7: 8: 9: 对 所 有 已 见 状 态 * e n d for 根据值函数得到策略. 以概率 1 - 7V\\X. d ) = ［\\ 以均… 匀. r概 率、 从» 4 中，选,一取 动二 作一 ， 以—概 率」e . ( a rg m a x a , Q (x , a!), 10: e n d for 输 出 ：策 略 7T 图 1 6 . 1 0 同策略蒙特卡罗强化学习算法 1 6 . 4 免模型学习 385 同策略蒙特卡罗强化学习算法最终产生的是■贪心策略.然而，引入■贪 心是为了便于策略评估，在使用策略时并不需要♦ 贪心；实际上我们希望改进 的是原始(非。贪心)策略.那么，能否仅在策略评估时引入♦ 贪心，而在策略改 进时却改进原始策略呢？ 这其实是可行的.不妨用两个不同的策略7T和 N 来产生采样轨迹,两者的 区 别在于每个“状态-动作对\"被采样的概率不同.一般的，函 数 /在概率分布 P 下的期望可表达为 E[/] = / p(x)f(x)dx , (16.21) Jx 可通过从概率分布p 上的采样 ｛3 , ①2 , … ，力m ｝来 估 计f 的期望，即 1 m 现 力 = 不 £ / ( * ) ・ m i=i (16.22) 若引入另一个分布q , 则 函 数f 在概率分布p 下的期望也可等价地写为 回力= / Jx Q W . (16.23) 上 式 可 看 作 需 / ( / ) 在 分 布 q 下 的 期 望 ，因 此 通 过 在 q 上 的 采 样 M ， 这 样 基 于 一 个 分 布 的 采 样 来 估 计 另 一 个 分 布 下的期望，称为重要性采 样(importance sampling). 弘 … ,必 ｝可估计为 郎 ] = 羔 耨 八 八 (16.24)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 684
    }
  },
  {
    "page_content": "Q W . (16.23) 上 式 可 看 作 需 / ( / ) 在 分 布 q 下 的 期 望 ，因 此 通 过 在 q 上 的 采 样 M ， 这 样 基 于 一 个 分 布 的 采 样 来 估 计 另 一 个 分 布 下的期望，称为重要性采 样(importance sampling). 弘 … ,必 ｝可估计为 郎 ] = 羔 耨 八 八 (16.24) 回到我们的问题上来，使 用 策 略 7 T 的采样轨迹来评估策略不 实际上就是 对累积奖赏估计期望 1 m Q (①,a) = — £ n . (16.25) 2=1 若改用策略 7T，的采样轨迹来评估策略7 T ,则仅需对累积奖赏加权，即 1 J 11、D7T Q(x ,a) = — / m ， m i=i 4 (16.26) 其 中 P f 和 P f 分别表示两个策略产生第i条轨迹的概率.对于给定的一条轨 迹 Q o , a 。,『1 , , XT- I , aT -i,rT , xT ),策略万产生该轨迹的概率为 T-1 严 = 1 1 7rd 6 )% * + 】• (16.27) 2=0 386 第 1 6 章 强化学习 虽然这里用到了环境的转移概率F M - g + j 但式(16.24)中实际只需两个策略概 率的比值 1 T —1 黑 二 口 耍 鼻 , 尸7r 公 叫 3 , 电) (16.28) 若 7T为 确 定 性 策 略 而 7 / 是 7T的 ，贪心策略，则 冗 (即 出 )始 终 为 1, M 0 。 ) 为 向 或 「 \" 鬲 于 是 就 能 对 策 略 7T进 行 评 估 了 .图 1 6 .1 1 给出了 “异策 略”(off-policy)蒙特卡罗强化学习算法的描述. 输入:环境E; 动作空间A ； 起始状态3); 策略执行步数T. 默认均匀概率选取动作. 采样第S 条轨迹. 过程： 1： Q（x ,a ） = 0, count （a;, a） = 0 , 开（7 ,。）= 2： for s = 1 ,2 ,... do 3： 在 E 中执行7T的.贪心策略产生轨迹 V X。30-0） 72） ・, ・）力丁一b QT—1, TT, a T ＞； 重要性采样系数. . “ f l - e + e/|A |, 出 =开（乃； 1e/ 园 ， 计算修正的累积奖赏. 式( 1 6 2 ) 更新平均奖赏. 根据值函数得到策略. for t = 0 ,1 ,..., T — 1 do",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 685
    }
  },
  {
    "page_content": "V X。30-0） 72） ・, ・）力丁一b QT—1, TT, a T ＞； 重要性采样系数. . “ f l - e + e/|A |, 出 =开（乃； 1e/ 园 ， 计算修正的累积奖赏. 式( 1 6 2 ) 更新平均奖赏. 根据值函数得到策略. for t = 0 ,1 ,..., T — 1 do £：=七+1（/ x Tlj=i 吉）； R = CM c \\ — Q（MMt）xcount（a；t,at）+A. ， count 即生）+1 count （g , at） = count （g , 俐）+ 1 en d for 7T(c) = arg maxa / Q(x, af ) 5： 6： 7. /. 8： 9： 10： 11： en d for 输出：策略7T 图 1 6 . 1 1 异策略蒙特卡罗强化学习算法 1 6 .4 .2 时序差分学习 蒙特卡罗强化学习算法通过考虑采样轨迹，克服了模型未知给策略估计造 成的困难.此类算法需在完成一个采样轨迹后再更新策略的值估计，而前面介 绍的基于动态规划的策略迭代和值迭代算法在每执行一步策略后就进行值函 数更新.两者相比，蒙特卡罗强化学习算法的效率低得多，这里的主要问题是 蒙特卡罗强化学习算法没有充分利用强化学习任务的M D P 结 构 .时 序 差 分 (Tem poral D ifferen ce,简 称 T D ) 学习则结合了动态规划与蒙特卡罗方法的思 想，能做到更高效的免模型学习. 蒙特卡罗强化学习算法的本质，是通过多次尝试后求平均来作为期望累 1 6 . 4 免模型学习 387 积奖赏的近似，但 它 在 求 平 均 时 是 “批 处 理 式 ”进行的，即在一个完整的采 样轨迹完成后再对所有的状态-动作对进行更新.实际上这个更新过程能增 量 式 进 行 . 对 于 状 态 -动 作 对 不 妨 假 定 基 于 方 个 采 样 已 估 计 出 值 函 数 Q f⑶ 。) = | E L i n , 则在得到第t + 1 个 采 样 々+1 时,类似式(16.3),有 Q仅式/,a) = a) + -^― (rt+1 - a)). (16.29) 显然，只 需 给 加 上 增 量 + g + i - Q：( e a ) ) 即可.更一般的，将 + 替 换 为 系 数 m i , 则可将增量项写作的+1(々+1 - Q f(伤a ) ) . 在实践中通常令",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 686
    }
  },
  {
    "page_content": "Q仅式/,a) = a) + -^― (rt+1 - a)). (16.29) 显然，只 需 给 加 上 增 量 + g + i - Q：( e a ) ) 即可.更一般的，将 + 替 换 为 系 数 m i , 则可将增量项写作的+1(々+1 - Q f(伤a ) ) . 在实践中通常令 必 为 一 个 较 小 的 正 数 值 必 若 将 Q f Q ,a ) 展开为每步累积奖赏之和，则可看出 系数之和为1 , 即 令 at = a 不会影响Q t 是累积奖赏之和这一性质.更新步长a 越大，则越靠后的累积奖赏越重要. 以 7 折扣累积奖赏为例，利用动态规划方法且考虑到模型未知时使用状 态-动作值函数更方便，由式(16.10)有 Q穴住a) = £ P匕 W㈤ 七 + 7 丁 ”)) wex = E * WwX 通过增量求和可得 (* + ) £ » ( 力 川 3 川). (16.30) areA Qt+i(力，a) = Qt (力，a) + a 网 T X，+ iQt 〃)一 Q；(力，。))， (16.31) 其 中 a 是前一次在状态力执行动作a 后转移到的状态，a!是策略我在步上选 择的动作. 使用式(16.31),每执行一步策略就更新一次值函数估计，于是得到图16.12 的算法.该算法由于每次更新值函数需知道前一步的状态(state)、前一步的动 作(action)、奖赏值(reward)、当前状态(state)、将要执行的动作(ac tio n ),由 此得名为 Sarsa 算 法 [Rummery and Niranjan, 1994].显然，Sarsa 是一个同策 略算法，算法中评估(第6 行)、执行(第5 行)的均为e 贪心策略. 将 Sarsa修改为异策略算法，则 得到图16.13描 述 的 Q-学习(Q-learning)算 法 [Watkins and Dayan, 1992],该算法评估(第6 行)的是土贪心策略,而执行(第 5 行)的是原始策略. 将这几个英文单词的首 字母连起来. 388 第 1 6 章强化 学 习 默认均匀概率选取动作. 单步执行策略. 原始策略的e-贪心策略. 式(16.31)更新值函数. 默认均匀概率选取动作.. 单步执行策略. 原始策略. 式(16.31)更新值函数. 输 入 ：环 境 E ； 动 作 空 间 4 起 始 状 态 如 ； 奖 赏 折 扣 7 ； 更 新 步 长 a. 过程： 1： Q(x, a) = 0, 7 r o ,。) =",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 687
    }
  },
  {
    "page_content": "默认均匀概率选取动作. 单步执行策略. 原始策略的e-贪心策略. 式(16.31)更新值函数. 默认均匀概率选取动作.. 单步执行策略. 原始策略. 式(16.31)更新值函数. 输 入 ：环 境 E ； 动 作 空 间 4 起 始 状 态 如 ； 奖 赏 折 扣 7 ； 更 新 步 长 a. 过程： 1： Q(x, a) = 0, 7 r o ,。) = 2: x = XQ, a = TTQ ) ； 3: for t = 1,2,... do 4: r,康 = 在 E 中执行动作a 产生的奖赏与转移的状态； 5： a!= 万晨镇)； Q (力，a) = Q(x, a) + a(r + ?Q(x', a!) — Q(x, a)); 6： 7: 7T(a?) = a r g m a x o /, Q(a7,a,/)； 8： 9 ： end for 输出 ：策 略 7T x = xf 1a = a! 图 16.12 Sarsa 算法 输 入 ：环 境 E; 动 作 空 间 A; 起 始 状 态 g ; 奖 赏 折 扣 7 ； 更 新 步 长 Q. 过程 ： 1： Q(x, a) = 0, TT(X , a)= 图叫; 2: x = &); 3: for t = 1 ,2 ,... do 4: T ,才 = 在 E 中执行动作K Q ) 产生的奖赏与转移的状态； a!= 笈3 ) ； 5： 6： Q(x,a) = Q(x,a) + Q ( r + 7: 7f(/) = a r g m a x a „ Q ( q , a 〃)； 8： 9： end for 输 出 ：策 略 7T x = xf, a = a! a 7) - Q(a,a)); 图 16.13 Q-学习算法 1 6 .5 值函数近似 前面我们一直假定强化学习任务是在有限状态空间上进行，每个状态可 用一个编号来指代；值函数则是关于有限状态的“表 格 值 函 数 \"(tabular value function),即值函数能表示为一个数组，输 入 i对应的函数值就是数组元素i的 值,且更改一个状态上的值不会影响其他状态上的值.然而，现实强化学习任务 1 6 . 5 值函数近似 389 所面临的状态空间往往是连续的，有无穷多个状态.这该怎么办呢? 一个直接的想法是对状态空间进行离散化，将连续状态空间转化为有限离 散状态空间，然后就能使用前面介绍的方法求解.遗憾的是，如何有效地对状态 空间进行离散化是一个难题,尤其是在对状态空间进行探索之前. 实际上，我们不妨直接对连续状态空间的值函数进行学习.假定状态空间",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 688
    }
  },
  {
    "page_content": "1 6 . 5 值函数近似 389 所面临的状态空间往往是连续的，有无穷多个状态.这该怎么办呢? 一个直接的想法是对状态空间进行离散化，将连续状态空间转化为有限离 散状态空间，然后就能使用前面介绍的方法求解.遗憾的是，如何有效地对状态 空间进行离散化是一个难题,尤其是在对状态空间进行探索之前. 实际上，我们不妨直接对连续状态空间的值函数进行学习.假定状态空间 为 n 维实数空间X = R \" , 此时显然无法用表格值函数来记录状态值.先考虑简 单情形，即值函数能表达为状态的线性函数［Busoniu et al., 2010］ Ve {x) = 0T x , (16.32) 其 中 x 为状态向量，0 为 参 数 向 量 .由 于 此 时 的 值 函 数 难 以 像 有 限 状 态 那 样精确记录每个状态的值，因此这样值函数的求解被称为值函数近似 (value function approximation). 我们希望通过式(16.32)学得的值函数尽可能近似真实值函数V 、 近似程 度常用最小二乘误差来度量： E e = % ~ 万 ［( V 7r ⑺ - / (x)) 2 ］ , (16.33) 其中旧0 ~ 7 r 表示由策略7T所采样而得的状态上的期望. 为了使误差最小化,采用梯度下降法,对误差求负导数 -嗡= R ” ㈤ - 修 ㈤ = % ~ 万 ［2 ( V 乃3 ) — % 3 ) ) 句 ， (16.34) 于是可得到对于单个样本的更新规则 0 = 0 + a ( h Q ) - %(宏))⑦「 (16.35) 、我 们 并 不 知 道 策 略 的 真 实 值 函 数 卜 乃 ，但 可 借 助 时 序 差 分 学 习 ，基于 『万Q ) = 7 + 7 卜%苏)用当前估计的值函数代替真实值函数，即 3 = 0-i- a(r + — % Q ) ) x = 6 + a(r + yOT x f — 0T x) x , (16.36) 390 第 16章强化学习 其中必是下一时刻的状态. 需注意的是，在时序差分学习中需要状态-动作值函数以便获取策略.这里 一种简单的做法是令0 作用于表示状态和动作的联合向量上，例如给状态向量 增加一维用于存放动作编号，即将式(16.32)中的宏替换为Q ; a ) ; 另一种做法是 用 0 / 1 对动作选择进行编码得到向量a = (0;...; 1;... ;0),其 中 “1 ”表示该动 作被选择，再将状态向量与其合并得到(宓;a ) , 用于替换式(16.32)中 的 公 这 样 就使得线性近似的对象为状态-动作值函数.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 689
    }
  },
  {
    "page_content": "增加一维用于存放动作编号，即将式(16.32)中的宏替换为Q ; a ) ; 另一种做法是 用 0 / 1 对动作选择进行编码得到向量a = (0;...; 1;... ;0),其 中 “1 ”表示该动 作被选择，再将状态向量与其合并得到(宓;a ) , 用于替换式(16.32)中 的 公 这 样 就使得线性近似的对象为状态-动作值函数. 基于线性值函数近似来替代Sarsa算法中的值函数，即 可 得 到 图 16.14的 线性值函数近似Sarsa算法.类似地可得到线性值函数近似Q - 学习算法.显然, 可以容易地用其他学习方法来代替式(16.32)中的线性学习器，例如通过引入核 核方法参见第6 章. 方法实现非线性值函数近似. 原始策略的e-贪心策略. 、 式(16.36)更新参数. 输入：环境E; 动作空间4; 起始状态比; 奖赏折扣7 ； 更新步长a. 过程： 1： 6 = 0; x = X Q, a = 7T(x) = ar g m a x a ,/ 8 T (①；a〃)； 3： fo r t = 1 , 2 , . . . d o 4： 〃 W = 在 E 中执行动作a 产生的奖赏与转移的状态； 5： a! = 7re (cc,)j 6： 0 = 0 + a(r + y0T {xf; a') — 0T {x; a))(①;a); 7： 8： x = x\\a = af 9： e n d fo r 输出：策略7F 7r(cc) = a r gmax a z, 61(比；/); 图 16.14 线性值函数近似Sarsa算法 1 6 .6 模仿学习 亦 称 “学 徒 学 习 ” (apprenticeship learning), \" 示 范 学 习 \" (learning from d e m o n s tra tio n ),“观 察 学 习 ” (learning by w a tc h in g );与机器学习早 期 的 “示教学习”有直接 联系，参 见 1 .5 节. 在强化学习的经典任务设置中，机器所能获得的反馈信息仅有多步决策后 的累积奖赏，但在现实任务中，往往能得到人类专家的决策过程范例，例如在种 瓜任务上能得到农业专家的种植过程范例.从这样的范例中学习，称 为 “模仿 学习” (imitation learning). 1 6 . 6 模仿学习 391 16.6.1 直接模仿学习 强化学习任务中多步决策的搜索空间巨大，基于累积奖赏来学习很多步之 前的合适决策非常困难，而直接模仿人类专家的“状态-动作对”可显著缓解这 一困难，我 们 称 其 为 “直接模仿学习”.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 690
    }
  },
  {
    "page_content": "瓜任务上能得到农业专家的种植过程范例.从这样的范例中学习，称 为 “模仿 学习” (imitation learning). 1 6 . 6 模仿学习 391 16.6.1 直接模仿学习 强化学习任务中多步决策的搜索空间巨大，基于累积奖赏来学习很多步之 前的合适决策非常困难，而直接模仿人类专家的“状态-动作对”可显著缓解这 一困难，我 们 称 其 为 “直接模仿学习”. 假定我们获得了一批人类专家的决策轨迹数据｛T b T 2 , 每条轨迹 包含状态和动作序列 T i — … ，5 ni+l)5 其 中 期 为 第 Z 条轨迹中的转移次数. 有了这样的数据，就相当于告诉机器在什么状态下应选择什么动作，于是 可利用监督学习来学得符合人类专家决策轨迹数据的策略. 我们可将所有轨迹上的所有“状态-动作对”抽取出来,构造出一个新的数 据集合 D = ｛0 1 , 肉），（5 2 , 。2 ）_ . . ，（5 £ 之1 电，。£建 1 电）｝， 即把状态作为特征，动作作为标记；然后，对这个新构造出的数据集合。 使用 分类（对于离散动作）或回归（对于连续动作）算法即可学得策略模型.学得的这 个策略模型可作为机器进行强化学习的初始策略，再通过强化学习方法基于环 境反馈进行改进,从而获得更好的策略. 16.6.2 逆强化学习 在很多任务中，设计奖赏函数往往相当困难，从人类专家提供的范例数据 中反推出奖赏函数有助于解决该问题，这 就 是 逆 强 化 学 习 （inverse reinforce­ ment learning） [Abbeel and Ng, 2004]. 在逆强化学习中，我们知道状态空间X 、动 作 空 间 4 并且与直接模仿学 逆强化学习的基本思想是：欲 习类似，有 一 个 决 策 轨 迹 数 据 集 … 使机器做出与范例一致的行为，等价于在某个奖赏函数的环境中求解最优策略, 该最优策略所产生的轨迹与范例数据一致.换言之，我们要寻找某种奖赏函数 使得范例数据是最优的，然后即可使用这个奖赏函数来训练强化学习策略. 不妨假设奖赏函数能表达为状态特征的线性函数，即兄（⑼ = W T X. 于是, 策 略 7 T 的累积奖赏可写为 ~ + 8 ' E £ 优 口 ＞ 力 \" = E 0 7r = ~+CXD ,t=0 . _i=0 7T 392 = W T E \"+oo _t=o \". 17T . , 即 状 态 向 量 加 权 和 的 期 望 与 系 数 %的 内 积 . 第 1 6 章强化学习 （16.37） 将 状 态 向 量 的 期 望 旧 ［£ 肾 I ,TT］简写为历， 注意到获得近万需求取期",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 691
    }
  },
  {
    "page_content": "= E 0 7r = ~+CXD ,t=0 . _i=0 7T 392 = W T E \"+oo _t=o \". 17T . , 即 状 态 向 量 加 权 和 的 期 望 与 系 数 %的 内 积 . 第 1 6 章强化学习 （16.37） 将 状 态 向 量 的 期 望 旧 ［£ 肾 I ,TT］简写为历， 注意到获得近万需求取期 望 .我 们 可 使 用 蒙 特 卡 罗 方 法 通 过 采 样 来 近 似 期 望 ，而范例轨迹数 据 集 恰 可 看 作最优策略的一个采样，于 是 ，可将每条范例轨迹上的状态加权求和再平均，记 为 历 *.对 于 最 优 奖 赏 函 数R （x} = w ^ x 和 任 意 其 他 策 略 产 生 的 Z万，有 w*T历* - 付 * % 7r = w*T（历* —名乃））0 . （16.38） 若 能 对 所 有 策 略 计 算 出 （历* - ①专，即可解出 w* = arg max min w T （^* —①万） 7r w （16.39） S.t. ||w|| 4 1 显 然 ，我们难以获得所有策略，一 个 较 好的办法是从随机策略开始，迭代地 求 解 更 好 的 奖 赏 函 数 ，基 于 奖 赏 函 数 获 得 更 好 的 策 略 ，直 至 最 终 获 得 最 符 合 范 例 轨 迹 数 据 集 的 奖 赏 函 数 和 策 略 ，如 图 16.15算 法 所 示 .注 意 在 求 解 更 好 的 奖 赏函数时，需将式（16.39）中对所有策略求最小改为对之前学得的策略求最小. 输入：环 境 E ； 状态空间X ; 动作空间A- 范例轨迹数据集。 = S ，% … 过程： 1：名*=从范例轨迹中算出状态加权和的均值向量； 2： 7T = 随机策略； 3 ： for 力= 1 , 2 , ... d o 4 ： 5 ： 求 解 切 * = 8埸 11120%］1111忆 111/11（历*一理） s.t. ||w|| 6 ： 7: e n d for = 从 7T的采样轨迹算出状态加权和的均值向量； 7T = 在 环 境 （X , A,五 ⑻ = 中求解最优策略； 1; 输出：奖赏函数R （X）= W^T X 与策略7T 图 16.15 迭代式逆强化学习算法 1 6 . 7 阅读材料 393 1 6 .7 阅读材料 强化学习专门书籍中最著名的是［Sutton and Barto, 1998］. ［Gosavi, 2003］",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 692
    }
  },
  {
    "page_content": "7T = 在 环 境 （X , A,五 ⑻ = 中求解最优策略； 1; 输出：奖赏函数R （X）= W^T X 与策略7T 图 16.15 迭代式逆强化学习算法 1 6 . 7 阅读材料 393 1 6 .7 阅读材料 强化学习专门书籍中最著名的是［Sutton and Barto, 1998］. ［Gosavi, 2003］ 从优化的角度来讨论强化学习，［Whiteson, 2010］则侧重于介绍基于演化算法 搜索的强化学习方法. ［Mausam and Kolobov, 2012］从马尔可夫决策过程的视 角介绍强化学习，［Sigaud and Buffet, 2010］覆盖了很多内容，包括本章未介绍 的部分可观察马尔可夫决策过程(Partially Observable M D P,简 称 POMDP)、 策略梯度法等.基于值函数近似的强化学习可参阅［Busoniu et a l, 2010］. 欧洲强化学习研讨会(EWRL)是专门性的强化学习系列研讨会，多学科强 化学习与决策会议(RLDM)则 是 从 2013年开始的新会议. ［Kaelbling et al., 1996］是一个较早的强化学习综述，［Kober et al., 2013; Deisenroth et al., 2013］则综述了强化学习在机器人领域的应用. ［Kuleshov and Precup, 2000］ ［Vermorel and Mohri, 2005］介绍了 多种 K -摇臂赌博机算法并进行了比较.多摇臂赌博机模型在统计学领域有大量研 究 ［Berry and Fristedt, 1985］, 近 年 来 在 “在线学习 ”(online learning)> “对 抗学习”(adversarial learning)等方面有广泛应用\"Bubeck and Cesa-Bianchi, 2012］对 其 “悔界”(regret bound)分析方面的结果进行了综述. 时 序 差 分 (TD)学 习 最 早 是 A. Sam uel在 他 著 名 的 跳 棋 工 作 中 提 出 , ［Sutton, 1988］提出了 TD (X )算法，由 于 ［Tesauro, 1995］基于 TD(X)研制的",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 693
    }
  },
  {
    "page_content": "时 序 差 分 (TD)学 习 最 早 是 A. Sam uel在 他 著 名 的 跳 棋 工 作 中 提 出 , ［Sutton, 1988］提出了 TD (X )算法，由 于 ［Tesauro, 1995］基于 TD(X)研制的 TD-Gammon程序在西洋双陆棋上达到人类世界冠军水平而使T D 学习备受 关 注 .Q-学 习 算 法 是［Watkins and Dayan, 1992］提出，Sarsa则 是 在 Q-学习算 法 基 础 上 的 改 进 ［Rummery and Niranjan, 1994］. T D 学习近年来仍有改进和 推广，例 如 广 义 T D 学 习 ［Ueno et al., 2011］> 使用资格迹(eligibility traces)的 TD 学 习 ［Geist and Scherrer, 2014］等 . ［Dann et al., 2014］对 TD 学习中的策略 评估方法进行了比较. 模仿学习被认为是强化学习提速的重要手段［Lin, 1992; Price and Boutili- er, 2003］, 在机器人领域被广泛使用［Argali et al., 2009］. ［Abbeel and Ng, 2004; Langford and Zadrozny, 2005］提出了逆强化学习方法. 在 运 筹 学 与 控 制 论 领 域 ，强 化 学 习 方 面 的 研 究 被 称 为 “近 似 动 态 规 戈 (approximate dynamic programming), 可 参 阅 ［Bertsekas, 2012］. “后悔”(regret)是指在 不确定性条件下的决策与 确定性条件下的决策所获 得的奖赏间的差别. Sam uel跳 棋 工 作 参 见 p.22. 394 第 1 6 章 强 化 学 习 习题 16.1 用 于 K -摇臂赌博机的UCB （Upper Confidence B ound,上置信界）方 法每次选择Q（k） + U C ⑹ 最大的摇臂，其 中 Q ⑹ 为 摇 臂k 当前的平 均奖赏，U C ⑹ 为置信区间.例如 其中九为已执行所有摇臂的总次数，nk 为已执行摇臂k 的次数.试比 较 U C B 方法与■贪心法和Softmax方法的异同. 16.2 借 鉴 图 16.7,试写出基于 7 折扣奖赏函数的策略评估算法. 16.3 借 鉴 图 16.8,试写出基于）折扣奖赏函数的策略迭代算法. 16.4 在 没 有 M D P 模型时，可以先学习M D P 模型（例如使用随机策略进行 采样，从样本中估计出转移函数和奖赏函数），然后再使用有模型强化",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 694
    }
  },
  {
    "page_content": "16.2 借 鉴 图 16.7,试写出基于 7 折扣奖赏函数的策略评估算法. 16.3 借 鉴 图 16.8,试写出基于）折扣奖赏函数的策略迭代算法. 16.4 在 没 有 M D P 模型时，可以先学习M D P 模型（例如使用随机策略进行 采样，从样本中估计出转移函数和奖赏函数），然后再使用有模型强化 学习方法.试述该方法与免模型强化学习方法的优缺点. 16.5 试推导 出Sarsa算法的更新公式（16.31）. 16.6 试 借 鉴 图 16.14给出线性值函数近似Q-学习算法. 16.7 线性值函数近似在实践中往往有较大误差.试结合B P 神经网络，将 线性值函数近似Sarsa算法推广为使用神经网络近似的Sarsa算法. 16.8 试结合核方法，将线性值函数近似Sarsa算法推广为使用核函数的非 线性值函数近似Sarsa算法. 16.9 对于目标驱动（goal-directed）的强化学习任务，目标是到达某一状态, 例如将汽车驾驶到预定位置.试为这样的任务设置奖赏函数，并讨论 不同奖赏函数的作用（例如每一步未达目标的奖赏为0、- 1 或 1）. 16.10 * 与传统监督学习不同，直接模仿学习在不同时刻所面临的数据分布可 能不同.试设计一个考虑不同时刻数据分布变化的模仿学习算法. 参考文献 395 参考文献 Abbeel, P. and A. Y. Ng. (2004). uApprenticeship learning via inverse rein­ forcement learning.5, In Proceedings of the 21st International Conference on Machine Learning (ICML)^ Banff, Canada. • Argali, B. D., S. Chernova, M. Veloso, and B. Browning. (2009). “A survey of robot learning from demonstration.5, Robotics and Autonomous Systems^ 57(5):469-483. Berry, D. and B. Fristedt. (1985). Bandit Problems. Chapman & Hall/CRC, London, UK. Bertsekas, D. P. (2012). Dynamic Programming and Optimal Control: Approx­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 695
    }
  },
  {
    "page_content": "57(5):469-483. Berry, D. and B. Fristedt. (1985). Bandit Problems. Chapman & Hall/CRC, London, UK. Bertsekas, D. P. (2012). Dynamic Programming and Optimal Control: Approx­ imate Dynamic Programming^ 4th edition. Athena Scientific, Nashua, NH. Bubeck, S. and N. Cesa-Bianchi. (2012). “Regret analysis of stochastic and nonstochastic multi-armed bandit p ro b le m s .Foundations and Trends in Machine Learning, 5(1):1-122. Busoniu, L., R. Babuska, B. De Schutt er, and D. Ernst. (2010). Reinforcement Learning and Dynamic Programming Using Function Approximators. Chap­ man & Hall/CRC Press, Boca Raton, FL. Dann, C., G. Neumann, and J. Peters. (2014). “Policy evaluation with tem­ poral differences: A survey and c o m p a riso n .Journal of Machine Learning Research, 15:809-883. Deisenroth, M. P., G. Neumann, and J. Peters. (2013). “A survey on policy search for robotics.,, Foundations and Trends in Robotics1 2(1-2):1-142. Geist, M. and B. Scherrer. (2014), “Off-policy learning with eligibility traces:",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 696
    }
  },
  {
    "page_content": "search for robotics.,, Foundations and Trends in Robotics1 2(1-2):1-142. Geist, M. and B. Scherrer. (2014), “Off-policy learning with eligibility traces: A survey.\" Journal of Machine Learning Research, 15:289-333. Gosavi, A. (2003). Simulation-Based Optimization: Parametric Optimization Techniques and Reinforcement Learning. Kluwer, Norwell, MA. Kaelbling, L. P., M. L. Littman, and A. W. Moore. (1996). ^Reinforcement learning: A s u r v e y .Journal of Artificial Intelligence Research1 4:237-285. Kober, J., J. A. Bagnell, and J. Peters. (2013). ^Reinforcement learning in robotics: A survey.,, International Journal on Robotics Research, 32(11): 1238-1274. Kuleshov, V. and D. Precup. (2000). uAlgorithms for the multi-armed bandit 396 第 1 6 章 强 化 学 习 problem.55 Journal of Machine Learning Research^ 1:1-48. Langford, J. and B. Zadrozny. (2005). “Relating reinforcement learning perfor­ mance to classification performance.” In Proceedings of the 22nd Interna­ tional Conference on Machine Learning (ICML), 473-480, Bonn, Germany.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 697
    }
  },
  {
    "page_content": "mance to classification performance.” In Proceedings of the 22nd Interna­ tional Conference on Machine Learning (ICML), 473-480, Bonn, Germany. Lin, L.-J. (1992). “Sel&improving reactive agents based on reinforcement learn­ ing, planning and teaching.,5 Machine Learning^ 8(3-4):293-321. Mausam and A. Kolobov. (2012). Planning with Markov Decision Processes: An A I Perspective. Morgan & Claypool, San Rafael, CA. Price, B. and C. Boutilier. (2003). uAccelerating reinforcement learning through implicit imitation.55 Journal of Artificial Intelligence Research, 19: 569-629. Rummery, G. A. and M. Niranjan. (1994). “On-line Q-learning using connec- tionist systems75 Technical Report CUED/F-INFENG/TR 166, Engineering Department, Cambridge University, Cambridge, UK. Sigaud, O. and O. Buffet. (2010). Markov Decision Processes in Artificial In­ telligence. Wiley, Hoboken, NJ. Sutton, R. S. (1988). “Learning to predict by the methods of temporal differ­ ences.,5 Machine Learning, 3(l):9-44. Sutton, R. S. and A. G. Barto. (1998). Reinforcement Learning: An Introduc­",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 698
    }
  },
  {
    "page_content": "ences.,5 Machine Learning, 3(l):9-44. Sutton, R. S. and A. G. Barto. (1998). Reinforcement Learning: An Introduc­ tion. MIT Press, Cambridge, MA. Tesauro, G. (1995). “Temporal difference learning and TD-Gammon.^^ Com­ munications of the ACM, 38(3):58-68. Ueno, T., S. Maeda, M. Kawanabe, and S. Ishii. (2011). ^Generalized TD learn­ ing.5, Journal of Machine Learning Research 12:1977-2020. Ver mor el, J. and M. Mohri. (2005). uMulti-armed bandit algorithms and empir­ ical evaluation.,5 In Proceedings of the 16th European Conference on Machine Learning (ECML), 437-448, Porto, Portugal. Watkins, C. J. C. H. and P. Dayan. (1992). “Q-learning.” Machine Learning1 8 (3-4):279-292. 、 Whiteson, S. (2010). Adaptive Representations for Reinforcement Learning. Springer, Berlin. 休息一会儿 397 休息一会儿 切比雪夫在圣彼得堡大 学培养出马尔可夫、李亚 普诺夫、柯尔金、格拉维 等著名数学家，还影响了 圣彼得堡大学之外的很多 数学家.圣彼得堡学派标 志着俄罗斯数学走到了世 界前沿. 小故事：马尔可夫决策过程与安德烈•马尔可夫 安 德 烈 •安 德 烈 维 奇 •马 尔 可 夫 (Andrey Andreyevich Markov, 1856— 1922)是著名俄罗斯数学家、圣彼得堡数学 学派代表性人物，在概率论、数论、函数逼近论、微分方程 等方面有重要贡献. , 马尔可夫出生在莫斯科东南的梁赞(Ryazan), 1 7 岁时 独立发现了一种线性常微分方程的解法，引起了圣彼得堡大学几位数学家的注",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 699
    }
  },
  {
    "page_content": "安 德 烈 •安 德 烈 维 奇 •马 尔 可 夫 (Andrey Andreyevich Markov, 1856— 1922)是著名俄罗斯数学家、圣彼得堡数学 学派代表性人物，在概率论、数论、函数逼近论、微分方程 等方面有重要贡献. , 马尔可夫出生在莫斯科东南的梁赞(Ryazan), 1 7 岁时 独立发现了一种线性常微分方程的解法，引起了圣彼得堡大学几位数学家的注 意 . 1874年他考入圣彼得堡大学数学系，1878年毕业并留校任教，1884年获博 士学位，导师是圣彼得堡学派领袖、著名数学家切比雪夫.此后马尔可夫一直 在圣彼得堡大学任教.马尔可夫在早期主要是沿着切比雪夫开创的方向，改进 和完善了大数定律和中心极限定理，但他最重要的工作无疑是开辟了随机过程 这个领域.他在1906— 1912年间提出了马尔可夫链，开创了对马尔可夫过程的 研究.现实世界里小到分子的布朗运动、大到传染病流行过程，马尔可夫过程 几 乎 无 所 不 在 .在 他 的 名 著 《概率演算》 中，马尔可夫是以普希金的长诗《叶 甫 根 尼 •奥 涅 金 》 中元、辅音字母变化的规律为例来展示马尔可夫链的性质. 马尔可夫决策过程是马尔可夫过程与确定性动态规划的结合,基本思想在二十 世纪五十年代出现，此时马尔可夫已去世三十多年了. 马 尔 可夫的儿子也叫安德烈-安德烈维奇•马尔可夫(1903— 1 9 7 9 ),也是 著名数学家，数 理 逻 辑 中 的 “马 尔 可 夫 原 则 \"(Markov Principle)、 “马尔可夫 规则”(Markov R u le ),理论计算机科学中图灵完备的“马尔可夫算法”等，是 以小马尔可夫的名字命名的.马尔可夫的弟弟弗拉基米尔・安德烈维奇・马尔 可夫(1871— 1897)也是一位数学家， “马尔可夫兄弟不等式”就是以他和哥哥 安德烈的名字命名的. 附 录 A 矩阵 A .1 基本演算 记 实 矩 阵 A e Rm x n 第 i行 第 j 列 的 元 素 为 (A % = 4 力 矩 阵 A 的转 置(transpose)记为 A T , (AT )ij = Aji，显然， (A + B)T = AT + BT , (AB)T = B T AT . (A.l) (A.2) 常直接用I 表示单位阵.人的逆矩阵A - 1 满 足 A A —i = A —1A = I . 不难发现， 对于矩阵A e Rm x n , 若m = n 则 称 为n 阶 方 阵 .用 J 表示九阶单位阵，方阵 (A T )T = (A - I )T , (A B )- 1 = B T A T . (A.3)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 700
    }
  },
  {
    "page_content": "(A.l) (A.2) 常直接用I 表示单位阵.人的逆矩阵A - 1 满 足 A A —i = A —1A = I . 不难发现， 对于矩阵A e Rm x n , 若m = n 则 称 为n 阶 方 阵 .用 J 表示九阶单位阵，方阵 (A T )T = (A - I )T , (A B )- 1 = B T A T . (A.3) (A.4) 对 于 n 阶 方 阵 A , 它 的 迹 (trace)是 主 对 角 线 上 的 元 素 之 和 ，即 t r ( A ) = £ 忆 1 4 法迹有如下性质： tr(A T ) = tr(A ) , tr(A + B) = tr(A ) + tr(B) , tr(A B ) = tr(BA ) , tr(A B C ) = tr(B C A ) = tr(C A B ) . n 阶 方 阵A 的行列式(determinant)定义为 det (A) = £ par(cr)Ai(T1A2(T 2... A 1(Tn , creSn (A.5) (A.6) (A.7) (A.8) (A.9) 其 中 sn 为 所 有 n 阶排列(permutation)的集合，p ar(cr)的 值 为 - 1 或 + 1 取决 于 。= ( 内曾2, • • . , 吟 为奇排列或偶排列，即其中出现降序的次数为奇数或偶 400 附 录 数，例 如 (1 ,3 ,2 ) 中 降 序 次 数 为1, (1 ,4 ,3 ,2 )中降序次数为2 . 对于单位阵，有 det(I) = 1. 对 于 2 阶方阵，有 det(A) = det ( A A 1 2 \\ ^ L21 4 2 2 = 4 1 1 力22 — 4 1 2 4 2 1 • n 阶 方 阵A 的行列式有如下性质: det(cA) = cn det (A) , det(A T ) = det (A) , det(AB) = det(A) det(B) , det(A _ 1 ) = det(A )- 1 , det(A n ) = det(A)n . (A.10) (A .ll) (A.12) (A.13) (A. 14) 矩 阵 A e Rm x n W Frobenius范数定义为 IIAIIF = (tr(A T A )) 1 /2 = fm n \\ 1/2 蜀 ) V = 1 j=i . (A.15)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 701
    }
  },
  {
    "page_content": "det(A n ) = det(A)n . (A.10) (A .ll) (A.12) (A.13) (A. 14) 矩 阵 A e Rm x n W Frobenius范数定义为 IIAIIF = (tr(A T A )) 1 /2 = fm n \\ 1/2 蜀 ) V = 1 j=i . (A.15) 容易看出，矩 阵 的 FYobenius范数就是将矩阵张成向量后的L2 范数. A .2 导数 向 量 a 相 对 于 标 量x 的导数(derivative),以 及 x 相 对 于 a 的导数都是向 量，其 第 。个分量分别为 (A.16) (A.17) 类似的，矩 阵 A 对 于 标 量 x 的导数，以及力对于A 的导数都是矩阵，其第 E行 第 3•列上的元素分别为 A 矩阵 401 (A.19) 对于函数八⑼,假定其对向量的元素可导，则 f Q ) 关于况的一阶导数是 一个向量，其 第 。个分量为 ( ▽ / ⑸ ) 产 舞 ， (A % ) /(«)关 于 x 的二阶导数是称为海森矩阵(Hessian m atrix)的一个方阵，其 第 i 行 第 3•列上的元素为 俨 ” 叽 记 震 ， (A21) 向量和矩阵的导数满足乘法法则(product rule) a 相对 于x 为常向量. d x T a d x = - ^ ― = a , d a ^ x d x c + AA dB -B - o x . B a A — R- o x = 万 A A o x , 、 A.22 “ c ( A.23 ) 、 由 A -1A = I 和 式 (A.23),逆矩阵的导数可表示为 d A - 1 H = - 4 Ar d A A- i ( A . 2 4 ) 若求导的标量是矩阵A 的元素,则有 进而有 叫 普 臼 ， oAij 驾 誓 = B T . d A * = B , a 慧 = 1 ， — (^ T - = A ( B + B T ). (A.25) (A.26) (A.27) (A.28) (A.29) 402 由式(A.15)和(A.29)有 a ||A 除 _ a tr(A A T ) dA = dA = 2A . 附 录 (A.30) 链式法则(chain rule)是计算复杂导数时的重要工具.简单地说,若函数/ 是 g 和八的复合，即 f(x) =g[h ⑺ )，则有 af⑺ 一 砌 ⑺",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 702
    }
  },
  {
    "page_content": "(A.27) (A.28) (A.29) 402 由式(A.15)和(A.29)有 a ||A 除 _ a tr(A A T ) dA = dA = 2A . 附 录 (A.30) 链式法则(chain rule)是计算复杂导数时的重要工具.简单地说,若函数/ 是 g 和八的复合，即 f(x) =g[h ⑺ )，则有 af⑺ 一 砌 ⑺ dx — dh(x) , dx . ( J 例如在计算下式时，将 A B - b 看作一个整体可简化计算： - b )T w (A z - b) = — 功 . 2W (A 2 - b) OX ox = 2AW (A® - b) . (A.32) A .3 奇异值分解 任意实矩阵A e Rm x n 都可分解为 A = U E V T , (A.33) 其中，U G Rm x m 是 满 足U T U = 工的馆阶酉矩阵(unitary matrix); V e Rn x n 是 满 足 V T V = 工的八阶酉矩阵；E e Rm x n 是m x n 的矩阵，其中② )近 二两 且其他位置的元素均为0 , 内 为 非 负 实 数 且 满 足 内 》逛 》 . • .2 0. 式(A.33)中的分 解称为奇异值分解(Singular Value Decomposition,简称 S V D ),其 中 U 的 列向量％ G Rm 称 为 A 的左奇异向量(left-singular vector), V 的列向量Vi € Rn 称 为 A 的右奇异向量(right-singular vector), 称为奇异 值(singular v alu e).矩 阵 A 的秩(rank)就等于非零奇异值的个数. 奇异值分解有广泛的用途，例如对于低秩矩阵近似(low-£ank matrix ap- proximation)问题，给 定 一 个 秩 为 r 的 矩 阵 A , 欲 求 其 最 优 k 秩 近 似 矩 阵 A, k W 人该问题可形式化为 〜 min AeRm X n || A — A ||^ s.t. rank(A) = k . (A.34) 常将奇异值按降序排列 以确保s 的唯一性. 当 A 为对 称 正 定 矩 阵 时，奇异值分解与特征值 分解结果相同. B 优化 403 奇异值分解提供了上述问题的解析解：对 矩 阵 A 进行奇异值分解后，将矩 阵 2 中的丁 - k 个最小的奇异值置零获得矩阵E Q 即仅保留最大的k 个奇异 值,则 Ak = (A.35)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 703
    }
  },
  {
    "page_content": "(A.34) 常将奇异值按降序排列 以确保s 的唯一性. 当 A 为对 称 正 定 矩 阵 时，奇异值分解与特征值 分解结果相同. B 优化 403 奇异值分解提供了上述问题的解析解：对 矩 阵 A 进行奇异值分解后，将矩 阵 2 中的丁 - k 个最小的奇异值置零获得矩阵E Q 即仅保留最大的k 个奇异 值,则 Ak = (A.35) 就是式(A.34)的最优解，其 中 U f c 和 7 k 分别是式(A.33)中 的 前 k 列组成的矩 阵.这个结果称为Eckart-Young-Mirsky定理. B 优化 B .1 拉格朗日乘子法 拉格朗日乘子法(Lagrange multipliers)是一种寻找多元函数在一组约束下 的极值的方法.通过引入拉格朗日乘子，可 将 有 d 个 变 量 与 k 个约束条件的最 优化问题转化为具有d + k 个变量的无约束优化问题求解. 先考虑一个等 式 约 束 的 优 化 问 题 .假 定 %为d 维向量，欲寻找冗的某个取 值宓*，使目标函数”为最小且同时满足gQ ) = 0 的约束.从几何角度看,该问 题的目标是在由方程gQ ) = 0 确 定 的 d - 1 维曲面上寻找能使目标函数;(x ) 最小化的点.此时不难得到如下结论： • 对于约束曲面上的任意点应该点的梯度Pg(x)正交于约束曲面； • 在最优点纪*,目标函数在该点的梯度▽〃%*)正交于约束曲面. 由此可知，在最优点%*,如附图B .1 所示，梯 度 和 V /(® )的方向必相同 或相反，即存在入多0 使得 ▽/Q * ) + XX7gQ*) = 0 , (B.1) 函数等值线与约束曲面 相切. 可 通 过 反 证 法 证 明 ：若 梯 度 与 约 束 曲 面 不 正 交 ，则 仍 可 在 约 束 曲 面 上 移 动 该 点 使 函 数 值 进 一步下降. 对 等 式 约 束 ，》可能为 入称为拉格朗日乘子.定义拉格朗日函数 正也 可 能 为 负 . L(cc, A) = y («) + Xg(x) , (B.2) 不难发现，将 其 对 ① 的 偏 导 数 VoJX叫入)置零即得式(B .1 ),同时，将 其 对 A 的 偏 导 数 亚 入 ) 置 零 即 得 约 束 条 件 gQ ) = 0 . 于是，原约束优化问题可转化 为对拉格朗日函数工(应入)的无约束优化问题. 404 附 录 (a)等式约束 (b)不等式约束",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 704
    }
  },
  {
    "page_content": "(B.2) 不难发现，将 其 对 ① 的 偏 导 数 VoJX叫入)置零即得式(B .1 ),同时，将 其 对 A 的 偏 导 数 亚 入 ) 置 零 即 得 约 束 条 件 gQ ) = 0 . 于是，原约束优化问题可转化 为对拉格朗日函数工(应入)的无约束优化问题. 404 附 录 (a)等式约束 (b)不等式约束 附图B. 1 拉格朗日乘子法的几何含义：在 (a)等式约束g Q ) = 0 或 (b)不等式约束 g(x) W 0 下，最小化目标函数〃?).红色曲线表示g Q ) = 0 构成的曲面，而其围成的 阴影区域表示g Q ) <0. 现 在 考 虑 不 等 式 约 束 g ( 为 < 0 , 如附图B. 1 所示，此 时 最 优 点 炉 或 在 g . ) < 0 的 区 域 中 ，或 在 边 界 g ( ⑹ = 0 上 . 对 于 g(x) < 0 的情形，约束 g(x)( 0 不起作用，可直接通过条件▽/(N) = 0 来获得最优点；这等价于， 置 零 然 后 对 V , L ( ^ , A ) 置零得到最优点. g Q ) = 0 的情形类似于上面等式约 束的分析，但需注意的是，此 时 ▽/(%*)的 方 向 必 与 V g (力*)相反，即存在常数 A > 0 使 得 ▽〃/*) + X V g Q * ) = 0 . 整合这两种情形，必 满 足 刖 ⑺ = 0 . 因此, 在 约 束g⑷ < 0 下 最 小 化以 前 可转化为在如下约束下最小化式(B.2)的拉格 朗日函数： g O ) W 0; < A > 0 ; 、 9j (®) = 0 - (B.3) 式(B.3)称为 Karush-Kuhn-Tucker (简称K K T ) 条件. 上述做法可推广到多个约束.考虑具有m 个等式约束和 n 个不等式约束, 且可行域D ) c R d 非空的优化问题 min j(x) X (B.4) s.t. hi(x) — 0 (z = 1,..., m ) , g，3) ( 。 C/ = i, • • • i 丹)• 引入拉格朗日乘子A = (Al, A 2 ,..., A m )T 和 4 = (41平2,… )门々尸，相应的拉格 B 优化 405 朗日函数为 E (叫入M = / ( ⑹ + + £ 4刈 ㈤ , (B.5) 2=1 j— 1 由不等式约束引入的K K T 条件0 = 1 ,2 ,… M )为 ft(« ) 0； < 出 》0 ; 、〃汹・㈤二0 • (B.6)",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 705
    }
  },
  {
    "page_content": "B 优化 405 朗日函数为 E (叫入M = / ( ⑹ + + £ 4刈 ㈤ , (B.5) 2=1 j— 1 由不等式约束引入的K K T 条件0 = 1 ,2 ,… M )为 ft(« ) 0； < 出 》0 ; 、〃汹・㈤二0 • (B.6) 一个优化问题可以从两个角度来考察，即 “主 问 题 \" (primal problem)和 “对偶问题”(dual problem ).对主问题(B .4),基于式(B .5),其 拉 格 朗 日 “对偶 在推导对偶问题时，常 函数“(dual function) T : Rm x Rn R 定义为 通过将拉格朗日家子 警 啜 丁 & 口 髓 兽 导数为0,来获何对偶函数 的表达形式. r (入 ⑷ = inf L(x, A, M ) ' ，尸/ ℃口 、' '广) / / m n \\ \\ = 如 看 局 ㈤ + £ 〃 汹 ㈤ , (B \" ) \\ £=1 j=l / ” 占。表示从的分量均 为非负. 若 花 €◎为主问题(B⑷可行域中的点，则对任意乂占0 和入都有 m n £ % 加 ( 比 ) + £ 〃 汹 3 忘 o , 2=1 j=l (B.8) 进而有 r (A,M) = inf g 05GD 入M W W /(« ) . (B.9) 若主问题(B.4)的最优值为0 * ,则对任意〃占0 和入都有 r \" W p*, (B.10) 即对偶函数给出了主问题最优值的下界.显然，这个下界取决于4 和工的值. 于是，一个很自然的问题是：基于对偶函数能获得的最好下界是什么？这就引 出了优化问题 406 附 录 max r (A, jjb) s.t. /z 0 . (B .ll) 式(B .ll)就是 主 问 题(B.4)的 对偶问题，其 中 入 和 从 称 为 “对 偶 变 量 ”(dual variable).无论主问题(B.4)的凸性如何,对偶问题(B.11)始终是凸优化问题. 考虑式(B.11)的 最 优 值 d * ,显 然 有 d * 4 这 称 为 “弱 对 偶 性 ”(weak duality)成立；若 d* = 0 * , 则 称 为 “强 对 偶 性 \"(strong duality)成立，此时由对 偶问题能获得主问题的最优下界.对于一般的优化问题，强对偶性通常不成立. 这称为 Slater条件.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 706
    }
  },
  {
    "page_content": "考虑式(B.11)的 最 优 值 d * ,显 然 有 d * 4 这 称 为 “弱 对 偶 性 ”(weak duality)成立；若 d* = 0 * , 则 称 为 “强 对 偶 性 \"(strong duality)成立，此时由对 偶问题能获得主问题的最优下界.对于一般的优化问题，强对偶性通常不成立. 这称为 Slater条件. 但是，若主问题为凸优化问题，如式(B.4)中 / Q ) 和 % Q ) 均为凸函数，g 仿射函数，且其可行域中至少有一点使不等式约束严格成立，则此时强对偶性 为 成立.值得注意的是,在强对偶性成立时,将拉格朗日函数分别对原变量和对偶 变量求导，再并令导数等于零，即可得到原变量与对偶变量的数值关系.于是, 对偶问题解决了，主问题也就解决了. B .2 二次规划 二次规划(Quadratic Program m ing,简 称 QP)是一类典型的优化问题，包 括凸二次优化和非凸二次优化.在此类问题中，目标函数是变量的二次函数，而 约束条件是变量的线性不等式. 非标准二次规划问题中 假定变量个数为& 约束条件的个数为m , 则标准的二次规划问题形如 可以包含等式约束.注意 到等式约束能用两个不等 式约束来代替；不等式约 束可通过增加松弛变量的 方式转化为等式约束. 1 mm -x Q x + x c x (B.12) s.t. Ax , 其 中 况 为 d 维向量，Q e R d x d 为实对称矩阵，A € c e R d 为实向量，A x ^ b 的每一行对应一个约束. 为实矩阵，b e 肽馆和 若 Q 为半正定矩阵，则式(B.12)目标函数是凸函数，相应的二次规划是凸. 二次优化问题；此时 若 约 束 条 件A z W b 定义的可行域不为空，且目标函数在 此可行域有下界，则该问题将有全局最小值.若Q 为正定矩阵，则该问题有唯 一的全局最小值.若Q 为非正定矩阵，则式(B.12)是有多个平稳点和局部极小 点 的 N P 难问题. 常 用 的 二 次 规 划 解 法 有 椭 球 法 (ellipsoid method) > 内 点 法 (interior point)> 增广拉格朗日法(augmented Lagrangian)、梯度投影法(gradient pro­ jection) 等 . 若 Q 为正定矩阵，则相应的二次规划问题可由椭球法在多项式时 间内求解. B 优化 407 B . 3 半正定规划 半正 定 规 划 (Semi-DefiLnite P r o g r a m m i n g , 简称S D P ) 是一类凸优化问题,",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 707
    }
  },
  {
    "page_content": "jection) 等 . 若 Q 为正定矩阵，则相应的二次规划问题可由椭球法在多项式时 间内求解. B 优化 407 B . 3 半正定规划 半正 定 规 划 (Semi-DefiLnite P r o g r a m m i n g , 简称S D P ) 是一类凸优化问题, 其中的变量可组织成半正定对称矩阵形式，且优化问题的目标函数和约束都是 这些变量的线性函数. 给 定 d x d 的对称矩阵X 、C, d d C .X = E £ G / 切」 2=1 j=l (B.13) 若 A c (E = 1,2,... , m ) 也 是 d x d 的对称矩阵,bi(i = L ，… )吟 为m 个实数, 则半正定规划问题形如 m i n C X (B.14) s.t. A i - X = , z — 1,2,..., m 0 表 示 X 半正定. X ^ O . 半正定规划与线性规划都拥有线性的目标函数和约束，但半正定规划中的 约 束 X 占。是一个非线性、非光滑约束条件.在优化理论中，半正定规划具有 一定的一般性，能将几种标准的优化问题(如线性规划、二次规划)统一起来. 常见的用于求解线性规划的内点法经过少许改造即可求解半正定规划问 题,但半正定规划的计算复杂度较高,难以直接用于大规模问题. B . 4 梯度下降法 一阶方法仅 使 用 目 标 函 数 的 一 阶 导 数 ，不 利 用 其 高阶导数. 梯度下降法(gradient descent)是一种常用的一阶(first-order)优化方法，是 求解无约束优化问题最简单、最经典的方法之一. 考虑无约束优化问题m i l % /(⑼ ，其 中 / Q ) 为连续可微函数.若能构造一 个序列宓。加 ，宓2,… 满足 f(xt+1) < /(^),力 = 0,1,2,... (B.15) 则不断执行该过程即可收敛到局部极小点.欲满足式(B.15),根据泰勒展式有 f(x + A x ) a f(x) + AajT V / ( x ) , (B.16) 408 附 录 于 是 , 欲 满 足 + △ ⑼ < / Q ) , 可选择 △宓= _ 7 V / ( x ) , (B.17) 每步的步长生可不同. 其中步长 7 是一个小常数.这就是梯度下降法. 若目标函数/(%)满足一些条件，则通过选取合适的步长，就能确保通过梯 L-Lipschitz条 件 是 指 对 于 任 意 皿 存 在 常 数 E 使 得 州 W L 成立• 度下降收敛到局部极小点.例如若 / ( x ) 满 足 L-Lipschitz条件，则将步长设置",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 708
    }
  },
  {
    "page_content": "(B.17) 每步的步长生可不同. 其中步长 7 是一个小常数.这就是梯度下降法. 若目标函数/(%)满足一些条件，则通过选取合适的步长，就能确保通过梯 L-Lipschitz条 件 是 指 对 于 任 意 皿 存 在 常 数 E 使 得 州 W L 成立• 度下降收敛到局部极小点.例如若 / ( x ) 满 足 L-Lipschitz条件，则将步长设置 为 1/(2为即可确保收敛到局部极小点.当目标函数为凸函数时，局部极小点就 对应着函数的全局最小点，此时梯度下降法可确保收敛到全局最优解. 当目标函数/ Q ) 二阶连续可微时，可将式(B.16)替换为更精确的二阶泰勒 展式，这样就得到了牛顿法(Newton's m e t h o d ) . 牛顿法是典型的二阶方法，其 迭 代 轮 数 远 小 于 梯 度 下 降 法 .但 牛 顿 法 使 用 了 二 阶 导 数 其 每 轮 迭 代 中 涉及到海森矩阵(A.21)的求逆，计算复杂度相当高，尤其在高维问题中几乎不 可行.若能以较低的计算代价寻找海森矩阵的近似逆矩阵，则可显著降低计算 开销，这就是拟牛顿法(quasi-Newton method). B . 5 坐标下降法 求解极大值问题时亦称 “坐 标 上 升 法 ” (coordi­ nate ascent). 坐标下降法(coordinate descent)是一种非梯度优化方法，它在每步迭代中 沿一个坐标方向进行搜索，通过循环使用不同的坐标方向来达到目标函数的局 部极小值. 不 妨 假 设 目 标 是 求 解 函 数 /(⑼ 的 极 小 值 ，其 中 a = ( 6 1 , % . . . , 3 产 e 期 是 一 个 d 维 向 量 . 从 初 始 点 八 开 始 ，坐 标 下 降 法 通 过 迭 代 地 构 造 序 列 宓。田 声 , ...来求解该问题,比计1 的 第 i个分量好+1 构造为 力朴1 = arg m i n g 禺 … ,嗡 ) . (B.18) 通过执行此操作，显然有 / Q 。) 》/(於 )》/(宓2 ) 》… (B.19) 与梯度下降法类似,通过迭代执行该过程，序 列 宓 宓 2,...能收敛到所期望 的局部极小点或驻点(stationary point). 坐标下降法不需计算目标函数的梯度，在每步迭代中仅需求解一维搜索问 题,对于某些复杂问题计算较为简便.但若目标函数不光滑，则坐标下降法有可 能陷入非驻点(non-stationary point). C 概率分布 409 C 概 率 分 布 C .1 常见概率分布 本节简要介绍几种常见概率分布.对于每种分布，我们将给出概率密度函",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 709
    }
  },
  {
    "page_content": "坐标下降法不需计算目标函数的梯度，在每步迭代中仅需求解一维搜索问 题,对于某些复杂问题计算较为简便.但若目标函数不光滑，则坐标下降法有可 能陷入非驻点(non-stationary point). C 概率分布 409 C 概 率 分 布 C .1 常见概率分布 本节简要介绍几种常见概率分布.对于每种分布，我们将给出概率密度函 数以及期望］£ ［-］、方 差 var［.］和协方差cov［.,.］等几个主要的统计量. C .1 .1 均匀分布 这里仅介绍连续均匀分 布. 均匀分布(uniform distribution)是关于定义在区间［a, b\\ (a < b )上连续变 量的简单概率分布,其概率密度函数如附图C .1 所示. p ⑵八 1 b ^ ' UQ | a, b) 0 A--------- 入 b a 》 6 附图C . 1 均匀分布的概率密度函数 p(x \\a,b) — UQ \\a,b) = 7 1 — ; b - a E 团 二 ; var［剑 = . (C.1) (C.2) (C.3) 不难发现，若 变 量 c 服从均匀分布UQ ［ 0 ,1 ) 且 a V \" 则 a + 他—a ) x 服 从均匀分布U(①| a, b). C .1 .2 伯努利分布 以 瑞 士 数 学 家 雅 各 布 ・ 伯 努 利 (Jacob Bernoulli, 1654—1705)的名字命名. 伯努利分布(Bernoulli distribution)是 关 于 布 尔 变 量 a 6 { 0 ,1 } 的概率分 布,其连续参数〃 e ［0,1］表示变量①= 1 的概率. P ［x | 〃)= Bern(rr | 〃)= * ( 1 —4 > 一” ; (C.4) 410 旧园= 〃 ； var[rr]= 4 (1 —4 ) . 附 录 (C.5) (C.6) C .1 .3 二项分布 二项分布(binomial distribution)用 以 描 述 N 次独立的伯努利实验中有m 次成功(即①= 1)的概率,其中每次伯努利实验成功的概率为M € [0,1]. P{m | N ,〃)= Bin(m \\ N # ) = — ^ N ~m ； (C.7) E [剑= N /i ; var[a;] = N g —4 ) . (C.8) (C.9) 对 于 参 数 出 二 项 分 布 的共朝先验分布是贝塔分 布.共朝分布参见C.2. 当 N = 1 时，二项分布退化为伯努利分布. C .1 .4 多项分布",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 710
    }
  },
  {
    "page_content": "P{m | N ,〃)= Bin(m \\ N # ) = — ^ N ~m ； (C.7) E [剑= N /i ; var[a;] = N g —4 ) . (C.8) (C.9) 对 于 参 数 出 二 项 分 布 的共朝先验分布是贝塔分 布.共朝分布参见C.2. 当 N = 1 时，二项分布退化为伯努利分布. C .1 .4 多项分布 若将伯努利分布由单变量扩展为d 维向量宓，其 中 0 e {0,1}且 E t i 电 = 1 , 并 假 设 g 取 1 的 概 率 为 也 e [0,1], M = 1 , 则将得到离散概率分布 d P Q |/ i ) = 口 端 ； 2=1 IE[g] = M ； v a r[^ ]= 由(1 一 曲 ； cov[叼,g] — I[,7 = i\\ l^i • (C.10) (C .ll) (C.12) (C.13) 对 于 参 数 出 多 项 分 布 的 共 朝 先 验 分 布 是 狄 利 克雷分布.共轲分布参见 C.2. 在此基础上扩展二项分布则得到多项分布(multinomial distribution),它 描述了在N 次独立实验中有r m 次 0 = 1 的概率. P (m i, m 2 ,..., rrid \\ = Mult (mi, m 2 ,..., 77M | N ,4) E[mi] = Nfii ; (C.15) C 概率分布 var[mi] = N瓯Q - 的 )； c o v [ m j , = —N j j i i . 411 (C.16) (C17) C .1 .5 贝塔分布 贝塔分布(Beta distribution)是关于连续变量四e [0 ,1 ]的概率分布)它由 两个参数。> 0 和 b > 0 确定，其概率密度函数如附图C .2 所示. 附图C. 2 贝塔分布的概率密度函数 目(4 % b) ; Beta(> \\ a.V) = 1 \\a )L \\0) = / 同 人 … 尸 ； 1 ( 1 —四广1 酮 = M ； V a r M = (a + 屋 + 6 + 1 ) ， 3 。 现 9 2 。) 其 中 r ( a ) 为 Gamma函数 B ( a ,b ) 为 Beta 函数 产一7 一力出；, (C.21) b ) = r ( a + b) (C.22) 412 附 录 当 a = b = 1 时，贝塔分布退化为均匀分布. C.1.6狄利克雷分布",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 711
    }
  },
  {
    "page_content": "V a r M = (a + 屋 + 6 + 1 ) ， 3 。 现 9 2 。) 其 中 r ( a ) 为 Gamma函数 B ( a ,b ) 为 Beta 函数 产一7 一力出；, (C.21) b ) = r ( a + b) (C.22) 412 附 录 当 a = b = 1 时，贝塔分布退化为均匀分布. C.1.6狄利克雷分布 以德国数学家狄利克雷 (1805— 1859)的名字命名. 狄利克雷分布(Dirichlet distribution)是关于一组d 个 连 续 变 量 也 e ［0,1］ 的概率分布，£ 3 由 = L 令 4 = (M1； M2； • • • ； AM),参 数 a = ( % ; & 2 ；… ；2 ， 8 > 0 , 6 = £ 3 即 p W | a ) = D i G | a ) = r g ：(a)r Q ) 企 尸 ； (C.23) 叫 词 = 孚 ； a 的 ［词 = 黑 割 ； az\\a + 1) cov［的,词 = 储 ( 工 1 ) . 当 d = 2 时，狄利克雷分布退化为贝塔分布. < . 1 . 7 高斯分布 (C.24) (C.25) (C.26) 高斯分布(Gaussian distribution)亦称正态分布(normal distribution),是应 用最为广泛的连续概率分布. a 为标准差. 拉 > 0 . 附图C . 3 给出了在几组不同参数下高斯分布的概率密度函数. 对 于 单 变 量 x € (-OO, oo),高斯分布的参数为均值从 e (-oo, o o ) 和方差 0 3 1 内 = N(x 1 M M ) = exp ｛一(/切?)｝ ； (C27) E 团 = 4 ； var［剑 = cr2 . (C.28) (C.29) 对 于 d 维 向 量 X , 多元高斯分布的参数为d 维 均 值 向 量 4 和 d 义d 的对称 正定协方差矩阵2. | % 2) = N Q 1 出 2) 一 ，(2疗 det ② )叩 ｛一 犷 一 ” 与 ％ * 出 ｝ ； 9 3 。) C 概率分布 413 附图C. 3 高斯分布的概率密度函数 M 罔 = \" ； COV 同 = 2 . (C.31) (C.32) C .2 共聊分布",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 712
    }
  },
  {
    "page_content": "正定协方差矩阵2. | % 2) = N Q 1 出 2) 一 ，(2疗 det ② )叩 ｛一 犷 一 ” 与 ％ * 出 ｝ ； 9 3 。) C 概率分布 413 附图C. 3 高斯分布的概率密度函数 M 罔 = \" ； COV 同 = 2 . (C.31) (C.32) C .2 共聊分布 假设变量X服从分布P(x |⑼ ，其 中 ®为 参 数 ,X = ｛% / 2 , … , xm ］为变 量力的观测样本，假设参数© 服从先验分布n (0 ), 若由先验分布n (0 ) 和抽样 分 布 P(X I @) 决定的后验分布F ( 0 I X ) 与 n (@) 是同种类型的分布，则称先 验分布 11(0)为分布 P(x | 0 ) 或 P(X | 0 ) 的共辄分布(conjugate distribution). 例如，假 设 x 〜 Bern(x | 4 ) ，X = ｛力.力2, • • ・，力馆｝为观测样本，x 为观测 样本的均值，4 ~ Beta(〃 | a, b ),其 中 a〉b为已知参数，则 〃的后验分布 | X) oc Beta(^ | a, b)P(X | 四) 4 1 ( 1 - B(a)b) __________ ___________ a+mS— 1 B(a + m 无)b + m — mx) (1 — M) = Beta(/2 | b')， (C.33) 这里仅 考 虑 高 斯 分 布 方 差 已 知 、均值服从先验的 情形. 亦为贝塔分布，其 中 , = 。+ mx, b，= b + m — mx,这意味着贝塔分布与伯努 利分布共甄.类似可知，多项分布的共辄分布是狄利克雷分布，而高斯分布的共 朝分布仍是高斯分布. 414 附 录 先验分布反映了某种先验信息，后验分布既反映了先验分布提供的信息、 又反映了样本提供的信息.当先验分布与抽样分布共朝时，后验分布与先验分 布属于同种类型，这意味着先验信息与样本提供的信息具有某种同一性.于 是，若使用后验分布作为进一步抽样的先验分布，则新的后验分布仍将属于同 种 类 型 .因 此 ，共朝分布在不少情形下会使问题得以简化.例如在式(C.33)的 例子中，对服从伯努利分布的事件X 使用贝塔先验分布，则贝塔分布的参数值 a 和 6 可视为对伯努利分布的真实情况(事件发生和不发生)的预估.随着“证 据 ”(样本)的不断到来，贝塔分布的参数值从a, b 变 化 为 a + m 化, b + 处 且 a /(a + 6 )将 随 着 m 的增大趋近于伯努利分布的真实参数值化.显然，使用共",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 713
    }
  },
  {
    "page_content": "a 和 6 可视为对伯努利分布的真实情况(事件发生和不发生)的预估.随着“证 据 ”(样本)的不断到来，贝塔分布的参数值从a, b 变 化 为 a + m 化, b + 处 且 a /(a + 6 )将 随 着 m 的增大趋近于伯努利分布的真实参数值化.显然，使用共 辗先验之后，只需调整a 和 b 这两个预估值即可方便地进行模型更新. C.3 KL散度 KL散度(Kullback-Leibler divergence),亦称相对燧(relative entropy)或信 息散度(information divergence),可用于度量两个概率分布之间的差异.给定两 个概率分布P 和 Q , 二者之间的KL散度定义为 K L (P ||Q )= 广 p ⑺ log 桨 d明 J-OO 虱力) (C.34) 其 中 0(力)和鼠①)分别为P 和 Q 的概率密度函数. KL散度满足非负性，即 K L (P ||Q )2 0 , (C.35) 当且仅当P = Q 时 KL(F||Q) = 0 . 但是,KL散度不满足对称性，即 K L (F ||Q ) ^ K L ( Q ||F ), (C.36) 这里假设两个分布均为 连续型概率分布；对于离 散型概率分布，只需将定 义中的积分替换为对所有 离散值遍历求和. 度量应满足四个基本性 质，参见9.3节. 因此，KL散度不是一个度量(metric). 若将KL散度的定义(C.34)展开,可得 KL(F||Q) = / p{x} logp(x)dx — / p(x) logq(x)dx poo P O O J—g J —oo = —H (P ) + H ( R Q ) , (C.37) 其中 H ( P ) 为埔(entropy), H (P, Q ) 为 P 和 Q 的交叉嫡(cross e n tro p y ).在信 C 概率分布 415 息论中，嫡 H(P)表 示 对来自P 的随机变量进行编码所需的最小字节数，而交 叉 嫡 H(P,Q)则表示使用基于Q 的编码对来自P 的变量进行编码所需的字节 数 .因 此 ，KL散度可认为是使用基于Q 的编码对来自P 的变量进行编码所需 的 “额 外 ”字节数；显然，额外字节数必然非负，当且仅当P = Q 时额外字节 数为零. 后 记 写作本书的主因，是 2016年准备在南京大学开设“机器学习”课.十五年前笔者曾主张开设此 课,但那时国内对机器学习闻之不多，不少人听到这个名字的第一反应是“学习什么机器?”学校估 计学生兴趣不大，于是笔者开设了 “数据挖掘”这门名字听上去就觉得很有用的课.被评为省优秀",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 714
    }
  },
  {
    "page_content": "数为零. 后 记 写作本书的主因，是 2016年准备在南京大学开设“机器学习”课.十五年前笔者曾主张开设此 课,但那时国内对机器学习闻之不多，不少人听到这个名字的第一反应是“学习什么机器?”学校估 计学生兴趣不大，于是笔者开设了 “数据挖掘”这门名字听上去就觉得很有用的课.被评为省优秀 研究生课程后，又给本科生单开了一门“数据挖掘导论”.这两门课很受欢迎,选修学生很多，包括 不少外来蹭听生.虽然课上有一多半其实在讲机器学习，但笔者仍一直希望专开一门机器学习课， 因笔者以为机器学习迟早会变成计算机学科的基础内容. 图灵奖得主E. W. D ijkstra曾 说 “计算机科学并不仅是关于计算机，就像天文学并不仅是关于 望远镜”.正如天文学早期的研究关注如何制造望远镜，计算机科学早期研究是在关注如何令计算 机运转.到了今天，建造强大的天文望远镜虽仍重要，但 天文学更要紧的是“用 ”望远镜来开展研 究.类似地，计算机科学发展至今，也 该 到 了 从 关 注 “造 ”计 算 机 转 入 更 关 注 “用 ”计算机来认识 和改造世界的阶段，其中最重要的无疑是用计算机对数据进行分析，因为这是计算的主要目的，而 这就离不开机器学习.十多年前在国内某次重要论坛上笔者刚抛出此观点就被专家迎头指斥，但今 日来看，甚至很多计算机学科外人士都已对机器学习的重大价值津津乐道，现在才开设机器学习基 础课似乎已有点嫌晚了. 1995年在南大图书馆偶然翻看了《机器学习：通往人工智能的途径》，这算是笔者接触机器学 习的开始.那时机器学习在国内问津者寥，甚至连科研人员申请基金项目也无合适代码方向可报. 周边无专家可求教，又因国内科研经费匮乏而几无国际交流，加之学校尚无互联网和电子文献库， 能看到的最新文献仅是两年前出版且页数不全的某IE E E 汇刊……可谓举步维艰，经历的困惑和陷 阱不可胜数.笔者切身体会到，入门阶段接触的书籍是何等重要，对自学者尤甚.一本好书能让人少 走许多弯路，材料不佳则后续要花费数倍精力方能纠偏.中文书当然要国人自己来写.虽已不需靠 “写书出名”，且深知写教科书极耗时间精力，但踌躇后笔者仍决定动手写这本书，唯望为初学者 略尽绵薄之力. 有 人 说 “一千个人眼中就有一千个哈姆雷特”，一个学科何尝不是如此.之所以不欲使用市面 上流行的教科书（主要是英文的），除了觉得对大多数中国学生来说中文教科书更便于学习，另一个 原因则是希望从笔者自己的视角来展现机器学习. 2013年中开始规划提纲，由此进入了焦躁的两年.该写哪些内容、先写什么后写什么、从哪个 角度写、写到什么程度，总有千丝万缕需考虑.及至写作进行，更是战战兢兢，深恐不慎误人子弟.",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 715
    }
  },
  {
    "page_content": "上流行的教科书（主要是英文的），除了觉得对大多数中国学生来说中文教科书更便于学习，另一个 原因则是希望从笔者自己的视角来展现机器学习. 2013年中开始规划提纲，由此进入了焦躁的两年.该写哪些内容、先写什么后写什么、从哪个 角度写、写到什么程度，总有千丝万缕需考虑.及至写作进行，更是战战兢兢，深恐不慎误人子弟. 写书难，写教科书更难.两年下来，甘苦自知.子曰：“取乎其上，得乎其中；取乎其中，得 乎 其 下 \" 且以顶级的态度，出一本勉强入得方家法眼之书. 418 机器学习 本 书 贯 穿 以 西 瓜 为 例 ，一 则 因 为 瓜 果 中 笔 者 尤 喜 西 瓜 ，二 则 因 为 西 瓜 在 笔 者 所 生 活 的 区 域 有 个 有 趣 的 蕴 义 .朋 友 小 聚 、请 客 吃 饭 ，菜 已 全 而 主 未 知 ，或 馔 未 齐 而 人 待 走 ，都 挺 尴 尬 .于 是 聪 明 人 发 明了 “潜 规 则 ”：席 终 上 西 瓜 . 无 论 整 盘 抑 或 小 碟 ，宾 主 见 瓜 至 ，则 心 领 神 会 准 备 起 身 ，皆大欢喜. 久 而 久 之 ，无 论 菜 肴 价 格 贵 贱 、场 所 雅 鄙 ，宴 必 有 西 瓜 .若 将 宴 席 比 作 （未 来 ）应 用 系 统 ，菜 肴 比 作 所 涉 技 术 ，则 机 器 学 习 好 似 那 必 有 的 西 瓜 ，它 可 能 不 是 最 “高 大 上 ” 的 ，但 却 是 离 不 了 的 、 没 用 上 总 觉得不甘心的. 本 书 写 作 过 程 从 材 料 搜 集 ，到 习 题 设 计 ，再 到 阅 读 校 勘 ，都 得 到 了 笔 者 的 很 多 学 生 、 同 事 和 学 术 界 朋 友 的 支 持 和 帮 助 ，在 此 谨 列 出 他 们 的 姓 名 以 致 谢 意 （姓 氏 拼 音 序 ）：陈 松 灿 ，戴 望 州 ，高 阳 ，高 尉 ，黄 圣 君 ，黎 铭 ，李 楠 ，李 武 军 ，李 宇 峰 ，钱 超 ，王 魏 ，王 威 廉 ，吴 建 鑫 ，徐 淼 ，俞 扬 ，詹 德 川 ，张利军, 张 敏 灵 ，朱 军 . 书 稿 在 LAMDA组 学 生 2015年 暑 期 讨 论 班 上 试 讲 ，高 斌 斌 、 郭 翔 宇 、 李 绍 园 、 钱 鸿 、沈 芷 玉 、 叶 翰 嘉 、张 腾 等 同 学 又 帮 助 发 现 了 许 多 笔 误 .特 别 感 谢 李 楠 把 笔 者 简 陋 的 手 绘 图 转 变 为 精 致 的 插 图 ，俞 扬 帮 助 调 整 排 版 格 式 和 索 弓 I , 刘 冲 把 笔 者 对 封 面 设 计 的 想 法 具 体 表 现 出 来 .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 716
    }
  },
  {
    "page_content": "为 精 致 的 插 图 ，俞 扬 帮 助 调 整 排 版 格 式 和 索 弓 I , 刘 冲 把 笔 者 对 封 面 设 计 的 想 法 具 体 表 现 出 来 . 中 国 计 算 机 学 会 终 身 成 就 奖 得 主 、 中 国 科 学 院 院 士 陆 汝 铃 先 生 是 我 国 人 工 智 能 事 业 的 开 拓 者 之 一 ，他 在 1988年 和 1996年 出 版 的 《人 工 智 能 》 （上 、 下 册 ）曾 给 予 笔 者 很 多 启 发 .承 蒙 陆 老 师 厚 爱 在 百 忙 中 为 本 书 作 序 ，不 胜 惶 恐 之 至 .陆 老 师 在 序 言 中 提 出 的 问 题 很 值 得 读 者 在 本 书 之 后 的 进 阶 学 习 与 研 究 中 深 思 . 感 谢 清 华 大 学 出 版 社 薛 慧 老 师 为 本 书 出 版 所 做 的 努 力 . 十 二 年 前 笔 者 入 选 国 家 杰 出 青 年 科 学 基 金 时 薛 老 师 即 邀 著 书 ，笔 者 以 年 纪 尚 轻 、 学 力 未 逮 婉 辞 . 十 年 前 “机 器 学 习 及 其 应 用 ”研 讨 会 （MLA）从 陆 汝 铃 院 士 肇 始 的 复 旦 大 学 智 能 信 息 处 理 重 点 实 验 室 移 师 南 京 ，参 会 人 数 从 复 旦 最 初 的 2 0 人 ，发 展 到 2010年 4 0 0 余 人 ，此 后 在 清 华 、 复 旦 、 西 电 达 8 0 0 余 人 ，今 年 再 回 南 大 竟 至 1300余 人 ，场 面 热 烈 . M LA 倡 导 “学 术 至 上 、 其 余 从 简 ” ，不 搞 繁 文 缗 节 ，参 会 免 费 . 但 即 便 如 此 ，仍 有 很 多 感 兴 趣 的 师 生 因 旅 费 不 菲 而 难 以 参 加 .于 是 笔 者 提 议 每 两 年 以 《机 器 学 习 及 其 应 用 》为 题 出 版 一 本 报 告 选 集 以 飨 读 者 .这 个 主 意 得 到 了 薛 老 师 、 陆 老 师 以 及 和 笔 者 一 起 长 期 组 织 MLA、 去 年因 病 去 世 的 王 珏 老 师 的 大 力 支 持 .此 类 专 业 性 学 术 文 集 销 量 不 大 ,出 版 社 多 半 要 贴 钱 .笔 者 曾 跟 薛 老 师 说 ，自 著 的 第 一 本 中 文 书 必 交 由 薛 老 师 在 清 华 出 版 ，或 可 稍 为 出 版 社 找 补 . 转 眼 《机 器 学 习 及 其 应 用 》 系 列 已 出 到 第 六 本 ，薛 老 师 或 以 为 十 年 前 是 玩 笑 话 ,某 日 告 之 书 快 完 稿 时 她 蓦 然 惊 喜 .",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 717
    }
  },
  {
    "page_content": "师 说 ，自 著 的 第 一 本 中 文 书 必 交 由 薛 老 师 在 清 华 出 版 ，或 可 稍 为 出 版 社 找 补 . 转 眼 《机 器 学 习 及 其 应 用 》 系 列 已 出 到 第 六 本 ，薛 老 师 或 以 为 十 年 前 是 玩 笑 话 ,某 日 告 之 书 快 完 稿 时 她 蓦 然 惊 喜 . 最 后 要 感 谢 笔 者 的 家 人 ，本 书 几 乎 耗 尽 了 两 年 来 笔 者 所 有 的 节 假 日 和 空 闲 时 间 .写 作 时 垂 髯 犬 子 常 跑 来 案 边 ，不 是 问 “爸 爸 去 哪 儿 ?”而 是 看 几 眼 然 后 问 “爸 爸 你 又 写 了 几 页 ?”为 了 给 他 满 意 的 答 复 ，笔者埋 头努力. 周 志 华 2015年 1 1 月 于 南 京 渐 宽 斋 索 引 0/1损 失 函 数 ，130, 147 5 x 2 交 叉 验 证 ，41 ・贪心，374 AdaBoost, 173 ART 网络，108 Bagging, 178 Bellman等 式 ，380 Boltzmann分 布 ，111 Boltzmann机 ，111 Boosting, 173, 190 BP算 法 ，101 B P 网络，101 C4.5决 策 树 ，78, 83 CART决 策 树 ，79 ECOC, 64 Elman网络 ，111 EM算 法 ，162, 208, 295, 335 F l , 32 Fisher判 别 分 析 ，60 Friedman检 验 ，42 Frobenius 范 薮 ，400 Hoeffding不 等 式 ，192, 268 hinge损 失 ，130 ID3决 策 树 ，75 ILP, 357, 364 Jensen不 等 式 ，268 K -摇 臂 赌 博 机 ,373 KKT 条 件 ，124, 132, 135 KL散 度 ，335, 414 Kohonen 网 综 109 k 折 交 叉 验 证 ，26 k近 邻 ，225 k均 值 算 法 ，202, 218 L i正 则 化 ，253 L2正 则 化 ，253 . LASSO, 252, 261 Lipschitz条 但 253 LVQ, 204, 218 M-P神 经 元 模 型 ，97 McDiarmid不 等 式 ，268 MCMC, 331 McNemar检 验 ，41 MDP, 371 Mercer 定 理 ，137, 139 MH算 法 ，333 MvM, 63 Nemenyi后 续 检 验 ,43 OvO, 63 OvR, 63",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 718
    }
  },
  {
    "page_content": "LVQ, 204, 218 M-P神 经 元 模 型 ，97 McDiarmid不 等 式 ，268 MCMC, 331 McNemar检 验 ，41 MDP, 371 Mercer 定 理 ，137, 139 MH算 法 ，333 MvM, 63 Nemenyi后 续 检 验 ,43 OvO, 63 OvR, 63 P -R 曲线，31 PAC辨 识 ，269 PAC可 学 习 ，269 PAC学 习 算 法 ，270 PCA, 229 Q-学 习 ，387, 393 Rademacher复 杂 度 ，279 RBF 网 络 ，108 ReLU, 114 RIPPER, 353 RKHS, 128 ROC 曲线，33, 46 S3VM, 298 Sarsa 算 法 ，387, 390 Sigmoid函数 ，58, 98, 102 Softmax, 375 SOM 网络，109 Stacking, 184 SVM, 123 TD 学 习 ，386, 393 Tikhonov正 则 化 ，252 VC维 ，273, 274 V型 结 构 ，158 WEKA, 16 420 机器学习 奥卡姆剃刀，7, 17 版本空间，5 半监督聚类，240, 307 半监督学习，293, 294 半监督支持向量机，298 半朴素贝叶斯分类器，154 半正定规划，407 包裹式特征选择，250 包外估计,27, 179 贝塔分布,411 贝叶斯定理，148 贝叶斯分类器，164 贝叶斯风险，147 贝叶斯决策论，147 贝叶斯模型平均，185 贝叶斯网，156, 319, 339 贝叶斯学习，164 贝叶斯最优分类器，147 本真低维空间，232 本真距离，234 必连约束，239, 307 边际独立性，158 边际分布,328 边际化，158, 328 边际似然，163 编码矩阵,65 变分推断，334 变量消去,328 标记，2 标记传播，302 标记空间，3 表格值函数，388 表示定理，137 表示学习，114 伯努利分布,409 不可分，269, 272 不可知P A C 可学习，273 不一致，269 参数估计，54 参数调节，28 参数空间，106 策略,372 策略迭代，381 测地线距离，234 测试,3 测试样本,3 层次聚类,214 查全率，30 查询，293 查准率，30 差异性度量，187 超父，155 成对马尔可夫性，325 冲突消解，348 重采样，177 重赋权，177 簇，3, 197 错误率，23, 29",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 719
    }
  },
  {
    "page_content": "参数估计，54 参数调节，28 参数空间，106 策略,372 策略迭代，381 测地线距离，234 测试,3 测试样本,3 层次聚类,214 查全率，30 查询，293 查准率，30 差异性度量，187 超父，155 成对马尔可夫性，325 冲突消解，348 重采样，177 重赋权，177 簇，3, 197 错误率，23, 29 打散，273 带序规则，348 代价,35, 47 代价矩阵，35 代价敏感，36, 67 代价曲线，36 单隐层网络，101 道德图，158 等度量映射，234 低密度分隔，298 低维嵌入,226 低秩矩阵近似,402 狄利克雷分布，412 递归神经网络，111 典型相关分析，240 独立同分布，3, 267 独依赖估计，154 度量学习，237 端正图，158 对比散度，112 对分，273 对率函数，58 对率回归，58, 132, 325 对率损失，130 对偶函数，405 对偶问题，123, 405 对数几率函数，58, 98 对数几率回归，57 对数似然，59, 149 对数线性回归，56 多变量决策树，88, 92 多标记学习，68 多层前馈神经网络，100 多分类,3 多分类器系统，171 多分类学习，63 多核学习，140 多视图学习，240, 304 多维缩放,227 索 引 421 多项分布,410 多样性，172 多样性度量，187 多元线性回归，55 二次规划，406 二分类，3 二项分布,410 二项检验，38 发散, 113 罚函数法，133 反向传播算法，101 泛化，3, 121, 350 泛化误差，23, 267 非参数化方法，340 非度量距离，201 非线性降维，232 非线性可分，99 分层采样，25 分而治之，74 分类, 3 分歧，185, 304 风险，147 符号主义，10, 363 概率近似正确，268 概率模型，206, 319 概率图模型，156, 319 概念类，268 概念学习，4, 17 感知机，98 高斯分布，412 高斯核，128 高斯混合，206, 296 割平面法，139 个体学习器，171 功能神经元，99 共朝分布,413 关系学习，363 广 义 6 规则，115 广义瑞利商，61 广义线性模型，57 规范化，36, 183 规则，347 规则学习，347 归结商，362 归纳，359 归纳逻辑程序设计，357, 364 归纳偏好，6 归纳学习，4, 11 归一化，36 过采样，67 过滤式特征选择，249 过拟合，23, 104, 191, 352 过配，23",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 720
    }
  },
  {
    "page_content": "归纳学习，4, 11 归一化，36 过采样，67 过滤式特征选择，249 过拟合，23, 104, 191, 352 过配，23 行列式，399 豪斯多夫距离，220 核范数，260 核方法，137 核函数，126 核化，137, 232 核化线性降维，232 核技巧，127 核矩阵，128, 138, 233 核线性判别分析，137 核主成分分析，232 合一，361 宏F 1, 32 宏查全率，32 宏查准率，32 后剪枝，79, 352 划分超平面，121, 298 划分选择，75, 92 话题模型,337 回归，3 汇合，114 混合属性，201 混合专家，191, 313 混淆矩阵,30 基尼指数，79 基学习器，171 ・基学习算法，171 基于分歧的方法，304 基于能量的模型，111 机械学习，11 迹，399 迹范数，260 激活函数，98 吉布斯采样，161, 334 极大似然法，59, 149, 297 极大似然估计，149, 328 集成修剪，191 集成学习，171, 311 急切学习，225 级联相关，110 挤压函数，98 几率，58 422 机器学习 计算学习理论，267 加权距离，201 加权平均，182, 225 加权投票，183, 225 加性模型，173 假设,2, 269 假设检验，37 假设空间，268 监督学习，3 间隔，122 简单平均，182 剪枝，79, 352 奖赏,371 降维，227 交叉验证成对方检验，40 交叉验证法,26 交叉嫡，415 街区距离，200 阶跃函数，57, 98 结构风险，133 近端梯度下降，253, 259 近邻成分分析，238 近似动态规划，393 近似推断，161, 328, 331 精度，23, 29 精确推断，161, 328 经验风险，133 经验风险最小化，278 经验误差，23, 267 径向基函数，108 竞争型学习，108 纠错输出码，64 局部极小，106 局部马尔可夫性，324 局部线性嵌入，235 矩阵补全，259 聚类,3, 197 聚类集成，219 聚类假设，294 距离度量，199 距离度量学习，201, 237 卷积神经网络，113 决策树，73, 363 决策树桩,82 绝对多数投票，182 均方误差，29, 54 均匀分布，409 均匀稳定性，285 可分，269, 270 可解释性，115, 191 可塑性■•稳定性窘境，109",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 721
    }
  },
  {
    "page_content": "可分，269, 270 可解释性，115, 191 可塑性■•稳定性窘境，109 拉格朗日乘子法，403 拉普拉斯修正，153 拉斯维加斯方法，251 懒惰学习，154, 225, 240 累积误差逆传播，105 类比学习，11 类别不平衡, 66, 299 类间散度矩阵，61, 138 类内散度矩阵，61, 138 离散化，83 离散属性，200 联系函数，57 连接权，101, 104 连接主义，10 连续属性,200 链式法则，103, 402 列联表，41, 187 列名属性，200 岭回归，252 留出法，25 流形假设，240, 294 流形学习，234 流形正则化，240 逻辑文字，347 码书学习，255 马尔可夫决策过程，371 马尔可夫链, 161, 320 . 马尔可夫随机场，322 马尔可夫毯，325 马尔可夫网，319 曼哈顿距离，200 没有免费的午餐定理，9 蒙特卡罗方法，251, 340, 384 密采样,226 密度聚类,211 免模型学习，382 闵可夫斯基距离，200, 220 命题规则，348 模仿学习，390 模拟退火，107 模型选择，24 默认规则，348 逆归结，359 逆强化学习，391 欧氏距离，200 索 引 423 盘式记法，334 判别式模型，148, 325 判定树,73 偏差-方差分解,44, 177 偏 好 ,6 平方损失，54 平衡点，31 平均场，337 平均法，225 平稳分布，161 朴素贝叶斯分类器，150 奇异值分解，231, 402 恰PAC可学习，270 迁移学习，17 嵌入式特征选择，252 欠采样，67 欠拟合，23 欠配，23 强化学习，371 切比雪夫距离，200 亲和矩阵，301 权共享，113 全局马尔可夫性，323 全局散度矩阵，62 全局最小，106 缺省规则，348 缺失值,.85 人工神经网络,97 人工智能，10 冗余特征，247 软间隔，129 软间隔支持向量机，131 弱学习器，171 嫡 ，415 上采样，67 深度学习，113 神经网络，97 神经元，97 生成式模型，148, 295, 325 胜者通吃，108 时间复杂度，269 时序差分学习，386, 393 示教学习，11 示例，2 势函数，322 视图，304 收敛，99 受限 Boltzmann 机，112 属性,2 属性空间，2 属性子集，189 数据集,2 数据挖掘，14 数据预处理,2 4 7 数值属性，200 似然，148 似然率,352 松弛变量，130 随机森林，179 随机子空间，189",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 722
    }
  },
  {
    "page_content": "受限 Boltzmann 机，112 属性,2 属性空间，2 属性子集，189 数据集,2 数据挖掘，14 数据预处理,2 4 7 数值属性，200 似然，148 似然率,352 松弛变量，130 随机森林，179 随机子空间，189 探索-利用窘境，374 特化，350 特征，2, 247 特征工程，114 特征向量,2 特征选择，247 特征学习，114 梯度下降，102, 254, 389, 407 替代函数，58 替代损失，130 条件独立性假设，150, 305 条件风险,1 4 7 条件随机场，325 同父，158 统计关系学习，364 统计学习，12, 139 投票法，172, 225 图半监督学习，300 推断，319 32 微 微查全率，32 微查准率，32 维数约简，227 维数灾难，227, 247 未标记样本，293 稳定基学习器，189 稳定性，284 无导师学习，3 无关特征，247 无监督学习，3, 197 无监督逐层训练，113 无序属性，200 勿连约束，239, 307 误差，23 误差-分歧分解，185 424 机器学习 误差逆传播，101 稀疏编码，255 稀疏表示，67, 255 稀疏性,67 下采样，67 先验，148 线性超平面，99 线性核，128 线性回归，53, 252 线性降维，229 线性可分,99, 126 线性模型,53 线性判别分析，60, 139 相对多数投票，183 相对燧，414 相关特征，247 相似度度量，201 协同过滤,259 协同训练，304 斜决策树，90 信念传播，330, 340 信念网，156 信息散度,414 信息增益,75, 248 信息熠，75 序贯覆盖，349 选择性集成，191 学习，2 学习率，99 学习器，2 学习向量量化，204 训练,2 训练集,2 训练误差，23 训练样本，2 压缩感知，257 哑结点，99 演绎，359 验证集，28, 105 样本,2 样本复杂度,270 样本空间，2 样例，2 一阶规则，348 一致性，140 遗传算法，107 异常检测，219 因子，322 隐变量，162, 319 隐狄利克雷分配模型，337 隐马尔可夫模型，319 硬间隔，129 优先级规则，348 有标记样本，293 有导师学习，3 有模型学习，377 有限假设空间，270 有向分离，158 有效性指标，197 有序属性，200 预剪枝，79, 352 阈值,97, 104 阈值逻辑单元，98 阈值移动，67 元规则，348 原型聚类，202 原子命题，348",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 723
    }
  },
  {
    "page_content": "隐变量，162, 319 隐狄利克雷分配模型，337 隐马尔可夫模型，319 硬间隔，129 优先级规则，348 有标记样本，293 有导师学习，3 有模型学习，377 有限假设空间，270 有向分离，158 有效性指标，197 有序属性，200 预剪枝，79, 352 阈值,97, 104 阈值逻辑单元，98 阈值移动，67 元规则，348 原型聚类，202 原子命题，348 再励学习，371 再平衡，67 再生核希尔伯特空间，128 再缩放，67 在线学习，109, 241, 393 早停，105 增长函数，273 增量学习，92, 109 增益率，77 召回率，30 真相，2 振荡，99 正态分布,412 正则化，56, 105, 133 证据，148 支持向量，122 支持向量回归，133 支持向量机，123 支持向量展式，127 直推学习，295 值迭代，382 值函数近似，388 指数损失，130, 173 置换，361 置信度，38 主成分分析，229 主动学习，293 状态-动作值函数,377 状态值函数，377 准确率，30 索 引 425 子集评价，248 子集搜索，248 子空间，189, 227 自适应谐振理论，108 自助采样法，178 自助法，27 自组织映射，109 字典学习，255 总体代价，36 最近邻分类器，225 最小二乘法，54, 72 . 最小描述长度，159 最小一般泛化,358 最一般合一置换，361 坐标下降，163, 408",
    "metadata": {
      "source": "input/机器学习 Machine Learning (Chinese Edition) (Zhou Zhihua 周志华) .pdf",
      "type": "pdf",
      "chunk_index": 724
    }
  },
  {
    "page_content": "机器学习简介 | 菜鸟教程 菜鸟教程 -- 学的不仅是技术，更是梦想！ 首页 HTML JavaScript CSS Vue React Python3 Java C C++ C# AI Go SQL Linux VS Code Bootstrap Git 本地书签 首页 HTML CSS JS 本地书签 Search Python3 教程 Python2 教程 Vue3 教程 vue2 教程 Bootstrap3 教程 Bootstrap4 教程 Bootstrap5 教程 Bootstrap2 教程 Ollama 教程 机器学习 PyTorch 教程 TensorFlow 教程 Sklearn 教程 NLP 教程 AI Agent 机器学习 机器学习教程 机器学习简介 机器学习如何工作 机器学习基础概念 Python 入门机器学习 机器学习算法 线性回归 逻辑回归 决策树 支持向量机 K 近邻算法 集成学习 机器学习教程 机器学习如何工作 机器学习简介 机器学习（Machine Learning）是人工智能（AI）的一个分支，它使计算机系统能够利用数据和算法自动学习和改进其性能。 机器学习是一个不断发展的领域，它正在改变我们与技术的互动方式，并为解决复杂问题提供了新的工具和方法。 机器学习是让计算机通过数据进行学习的一种技术，广泛应用于各行各业。 机器学习是如何工作的？ 机器学习通过让计算机从大量数据中学习模式和规律来做出决策和预测。 首先，收集并准备数据，然后选择一个合适的算法来训练模型。 然后，模型通过不断优化参数，最小化预测错误，直到能准确地对新数据进行预测。 最后，模型部署到实际应用中，实时做出预测或决策，并根据新的数据进行更新。 机器学习是一个迭代过程，可能需要多次调整模型参数和特征选择，以提高模型的性能。 下面这张图展示了机器学习的基本流程： Labeled Data（标记数据）： ：图中蓝色区域显示了标记数据，这些数据包括了不同的几何形状（如六边形、正方形、三角形）。 Model Training（模型训练）： ：在这个阶段，机器学习算法分析数据的特征，并学习如何根据这些特征来预测标签。 Test Data（测试数据）： ：图中深绿色区域显示了测试数据，包括一个正方形和一个三角形。 Prediction（预测）： ：模型使用从训练数据中学到的规则来预测测试数据的标签。在图中，模型预测了测试数据中的正方形和三角形。 Evaluation（评估）： ：预测结果与测试数据的真实标签进行比较，以评估模型的准确性。 机器学习的工作流程可以大致分为以下几个步骤： 1. 数据收集 收集数据 ：这是机器学习项目的第一步，涉及收集相关数据。数据可以来自数据库、文件、网络或实时数据流。 数据类型",
    "metadata": {
      "source": "https://www.runoob.com/ml/ml-intro.html",
      "type": "url",
      "title": "机器学习简介 | 菜鸟教程",
      "chunk_index": 725
    }
  },
  {
    "page_content": "：模型使用从训练数据中学到的规则来预测测试数据的标签。在图中，模型预测了测试数据中的正方形和三角形。 Evaluation（评估）： ：预测结果与测试数据的真实标签进行比较，以评估模型的准确性。 机器学习的工作流程可以大致分为以下几个步骤： 1. 数据收集 收集数据 ：这是机器学习项目的第一步，涉及收集相关数据。数据可以来自数据库、文件、网络或实时数据流。 数据类型 ：可以是结构化数据（如表格数据）或非结构化数据（如文本、图像、视频）。 2. 数据预处理 清洗数据 ：处理缺失值、异常值、错误和重复数据。 特征工程 ：选择有助于模型学习的最相关特征，可能包括创建新特征或转换现有特征。 数据标准化/归一化 ：调整数据的尺度，使其在同一范围内，有助于某些算法的性能。 3. 选择模型 确定问题类型 ：根据问题的性质（分类、回归、聚类等）选择合适的机器学习模型。 选择算法 ：基于问题类型和数据特性，选择一个或多个算法进行实验。 4. 训练模型 划分数据集 ：将数据分为训练集、验证集和测试集。 训练 ：使用训练集上的数据来训练模型，调整模型参数以最小化损失函数。 验证 ：使用验证集来调整模型参数，防止过拟合。 5. 评估模型 性能指标 ：使用测试集来评估模型的性能，常用的指标包括准确率、召回率、F1分数等。 交叉验证 ：一种评估模型泛化能力的技术，通过将数据分成多个子集进行训练和验证。 6. 模型优化 调整超参数 ：超参数是学习过程之前设置的参数，如学习率、树的深度等，可以通过网格搜索、随机搜索或贝叶斯优化等方法来调整。 特征选择 ：可能需要重新评估和选择特征，以提高模型性能。 7. 部署模型 集成到应用 ：将训练好的模型集成到实际应用中，如网站、移动应用或软件中。 监控和维护 ：持续监控模型的性能，并根据新数据更新模型。 8. 反馈循环 持续学习 ：机器学习模型可以设计为随着时间的推移自动从新数据中学习，以适应变化。 技术细节 损失函数 ：一个衡量模型预测与实际结果差异的函数，模型训练的目标是最小化这个函数。 优化算法 ：如梯度下降，用于找到最小化损失函数的参数值。 正则化 ：一种技术，通过添加惩罚项来防止模型过拟合。 机器学习的工作流程是迭代的，可能需要多次调整和优化以达到最佳性能。此外，随着数据的积累和算法的发展，机器学习模型可以变得更加精确和高效。 机器学习的类型 机器学习主要分为以下三种类型： 1. 监督学习（Supervised Learning） 定义： 监督学习是指使用带标签的数据进行训练，模型通过学习输入数据与标签之间的关系，来做出预测或分类。 应用： 分类（如垃圾邮件识别）、回归（如房价预测）。 例子： 线性回归、决策树、支持向量机（SVM）。 2. 无监督学习（Unsupervised Learning） 定义：",
    "metadata": {
      "source": "https://www.runoob.com/ml/ml-intro.html",
      "type": "url",
      "title": "机器学习简介 | 菜鸟教程",
      "chunk_index": 726
    }
  },
  {
    "page_content": "机器学习的类型 机器学习主要分为以下三种类型： 1. 监督学习（Supervised Learning） 定义： 监督学习是指使用带标签的数据进行训练，模型通过学习输入数据与标签之间的关系，来做出预测或分类。 应用： 分类（如垃圾邮件识别）、回归（如房价预测）。 例子： 线性回归、决策树、支持向量机（SVM）。 2. 无监督学习（Unsupervised Learning） 定义： 无监督学习使用没有标签的数据，模型试图在数据中发现潜在的结构或模式。 应用： 聚类（如客户分群）、降维（如数据可视化）。 例子： K-means 聚类、主成分分析（PCA）。 3. 强化学习（Reinforcement Learning） 定义： 强化学习通过与环境互动，智能体在试错中学习最佳策略，以最大化长期回报。每次行动后，系统会收到奖励或惩罚，来指导行为的改进。 应用： 游戏AI（如AlphaGo）、自动驾驶、机器人控制。 例子： Q-learning、深度Q网络（DQN）。 这三种机器学习类型各有其应用场景和优势，监督学习适用于有明确标签的数据，无监督学习适用于探索数据内在结构，而强化学习适用于需要通过试错来学习最优策略的场景。 机器学习的应用领域 推荐系统： 例如，抖音推荐你可能感兴趣的视频，淘宝推荐你可能会购买的商品，网易云音乐推荐你喜欢的音乐。 自然语言处理（NLP）： 机器学习在语音识别、机器翻译、情感分析、聊天机器人等方面的应用。例如，Google 翻译、Siri 和智能客服等。 计算机视觉： 机器学习在图像识别、物体检测、面部识别、自动驾驶等领域有广泛应用。例如，自动驾驶汽车通过摄像头和传感器识别周围的障碍物，识别行人和其他车辆。 金融分析： 机器学习在股市预测、信用评分、欺诈检测等金融领域具有重要应用。例如，银行利用机器学习检测信用卡交易中的欺诈行为。 医疗健康： 机器学习帮助医生诊断疾病、发现药物副作用、预测病情发展等。例如，IBM 的 Watson 系统帮助医生分析患者的病历数据，提供诊断和治疗建议。 游戏和娱乐： 机器学习不仅用于游戏中的智能对手，还应用于游戏设计、动态难度调整等方面。例如，AlphaGo 使用深度学习技术战胜了围棋世界冠军。 机器学习的未来 随着数据量的爆炸式增长和计算能力的提升，机器学习的应用将继续扩展，带来更加智能和高效的系统。例如： 强化学习： 使计算机能够在没有明确指导的情况下通过试错来解决复杂问题。例如，AlphaGo 和 Dota 2 游戏 AI 都使用了强化学习。 自监督学习： 目前的机器学习模型通常需要大量带标签的数据来进行训练，而自监督学习则能够在没有标签的数据下学习更有效的表示。 深度学习：",
    "metadata": {
      "source": "https://www.runoob.com/ml/ml-intro.html",
      "type": "url",
      "title": "机器学习简介 | 菜鸟教程",
      "chunk_index": 727
    }
  },
  {
    "page_content": "机器学习的未来 随着数据量的爆炸式增长和计算能力的提升，机器学习的应用将继续扩展，带来更加智能和高效的系统。例如： 强化学习： 使计算机能够在没有明确指导的情况下通过试错来解决复杂问题。例如，AlphaGo 和 Dota 2 游戏 AI 都使用了强化学习。 自监督学习： 目前的机器学习模型通常需要大量带标签的数据来进行训练，而自监督学习则能够在没有标签的数据下学习更有效的表示。 深度学习： 深度学习是机器学习中的一个分支，主要关注神经网络的应用，它已经在图像识别、自然语言处理等方面取得了突破性进展。未来，深度学习将继续推动人工智能的发展。 通过机器学习，我们能够创建更智能的系统，自动化繁琐的任务，并改善我们日常生活的各个方面。随着技术的发展，机器学习将成为未来各行业的核心驱动力之一。 AI 思考中... 机器学习教程 机器学习如何工作 点我分享笔记 取消 分享笔记 昵称 昵称 (必填) 邮箱 邮箱 (必填) 引用地址 引用地址 分类导航 HTML / CSS HTML 教程 HTML5 教程 CSS 教程 CSS3 教程 Tailwind CSS 教程 Bootstrap4 教程 Bootstrap5 教程 Font Awesome 教程 Foundation 教程 JavaScript JavaScript 教程 HTML DOM 教程 jQuery 教程 AngularJS 教程 AngularJS2 教程 Vue.js 教程 Vue3 教程 React 教程 Next.js 教程 TypeScript 教程 jQuery UI 教程 jQuery EasyUI 教程 Node.js 教程 Electron 教程 Playwright 教程 AJAX 教程 JSON 教程 Echarts 教程 Chart.js 教程 Highcharts 教程 Google 地图 教程 服务端 Python 教程 Python2.x 教程 Linux 教程 Docker 教程 Ruby 教程 Java 教程 C 教程 C++ 教程 Perl 教程 Servlet 教程 JSP 教程 Lua 教程 Rust 教程 Zig 教程 Scala 教程 Go 教程 PHP 教程 数据结构与算法 Django 教程 FastAPI 教程 Flask 教程 Pillow 教程 Zookeeper 教程 设计模式 Python 设计模式 正则表达式 Maven 教程 CMake 教程 Verilog 教程 ASP 教程 AppML 教程 VBScript 教程 数据库 SQL 教程 MySQL 教程 PostgreSQL 教程 SQLite 教程 MongoDB 教程 Redis 教程 Memcached 教程 AI & 数据分析 Python 教程 NumPy 教程",
    "metadata": {
      "source": "https://www.runoob.com/ml/ml-intro.html",
      "type": "url",
      "title": "机器学习简介 | 菜鸟教程",
      "chunk_index": 728
    }
  },
  {
    "page_content": "Zookeeper 教程 设计模式 Python 设计模式 正则表达式 Maven 教程 CMake 教程 Verilog 教程 ASP 教程 AppML 教程 VBScript 教程 数据库 SQL 教程 MySQL 教程 PostgreSQL 教程 SQLite 教程 MongoDB 教程 Redis 教程 Memcached 教程 AI & 数据分析 Python 教程 NumPy 教程 Pandas 教程 Matplotlib 教程 Scipy 教程 Pytorch 教程 TensorFlow 教程 Ollama 教程 机器 教程 AI Agent(智能体) scikit-learn 教程 R 教程 OpenCV 教程 NLP 教程 Selenium 教程 Julia 教程 量化交易 Dash 教程 移动端 Android 教程 Swift 教程 jQuery Mobile 教程 ionic 教程 Kotlin 教程 开发工具 VS Code 教程 PyCharm 教程 Swagger 教程 RESTful API 教程 Eclipse 教程 Git 教程 Svn 教程 Markdown 教程 XML 教程 XML 教程 DTD 教程 XML DOM 教程 XSLT 教程 XPath 教程 XQuery 教程 XLink 教程 XPointer 教程 XML Schema 教程 XSL-FO 教程 SVG 教程 ASP.NET ASP.NET 教程 C# 教程 PowerShell 教程 Web Pages 教程 Razor 教程 MVC 教程 Web Forms 教程 Web Service Web Service 教程 WSDL 教程 SOAP 教程 RSS 教程 RDF 教程 网站建设 HTTP 教程 网站建设指南 浏览器信息 网络协议 网站主机教程 TCP/IP 教程 W3C 教程 网站品质 Advertisement 在线实例 · HTML 实例 · CSS 实例 · JavaScript 实例 · Ajax 实例 · jQuery 实例 · XML 实例 · Java 实例 字符集&工具 · HTML 字符集设置 · HTML ASCII 字符集 · JS 混淆/加密 · PNG/JPEG 图片压缩 · HTML 拾色器 · JSON 格式化工具 · 随机数生成器 最新更新 · Obsidian 使用教程 · CSS 编辑器 · CSS AI 编程 · Python 实现 AI ... · 第一个 AI Agent · AI Agent 核心组件 · AI Agent 简介 站点信息 · 意见反馈 · 免责声明 · 关于我们 · 文章归档 关注微信 Copyright © 2013-2025 菜鸟教程 runoob.com",
    "metadata": {
      "source": "https://www.runoob.com/ml/ml-intro.html",
      "type": "url",
      "title": "机器学习简介 | 菜鸟教程",
      "chunk_index": 729
    }
  },
  {
    "page_content": "· 随机数生成器 最新更新 · Obsidian 使用教程 · CSS 编辑器 · CSS AI 编程 · Python 实现 AI ... · 第一个 AI Agent · AI Agent 核心组件 · AI Agent 简介 站点信息 · 意见反馈 · 免责声明 · 关于我们 · 文章归档 关注微信 Copyright © 2013-2025 菜鸟教程 runoob.com All Rights Reserved. 备案号： 闽ICP备15012807号-1 微信关注",
    "metadata": {
      "source": "https://www.runoob.com/ml/ml-intro.html",
      "type": "url",
      "title": "机器学习简介 | 菜鸟教程",
      "chunk_index": 730
    }
  }
]